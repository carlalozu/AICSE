{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinns_phase import Pinns, PinnLaterPhase\n",
    "\n",
    "kwargs = {\n",
    "    \"alpha_f\" : 0.005,\n",
    "    \"h_f\" : 5,\n",
    "    \"T_hot\" : 4,\n",
    "    \"T0\" : 1,\n",
    "    \"T_cold\" : 1,\n",
    "}\n",
    "\n",
    "n_int = 128\n",
    "n_sb = 64\n",
    "n_tb = 64\n",
    "\n",
    "pins_phases = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charging\n",
      "################################  0  ################################\n",
      "Total loss:  2.1298 | PDE Loss:  -0.1603 | Function Loss:  1.1276\n",
      "Total loss:  2.1169 | PDE Loss:  0.0284 | Function Loss:  1.1133\n",
      "Total loss:  2.0142 | PDE Loss:  0.9145 | Function Loss:  0.9782\n",
      "Total loss:  1.9372 | PDE Loss:  1.6755 | Function Loss:  0.593\n",
      "Total loss:  1.8505 | PDE Loss:  1.4492 | Function Loss:  0.6309\n",
      "Total loss:  1.6863 | PDE Loss:  -1.599 | Function Loss:  0.6861\n",
      "Total loss:  1.6491 | PDE Loss:  -1.3125 | Function Loss:  0.6486\n",
      "Total loss:  1.5618 | PDE Loss:  -1.0777 | Function Loss:  0.5608\n",
      "Total loss:  1.5522 | PDE Loss:  -1.1206 | Function Loss:  0.5512\n",
      "Total loss:  1.543 | PDE Loss:  -1.0916 | Function Loss:  0.542\n",
      "Total loss:  1.5223 | PDE Loss:  -0.5669 | Function Loss:  0.5187\n",
      "Total loss:  1.5055 | PDE Loss:  -0.0363 | Function Loss:  0.4929\n",
      "Total loss:  1.4938 | PDE Loss:  0.0293 | Function Loss:  0.4786\n",
      "Total loss:  1.4609 | PDE Loss:  0.3808 | Function Loss:  0.4232\n",
      "Total loss:  1.4582 | PDE Loss:  0.3323 | Function Loss:  0.4244\n",
      "Total loss:  1.4491 | PDE Loss:  0.3168 | Function Loss:  0.4159\n",
      "Total loss:  1.4137 | PDE Loss:  0.326 | Function Loss:  0.3767\n",
      "Total loss:  1.3864 | PDE Loss:  0.4039 | Function Loss:  0.3386\n",
      "Total loss:  1.3563 | PDE Loss:  0.3156 | Function Loss:  0.3148\n",
      "Total loss:  1.3087 | PDE Loss:  0.1893 | Function Loss:  0.2744\n",
      "Total loss:  1.2586 | PDE Loss:  0.2923 | Function Loss:  0.209\n",
      "Total loss:  1.9679 | PDE Loss:  1.2291 | Function Loss:  0.8804\n",
      "Total loss:  1.1985 | PDE Loss:  0.3363 | Function Loss:  0.1343\n",
      "Total loss:  1.1666 | PDE Loss:  0.5021 | Function Loss:  0.0607\n",
      "Total loss:  1.1314 | PDE Loss:  0.3967 | Function Loss:  0.043\n",
      "Total loss:  1.0627 | PDE Loss:  0.3532 | Function Loss:  -0.0316\n",
      "Total loss:  0.9626 | PDE Loss:  0.18 | Function Loss:  -0.1157\n",
      "Total loss:  0.9337 | PDE Loss:  0.1092 | Function Loss:  -0.1368\n",
      "Total loss:  0.9272 | PDE Loss:  0.1028 | Function Loss:  -0.1433\n",
      "Total loss:  0.9068 | PDE Loss:  0.0909 | Function Loss:  -0.1652\n",
      "Total loss:  0.8451 | PDE Loss:  -0.0481 | Function Loss:  -0.2143\n",
      "Total loss:  0.7919 | PDE Loss:  -0.198 | Function Loss:  -0.255\n",
      "Total loss:  0.765 | PDE Loss:  -0.2872 | Function Loss:  -0.2754\n",
      "Total loss:  0.7567 | PDE Loss:  -0.3348 | Function Loss:  -0.2799\n",
      "Total loss:  0.7519 | PDE Loss:  -0.3489 | Function Loss:  -0.284\n",
      "Total loss:  0.7481 | PDE Loss:  -0.3669 | Function Loss:  -0.2865\n",
      "Total loss:  0.7265 | PDE Loss:  -0.398 | Function Loss:  -0.3074\n",
      "Total loss:  0.7056 | PDE Loss:  -0.2955 | Function Loss:  -0.34\n",
      "Total loss:  0.6923 | PDE Loss:  -0.2549 | Function Loss:  -0.3597\n",
      "Total loss:  0.6673 | PDE Loss:  -0.1805 | Function Loss:  -0.3992\n",
      "Total loss:  0.6501 | PDE Loss:  -0.2136 | Function Loss:  -0.4138\n",
      "Total loss:  0.6402 | PDE Loss:  -0.2068 | Function Loss:  -0.4264\n",
      "Total loss:  0.6274 | PDE Loss:  -0.2501 | Function Loss:  -0.4344\n",
      "Total loss:  0.6109 | PDE Loss:  -0.2462 | Function Loss:  -0.4541\n",
      "Total loss:  0.5885 | PDE Loss:  -0.1927 | Function Loss:  -0.4901\n",
      "Total loss:  0.5761 | PDE Loss:  -0.1364 | Function Loss:  -0.5174\n",
      "Total loss:  0.5662 | PDE Loss:  -0.16 | Function Loss:  -0.5242\n",
      "Total loss:  0.5625 | PDE Loss:  -0.1954 | Function Loss:  -0.5208\n",
      "Total loss:  0.5591 | PDE Loss:  -0.2285 | Function Loss:  -0.5183\n",
      "Total loss:  0.5545 | PDE Loss:  -0.2712 | Function Loss:  -0.5157\n",
      "Total loss:  0.5479 | PDE Loss:  -0.3013 | Function Loss:  -0.5184\n",
      "Total loss:  0.5335 | PDE Loss:  -0.3722 | Function Loss:  -0.5241\n",
      "Total loss:  0.5117 | PDE Loss:  -0.4842 | Function Loss:  -0.5345\n",
      "Total loss:  0.4926 | PDE Loss:  -0.5964 | Function Loss:  -0.5443\n",
      "Total loss:  0.4739 | PDE Loss:  -0.7343 | Function Loss:  -0.5538\n",
      "Total loss:  0.4513 | PDE Loss:  -0.8142 | Function Loss:  -0.5729\n",
      "Total loss:  0.4329 | PDE Loss:  -0.9325 | Function Loss:  -0.5863\n",
      "Total loss:  0.4181 | PDE Loss:  -0.8907 | Function Loss:  -0.6038\n",
      "Total loss:  0.4071 | PDE Loss:  -0.8104 | Function Loss:  -0.62\n",
      "Total loss:  0.4021 | PDE Loss:  -0.7709 | Function Loss:  -0.628\n",
      "Total loss:  0.3962 | PDE Loss:  -0.7794 | Function Loss:  -0.6338\n",
      "Total loss:  0.3906 | PDE Loss:  -0.8382 | Function Loss:  -0.6358\n",
      "Total loss:  0.3858 | PDE Loss:  -0.8237 | Function Loss:  -0.6418\n",
      "Total loss:  0.3827 | PDE Loss:  -0.8395 | Function Loss:  -0.6442\n",
      "Total loss:  0.3791 | PDE Loss:  -0.8028 | Function Loss:  -0.6505\n",
      "Total loss:  0.3749 | PDE Loss:  -0.7414 | Function Loss:  -0.6597\n",
      "Total loss:  0.3716 | PDE Loss:  -0.6789 | Function Loss:  -0.6689\n",
      "Total loss:  0.3662 | PDE Loss:  -0.6053 | Function Loss:  -0.6828\n",
      "Total loss:  0.3543 | PDE Loss:  -0.4873 | Function Loss:  -0.7133\n",
      "Total loss:  0.3411 | PDE Loss:  -0.3633 | Function Loss:  -0.7544\n",
      "Total loss:  0.3284 | PDE Loss:  -0.2981 | Function Loss:  -0.7886\n",
      "Total loss:  0.3189 | PDE Loss:  -0.2826 | Function Loss:  -0.8062\n",
      "Total loss:  0.2994 | PDE Loss:  -0.2912 | Function Loss:  -0.8295\n",
      "Total loss:  0.2748 | PDE Loss:  -0.3374 | Function Loss:  -0.8468\n",
      "Total loss:  0.2567 | PDE Loss:  -0.3566 | Function Loss:  -0.8646\n",
      "Total loss:  0.2432 | PDE Loss:  -0.3982 | Function Loss:  -0.8693\n",
      "Total loss:  0.234 | PDE Loss:  -0.4044 | Function Loss:  -0.8794\n",
      "Total loss:  0.216 | PDE Loss:  -0.4256 | Function Loss:  -0.8965\n",
      "Total loss:  0.1944 | PDE Loss:  -0.4221 | Function Loss:  -0.9258\n",
      "Total loss:  0.1702 | PDE Loss:  -0.487 | Function Loss:  -0.9378\n",
      "Total loss:  0.1566 | PDE Loss:  -0.4544 | Function Loss:  -0.9654\n",
      "Total loss:  0.1324 | PDE Loss:  -0.4682 | Function Loss:  -0.993\n",
      "Total loss:  0.1175 | PDE Loss:  -0.4611 | Function Loss:  -1.0156\n",
      "Total loss:  0.1051 | PDE Loss:  -0.4521 | Function Loss:  -1.0359\n",
      "Total loss:  0.1012 | PDE Loss:  -0.4634 | Function Loss:  -1.037\n",
      "Total loss:  0.0976 | PDE Loss:  -0.459 | Function Loss:  -1.0437\n",
      "Total loss:  0.095 | PDE Loss:  -0.4583 | Function Loss:  -1.0475\n",
      "Total loss:  0.093 | PDE Loss:  -0.4601 | Function Loss:  -1.0496\n",
      "Total loss:  0.0882 | PDE Loss:  -0.4766 | Function Loss:  -1.0499\n",
      "Total loss:  0.0822 | PDE Loss:  -0.4829 | Function Loss:  -1.0558\n",
      "Total loss:  0.077 | PDE Loss:  -0.502 | Function Loss:  -1.0559\n",
      "Total loss:  0.0686 | PDE Loss:  -0.5176 | Function Loss:  -1.0617\n",
      "Total loss:  0.0607 | PDE Loss:  -0.5381 | Function Loss:  -1.0653\n",
      "Total loss:  0.0563 | PDE Loss:  -0.5355 | Function Loss:  -1.0721\n",
      "Total loss:  0.0547 | PDE Loss:  -0.5391 | Function Loss:  -1.073\n",
      "Total loss:  0.0522 | PDE Loss:  -0.5537 | Function Loss:  -1.0715\n",
      "Total loss:  0.0462 | PDE Loss:  -0.5865 | Function Loss:  -1.069\n",
      "Total loss:  0.04 | PDE Loss:  -0.6362 | Function Loss:  -1.0628\n",
      "Total loss:  0.0347 | PDE Loss:  -0.6712 | Function Loss:  -1.0605\n",
      "Total loss:  0.0292 | PDE Loss:  -0.7072 | Function Loss:  -1.0589\n",
      "Total loss:  0.0226 | PDE Loss:  -0.7402 | Function Loss:  -1.0597\n",
      "Total loss:  0.0137 | PDE Loss:  -0.7814 | Function Loss:  -1.0621\n",
      "Total loss:  0.0023 | PDE Loss:  -0.7955 | Function Loss:  -1.073\n",
      "Total loss:  -0.0082 | PDE Loss:  -0.8148 | Function Loss:  -1.0819\n",
      "Total loss:  -0.0166 | PDE Loss:  -0.7768 | Function Loss:  -1.0995\n",
      "Total loss:  -0.0221 | PDE Loss:  -0.7661 | Function Loss:  -1.1084\n",
      "Total loss:  -0.0252 | PDE Loss:  -0.7449 | Function Loss:  -1.1171\n",
      "Total loss:  -0.0285 | PDE Loss:  -0.736 | Function Loss:  -1.1233\n",
      "Total loss:  -0.0311 | PDE Loss:  -0.73 | Function Loss:  -1.128\n",
      "Total loss:  -0.0324 | PDE Loss:  -0.7322 | Function Loss:  -1.1291\n",
      "Total loss:  -0.0339 | PDE Loss:  -0.7401 | Function Loss:  -1.1291\n",
      "Total loss:  -0.0356 | PDE Loss:  -0.7479 | Function Loss:  -1.1292\n",
      "Total loss:  -0.0375 | PDE Loss:  -0.7557 | Function Loss:  -1.1297\n",
      "Total loss:  -0.0398 | PDE Loss:  -0.7642 | Function Loss:  -1.1306\n",
      "Total loss:  -0.0433 | PDE Loss:  -0.773 | Function Loss:  -1.1328\n",
      "Total loss:  -0.048 | PDE Loss:  -0.7897 | Function Loss:  -1.1348\n",
      "Total loss:  -0.0532 | PDE Loss:  -0.7976 | Function Loss:  -1.1395\n",
      "Total loss:  -0.0594 | PDE Loss:  -0.8184 | Function Loss:  -1.1425\n",
      "Total loss:  -0.0661 | PDE Loss:  -0.8365 | Function Loss:  -1.1469\n",
      "Total loss:  -0.0709 | PDE Loss:  -0.8549 | Function Loss:  -1.1489\n",
      "Total loss:  -0.0757 | PDE Loss:  -0.8963 | Function Loss:  -1.1469\n",
      "Total loss:  -0.0779 | PDE Loss:  -0.9015 | Function Loss:  -1.1485\n",
      "Total loss:  -0.0799 | PDE Loss:  -0.9016 | Function Loss:  -1.1509\n",
      "Total loss:  -0.081 | PDE Loss:  -0.9141 | Function Loss:  -1.15\n",
      "Total loss:  -0.0815 | PDE Loss:  -0.9092 | Function Loss:  -1.1514\n",
      "Total loss:  -0.0834 | PDE Loss:  -0.9001 | Function Loss:  -1.1552\n",
      "Total loss:  -0.0874 | PDE Loss:  -0.8858 | Function Loss:  -1.1627\n",
      "Total loss:  -0.0935 | PDE Loss:  -0.8636 | Function Loss:  -1.1743\n",
      "Total loss:  -0.0999 | PDE Loss:  -0.8434 | Function Loss:  -1.1863\n",
      "Total loss:  -0.1062 | PDE Loss:  -0.8319 | Function Loss:  -1.1967\n",
      "Total loss:  -0.1137 | PDE Loss:  -0.8371 | Function Loss:  -1.2047\n",
      "Total loss:  -0.1206 | PDE Loss:  -0.8427 | Function Loss:  -1.212\n",
      "Total loss:  -0.1245 | PDE Loss:  -0.8545 | Function Loss:  -1.214\n",
      "Total loss:  -0.1267 | PDE Loss:  -0.8574 | Function Loss:  -1.216\n",
      "Total loss:  -0.1287 | PDE Loss:  -0.8594 | Function Loss:  -1.218\n",
      "Total loss:  -0.1328 | PDE Loss:  -0.8658 | Function Loss:  -1.2216\n",
      "Total loss:  -0.1391 | PDE Loss:  -0.869 | Function Loss:  -1.2286\n",
      "Total loss:  -0.1462 | PDE Loss:  -0.8657 | Function Loss:  -1.2381\n",
      "Total loss:  -0.1533 | PDE Loss:  -0.8715 | Function Loss:  -1.2455\n",
      "Total loss:  -0.1562 | PDE Loss:  -0.8032 | Function Loss:  -1.2672\n",
      "Total loss:  -0.16 | PDE Loss:  -0.8321 | Function Loss:  -1.2638\n",
      "Total loss:  -0.1623 | PDE Loss:  -0.8452 | Function Loss:  -1.2633\n",
      "Total loss:  -0.1655 | PDE Loss:  -0.8707 | Function Loss:  -1.2609\n",
      "Total loss:  -0.1694 | PDE Loss:  -0.8892 | Function Loss:  -1.2612\n",
      "Total loss:  -0.1782 | PDE Loss:  -0.9332 | Function Loss:  -1.2621\n",
      "Total loss:  -0.1912 | PDE Loss:  -0.9886 | Function Loss:  -1.2666\n",
      "Total loss:  -0.2022 | PDE Loss:  -1.0361 | Function Loss:  -1.271\n",
      "Total loss:  -0.2128 | PDE Loss:  -1.0592 | Function Loss:  -1.2796\n",
      "Total loss:  -0.2214 | PDE Loss:  -1.0636 | Function Loss:  -1.2889\n",
      "Total loss:  -0.2278 | PDE Loss:  -1.0544 | Function Loss:  -1.2979\n",
      "Total loss:  -0.2318 | PDE Loss:  -1.0444 | Function Loss:  -1.3044\n",
      "Total loss:  -0.2367 | PDE Loss:  -1.0159 | Function Loss:  -1.3157\n",
      "Total loss:  -0.2409 | PDE Loss:  -1.0178 | Function Loss:  -1.3203\n",
      "Total loss:  -0.2443 | PDE Loss:  -1.0056 | Function Loss:  -1.3269\n",
      "Total loss:  -0.2497 | PDE Loss:  -0.992 | Function Loss:  -1.3364\n",
      "Total loss:  -0.256 | PDE Loss:  -0.9649 | Function Loss:  -1.3504\n",
      "Total loss:  -0.2599 | PDE Loss:  -0.9696 | Function Loss:  -1.3541\n",
      "Total loss:  -0.2621 | PDE Loss:  -0.9531 | Function Loss:  -1.3611\n",
      "Total loss:  -0.2643 | PDE Loss:  -0.9665 | Function Loss:  -1.3604\n",
      "Total loss:  -0.2678 | PDE Loss:  -0.9798 | Function Loss:  -1.3615\n",
      "Total loss:  -0.2704 | PDE Loss:  -1.0016 | Function Loss:  -1.3596\n",
      "Total loss:  -0.2742 | PDE Loss:  -1.0156 | Function Loss:  -1.3612\n",
      "Total loss:  -0.2787 | PDE Loss:  -1.0443 | Function Loss:  -1.3604\n",
      "Total loss:  -0.2835 | PDE Loss:  -1.058 | Function Loss:  -1.3635\n",
      "Total loss:  -0.2899 | PDE Loss:  -1.0729 | Function Loss:  -1.3682\n",
      "Total loss:  -0.2967 | PDE Loss:  -1.0899 | Function Loss:  -1.373\n",
      "Total loss:  -0.3028 | PDE Loss:  -1.0818 | Function Loss:  -1.3819\n",
      "Total loss:  -0.3073 | PDE Loss:  -1.0754 | Function Loss:  -1.3885\n",
      "Total loss:  -0.3097 | PDE Loss:  -1.0579 | Function Loss:  -1.3951\n",
      "Total loss:  -0.3118 | PDE Loss:  -1.0541 | Function Loss:  -1.3985\n",
      "Total loss:  -0.3143 | PDE Loss:  -1.0415 | Function Loss:  -1.4044\n",
      "Total loss:  -0.3173 | PDE Loss:  -1.0305 | Function Loss:  -1.4107\n",
      "Total loss:  -0.3209 | PDE Loss:  -1.0157 | Function Loss:  -1.4189\n",
      "Total loss:  -0.3244 | PDE Loss:  -1.003 | Function Loss:  -1.4265\n",
      "Total loss:  -0.3278 | PDE Loss:  -1.0196 | Function Loss:  -1.4265\n",
      "Total loss:  -0.3348 | PDE Loss:  -1.0431 | Function Loss:  -1.4295\n",
      "Total loss:  -0.3399 | PDE Loss:  -1.0619 | Function Loss:  -1.4312\n",
      "Total loss:  -0.3447 | PDE Loss:  -1.0693 | Function Loss:  -1.4354\n",
      "Total loss:  -0.3517 | PDE Loss:  -1.0854 | Function Loss:  -1.4403\n",
      "Total loss:  -0.3616 | PDE Loss:  -1.0706 | Function Loss:  -1.456\n",
      "Total loss:  -0.3723 | PDE Loss:  -1.058 | Function Loss:  -1.4726\n",
      "Total loss:  -0.3848 | PDE Loss:  -1.0366 | Function Loss:  -1.4943\n",
      "Total loss:  -0.3939 | PDE Loss:  -1.0167 | Function Loss:  -1.5122\n",
      "Total loss:  -0.3983 | PDE Loss:  -1.0237 | Function Loss:  -1.5158\n",
      "Total loss:  -0.4024 | PDE Loss:  -1.012 | Function Loss:  -1.5249\n",
      "Total loss:  -0.4046 | PDE Loss:  -1.0099 | Function Loss:  -1.5285\n",
      "Total loss:  -0.406 | PDE Loss:  -1.0161 | Function Loss:  -1.5283\n",
      "Total loss:  -0.4074 | PDE Loss:  -1.0126 | Function Loss:  -1.5313\n",
      "Total loss:  -0.4103 | PDE Loss:  -1.0229 | Function Loss:  -1.5318\n",
      "Total loss:  -0.4155 | PDE Loss:  -1.022 | Function Loss:  -1.539\n",
      "Total loss:  -0.4238 | PDE Loss:  -1.0253 | Function Loss:  -1.5489\n",
      "Total loss:  -0.435 | PDE Loss:  -1.0478 | Function Loss:  -1.5565\n",
      "Total loss:  -0.446 | PDE Loss:  -1.066 | Function Loss:  -1.5651\n",
      "Total loss:  -0.454 | PDE Loss:  -1.0862 | Function Loss:  -1.5694\n",
      "Total loss:  -0.4636 | PDE Loss:  -1.111 | Function Loss:  -1.5745\n",
      "Total loss:  -0.4689 | PDE Loss:  -1.1245 | Function Loss:  -1.5774\n",
      "Total loss:  -0.4711 | PDE Loss:  -1.1307 | Function Loss:  -1.5785\n",
      "Total loss:  -0.4732 | PDE Loss:  -1.1421 | Function Loss:  -1.578\n",
      "Total loss:  -0.4749 | PDE Loss:  -1.1537 | Function Loss:  -1.577\n",
      "Total loss:  -0.4762 | PDE Loss:  -1.1658 | Function Loss:  -1.5755\n",
      "Total loss:  -0.4774 | PDE Loss:  -1.1712 | Function Loss:  -1.5756\n",
      "Total loss:  -0.4792 | PDE Loss:  -1.1805 | Function Loss:  -1.5755\n",
      "Total loss:  -0.4826 | PDE Loss:  -1.1848 | Function Loss:  -1.5788\n",
      "Total loss:  -0.4889 | PDE Loss:  -1.1968 | Function Loss:  -1.5836\n",
      "Total loss:  -0.4953 | PDE Loss:  -1.1886 | Function Loss:  -1.5937\n",
      "Total loss:  -0.5012 | PDE Loss:  -1.1969 | Function Loss:  -1.5989\n",
      "Total loss:  -0.5052 | PDE Loss:  -1.1933 | Function Loss:  -1.6049\n",
      "Total loss:  -0.5098 | PDE Loss:  -1.208 | Function Loss:  -1.6069\n",
      "Total loss:  -0.5137 | PDE Loss:  -1.2078 | Function Loss:  -1.6119\n",
      "Total loss:  -0.5189 | PDE Loss:  -1.2227 | Function Loss:  -1.6147\n",
      "Total loss:  -0.5255 | PDE Loss:  -1.2403 | Function Loss:  -1.6185\n",
      "Total loss:  -0.5339 | PDE Loss:  -1.2645 | Function Loss:  -1.6233\n",
      "Total loss:  -0.5415 | PDE Loss:  -1.3019 | Function Loss:  -1.6243\n",
      "Total loss:  -0.546 | PDE Loss:  -1.3074 | Function Loss:  -1.6286\n",
      "Total loss:  -0.5486 | PDE Loss:  -1.3222 | Function Loss:  -1.6286\n",
      "Total loss:  -0.5512 | PDE Loss:  -1.3303 | Function Loss:  -1.6302\n",
      "Total loss:  -0.5531 | PDE Loss:  -1.3429 | Function Loss:  -1.63\n",
      "Total loss:  -0.5548 | PDE Loss:  -1.3507 | Function Loss:  -1.6306\n",
      "Total loss:  -0.5566 | PDE Loss:  -1.3607 | Function Loss:  -1.6308\n",
      "Total loss:  -0.5586 | PDE Loss:  -1.3691 | Function Loss:  -1.6316\n",
      "Total loss:  -0.5629 | PDE Loss:  -1.383 | Function Loss:  -1.6341\n",
      "Total loss:  -0.5683 | PDE Loss:  -1.3804 | Function Loss:  -1.641\n",
      "Total loss:  -0.573 | PDE Loss:  -1.3841 | Function Loss:  -1.6459\n",
      "Total loss:  -0.5754 | PDE Loss:  -1.3688 | Function Loss:  -1.6516\n",
      "Total loss:  -0.577 | PDE Loss:  -1.349 | Function Loss:  -1.6574\n",
      "Total loss:  -0.578 | PDE Loss:  -1.3482 | Function Loss:  -1.6589\n",
      "Total loss:  -0.5789 | PDE Loss:  -1.3476 | Function Loss:  -1.66\n",
      "Total loss:  -0.5803 | PDE Loss:  -1.3466 | Function Loss:  -1.6619\n",
      "Total loss:  -0.5821 | PDE Loss:  -1.3538 | Function Loss:  -1.6626\n",
      "Total loss:  -0.584 | PDE Loss:  -1.3523 | Function Loss:  -1.6652\n",
      "Total loss:  -0.5881 | PDE Loss:  -1.3536 | Function Loss:  -1.6698\n",
      "Total loss:  -0.5937 | PDE Loss:  -1.3491 | Function Loss:  -1.6776\n",
      "Total loss:  -0.599 | PDE Loss:  -1.347 | Function Loss:  -1.6845\n",
      "Total loss:  -0.6042 | PDE Loss:  -1.3497 | Function Loss:  -1.6902\n",
      "Total loss:  -0.6089 | PDE Loss:  -1.3432 | Function Loss:  -1.6975\n",
      "Total loss:  -0.6126 | PDE Loss:  -1.3592 | Function Loss:  -1.6984\n",
      "Total loss:  -0.6148 | PDE Loss:  -1.3593 | Function Loss:  -1.701\n",
      "Total loss:  -0.6172 | PDE Loss:  -1.3663 | Function Loss:  -1.7024\n",
      "Total loss:  -0.6192 | PDE Loss:  -1.3709 | Function Loss:  -1.7039\n",
      "Total loss:  -0.6212 | PDE Loss:  -1.3685 | Function Loss:  -1.7068\n",
      "Total loss:  -0.6234 | PDE Loss:  -1.3718 | Function Loss:  -1.7088\n",
      "Total loss:  -0.6261 | PDE Loss:  -1.369 | Function Loss:  -1.7126\n",
      "Total loss:  -0.6292 | PDE Loss:  -1.37 | Function Loss:  -1.7162\n",
      "Total loss:  -0.6327 | PDE Loss:  -1.3633 | Function Loss:  -1.722\n",
      "Total loss:  -0.6359 | PDE Loss:  -1.3741 | Function Loss:  -1.7235\n",
      "Total loss:  -0.6383 | PDE Loss:  -1.3544 | Function Loss:  -1.731\n",
      "Total loss:  -0.6398 | PDE Loss:  -1.3617 | Function Loss:  -1.7312\n",
      "Total loss:  -0.6409 | PDE Loss:  -1.3596 | Function Loss:  -1.733\n",
      "Total loss:  -0.642 | PDE Loss:  -1.3589 | Function Loss:  -1.7345\n",
      "Total loss:  -0.6429 | PDE Loss:  -1.3536 | Function Loss:  -1.7369\n",
      "Total loss:  -0.6437 | PDE Loss:  -1.3549 | Function Loss:  -1.7376\n",
      "Total loss:  -0.6442 | PDE Loss:  -1.354 | Function Loss:  -1.7385\n",
      "Total loss:  -0.6449 | PDE Loss:  -1.3549 | Function Loss:  -1.7391\n",
      "Total loss:  -0.6471 | PDE Loss:  -1.3576 | Function Loss:  -1.7411\n",
      "Total loss:  -0.6504 | PDE Loss:  -1.3701 | Function Loss:  -1.7423\n",
      "Total loss:  -0.6542 | PDE Loss:  -1.3806 | Function Loss:  -1.7445\n",
      "Total loss:  -0.657 | PDE Loss:  -1.3974 | Function Loss:  -1.7442\n",
      "Total loss:  -0.6601 | PDE Loss:  -1.4161 | Function Loss:  -1.7439\n",
      "Total loss:  -0.6628 | PDE Loss:  -1.4331 | Function Loss:  -1.7436\n",
      "Total loss:  -0.6652 | PDE Loss:  -1.4539 | Function Loss:  -1.7423\n",
      "Total loss:  -0.667 | PDE Loss:  -1.4629 | Function Loss:  -1.7428\n",
      "Total loss:  -0.6687 | PDE Loss:  -1.4669 | Function Loss:  -1.744\n",
      "Total loss:  -0.6705 | PDE Loss:  -1.4652 | Function Loss:  -1.7464\n",
      "Total loss:  -0.6734 | PDE Loss:  -1.4594 | Function Loss:  -1.751\n",
      "Total loss:  -0.6768 | PDE Loss:  -1.4494 | Function Loss:  -1.7571\n",
      "Total loss:  -0.6809 | PDE Loss:  -1.4434 | Function Loss:  -1.7633\n",
      "Total loss:  -0.6871 | PDE Loss:  -1.4341 | Function Loss:  -1.7727\n",
      "Total loss:  -0.6915 | PDE Loss:  -1.4185 | Function Loss:  -1.7817\n",
      "Total loss:  -0.6982 | PDE Loss:  -1.4296 | Function Loss:  -1.7873\n",
      "Total loss:  -0.7027 | PDE Loss:  -1.4281 | Function Loss:  -1.7933\n",
      "Total loss:  -0.7065 | PDE Loss:  -1.4463 | Function Loss:  -1.7938\n",
      "Total loss:  -0.7091 | PDE Loss:  -1.4582 | Function Loss:  -1.7944\n",
      "Total loss:  -0.7109 | PDE Loss:  -1.4733 | Function Loss:  -1.7933\n",
      "Total loss:  -0.7113 | PDE Loss:  -1.4757 | Function Loss:  -1.7933\n",
      "Total loss:  -0.7122 | PDE Loss:  -1.4847 | Function Loss:  -1.7925\n",
      "Total loss:  -0.7128 | PDE Loss:  -1.4827 | Function Loss:  -1.7937\n",
      "Total loss:  -0.7146 | PDE Loss:  -1.4783 | Function Loss:  -1.7967\n",
      "Total loss:  -0.7163 | PDE Loss:  -1.4709 | Function Loss:  -1.8004\n",
      "Total loss:  -0.7187 | PDE Loss:  -1.4654 | Function Loss:  -1.8044\n",
      "Total loss:  -0.7222 | PDE Loss:  -1.462 | Function Loss:  -1.8094\n",
      "Total loss:  -0.7282 | PDE Loss:  -1.4647 | Function Loss:  -1.8163\n",
      "Total loss:  -0.7336 | PDE Loss:  -1.4716 | Function Loss:  -1.8212\n",
      "Total loss:  -0.7396 | PDE Loss:  -1.4798 | Function Loss:  -1.8267\n",
      "Total loss:  -0.7413 | PDE Loss:  -1.4998 | Function Loss:  -1.8246\n",
      "Total loss:  -0.7436 | PDE Loss:  -1.5169 | Function Loss:  -1.8237\n",
      "Total loss:  -0.7453 | PDE Loss:  -1.5465 | Function Loss:  -1.82\n",
      "Total loss:  -0.7461 | PDE Loss:  -1.5607 | Function Loss:  -1.8184\n",
      "Total loss:  -0.7474 | PDE Loss:  -1.5665 | Function Loss:  -1.8188\n",
      "Total loss:  -0.7486 | PDE Loss:  -1.5735 | Function Loss:  -1.819\n",
      "Total loss:  -0.7497 | PDE Loss:  -1.5713 | Function Loss:  -1.8207\n",
      "Total loss:  -0.7509 | PDE Loss:  -1.5675 | Function Loss:  -1.8228\n",
      "Total loss:  -0.7529 | PDE Loss:  -1.5605 | Function Loss:  -1.8265\n",
      "Total loss:  -0.7566 | PDE Loss:  -1.5551 | Function Loss:  -1.8319\n",
      "Total loss:  -0.7633 | PDE Loss:  -1.5517 | Function Loss:  -1.8405\n",
      "Total loss:  -0.7712 | PDE Loss:  -1.5692 | Function Loss:  -1.8466\n",
      "Total loss:  -0.7768 | PDE Loss:  -1.5762 | Function Loss:  -1.8519\n",
      "Total loss:  -0.7809 | PDE Loss:  -1.605 | Function Loss:  -1.8515\n",
      "Total loss:  -0.7833 | PDE Loss:  -1.6154 | Function Loss:  -1.8525\n",
      "Total loss:  -0.7853 | PDE Loss:  -1.6258 | Function Loss:  -1.853\n",
      "Total loss:  -0.7871 | PDE Loss:  -1.6479 | Function Loss:  -1.8515\n",
      "Total loss:  -0.7884 | PDE Loss:  -1.6643 | Function Loss:  -1.8505\n",
      "Total loss:  -0.7896 | PDE Loss:  -1.6804 | Function Loss:  -1.8493\n",
      "Total loss:  -0.7904 | PDE Loss:  -1.6874 | Function Loss:  -1.8492\n",
      "Total loss:  -0.7911 | PDE Loss:  -1.699 | Function Loss:  -1.8484\n",
      "Total loss:  -0.7916 | PDE Loss:  -1.6981 | Function Loss:  -1.8491\n",
      "Total loss:  -0.7921 | PDE Loss:  -1.6971 | Function Loss:  -1.8499\n",
      "Total loss:  -0.7929 | PDE Loss:  -1.6967 | Function Loss:  -1.8508\n",
      "Total loss:  -0.7938 | PDE Loss:  -1.6939 | Function Loss:  -1.8522\n",
      "Total loss:  -0.7949 | PDE Loss:  -1.6955 | Function Loss:  -1.8532\n",
      "Total loss:  -0.7965 | PDE Loss:  -1.6933 | Function Loss:  -1.8554\n",
      "Total loss:  -0.7984 | PDE Loss:  -1.6979 | Function Loss:  -1.8569\n",
      "Total loss:  -0.8008 | PDE Loss:  -1.6925 | Function Loss:  -1.8605\n",
      "Total loss:  -0.8031 | PDE Loss:  -1.6944 | Function Loss:  -1.8628\n",
      "Total loss:  -0.8054 | PDE Loss:  -1.6933 | Function Loss:  -1.8656\n",
      "Total loss:  -0.808 | PDE Loss:  -1.6846 | Function Loss:  -1.8699\n",
      "Total loss:  -0.8104 | PDE Loss:  -1.6834 | Function Loss:  -1.8729\n",
      "Total loss:  -0.812 | PDE Loss:  -1.6764 | Function Loss:  -1.8759\n",
      "Total loss:  -0.813 | PDE Loss:  -1.6713 | Function Loss:  -1.8778\n",
      "Total loss:  -0.814 | PDE Loss:  -1.6714 | Function Loss:  -1.8789\n",
      "Total loss:  -0.8151 | PDE Loss:  -1.6731 | Function Loss:  -1.8799\n",
      "Total loss:  -0.816 | PDE Loss:  -1.6756 | Function Loss:  -1.8806\n",
      "Total loss:  -0.8168 | PDE Loss:  -1.6792 | Function Loss:  -1.8809\n",
      "Total loss:  -0.8175 | PDE Loss:  -1.6845 | Function Loss:  -1.8809\n",
      "Total loss:  -0.8182 | PDE Loss:  -1.6889 | Function Loss:  -1.881\n",
      "Total loss:  -0.8189 | PDE Loss:  -1.6961 | Function Loss:  -1.8807\n",
      "Total loss:  -0.8196 | PDE Loss:  -1.7027 | Function Loss:  -1.8806\n",
      "Total loss:  -0.8204 | PDE Loss:  -1.71 | Function Loss:  -1.8804\n",
      "Total loss:  -0.8215 | PDE Loss:  -1.7177 | Function Loss:  -1.8804\n",
      "Total loss:  -0.8227 | PDE Loss:  -1.7279 | Function Loss:  -1.8804\n",
      "Total loss:  -0.8241 | PDE Loss:  -1.7356 | Function Loss:  -1.8809\n",
      "Total loss:  -0.8253 | PDE Loss:  -1.7417 | Function Loss:  -1.8814\n",
      "Total loss:  -0.8267 | PDE Loss:  -1.7501 | Function Loss:  -1.8819\n",
      "Total loss:  -0.8281 | PDE Loss:  -1.7546 | Function Loss:  -1.8829\n",
      "Total loss:  -0.8295 | PDE Loss:  -1.7608 | Function Loss:  -1.8836\n",
      "Total loss:  -0.8305 | PDE Loss:  -1.764 | Function Loss:  -1.8843\n",
      "Total loss:  -0.8318 | PDE Loss:  -1.7676 | Function Loss:  -1.8853\n",
      "Total loss:  -0.8332 | PDE Loss:  -1.7747 | Function Loss:  -1.886\n",
      "Total loss:  -0.8345 | PDE Loss:  -1.7739 | Function Loss:  -1.8875\n",
      "Total loss:  -0.8354 | PDE Loss:  -1.7788 | Function Loss:  -1.8879\n",
      "Total loss:  -0.8359 | PDE Loss:  -1.7774 | Function Loss:  -1.8887\n",
      "Total loss:  -0.8363 | PDE Loss:  -1.7757 | Function Loss:  -1.8893\n",
      "Total loss:  -0.8368 | PDE Loss:  -1.7754 | Function Loss:  -1.8899\n",
      "Total loss:  -0.8375 | PDE Loss:  -1.7733 | Function Loss:  -1.8911\n",
      "Total loss:  -0.8385 | PDE Loss:  -1.774 | Function Loss:  -1.8921\n",
      "Total loss:  -0.8397 | PDE Loss:  -1.7758 | Function Loss:  -1.8932\n",
      "Total loss:  -0.841 | PDE Loss:  -1.7822 | Function Loss:  -1.8938\n",
      "Total loss:  -0.8421 | PDE Loss:  -1.7877 | Function Loss:  -1.8943\n",
      "Total loss:  -0.843 | PDE Loss:  -1.7936 | Function Loss:  -1.8946\n",
      "Total loss:  -0.8438 | PDE Loss:  -1.7974 | Function Loss:  -1.895\n",
      "Total loss:  -0.8443 | PDE Loss:  -1.8014 | Function Loss:  -1.8951\n",
      "Total loss:  -0.8446 | PDE Loss:  -1.8031 | Function Loss:  -1.8953\n",
      "Total loss:  -0.8449 | PDE Loss:  -1.8054 | Function Loss:  -1.8953\n",
      "Total loss:  -0.8452 | PDE Loss:  -1.8079 | Function Loss:  -1.8953\n",
      "Total loss:  -0.8455 | PDE Loss:  -1.8107 | Function Loss:  -1.8953\n",
      "Total loss:  -0.846 | PDE Loss:  -1.8143 | Function Loss:  -1.8955\n",
      "Total loss:  -0.8467 | PDE Loss:  -1.8166 | Function Loss:  -1.896\n",
      "Total loss:  -0.8476 | PDE Loss:  -1.8165 | Function Loss:  -1.8969\n",
      "Total loss:  -0.8484 | PDE Loss:  -1.8133 | Function Loss:  -1.8982\n",
      "Total loss:  -0.8492 | PDE Loss:  -1.8118 | Function Loss:  -1.8993\n",
      "Total loss:  -0.8499 | PDE Loss:  -1.8055 | Function Loss:  -1.9009\n",
      "Total loss:  -0.8505 | PDE Loss:  -1.803 | Function Loss:  -1.9019\n",
      "Total loss:  -0.851 | PDE Loss:  -1.7994 | Function Loss:  -1.9029\n",
      "Total loss:  -0.8515 | PDE Loss:  -1.7951 | Function Loss:  -1.904\n",
      "Total loss:  -0.8519 | PDE Loss:  -1.7902 | Function Loss:  -1.9051\n",
      "Total loss:  -0.8526 | PDE Loss:  -1.7845 | Function Loss:  -1.9066\n",
      "Total loss:  -0.8535 | PDE Loss:  -1.7754 | Function Loss:  -1.9089\n",
      "Total loss:  -0.8544 | PDE Loss:  -1.7706 | Function Loss:  -1.9105\n",
      "Total loss:  -0.8552 | PDE Loss:  -1.766 | Function Loss:  -1.9121\n",
      "Total loss:  -0.8562 | PDE Loss:  -1.7662 | Function Loss:  -1.9132\n",
      "Total loss:  -0.8572 | PDE Loss:  -1.767 | Function Loss:  -1.9143\n",
      "Total loss:  -0.8581 | PDE Loss:  -1.768 | Function Loss:  -1.9151\n",
      "Total loss:  -0.8586 | PDE Loss:  -1.7711 | Function Loss:  -1.9153\n",
      "Total loss:  -0.8591 | PDE Loss:  -1.7694 | Function Loss:  -1.9161\n",
      "Total loss:  -0.8596 | PDE Loss:  -1.7726 | Function Loss:  -1.9162\n",
      "Total loss:  -0.86 | PDE Loss:  -1.7737 | Function Loss:  -1.9165\n",
      "Total loss:  -0.8603 | PDE Loss:  -1.7742 | Function Loss:  -1.9168\n",
      "Total loss:  -0.8606 | PDE Loss:  -1.7749 | Function Loss:  -1.9171\n",
      "Total loss:  -0.861 | PDE Loss:  -1.7744 | Function Loss:  -1.9176\n",
      "Total loss:  -0.8616 | PDE Loss:  -1.7746 | Function Loss:  -1.9182\n",
      "Total loss:  -0.8626 | PDE Loss:  -1.7739 | Function Loss:  -1.9195\n",
      "Total loss:  -0.864 | PDE Loss:  -1.7719 | Function Loss:  -1.9213\n",
      "Total loss:  -0.8658 | PDE Loss:  -1.7722 | Function Loss:  -1.9233\n",
      "Total loss:  -0.8678 | PDE Loss:  -1.7699 | Function Loss:  -1.9259\n",
      "Total loss:  -0.8699 | PDE Loss:  -1.7754 | Function Loss:  -1.9276\n",
      "Total loss:  -0.8717 | PDE Loss:  -1.778 | Function Loss:  -1.9292\n",
      "Total loss:  -0.8734 | PDE Loss:  -1.7765 | Function Loss:  -1.9314\n",
      "Total loss:  -0.8746 | PDE Loss:  -1.7811 | Function Loss:  -1.9321\n",
      "Total loss:  -0.8753 | PDE Loss:  -1.7749 | Function Loss:  -1.9338\n",
      "Total loss:  -0.8759 | PDE Loss:  -1.7788 | Function Loss:  -1.9339\n",
      "Total loss:  -0.8764 | PDE Loss:  -1.7729 | Function Loss:  -1.9353\n",
      "Total loss:  -0.8767 | PDE Loss:  -1.7717 | Function Loss:  -1.9359\n",
      "Total loss:  -0.877 | PDE Loss:  -1.7741 | Function Loss:  -1.9358\n",
      "Total loss:  -0.8773 | PDE Loss:  -1.7764 | Function Loss:  -1.9359\n",
      "Total loss:  -0.8777 | PDE Loss:  -1.7774 | Function Loss:  -1.9361\n",
      "Total loss:  -0.8781 | PDE Loss:  -1.7809 | Function Loss:  -1.9361\n",
      "Total loss:  -0.8787 | PDE Loss:  -1.7904 | Function Loss:  -1.9355\n",
      "Total loss:  -0.8793 | PDE Loss:  -1.7968 | Function Loss:  -1.9353\n",
      "Total loss:  -0.8799 | PDE Loss:  -1.8039 | Function Loss:  -1.935\n",
      "Total loss:  -0.8806 | PDE Loss:  -1.8125 | Function Loss:  -1.9346\n",
      "Total loss:  -0.8815 | PDE Loss:  -1.8189 | Function Loss:  -1.9348\n",
      "Total loss:  -0.8825 | PDE Loss:  -1.826 | Function Loss:  -1.935\n",
      "Total loss:  -0.8838 | PDE Loss:  -1.8293 | Function Loss:  -1.936\n",
      "Total loss:  -0.8852 | PDE Loss:  -1.8312 | Function Loss:  -1.9374\n",
      "Total loss:  -0.8866 | PDE Loss:  -1.8269 | Function Loss:  -1.9395\n",
      "Total loss:  -0.8883 | PDE Loss:  -1.8226 | Function Loss:  -1.942\n",
      "Total loss:  -0.8899 | PDE Loss:  -1.8079 | Function Loss:  -1.9458\n",
      "Total loss:  -0.8912 | PDE Loss:  -1.7924 | Function Loss:  -1.9495\n",
      "Total loss:  -0.8923 | PDE Loss:  -1.7823 | Function Loss:  -1.9522\n",
      "Total loss:  -0.8931 | PDE Loss:  -1.766 | Function Loss:  -1.9556\n",
      "Total loss:  -0.8937 | PDE Loss:  -1.7579 | Function Loss:  -1.9575\n",
      "Total loss:  -0.8942 | PDE Loss:  -1.7514 | Function Loss:  -1.9592\n",
      "Total loss:  -0.8947 | PDE Loss:  -1.7463 | Function Loss:  -1.9606\n",
      "Total loss:  -0.8953 | PDE Loss:  -1.743 | Function Loss:  -1.9618\n",
      "Total loss:  -0.8959 | PDE Loss:  -1.7436 | Function Loss:  -1.9625\n",
      "Total loss:  -0.8967 | PDE Loss:  -1.746 | Function Loss:  -1.9629\n",
      "Total loss:  -0.8978 | PDE Loss:  -1.75 | Function Loss:  -1.9635\n",
      "Total loss:  -0.8993 | PDE Loss:  -1.7558 | Function Loss:  -1.9643\n",
      "Total loss:  -0.9013 | PDE Loss:  -1.7619 | Function Loss:  -1.9657\n",
      "Total loss:  -0.9032 | PDE Loss:  -1.7662 | Function Loss:  -1.9672\n",
      "Total loss:  -0.9049 | PDE Loss:  -1.773 | Function Loss:  -1.9681\n",
      "Total loss:  -0.9062 | PDE Loss:  -1.7719 | Function Loss:  -1.9698\n",
      "Total loss:  -0.9075 | PDE Loss:  -1.7794 | Function Loss:  -1.9701\n",
      "Total loss:  -0.9084 | PDE Loss:  -1.7812 | Function Loss:  -1.9709\n",
      "Total loss:  -0.9095 | PDE Loss:  -1.7838 | Function Loss:  -1.9717\n",
      "Total loss:  -0.9107 | PDE Loss:  -1.7899 | Function Loss:  -1.9722\n",
      "Total loss:  -0.9118 | PDE Loss:  -1.7934 | Function Loss:  -1.9729\n",
      "Total loss:  -0.9132 | PDE Loss:  -1.7952 | Function Loss:  -1.9743\n",
      "Total loss:  -0.9145 | PDE Loss:  -1.8043 | Function Loss:  -1.9744\n",
      "Total loss:  -0.9155 | PDE Loss:  -1.8033 | Function Loss:  -1.9757\n",
      "Total loss:  -0.9162 | PDE Loss:  -1.8075 | Function Loss:  -1.9759\n",
      "Total loss:  -0.9169 | PDE Loss:  -1.8099 | Function Loss:  -1.9764\n",
      "Total loss:  -0.9178 | PDE Loss:  -1.811 | Function Loss:  -1.9772\n",
      "Total loss:  -0.9186 | PDE Loss:  -1.8106 | Function Loss:  -1.9782\n",
      "Total loss:  -0.9197 | PDE Loss:  -1.8096 | Function Loss:  -1.9796\n",
      "Total loss:  -0.9207 | PDE Loss:  -1.7992 | Function Loss:  -1.9824\n",
      "Total loss:  -0.9216 | PDE Loss:  -1.7971 | Function Loss:  -1.9837\n",
      "Total loss:  -0.9221 | PDE Loss:  -1.7929 | Function Loss:  -1.9849\n",
      "Total loss:  -0.923 | PDE Loss:  -1.7873 | Function Loss:  -1.9868\n",
      "Total loss:  -0.9238 | PDE Loss:  -1.7818 | Function Loss:  -1.9887\n",
      "Total loss:  -0.9246 | PDE Loss:  -1.774 | Function Loss:  -1.9909\n",
      "Total loss:  -0.9253 | PDE Loss:  -1.7662 | Function Loss:  -1.9929\n",
      "Total loss:  -0.926 | PDE Loss:  -1.7681 | Function Loss:  -1.9934\n",
      "Total loss:  -0.9269 | PDE Loss:  -1.7698 | Function Loss:  -1.9942\n",
      "Total loss:  -0.9279 | PDE Loss:  -1.774 | Function Loss:  -1.9947\n",
      "Total loss:  -0.929 | PDE Loss:  -1.7741 | Function Loss:  -1.996\n",
      "Total loss:  -0.9303 | PDE Loss:  -1.7738 | Function Loss:  -1.9976\n",
      "Total loss:  -0.9323 | PDE Loss:  -1.771 | Function Loss:  -2.0003\n",
      "Total loss:  -0.9353 | PDE Loss:  -1.7689 | Function Loss:  -2.0042\n",
      "Total loss:  -0.9388 | PDE Loss:  -1.764 | Function Loss:  -2.0091\n",
      "Total loss:  -0.9419 | PDE Loss:  -1.765 | Function Loss:  -2.0126\n",
      "Total loss:  -0.9444 | PDE Loss:  -1.7759 | Function Loss:  -2.0137\n",
      "Total loss:  -0.9475 | PDE Loss:  -1.7652 | Function Loss:  -2.0192\n",
      "Total loss:  -0.9526 | PDE Loss:  -1.7647 | Function Loss:  -2.0252\n",
      "Total loss:  -0.9569 | PDE Loss:  -1.7751 | Function Loss:  -2.0285\n",
      "Total loss:  -0.9601 | PDE Loss:  -1.7754 | Function Loss:  -2.0323\n",
      "Total loss:  -0.9621 | PDE Loss:  -1.7832 | Function Loss:  -2.0332\n",
      "Total loss:  -0.9652 | PDE Loss:  -1.7861 | Function Loss:  -2.0363\n",
      "Total loss:  -0.9697 | PDE Loss:  -1.7981 | Function Loss:  -2.0395\n",
      "Total loss:  -0.9729 | PDE Loss:  -1.8055 | Function Loss:  -2.042\n",
      "Total loss:  -0.975 | PDE Loss:  -1.8199 | Function Loss:  -2.042\n",
      "Total loss:  -0.9768 | PDE Loss:  -1.8156 | Function Loss:  -2.0448\n",
      "Total loss:  -0.9785 | PDE Loss:  -1.818 | Function Loss:  -2.0463\n",
      "Total loss:  -0.9803 | PDE Loss:  -1.8225 | Function Loss:  -2.0477\n",
      "Total loss:  -0.9818 | PDE Loss:  -1.8394 | Function Loss:  -2.0467\n",
      "Total loss:  -0.9829 | PDE Loss:  -1.8283 | Function Loss:  -2.0498\n",
      "Total loss:  -0.9839 | PDE Loss:  -1.8274 | Function Loss:  -2.0511\n",
      "Total loss:  -0.9852 | PDE Loss:  -1.8315 | Function Loss:  -2.0519\n",
      "Total loss:  -0.9874 | PDE Loss:  -1.8297 | Function Loss:  -2.0548\n",
      "Total loss:  -0.9901 | PDE Loss:  -1.8281 | Function Loss:  -2.0583\n",
      "Total loss:  -0.9938 | PDE Loss:  -1.8311 | Function Loss:  -2.0621\n",
      "Total loss:  -0.9989 | PDE Loss:  -1.8269 | Function Loss:  -2.0687\n",
      "Total loss:  -1.0042 | PDE Loss:  -1.8384 | Function Loss:  -2.0729\n",
      "Total loss:  -1.0083 | PDE Loss:  -1.8345 | Function Loss:  -2.0785\n",
      "Total loss:  -1.0113 | PDE Loss:  -1.8327 | Function Loss:  -2.0823\n",
      "Total loss:  -1.0136 | PDE Loss:  -1.8431 | Function Loss:  -2.0832\n",
      "Total loss:  -1.0164 | PDE Loss:  -1.847 | Function Loss:  -2.0858\n",
      "Total loss:  -1.0201 | PDE Loss:  -1.8537 | Function Loss:  -2.089\n",
      "Total loss:  -1.0232 | PDE Loss:  -1.8493 | Function Loss:  -2.0934\n",
      "Total loss:  -1.0245 | PDE Loss:  -1.8457 | Function Loss:  -2.0956\n",
      "Total loss:  -1.0259 | PDE Loss:  -1.8443 | Function Loss:  -2.0975\n",
      "Total loss:  -1.0275 | PDE Loss:  -1.8435 | Function Loss:  -2.0995\n",
      "Total loss:  -1.0289 | PDE Loss:  -1.834 | Function Loss:  -2.1029\n",
      "Total loss:  -1.0304 | PDE Loss:  -1.8278 | Function Loss:  -2.1058\n",
      "Total loss:  -1.0342 | PDE Loss:  -1.8087 | Function Loss:  -2.1141\n",
      "Total loss:  -1.0374 | PDE Loss:  -1.7879 | Function Loss:  -2.1223\n",
      "Total loss:  -1.0403 | PDE Loss:  -1.7726 | Function Loss:  -2.1293\n",
      "Total loss:  -1.0434 | PDE Loss:  -1.7606 | Function Loss:  -2.1359\n",
      "Total loss:  -1.0461 | PDE Loss:  -1.7494 | Function Loss:  -2.1419\n",
      "Total loss:  -1.0479 | PDE Loss:  -1.7449 | Function Loss:  -2.1453\n",
      "Total loss:  -1.0489 | PDE Loss:  -1.7419 | Function Loss:  -2.1473\n",
      "Total loss:  -1.0499 | PDE Loss:  -1.7405 | Function Loss:  -2.149\n",
      "Total loss:  -1.0515 | PDE Loss:  -1.7425 | Function Loss:  -2.1504\n",
      "Total loss:  -1.0532 | PDE Loss:  -1.7427 | Function Loss:  -2.1525\n",
      "Total loss:  -1.0549 | PDE Loss:  -1.7441 | Function Loss:  -2.1543\n",
      "Total loss:  -1.0575 | PDE Loss:  -1.7422 | Function Loss:  -2.1581\n",
      "Total loss:  -1.061 | PDE Loss:  -1.7425 | Function Loss:  -2.1624\n",
      "Total loss:  -1.0651 | PDE Loss:  -1.7362 | Function Loss:  -2.1693\n",
      "Total loss:  -1.0695 | PDE Loss:  -1.7347 | Function Loss:  -2.1753\n",
      "Total loss:  -1.0752 | PDE Loss:  -1.7268 | Function Loss:  -2.1848\n",
      "Total loss:  -1.0808 | PDE Loss:  -1.721 | Function Loss:  -2.1937\n",
      "Total loss:  -1.0856 | PDE Loss:  -1.7196 | Function Loss:  -2.2004\n",
      "Total loss:  -1.0899 | PDE Loss:  -1.7133 | Function Loss:  -2.2079\n",
      "Total loss:  -1.0949 | PDE Loss:  -1.714 | Function Loss:  -2.2143\n",
      "Total loss:  -1.0985 | PDE Loss:  -1.6964 | Function Loss:  -2.2249\n",
      "Total loss:  -1.1013 | PDE Loss:  -1.693 | Function Loss:  -2.2298\n",
      "Total loss:  -1.103 | PDE Loss:  -1.6952 | Function Loss:  -2.2312\n",
      "Total loss:  -1.1049 | PDE Loss:  -1.6973 | Function Loss:  -2.2332\n",
      "Total loss:  -1.1071 | PDE Loss:  -1.6999 | Function Loss:  -2.2352\n",
      "Total loss:  -1.1092 | PDE Loss:  -1.7046 | Function Loss:  -2.2364\n",
      "Total loss:  -1.1115 | PDE Loss:  -1.7032 | Function Loss:  -2.24\n",
      "Total loss:  -1.114 | PDE Loss:  -1.708 | Function Loss:  -2.2416\n",
      "Total loss:  -1.1203 | PDE Loss:  -1.7156 | Function Loss:  -2.2475\n",
      "Total loss:  -1.1285 | PDE Loss:  -1.731 | Function Loss:  -2.2533\n",
      "Total loss:  -1.1344 | PDE Loss:  -1.7451 | Function Loss:  -2.2565\n",
      "Total loss:  -1.1378 | PDE Loss:  -1.7455 | Function Loss:  -2.2608\n",
      "Total loss:  -1.1406 | PDE Loss:  -1.7541 | Function Loss:  -2.2618\n",
      "Total loss:  -1.1421 | PDE Loss:  -1.7591 | Function Loss:  -2.2621\n",
      "Total loss:  -1.1429 | PDE Loss:  -1.7603 | Function Loss:  -2.2629\n",
      "Total loss:  -1.1437 | PDE Loss:  -1.7616 | Function Loss:  -2.2634\n",
      "Total loss:  -1.1449 | PDE Loss:  -1.7654 | Function Loss:  -2.2639\n",
      "Total loss:  -1.1464 | PDE Loss:  -1.7731 | Function Loss:  -2.2635\n",
      "Total loss:  -1.1478 | PDE Loss:  -1.7767 | Function Loss:  -2.2642\n",
      "Total loss:  -1.1498 | PDE Loss:  -1.7824 | Function Loss:  -2.265\n",
      "Total loss:  -1.1532 | PDE Loss:  -1.7892 | Function Loss:  -2.2674\n",
      "Total loss:  -1.1574 | PDE Loss:  -1.7997 | Function Loss:  -2.2696\n",
      "Total loss:  -1.1616 | PDE Loss:  -1.8049 | Function Loss:  -2.2736\n",
      "Total loss:  -1.1653 | PDE Loss:  -1.812 | Function Loss:  -2.2763\n",
      "Total loss:  -1.1697 | PDE Loss:  -1.8184 | Function Loss:  -2.2801\n",
      "Total loss:  -1.1736 | PDE Loss:  -1.8194 | Function Loss:  -2.2849\n",
      "Total loss:  -1.1772 | PDE Loss:  -1.8207 | Function Loss:  -2.2891\n",
      "Total loss:  -1.1798 | PDE Loss:  -1.8163 | Function Loss:  -2.2939\n",
      "Total loss:  -1.1815 | PDE Loss:  -1.8089 | Function Loss:  -2.2984\n",
      "Total loss:  -1.1838 | PDE Loss:  -1.8047 | Function Loss:  -2.3027\n",
      "Total loss:  -1.1865 | PDE Loss:  -1.802 | Function Loss:  -2.3071\n",
      "Total loss:  -1.1893 | PDE Loss:  -1.8007 | Function Loss:  -2.3112\n",
      "Total loss:  -1.1918 | PDE Loss:  -1.7967 | Function Loss:  -2.3158\n",
      "Total loss:  -1.1939 | PDE Loss:  -1.8 | Function Loss:  -2.3175\n",
      "Total loss:  -1.1953 | PDE Loss:  -1.8022 | Function Loss:  -2.3186\n",
      "Total loss:  -1.1975 | PDE Loss:  -1.8049 | Function Loss:  -2.3207\n",
      "Total loss:  -1.2003 | PDE Loss:  -1.8149 | Function Loss:  -2.3211\n",
      "Total loss:  -1.2024 | PDE Loss:  -1.8224 | Function Loss:  -2.3215\n",
      "Total loss:  -1.204 | PDE Loss:  -1.8307 | Function Loss:  -2.3211\n",
      "Total loss:  -1.2058 | PDE Loss:  -1.8356 | Function Loss:  -2.3219\n",
      "Total loss:  -1.2073 | PDE Loss:  -1.8392 | Function Loss:  -2.3227\n",
      "Total loss:  -1.2087 | PDE Loss:  -1.837 | Function Loss:  -2.3252\n",
      "Total loss:  -1.2102 | PDE Loss:  -1.8336 | Function Loss:  -2.3282\n",
      "Total loss:  -1.2117 | PDE Loss:  -1.8274 | Function Loss:  -2.3322\n",
      "Total loss:  -1.2132 | PDE Loss:  -1.8207 | Function Loss:  -2.3364\n",
      "Total loss:  -1.2145 | PDE Loss:  -1.8132 | Function Loss:  -2.3406\n",
      "Total loss:  -1.2159 | PDE Loss:  -1.807 | Function Loss:  -2.3445\n",
      "Total loss:  -1.2177 | PDE Loss:  -1.8022 | Function Loss:  -2.3486\n",
      "Total loss:  -1.2204 | PDE Loss:  -1.7988 | Function Loss:  -2.3535\n",
      "Total loss:  -1.2238 | PDE Loss:  -1.7983 | Function Loss:  -2.3583\n",
      "Total loss:  -1.2276 | PDE Loss:  -1.8003 | Function Loss:  -2.3628\n",
      "Total loss:  -1.2311 | PDE Loss:  -1.8041 | Function Loss:  -2.3662\n",
      "Total loss:  -1.2339 | PDE Loss:  -1.8098 | Function Loss:  -2.368\n",
      "Total loss:  -1.2376 | PDE Loss:  -1.8216 | Function Loss:  -2.3688\n",
      "Total loss:  -1.241 | PDE Loss:  -1.8361 | Function Loss:  -2.3683\n",
      "Total loss:  -1.244 | PDE Loss:  -1.8472 | Function Loss:  -2.3686\n",
      "Total loss:  -1.2465 | PDE Loss:  -1.8621 | Function Loss:  -2.3671\n",
      "Total loss:  -1.2506 | PDE Loss:  -1.8754 | Function Loss:  -2.3683\n",
      "Total loss:  -1.2561 | PDE Loss:  -1.8881 | Function Loss:  -2.3715\n",
      "Total loss:  -1.2604 | PDE Loss:  -1.8916 | Function Loss:  -2.3761\n",
      "Total loss:  -1.2632 | PDE Loss:  -1.8885 | Function Loss:  -2.3807\n",
      "Total loss:  -1.2657 | PDE Loss:  -1.8839 | Function Loss:  -2.3854\n",
      "Total loss:  -1.2674 | PDE Loss:  -1.88 | Function Loss:  -2.3889\n",
      "Total loss:  -1.2685 | PDE Loss:  -1.8757 | Function Loss:  -2.3917\n",
      "Total loss:  -1.2691 | PDE Loss:  -1.8767 | Function Loss:  -2.3922\n",
      "Total loss:  -1.2699 | PDE Loss:  -1.8786 | Function Loss:  -2.3927\n",
      "Total loss:  -1.2711 | PDE Loss:  -1.8834 | Function Loss:  -2.3926\n",
      "Total loss:  -1.2727 | PDE Loss:  -1.8908 | Function Loss:  -2.3924\n",
      "Total loss:  -1.2753 | PDE Loss:  -1.9009 | Function Loss:  -2.3926\n",
      "Total loss:  -1.2781 | PDE Loss:  -1.9164 | Function Loss:  -2.3917\n",
      "Total loss:  -1.2813 | PDE Loss:  -1.9226 | Function Loss:  -2.3939\n",
      "Total loss:  -1.2852 | PDE Loss:  -1.9339 | Function Loss:  -2.3956\n",
      "Total loss:  -1.2892 | PDE Loss:  -1.9364 | Function Loss:  -2.4001\n",
      "Total loss:  -1.2907 | PDE Loss:  -1.9388 | Function Loss:  -2.4013\n",
      "Total loss:  -1.2923 | PDE Loss:  -1.9349 | Function Loss:  -2.4046\n",
      "Total loss:  -1.2933 | PDE Loss:  -1.9334 | Function Loss:  -2.4062\n",
      "Total loss:  -1.2939 | PDE Loss:  -1.9319 | Function Loss:  -2.4075\n",
      "Total loss:  -1.2946 | PDE Loss:  -1.9292 | Function Loss:  -2.4092\n",
      "Total loss:  -1.2953 | PDE Loss:  -1.9279 | Function Loss:  -2.4106\n",
      "Total loss:  -1.2961 | PDE Loss:  -1.9263 | Function Loss:  -2.4121\n",
      "Total loss:  -1.2969 | PDE Loss:  -1.9262 | Function Loss:  -2.4131\n",
      "Total loss:  -1.2979 | PDE Loss:  -1.9281 | Function Loss:  -2.4138\n",
      "Total loss:  -1.2989 | PDE Loss:  -1.9302 | Function Loss:  -2.4146\n",
      "Total loss:  -1.2999 | PDE Loss:  -1.9334 | Function Loss:  -2.4149\n",
      "Total loss:  -1.301 | PDE Loss:  -1.9374 | Function Loss:  -2.4151\n",
      "Total loss:  -1.3021 | PDE Loss:  -1.9409 | Function Loss:  -2.4155\n",
      "Total loss:  -1.3031 | PDE Loss:  -1.9452 | Function Loss:  -2.4154\n",
      "Total loss:  -1.3041 | PDE Loss:  -1.947 | Function Loss:  -2.4163\n",
      "Total loss:  -1.3053 | PDE Loss:  -1.9519 | Function Loss:  -2.4164\n",
      "Total loss:  -1.3063 | PDE Loss:  -1.9517 | Function Loss:  -2.4177\n",
      "Total loss:  -1.3076 | PDE Loss:  -1.9506 | Function Loss:  -2.4197\n",
      "Total loss:  -1.3094 | PDE Loss:  -1.9499 | Function Loss:  -2.4223\n",
      "Total loss:  -1.3112 | PDE Loss:  -1.9476 | Function Loss:  -2.4253\n",
      "Total loss:  -1.3131 | PDE Loss:  -1.9452 | Function Loss:  -2.4285\n",
      "Total loss:  -1.3155 | PDE Loss:  -1.9427 | Function Loss:  -2.4324\n",
      "Total loss:  -1.3184 | PDE Loss:  -1.9426 | Function Loss:  -2.4362\n",
      "Total loss:  -1.3219 | PDE Loss:  -1.9453 | Function Loss:  -2.44\n",
      "Total loss:  -1.3252 | PDE Loss:  -1.9489 | Function Loss:  -2.4432\n",
      "Total loss:  -1.328 | PDE Loss:  -1.9607 | Function Loss:  -2.4432\n",
      "Total loss:  -1.3307 | PDE Loss:  -1.9727 | Function Loss:  -2.4431\n",
      "Total loss:  -1.3335 | PDE Loss:  -1.9866 | Function Loss:  -2.4427\n",
      "Total loss:  -1.3358 | PDE Loss:  -1.9999 | Function Loss:  -2.4418\n",
      "Total loss:  -1.3371 | PDE Loss:  -2.0074 | Function Loss:  -2.4415\n",
      "Total loss:  -1.3379 | PDE Loss:  -2.0102 | Function Loss:  -2.4417\n",
      "Total loss:  -1.3387 | PDE Loss:  -2.0139 | Function Loss:  -2.4418\n",
      "Total loss:  -1.3398 | PDE Loss:  -2.016 | Function Loss:  -2.4426\n",
      "Total loss:  -1.3408 | PDE Loss:  -2.0179 | Function Loss:  -2.4433\n",
      "Total loss:  -1.342 | PDE Loss:  -2.0192 | Function Loss:  -2.4446\n",
      "Total loss:  -1.3438 | PDE Loss:  -2.0194 | Function Loss:  -2.4467\n",
      "Total loss:  -1.3457 | PDE Loss:  -2.0203 | Function Loss:  -2.4489\n",
      "Total loss:  -1.348 | PDE Loss:  -2.0171 | Function Loss:  -2.4527\n",
      "Total loss:  -1.3502 | PDE Loss:  -2.0142 | Function Loss:  -2.4564\n",
      "Total loss:  -1.3521 | PDE Loss:  -2.0063 | Function Loss:  -2.461\n",
      "Total loss:  -1.3538 | PDE Loss:  -1.9993 | Function Loss:  -2.4651\n",
      "Total loss:  -1.3557 | PDE Loss:  -1.9894 | Function Loss:  -2.4705\n",
      "Total loss:  -1.3577 | PDE Loss:  -1.98 | Function Loss:  -2.4761\n",
      "Total loss:  -1.3596 | PDE Loss:  -1.9704 | Function Loss:  -2.4817\n",
      "Total loss:  -1.3609 | PDE Loss:  -1.9668 | Function Loss:  -2.4845\n",
      "Total loss:  -1.3622 | PDE Loss:  -1.9633 | Function Loss:  -2.4875\n",
      "Total loss:  -1.3633 | PDE Loss:  -1.9633 | Function Loss:  -2.4889\n",
      "Total loss:  -1.3658 | PDE Loss:  -1.9678 | Function Loss:  -2.4907\n",
      "Total loss:  -1.369 | PDE Loss:  -1.9718 | Function Loss:  -2.4937\n",
      "Total loss:  -1.373 | PDE Loss:  -1.9787 | Function Loss:  -2.4967\n",
      "Total loss:  -1.3769 | PDE Loss:  -1.9876 | Function Loss:  -2.4989\n",
      "Total loss:  -1.38 | PDE Loss:  -1.995 | Function Loss:  -2.5007\n",
      "Total loss:  -1.3831 | PDE Loss:  -2.0057 | Function Loss:  -2.5014\n",
      "Total loss:  -1.386 | PDE Loss:  -2.0105 | Function Loss:  -2.5037\n",
      "Total loss:  -1.3883 | PDE Loss:  -2.0177 | Function Loss:  -2.5045\n",
      "Total loss:  -1.3899 | PDE Loss:  -2.0196 | Function Loss:  -2.506\n",
      "Total loss:  -1.3915 | PDE Loss:  -2.0237 | Function Loss:  -2.5068\n",
      "Total loss:  -1.3934 | PDE Loss:  -2.0307 | Function Loss:  -2.5071\n",
      "Total loss:  -1.3951 | PDE Loss:  -2.0343 | Function Loss:  -2.5083\n",
      "Total loss:  -1.3963 | PDE Loss:  -2.0406 | Function Loss:  -2.508\n",
      "Total loss:  -1.3973 | PDE Loss:  -2.043 | Function Loss:  -2.5086\n",
      "Total loss:  -1.3982 | PDE Loss:  -2.0462 | Function Loss:  -2.5089\n",
      "Total loss:  -1.3991 | PDE Loss:  -2.0483 | Function Loss:  -2.5094\n",
      "Total loss:  -1.4004 | PDE Loss:  -2.0508 | Function Loss:  -2.5104\n",
      "Total loss:  -1.4021 | PDE Loss:  -2.0539 | Function Loss:  -2.5117\n",
      "Total loss:  -1.4039 | PDE Loss:  -2.0578 | Function Loss:  -2.5128\n",
      "Total loss:  -1.4058 | PDE Loss:  -2.0613 | Function Loss:  -2.5143\n",
      "Total loss:  -1.408 | PDE Loss:  -2.0671 | Function Loss:  -2.5155\n",
      "Total loss:  -1.4103 | PDE Loss:  -2.0748 | Function Loss:  -2.5162\n",
      "Total loss:  -1.4127 | PDE Loss:  -2.0824 | Function Loss:  -2.5172\n",
      "Total loss:  -1.4151 | PDE Loss:  -2.0943 | Function Loss:  -2.517\n",
      "Total loss:  -1.4174 | PDE Loss:  -2.1038 | Function Loss:  -2.5174\n",
      "Total loss:  -1.4197 | PDE Loss:  -2.1155 | Function Loss:  -2.5174\n",
      "Total loss:  -1.4214 | PDE Loss:  -2.1231 | Function Loss:  -2.5177\n",
      "Total loss:  -1.4233 | PDE Loss:  -2.1296 | Function Loss:  -2.5184\n",
      "Total loss:  -1.4248 | PDE Loss:  -2.1411 | Function Loss:  -2.5175\n",
      "Total loss:  -1.4261 | PDE Loss:  -2.1435 | Function Loss:  -2.5185\n",
      "Total loss:  -1.4269 | PDE Loss:  -2.1466 | Function Loss:  -2.5188\n",
      "Total loss:  -1.4283 | PDE Loss:  -2.1519 | Function Loss:  -2.5192\n",
      "Total loss:  -1.4296 | PDE Loss:  -2.1555 | Function Loss:  -2.52\n",
      "Total loss:  -1.4304 | PDE Loss:  -2.1581 | Function Loss:  -2.5204\n",
      "Total loss:  -1.4309 | PDE Loss:  -2.1591 | Function Loss:  -2.5208\n",
      "Total loss:  -1.4312 | PDE Loss:  -2.1597 | Function Loss:  -2.521\n",
      "Total loss:  -1.4313 | PDE Loss:  -2.1593 | Function Loss:  -2.5213\n",
      "Total loss:  -1.4316 | PDE Loss:  -2.1593 | Function Loss:  -2.5216\n",
      "Total loss:  -1.4319 | PDE Loss:  -2.1585 | Function Loss:  -2.5221\n",
      "Total loss:  -1.4324 | PDE Loss:  -2.1584 | Function Loss:  -2.5228\n",
      "Total loss:  -1.4332 | PDE Loss:  -2.1566 | Function Loss:  -2.5242\n",
      "Total loss:  -1.434 | PDE Loss:  -2.1549 | Function Loss:  -2.5256\n",
      "Total loss:  -1.4346 | PDE Loss:  -2.1536 | Function Loss:  -2.5267\n",
      "Total loss:  -1.4355 | PDE Loss:  -2.152 | Function Loss:  -2.5281\n",
      "Total loss:  -1.4365 | PDE Loss:  -2.1525 | Function Loss:  -2.5293\n",
      "Total loss:  -1.4377 | PDE Loss:  -2.1468 | Function Loss:  -2.5321\n",
      "Total loss:  -1.4393 | PDE Loss:  -2.1492 | Function Loss:  -2.5335\n",
      "Total loss:  -1.4415 | PDE Loss:  -2.1551 | Function Loss:  -2.5349\n",
      "Total loss:  -1.4444 | PDE Loss:  -2.1613 | Function Loss:  -2.5369\n",
      "Total loss:  -1.4476 | PDE Loss:  -2.1743 | Function Loss:  -2.5378\n",
      "Total loss:  -1.4508 | PDE Loss:  -2.1836 | Function Loss:  -2.5397\n",
      "Total loss:  -1.454 | PDE Loss:  -2.195 | Function Loss:  -2.5411\n",
      "Total loss:  -1.4568 | PDE Loss:  -2.2042 | Function Loss:  -2.5424\n",
      "Total loss:  -1.4584 | PDE Loss:  -2.2082 | Function Loss:  -2.5435\n",
      "Total loss:  -1.4595 | PDE Loss:  -2.2094 | Function Loss:  -2.5446\n",
      "Total loss:  -1.4606 | PDE Loss:  -2.2106 | Function Loss:  -2.5456\n",
      "Total loss:  -1.4619 | PDE Loss:  -2.2111 | Function Loss:  -2.5471\n",
      "Total loss:  -1.4631 | PDE Loss:  -2.2105 | Function Loss:  -2.5487\n",
      "Total loss:  -1.4642 | PDE Loss:  -2.2127 | Function Loss:  -2.5496\n",
      "Total loss:  -1.4649 | PDE Loss:  -2.2169 | Function Loss:  -2.5496\n",
      "Total loss:  -1.466 | PDE Loss:  -2.2258 | Function Loss:  -2.549\n",
      "Total loss:  -1.4667 | PDE Loss:  -2.2344 | Function Loss:  -2.548\n",
      "Total loss:  -1.4672 | PDE Loss:  -2.2406 | Function Loss:  -2.5473\n",
      "Total loss:  -1.4676 | PDE Loss:  -2.245 | Function Loss:  -2.547\n",
      "Total loss:  -1.4683 | PDE Loss:  -2.2509 | Function Loss:  -2.5466\n",
      "Total loss:  -1.4689 | PDE Loss:  -2.253 | Function Loss:  -2.547\n",
      "Total loss:  -1.4694 | PDE Loss:  -2.254 | Function Loss:  -2.5473\n",
      "Total loss:  -1.4698 | PDE Loss:  -2.2536 | Function Loss:  -2.5479\n",
      "Total loss:  -1.4703 | PDE Loss:  -2.252 | Function Loss:  -2.5488\n",
      "Total loss:  -1.4708 | PDE Loss:  -2.2517 | Function Loss:  -2.5494\n",
      "Total loss:  -1.4712 | PDE Loss:  -2.2476 | Function Loss:  -2.5508\n",
      "Total loss:  -1.4715 | PDE Loss:  -2.2483 | Function Loss:  -2.551\n",
      "Total loss:  -1.4719 | PDE Loss:  -2.2487 | Function Loss:  -2.5513\n",
      "Total loss:  -1.4724 | PDE Loss:  -2.2506 | Function Loss:  -2.5516\n",
      "Total loss:  -1.4729 | PDE Loss:  -2.2519 | Function Loss:  -2.5519\n",
      "Total loss:  -1.4735 | PDE Loss:  -2.2543 | Function Loss:  -2.5521\n",
      "Total loss:  -1.4741 | PDE Loss:  -2.2556 | Function Loss:  -2.5526\n",
      "Total loss:  -1.4746 | PDE Loss:  -2.2557 | Function Loss:  -2.5532\n",
      "Total loss:  -1.4752 | PDE Loss:  -2.2563 | Function Loss:  -2.5538\n",
      "Total loss:  -1.4759 | PDE Loss:  -2.2547 | Function Loss:  -2.555\n",
      "Total loss:  -1.4765 | PDE Loss:  -2.2539 | Function Loss:  -2.5558\n",
      "Total loss:  -1.4769 | PDE Loss:  -2.2528 | Function Loss:  -2.5565\n",
      "Total loss:  -1.4773 | PDE Loss:  -2.2518 | Function Loss:  -2.5573\n",
      "Total loss:  -1.4779 | PDE Loss:  -2.2513 | Function Loss:  -2.5581\n",
      "Total loss:  -1.4786 | PDE Loss:  -2.2515 | Function Loss:  -2.5588\n",
      "Total loss:  -1.4793 | PDE Loss:  -2.252 | Function Loss:  -2.5595\n",
      "Total loss:  -1.4799 | PDE Loss:  -2.2533 | Function Loss:  -2.5601\n",
      "Total loss:  -1.4806 | PDE Loss:  -2.2556 | Function Loss:  -2.5605\n",
      "Total loss:  -1.4814 | PDE Loss:  -2.2587 | Function Loss:  -2.5607\n",
      "Total loss:  -1.4822 | PDE Loss:  -2.2617 | Function Loss:  -2.5611\n",
      "Total loss:  -1.4831 | PDE Loss:  -2.2688 | Function Loss:  -2.5608\n",
      "Total loss:  -1.4838 | PDE Loss:  -2.271 | Function Loss:  -2.5613\n",
      "Total loss:  -1.4846 | PDE Loss:  -2.275 | Function Loss:  -2.5614\n",
      "Total loss:  -1.4855 | PDE Loss:  -2.2783 | Function Loss:  -2.5618\n",
      "Total loss:  -1.486 | PDE Loss:  -2.2809 | Function Loss:  -2.5619\n",
      "Total loss:  -1.4865 | PDE Loss:  -2.2833 | Function Loss:  -2.562\n",
      "Total loss:  -1.4869 | PDE Loss:  -2.2854 | Function Loss:  -2.5621\n",
      "Total loss:  -1.4875 | PDE Loss:  -2.2889 | Function Loss:  -2.5622\n",
      "Total loss:  -1.4882 | PDE Loss:  -2.2931 | Function Loss:  -2.5622\n",
      "Total loss:  -1.4889 | PDE Loss:  -2.2973 | Function Loss:  -2.5622\n",
      "Total loss:  -1.489 | PDE Loss:  -2.3007 | Function Loss:  -2.5617\n",
      "Total loss:  -1.4899 | PDE Loss:  -2.3046 | Function Loss:  -2.5621\n",
      "Total loss:  -1.4905 | PDE Loss:  -2.3071 | Function Loss:  -2.5624\n",
      "Total loss:  -1.4912 | PDE Loss:  -2.3105 | Function Loss:  -2.5626\n",
      "Total loss:  -1.492 | PDE Loss:  -2.3135 | Function Loss:  -2.563\n",
      "Total loss:  -1.4928 | PDE Loss:  -2.3174 | Function Loss:  -2.5633\n",
      "Total loss:  -1.4937 | PDE Loss:  -2.322 | Function Loss:  -2.5635\n",
      "Total loss:  -1.4946 | PDE Loss:  -2.3254 | Function Loss:  -2.5639\n",
      "Total loss:  -1.4954 | PDE Loss:  -2.3303 | Function Loss:  -2.5641\n",
      "Total loss:  -1.4961 | PDE Loss:  -2.3322 | Function Loss:  -2.5646\n",
      "Total loss:  -1.4969 | PDE Loss:  -2.3339 | Function Loss:  -2.5652\n",
      "Total loss:  -1.4975 | PDE Loss:  -2.3336 | Function Loss:  -2.566\n",
      "Total loss:  -1.4981 | PDE Loss:  -2.3325 | Function Loss:  -2.5669\n",
      "Total loss:  -1.4986 | PDE Loss:  -2.3311 | Function Loss:  -2.5677\n",
      "Total loss:  -1.4992 | PDE Loss:  -2.3298 | Function Loss:  -2.5687\n",
      "Total loss:  -1.5001 | PDE Loss:  -2.3292 | Function Loss:  -2.5698\n",
      "Total loss:  -1.501 | PDE Loss:  -2.3292 | Function Loss:  -2.5709\n",
      "Total loss:  -1.502 | PDE Loss:  -2.3309 | Function Loss:  -2.5717\n",
      "Total loss:  -1.5028 | PDE Loss:  -2.3323 | Function Loss:  -2.5724\n",
      "Total loss:  -1.5037 | PDE Loss:  -2.3334 | Function Loss:  -2.5733\n",
      "Total loss:  -1.5044 | PDE Loss:  -2.3353 | Function Loss:  -2.5738\n",
      "Total loss:  -1.5055 | PDE Loss:  -2.3371 | Function Loss:  -2.5747\n",
      "Total loss:  -1.5063 | PDE Loss:  -2.3381 | Function Loss:  -2.5755\n",
      "Total loss:  -1.5071 | PDE Loss:  -2.3402 | Function Loss:  -2.5761\n",
      "Total loss:  -1.508 | PDE Loss:  -2.3403 | Function Loss:  -2.5771\n",
      "Total loss:  -1.5088 | PDE Loss:  -2.3413 | Function Loss:  -2.5779\n",
      "Total loss:  -1.5095 | PDE Loss:  -2.3422 | Function Loss:  -2.5786\n",
      "Total loss:  -1.5101 | PDE Loss:  -2.3427 | Function Loss:  -2.5792\n",
      "Total loss:  -1.5106 | PDE Loss:  -2.3458 | Function Loss:  -2.5792\n",
      "Total loss:  -1.511 | PDE Loss:  -2.3472 | Function Loss:  -2.5794\n",
      "Total loss:  -1.5114 | PDE Loss:  -2.3512 | Function Loss:  -2.5793\n",
      "Total loss:  -1.5118 | PDE Loss:  -2.3531 | Function Loss:  -2.5794\n",
      "Total loss:  -1.5123 | PDE Loss:  -2.3552 | Function Loss:  -2.5796\n",
      "Total loss:  -1.5126 | PDE Loss:  -2.3569 | Function Loss:  -2.5797\n",
      "Total loss:  -1.5129 | PDE Loss:  -2.3563 | Function Loss:  -2.5802\n",
      "Total loss:  -1.5132 | PDE Loss:  -2.3561 | Function Loss:  -2.5806\n",
      "Total loss:  -1.5135 | PDE Loss:  -2.3552 | Function Loss:  -2.581\n",
      "Total loss:  -1.5136 | PDE Loss:  -2.355 | Function Loss:  -2.5812\n",
      "Total loss:  -1.5137 | PDE Loss:  -2.3551 | Function Loss:  -2.5813\n",
      "Total loss:  -1.5141 | PDE Loss:  -2.3557 | Function Loss:  -2.5816\n",
      "Total loss:  -1.5145 | PDE Loss:  -2.3596 | Function Loss:  -2.5814\n",
      "Total loss:  -1.5149 | PDE Loss:  -2.3633 | Function Loss:  -2.5813\n",
      "Total loss:  -1.5155 | PDE Loss:  -2.369 | Function Loss:  -2.581\n",
      "Total loss:  -1.5161 | PDE Loss:  -2.3757 | Function Loss:  -2.5806\n",
      "Total loss:  -1.5166 | PDE Loss:  -2.3805 | Function Loss:  -2.5805\n",
      "Total loss:  -1.5172 | PDE Loss:  -2.3876 | Function Loss:  -2.5801\n",
      "Total loss:  -1.5176 | PDE Loss:  -2.389 | Function Loss:  -2.5803\n",
      "Total loss:  -1.5181 | PDE Loss:  -2.3886 | Function Loss:  -2.581\n",
      "Total loss:  -1.5185 | PDE Loss:  -2.3872 | Function Loss:  -2.5817\n",
      "Total loss:  -1.5188 | PDE Loss:  -2.3857 | Function Loss:  -2.5822\n",
      "Total loss:  -1.5191 | PDE Loss:  -2.3842 | Function Loss:  -2.5828\n",
      "Total loss:  -1.5198 | PDE Loss:  -2.3842 | Function Loss:  -2.5836\n",
      "Total loss:  -1.5206 | PDE Loss:  -2.3839 | Function Loss:  -2.5846\n",
      "Total loss:  -1.5214 | PDE Loss:  -2.3862 | Function Loss:  -2.5852\n",
      "Total loss:  -1.5226 | PDE Loss:  -2.3918 | Function Loss:  -2.5856\n",
      "Total loss:  -1.5238 | PDE Loss:  -2.3983 | Function Loss:  -2.586\n",
      "Total loss:  -1.5248 | PDE Loss:  -2.409 | Function Loss:  -2.5855\n",
      "Total loss:  -1.5256 | PDE Loss:  -2.4166 | Function Loss:  -2.5853\n",
      "Total loss:  -1.5265 | PDE Loss:  -2.429 | Function Loss:  -2.5846\n",
      "Total loss:  -1.5273 | PDE Loss:  -2.437 | Function Loss:  -2.5843\n",
      "Total loss:  -1.5279 | PDE Loss:  -2.4427 | Function Loss:  -2.5842\n",
      "Total loss:  -1.5283 | PDE Loss:  -2.4456 | Function Loss:  -2.5843\n",
      "Total loss:  -1.5288 | PDE Loss:  -2.4454 | Function Loss:  -2.5849\n",
      "Total loss:  -1.5294 | PDE Loss:  -2.4437 | Function Loss:  -2.5858\n",
      "Total loss:  -1.5303 | PDE Loss:  -2.4397 | Function Loss:  -2.5874\n",
      "Total loss:  -1.5314 | PDE Loss:  -2.4347 | Function Loss:  -2.5893\n",
      "Total loss:  -1.5325 | PDE Loss:  -2.4288 | Function Loss:  -2.5915\n",
      "Total loss:  -1.5336 | PDE Loss:  -2.424 | Function Loss:  -2.5934\n",
      "Total loss:  -1.5348 | PDE Loss:  -2.4172 | Function Loss:  -2.5958\n",
      "Total loss:  -1.5357 | PDE Loss:  -2.4162 | Function Loss:  -2.597\n",
      "Total loss:  -1.5367 | PDE Loss:  -2.4198 | Function Loss:  -2.5977\n",
      "Total loss:  -1.538 | PDE Loss:  -2.4247 | Function Loss:  -2.5984\n",
      "Total loss:  -1.5397 | PDE Loss:  -2.437 | Function Loss:  -2.5985\n",
      "Total loss:  -1.5409 | PDE Loss:  -2.4423 | Function Loss:  -2.5992\n",
      "Total loss:  -1.5422 | PDE Loss:  -2.4461 | Function Loss:  -2.6001\n",
      "Total loss:  -1.5433 | PDE Loss:  -2.4492 | Function Loss:  -2.6009\n",
      "Total loss:  -1.544 | PDE Loss:  -2.4466 | Function Loss:  -2.6021\n",
      "Total loss:  -1.5445 | PDE Loss:  -2.4431 | Function Loss:  -2.6032\n",
      "Total loss:  -1.5452 | PDE Loss:  -2.4389 | Function Loss:  -2.6045\n",
      "Total loss:  -1.5458 | PDE Loss:  -2.4354 | Function Loss:  -2.6057\n",
      "Total loss:  -1.5466 | PDE Loss:  -2.4321 | Function Loss:  -2.6071\n",
      "Total loss:  -1.5475 | PDE Loss:  -2.4295 | Function Loss:  -2.6086\n",
      "Total loss:  -1.5482 | PDE Loss:  -2.4217 | Function Loss:  -2.6106\n",
      "Total loss:  -1.5489 | PDE Loss:  -2.4181 | Function Loss:  -2.612\n",
      "Total loss:  -1.5495 | PDE Loss:  -2.4177 | Function Loss:  -2.6127\n",
      "Total loss:  -1.55 | PDE Loss:  -2.4147 | Function Loss:  -2.6137\n",
      "Total loss:  -1.5506 | PDE Loss:  -2.4123 | Function Loss:  -2.6149\n",
      "Total loss:  -1.5513 | PDE Loss:  -2.4095 | Function Loss:  -2.6161\n",
      "Total loss:  -1.5517 | PDE Loss:  -2.4108 | Function Loss:  -2.6164\n",
      "Total loss:  -1.5521 | PDE Loss:  -2.4104 | Function Loss:  -2.6169\n",
      "Total loss:  -1.5523 | PDE Loss:  -2.4123 | Function Loss:  -2.6169\n",
      "Total loss:  -1.5527 | PDE Loss:  -2.4148 | Function Loss:  -2.6168\n",
      "Total loss:  -1.553 | PDE Loss:  -2.4201 | Function Loss:  -2.6163\n",
      "Total loss:  -1.5533 | PDE Loss:  -2.4222 | Function Loss:  -2.6164\n",
      "Total loss:  -1.5536 | PDE Loss:  -2.4258 | Function Loss:  -2.6162\n",
      "Total loss:  -1.5541 | PDE Loss:  -2.4291 | Function Loss:  -2.6163\n",
      "Total loss:  -1.5549 | PDE Loss:  -2.4327 | Function Loss:  -2.6166\n",
      "Total loss:  -1.5558 | PDE Loss:  -2.4357 | Function Loss:  -2.6172\n",
      "Total loss:  -1.5567 | PDE Loss:  -2.4363 | Function Loss:  -2.6182\n",
      "Total loss:  -1.5578 | PDE Loss:  -2.4372 | Function Loss:  -2.6192\n",
      "Total loss:  -1.559 | PDE Loss:  -2.4352 | Function Loss:  -2.621\n",
      "Total loss:  -1.5607 | PDE Loss:  -2.4343 | Function Loss:  -2.6231\n",
      "Total loss:  -1.5621 | PDE Loss:  -2.4335 | Function Loss:  -2.6248\n",
      "Total loss:  -1.5636 | PDE Loss:  -2.4318 | Function Loss:  -2.6268\n",
      "Total loss:  -1.5644 | PDE Loss:  -2.4351 | Function Loss:  -2.6273\n",
      "Total loss:  -1.5652 | PDE Loss:  -2.4369 | Function Loss:  -2.6279\n",
      "Total loss:  -1.566 | PDE Loss:  -2.4402 | Function Loss:  -2.6283\n",
      "Total loss:  -1.5672 | PDE Loss:  -2.4432 | Function Loss:  -2.6292\n",
      "Total loss:  -1.5681 | PDE Loss:  -2.4463 | Function Loss:  -2.6297\n",
      "Total loss:  -1.5689 | PDE Loss:  -2.4461 | Function Loss:  -2.6307\n",
      "Total loss:  -1.5701 | PDE Loss:  -2.4465 | Function Loss:  -2.632\n",
      "Total loss:  -1.5712 | PDE Loss:  -2.4439 | Function Loss:  -2.6338\n",
      "Total loss:  -1.5723 | PDE Loss:  -2.441 | Function Loss:  -2.6355\n",
      "Total loss:  -1.5734 | PDE Loss:  -2.4354 | Function Loss:  -2.6375\n",
      "Total loss:  -1.574 | PDE Loss:  -2.4298 | Function Loss:  -2.6392\n",
      "Total loss:  -1.5743 | PDE Loss:  -2.4274 | Function Loss:  -2.6399\n",
      "Total loss:  -1.5746 | PDE Loss:  -2.4243 | Function Loss:  -2.6408\n",
      "Total loss:  -1.575 | PDE Loss:  -2.4203 | Function Loss:  -2.6419\n",
      "Total loss:  -1.5753 | PDE Loss:  -2.4168 | Function Loss:  -2.6428\n",
      "Total loss:  -1.5755 | PDE Loss:  -2.4138 | Function Loss:  -2.6436\n",
      "Total loss:  -1.5757 | PDE Loss:  -2.4107 | Function Loss:  -2.6443\n",
      "Total loss:  -1.5759 | PDE Loss:  -2.4083 | Function Loss:  -2.6449\n",
      "Total loss:  -1.5761 | PDE Loss:  -2.4054 | Function Loss:  -2.6457\n",
      "Total loss:  -1.5763 | PDE Loss:  -2.4044 | Function Loss:  -2.6461\n",
      "Total loss:  -1.5766 | PDE Loss:  -2.4039 | Function Loss:  -2.6466\n",
      "Total loss:  -1.5768 | PDE Loss:  -2.4016 | Function Loss:  -2.6472\n",
      "Total loss:  -1.5773 | PDE Loss:  -2.4048 | Function Loss:  -2.6472\n",
      "Total loss:  -1.5777 | PDE Loss:  -2.4089 | Function Loss:  -2.6471\n",
      "Total loss:  -1.5782 | PDE Loss:  -2.4134 | Function Loss:  -2.6469\n",
      "Total loss:  -1.5789 | PDE Loss:  -2.4191 | Function Loss:  -2.6467\n",
      "Total loss:  -1.5798 | PDE Loss:  -2.4247 | Function Loss:  -2.6468\n",
      "Total loss:  -1.581 | PDE Loss:  -2.4334 | Function Loss:  -2.6468\n",
      "Total loss:  -1.5826 | PDE Loss:  -2.4404 | Function Loss:  -2.6475\n",
      "Total loss:  -1.5847 | PDE Loss:  -2.4521 | Function Loss:  -2.6481\n",
      "Total loss:  -1.5868 | PDE Loss:  -2.4601 | Function Loss:  -2.6492\n",
      "Total loss:  -1.5891 | PDE Loss:  -2.4724 | Function Loss:  -2.65\n",
      "Total loss:  -1.5905 | PDE Loss:  -2.4796 | Function Loss:  -2.6505\n",
      "Total loss:  -1.5915 | PDE Loss:  -2.4799 | Function Loss:  -2.6517\n",
      "Total loss:  -1.5921 | PDE Loss:  -2.482 | Function Loss:  -2.652\n",
      "Total loss:  -1.5925 | PDE Loss:  -2.4847 | Function Loss:  -2.652\n",
      "Total loss:  -1.5928 | PDE Loss:  -2.4861 | Function Loss:  -2.6522\n",
      "Total loss:  -1.5933 | PDE Loss:  -2.49 | Function Loss:  -2.6522\n",
      "Total loss:  -1.5939 | PDE Loss:  -2.4915 | Function Loss:  -2.6527\n",
      "Total loss:  -1.5946 | PDE Loss:  -2.4935 | Function Loss:  -2.6532\n",
      "Total loss:  -1.5953 | PDE Loss:  -2.4937 | Function Loss:  -2.654\n",
      "Total loss:  -1.5961 | PDE Loss:  -2.489 | Function Loss:  -2.6556\n",
      "Total loss:  -1.5972 | PDE Loss:  -2.4876 | Function Loss:  -2.657\n",
      "Total loss:  -1.5982 | PDE Loss:  -2.4837 | Function Loss:  -2.6588\n",
      "Total loss:  -1.5997 | PDE Loss:  -2.485 | Function Loss:  -2.6603\n",
      "Total loss:  -1.6011 | PDE Loss:  -2.4816 | Function Loss:  -2.6624\n",
      "Total loss:  -1.6022 | PDE Loss:  -2.4811 | Function Loss:  -2.6638\n",
      "Total loss:  -1.6032 | PDE Loss:  -2.4827 | Function Loss:  -2.6646\n",
      "Total loss:  -1.6043 | PDE Loss:  -2.4876 | Function Loss:  -2.6652\n",
      "Total loss:  -1.6054 | PDE Loss:  -2.496 | Function Loss:  -2.6652\n",
      "Total loss:  -1.6062 | PDE Loss:  -2.4992 | Function Loss:  -2.6656\n",
      "Total loss:  -1.6067 | PDE Loss:  -2.4977 | Function Loss:  -2.6665\n",
      "Total loss:  -1.6072 | PDE Loss:  -2.4966 | Function Loss:  -2.6672\n",
      "Total loss:  -1.6076 | PDE Loss:  -2.492 | Function Loss:  -2.6683\n",
      "Total loss:  -1.6079 | PDE Loss:  -2.4862 | Function Loss:  -2.6695\n",
      "Total loss:  -1.6082 | PDE Loss:  -2.4773 | Function Loss:  -2.6713\n",
      "Total loss:  -1.6084 | PDE Loss:  -2.4725 | Function Loss:  -2.6723\n",
      "Total loss:  -1.6087 | PDE Loss:  -2.4664 | Function Loss:  -2.6736\n",
      "Total loss:  -1.6091 | PDE Loss:  -2.461 | Function Loss:  -2.6749\n",
      "Total loss:  -1.6093 | PDE Loss:  -2.4533 | Function Loss:  -2.6764\n",
      "Total loss:  -1.6095 | PDE Loss:  -2.4525 | Function Loss:  -2.6768\n",
      "Total loss:  -1.6097 | PDE Loss:  -2.453 | Function Loss:  -2.677\n",
      "Total loss:  -1.6102 | PDE Loss:  -2.4552 | Function Loss:  -2.6771\n",
      "Total loss:  -1.6108 | PDE Loss:  -2.4588 | Function Loss:  -2.6772\n",
      "Total loss:  -1.6115 | PDE Loss:  -2.4645 | Function Loss:  -2.6772\n",
      "Total loss:  -1.6125 | PDE Loss:  -2.4707 | Function Loss:  -2.6774\n",
      "Total loss:  -1.6139 | PDE Loss:  -2.4816 | Function Loss:  -2.6772\n",
      "Total loss:  -1.6153 | PDE Loss:  -2.4886 | Function Loss:  -2.6777\n",
      "Total loss:  -1.6172 | PDE Loss:  -2.4962 | Function Loss:  -2.6787\n",
      "Total loss:  -1.6188 | PDE Loss:  -2.4996 | Function Loss:  -2.6801\n",
      "Total loss:  -1.6205 | PDE Loss:  -2.4962 | Function Loss:  -2.6825\n",
      "Total loss:  -1.6219 | PDE Loss:  -2.4914 | Function Loss:  -2.6849\n",
      "Total loss:  -1.6234 | PDE Loss:  -2.4799 | Function Loss:  -2.6885\n",
      "Total loss:  -1.6243 | PDE Loss:  -2.4749 | Function Loss:  -2.6903\n",
      "Total loss:  -1.6263 | PDE Loss:  -2.4732 | Function Loss:  -2.6929\n",
      "Total loss:  -1.6276 | PDE Loss:  -2.4651 | Function Loss:  -2.6958\n",
      "Total loss:  -1.6286 | PDE Loss:  -2.4637 | Function Loss:  -2.6972\n",
      "Total loss:  -1.6295 | PDE Loss:  -2.4626 | Function Loss:  -2.6985\n",
      "Total loss:  -1.6305 | PDE Loss:  -2.4596 | Function Loss:  -2.7001\n",
      "Total loss:  -1.6316 | PDE Loss:  -2.4608 | Function Loss:  -2.7012\n",
      "Total loss:  -1.6324 | PDE Loss:  -2.4575 | Function Loss:  -2.7028\n",
      "Total loss:  -1.6332 | PDE Loss:  -2.456 | Function Loss:  -2.704\n",
      "Total loss:  -1.634 | PDE Loss:  -2.4538 | Function Loss:  -2.7054\n",
      "Total loss:  -1.6349 | PDE Loss:  -2.4524 | Function Loss:  -2.7066\n",
      "Total loss:  -1.6357 | PDE Loss:  -2.4522 | Function Loss:  -2.7076\n",
      "Total loss:  -1.6364 | PDE Loss:  -2.4501 | Function Loss:  -2.7088\n",
      "Total loss:  -1.6371 | PDE Loss:  -2.452 | Function Loss:  -2.7093\n",
      "Total loss:  -1.6378 | PDE Loss:  -2.4556 | Function Loss:  -2.7095\n",
      "Total loss:  -1.6383 | PDE Loss:  -2.4621 | Function Loss:  -2.7089\n",
      "Total loss:  -1.6386 | PDE Loss:  -2.4674 | Function Loss:  -2.7084\n",
      "Total loss:  -1.639 | PDE Loss:  -2.4717 | Function Loss:  -2.708\n",
      "Total loss:  -1.6393 | PDE Loss:  -2.4765 | Function Loss:  -2.7076\n",
      "Total loss:  -1.6399 | PDE Loss:  -2.4811 | Function Loss:  -2.7075\n",
      "Total loss:  -1.6406 | PDE Loss:  -2.4855 | Function Loss:  -2.7075\n",
      "Total loss:  -1.6412 | PDE Loss:  -2.4882 | Function Loss:  -2.7078\n",
      "Total loss:  -1.6416 | PDE Loss:  -2.4883 | Function Loss:  -2.7083\n",
      "Total loss:  -1.6419 | PDE Loss:  -2.4873 | Function Loss:  -2.7088\n",
      "Total loss:  -1.6424 | PDE Loss:  -2.4843 | Function Loss:  -2.7098\n",
      "Total loss:  -1.643 | PDE Loss:  -2.4814 | Function Loss:  -2.711\n",
      "Total loss:  -1.6435 | PDE Loss:  -2.475 | Function Loss:  -2.7128\n",
      "Total loss:  -1.644 | PDE Loss:  -2.4692 | Function Loss:  -2.7144\n",
      "Total loss:  -1.6446 | PDE Loss:  -2.4649 | Function Loss:  -2.7158\n",
      "Total loss:  -1.6451 | PDE Loss:  -2.4604 | Function Loss:  -2.7172\n",
      "Total loss:  -1.6457 | PDE Loss:  -2.4579 | Function Loss:  -2.7184\n",
      "Total loss:  -1.6465 | PDE Loss:  -2.4551 | Function Loss:  -2.7198\n",
      "Total loss:  -1.6473 | PDE Loss:  -2.4524 | Function Loss:  -2.7212\n",
      "Total loss:  -1.648 | PDE Loss:  -2.4529 | Function Loss:  -2.722\n",
      "Total loss:  -1.6487 | PDE Loss:  -2.4534 | Function Loss:  -2.7227\n",
      "Total loss:  -1.6494 | PDE Loss:  -2.4585 | Function Loss:  -2.7227\n",
      "Total loss:  -1.6502 | PDE Loss:  -2.4629 | Function Loss:  -2.7228\n",
      "Total loss:  -1.6511 | PDE Loss:  -2.4692 | Function Loss:  -2.7227\n",
      "Total loss:  -1.6519 | PDE Loss:  -2.4727 | Function Loss:  -2.723\n",
      "Total loss:  -1.6527 | PDE Loss:  -2.4771 | Function Loss:  -2.7231\n",
      "Total loss:  -1.6533 | PDE Loss:  -2.4785 | Function Loss:  -2.7237\n",
      "Total loss:  -1.6539 | PDE Loss:  -2.4796 | Function Loss:  -2.7242\n",
      "Total loss:  -1.6544 | PDE Loss:  -2.4795 | Function Loss:  -2.7248\n",
      "Total loss:  -1.6549 | PDE Loss:  -2.4784 | Function Loss:  -2.7255\n",
      "Total loss:  -1.6553 | PDE Loss:  -2.4781 | Function Loss:  -2.7261\n",
      "Total loss:  -1.6559 | PDE Loss:  -2.4777 | Function Loss:  -2.7269\n",
      "Total loss:  -1.6566 | PDE Loss:  -2.4748 | Function Loss:  -2.7282\n",
      "Total loss:  -1.6573 | PDE Loss:  -2.4746 | Function Loss:  -2.729\n",
      "Total loss:  -1.6577 | PDE Loss:  -2.4763 | Function Loss:  -2.7293\n",
      "Total loss:  -1.6583 | PDE Loss:  -2.4782 | Function Loss:  -2.7295\n",
      "Total loss:  -1.6587 | PDE Loss:  -2.4808 | Function Loss:  -2.7296\n",
      "Total loss:  -1.659 | PDE Loss:  -2.4841 | Function Loss:  -2.7294\n",
      "Total loss:  -1.6592 | PDE Loss:  -2.4844 | Function Loss:  -2.7296\n",
      "Total loss:  -1.6594 | PDE Loss:  -2.485 | Function Loss:  -2.7297\n",
      "Total loss:  -1.6598 | PDE Loss:  -2.4859 | Function Loss:  -2.73\n",
      "Total loss:  -1.6604 | PDE Loss:  -2.4865 | Function Loss:  -2.7306\n",
      "Total loss:  -1.6612 | PDE Loss:  -2.4885 | Function Loss:  -2.7312\n",
      "Total loss:  -1.6623 | PDE Loss:  -2.4894 | Function Loss:  -2.7323\n",
      "Total loss:  -1.6635 | PDE Loss:  -2.4871 | Function Loss:  -2.7341\n",
      "Total loss:  -1.6644 | PDE Loss:  -2.4903 | Function Loss:  -2.7346\n",
      "Total loss:  -1.6655 | PDE Loss:  -2.4883 | Function Loss:  -2.7363\n",
      "Total loss:  -1.6666 | PDE Loss:  -2.4928 | Function Loss:  -2.7368\n",
      "Total loss:  -1.6675 | PDE Loss:  -2.4948 | Function Loss:  -2.7374\n",
      "Total loss:  -1.6683 | PDE Loss:  -2.4955 | Function Loss:  -2.7383\n",
      "Total loss:  -1.6691 | PDE Loss:  -2.4981 | Function Loss:  -2.7387\n",
      "Total loss:  -1.6698 | PDE Loss:  -2.4981 | Function Loss:  -2.7396\n",
      "Total loss:  -1.6705 | PDE Loss:  -2.4999 | Function Loss:  -2.7401\n",
      "Total loss:  -1.671 | PDE Loss:  -2.4998 | Function Loss:  -2.7407\n",
      "Total loss:  -1.6713 | PDE Loss:  -2.4993 | Function Loss:  -2.7412\n",
      "Total loss:  -1.6717 | PDE Loss:  -2.4988 | Function Loss:  -2.7417\n",
      "Total loss:  -1.672 | PDE Loss:  -2.4973 | Function Loss:  -2.7423\n",
      "Total loss:  -1.6723 | PDE Loss:  -2.497 | Function Loss:  -2.7427\n",
      "Total loss:  -1.6725 | PDE Loss:  -2.4959 | Function Loss:  -2.7432\n",
      "Total loss:  -1.6728 | PDE Loss:  -2.4966 | Function Loss:  -2.7434\n",
      "Total loss:  -1.6731 | PDE Loss:  -2.4971 | Function Loss:  -2.7436\n",
      "Total loss:  -1.6734 | PDE Loss:  -2.4995 | Function Loss:  -2.7436\n",
      "Total loss:  -1.6739 | PDE Loss:  -2.5009 | Function Loss:  -2.7439\n",
      "Total loss:  -1.6742 | PDE Loss:  -2.512 | Function Loss:  -2.7424\n",
      "Total loss:  -1.6748 | PDE Loss:  -2.5124 | Function Loss:  -2.743\n",
      "Total loss:  -1.6754 | PDE Loss:  -2.5123 | Function Loss:  -2.7437\n",
      "Total loss:  -1.676 | PDE Loss:  -2.5094 | Function Loss:  -2.745\n",
      "Total loss:  -1.6766 | PDE Loss:  -2.5078 | Function Loss:  -2.7459\n",
      "Total loss:  -1.6769 | PDE Loss:  -2.5073 | Function Loss:  -2.7464\n",
      "Total loss:  -1.6773 | PDE Loss:  -2.504 | Function Loss:  -2.7474\n",
      "Total loss:  -1.6776 | PDE Loss:  -2.504 | Function Loss:  -2.7478\n",
      "Total loss:  -1.6781 | PDE Loss:  -2.5019 | Function Loss:  -2.7487\n",
      "Total loss:  -1.6786 | PDE Loss:  -2.5009 | Function Loss:  -2.7495\n",
      "Total loss:  -1.6791 | PDE Loss:  -2.5001 | Function Loss:  -2.7502\n",
      "Total loss:  -1.6798 | PDE Loss:  -2.4997 | Function Loss:  -2.7511\n",
      "Total loss:  -1.6804 | PDE Loss:  -2.4994 | Function Loss:  -2.7519\n",
      "Total loss:  -1.681 | PDE Loss:  -2.5012 | Function Loss:  -2.7522\n",
      "Total loss:  -1.6815 | PDE Loss:  -2.503 | Function Loss:  -2.7525\n",
      "Total loss:  -1.6819 | PDE Loss:  -2.5041 | Function Loss:  -2.7527\n",
      "Total loss:  -1.6823 | PDE Loss:  -2.5076 | Function Loss:  -2.7527\n",
      "Total loss:  -1.683 | PDE Loss:  -2.5139 | Function Loss:  -2.7524\n",
      "Total loss:  -1.6837 | PDE Loss:  -2.5172 | Function Loss:  -2.7526\n",
      "Total loss:  -1.6848 | PDE Loss:  -2.5249 | Function Loss:  -2.7526\n",
      "Total loss:  -1.6866 | PDE Loss:  -2.5304 | Function Loss:  -2.7537\n",
      "Total loss:  -1.6884 | PDE Loss:  -2.538 | Function Loss:  -2.7546\n",
      "Total loss:  -1.6901 | PDE Loss:  -2.5407 | Function Loss:  -2.7561\n",
      "Total loss:  -1.6916 | PDE Loss:  -2.5397 | Function Loss:  -2.758\n",
      "Total loss:  -1.693 | PDE Loss:  -2.5394 | Function Loss:  -2.7598\n",
      "Total loss:  -1.6945 | PDE Loss:  -2.5384 | Function Loss:  -2.7616\n",
      "Total loss:  -1.6962 | PDE Loss:  -2.5392 | Function Loss:  -2.7635\n",
      "Total loss:  -1.6983 | PDE Loss:  -2.5393 | Function Loss:  -2.766\n",
      "Total loss:  -1.7 | PDE Loss:  -2.5467 | Function Loss:  -2.7667\n",
      "Total loss:  -1.7009 | PDE Loss:  -2.5469 | Function Loss:  -2.7677\n",
      "Total loss:  -1.7016 | PDE Loss:  -2.5496 | Function Loss:  -2.768\n",
      "Total loss:  -1.7022 | PDE Loss:  -2.5509 | Function Loss:  -2.7686\n",
      "Total loss:  -1.7028 | PDE Loss:  -2.5525 | Function Loss:  -2.769\n",
      "Total loss:  -1.7033 | PDE Loss:  -2.5518 | Function Loss:  -2.7696\n",
      "Total loss:  -1.7035 | PDE Loss:  -2.5527 | Function Loss:  -2.7698\n",
      "Total loss:  -1.7037 | PDE Loss:  -2.5516 | Function Loss:  -2.7701\n",
      "Total loss:  -1.7038 | PDE Loss:  -2.552 | Function Loss:  -2.7702\n",
      "Total loss:  -1.7039 | PDE Loss:  -2.5523 | Function Loss:  -2.7703\n",
      "Total loss:  -1.704 | PDE Loss:  -2.5529 | Function Loss:  -2.7703\n",
      "Total loss:  -1.7042 | PDE Loss:  -2.5539 | Function Loss:  -2.7703\n",
      "Total loss:  -1.7044 | PDE Loss:  -2.5554 | Function Loss:  -2.7704\n",
      "Total loss:  -1.7047 | PDE Loss:  -2.5585 | Function Loss:  -2.7702\n",
      "Total loss:  -1.705 | PDE Loss:  -2.5612 | Function Loss:  -2.7701\n",
      "Total loss:  -1.7054 | PDE Loss:  -2.5654 | Function Loss:  -2.7699\n",
      "Total loss:  -1.7058 | PDE Loss:  -2.5688 | Function Loss:  -2.7698\n",
      "Total loss:  -1.7062 | PDE Loss:  -2.5731 | Function Loss:  -2.7697\n",
      "Total loss:  -1.7068 | PDE Loss:  -2.5779 | Function Loss:  -2.7695\n",
      "Total loss:  -1.7075 | PDE Loss:  -2.5833 | Function Loss:  -2.7695\n",
      "Total loss:  -1.7082 | PDE Loss:  -2.5864 | Function Loss:  -2.7699\n",
      "Total loss:  -1.709 | PDE Loss:  -2.5908 | Function Loss:  -2.7701\n",
      "Total loss:  -1.7098 | PDE Loss:  -2.5923 | Function Loss:  -2.7708\n",
      "Total loss:  -1.7107 | PDE Loss:  -2.5953 | Function Loss:  -2.7714\n",
      "Total loss:  -1.7116 | PDE Loss:  -2.5997 | Function Loss:  -2.7718\n",
      "Total loss:  -1.7128 | PDE Loss:  -2.6017 | Function Loss:  -2.7729\n",
      "Total loss:  -1.7139 | PDE Loss:  -2.6032 | Function Loss:  -2.7739\n",
      "Total loss:  -1.7148 | PDE Loss:  -2.6011 | Function Loss:  -2.7752\n",
      "Total loss:  -1.7153 | PDE Loss:  -2.5991 | Function Loss:  -2.7762\n",
      "Total loss:  -1.716 | PDE Loss:  -2.5971 | Function Loss:  -2.7772\n",
      "Total loss:  -1.7167 | PDE Loss:  -2.5946 | Function Loss:  -2.7784\n",
      "Total loss:  -1.7173 | PDE Loss:  -2.5921 | Function Loss:  -2.7795\n",
      "Total loss:  -1.718 | PDE Loss:  -2.5893 | Function Loss:  -2.7807\n",
      "Total loss:  -1.7187 | PDE Loss:  -2.5869 | Function Loss:  -2.7819\n",
      "Total loss:  -1.7197 | PDE Loss:  -2.5841 | Function Loss:  -2.7835\n",
      "Total loss:  -1.7208 | PDE Loss:  -2.5819 | Function Loss:  -2.7851\n",
      "Total loss:  -1.7217 | PDE Loss:  -2.5793 | Function Loss:  -2.7866\n",
      "Total loss:  -1.7225 | PDE Loss:  -2.5785 | Function Loss:  -2.7876\n",
      "Total loss:  -1.7231 | PDE Loss:  -2.5781 | Function Loss:  -2.7884\n",
      "Total loss:  -1.7237 | PDE Loss:  -2.578 | Function Loss:  -2.7891\n",
      "Total loss:  -1.7244 | PDE Loss:  -2.5767 | Function Loss:  -2.7901\n",
      "Total loss:  -1.7251 | PDE Loss:  -2.5769 | Function Loss:  -2.7909\n",
      "Total loss:  -1.7258 | PDE Loss:  -2.577 | Function Loss:  -2.7918\n",
      "Total loss:  -1.727 | PDE Loss:  -2.5772 | Function Loss:  -2.7931\n",
      "Total loss:  -1.7278 | PDE Loss:  -2.5764 | Function Loss:  -2.7942\n",
      "Total loss:  -1.7284 | PDE Loss:  -2.5778 | Function Loss:  -2.7946\n",
      "Total loss:  -1.729 | PDE Loss:  -2.5816 | Function Loss:  -2.7947\n",
      "Total loss:  -1.7298 | PDE Loss:  -2.5866 | Function Loss:  -2.7948\n",
      "Total loss:  -1.7305 | PDE Loss:  -2.5896 | Function Loss:  -2.7951\n",
      "Total loss:  -1.7311 | PDE Loss:  -2.5934 | Function Loss:  -2.7952\n",
      "Total loss:  -1.7317 | PDE Loss:  -2.5922 | Function Loss:  -2.7961\n",
      "Total loss:  -1.7322 | PDE Loss:  -2.5951 | Function Loss:  -2.7962\n",
      "Total loss:  -1.7326 | PDE Loss:  -2.5943 | Function Loss:  -2.7968\n",
      "Total loss:  -1.7332 | PDE Loss:  -2.5889 | Function Loss:  -2.7984\n",
      "Total loss:  -1.7337 | PDE Loss:  -2.5863 | Function Loss:  -2.7994\n",
      "Total loss:  -1.7339 | PDE Loss:  -2.5857 | Function Loss:  -2.7998\n",
      "Total loss:  -1.7341 | PDE Loss:  -2.5847 | Function Loss:  -2.8001\n",
      "Total loss:  -1.7343 | PDE Loss:  -2.5832 | Function Loss:  -2.8006\n",
      "Total loss:  -1.7344 | PDE Loss:  -2.5827 | Function Loss:  -2.8009\n",
      "Total loss:  -1.7347 | PDE Loss:  -2.5821 | Function Loss:  -2.8013\n",
      "Total loss:  -1.7351 | PDE Loss:  -2.5822 | Function Loss:  -2.8018\n",
      "Total loss:  -1.7359 | PDE Loss:  -2.5739 | Function Loss:  -2.804\n",
      "Total loss:  -1.7364 | PDE Loss:  -2.5774 | Function Loss:  -2.804\n",
      "Total loss:  -1.7374 | PDE Loss:  -2.5813 | Function Loss:  -2.8045\n",
      "Total loss:  -1.7384 | PDE Loss:  -2.5767 | Function Loss:  -2.8064\n",
      "Total loss:  -1.7395 | PDE Loss:  -2.5791 | Function Loss:  -2.8073\n",
      "Total loss:  -1.7405 | PDE Loss:  -2.5819 | Function Loss:  -2.8081\n",
      "Total loss:  -1.7418 | PDE Loss:  -2.5887 | Function Loss:  -2.8085\n",
      "Total loss:  -1.7433 | PDE Loss:  -2.5927 | Function Loss:  -2.8096\n",
      "Total loss:  -1.7451 | PDE Loss:  -2.6022 | Function Loss:  -2.8101\n",
      "Total loss:  -1.7462 | PDE Loss:  -2.6068 | Function Loss:  -2.8106\n",
      "Total loss:  -1.7475 | PDE Loss:  -2.6083 | Function Loss:  -2.8118\n",
      "Total loss:  -1.7486 | PDE Loss:  -2.6121 | Function Loss:  -2.8126\n",
      "Total loss:  -1.7493 | PDE Loss:  -2.6147 | Function Loss:  -2.813\n",
      "Total loss:  -1.75 | PDE Loss:  -2.6163 | Function Loss:  -2.8136\n",
      "Total loss:  -1.7508 | PDE Loss:  -2.6221 | Function Loss:  -2.8135\n",
      "Total loss:  -1.7514 | PDE Loss:  -2.6236 | Function Loss:  -2.814\n",
      "Total loss:  -1.7522 | PDE Loss:  -2.6265 | Function Loss:  -2.8144\n",
      "Total loss:  -1.7531 | PDE Loss:  -2.6296 | Function Loss:  -2.8151\n",
      "Total loss:  -1.754 | PDE Loss:  -2.6313 | Function Loss:  -2.8158\n",
      "Total loss:  -1.7547 | PDE Loss:  -2.6316 | Function Loss:  -2.8166\n",
      "Total loss:  -1.7554 | PDE Loss:  -2.6304 | Function Loss:  -2.8176\n",
      "Total loss:  -1.7559 | PDE Loss:  -2.6295 | Function Loss:  -2.8183\n",
      "Total loss:  -1.7564 | PDE Loss:  -2.6294 | Function Loss:  -2.8189\n",
      "Total loss:  -1.7568 | PDE Loss:  -2.6283 | Function Loss:  -2.8195\n",
      "Total loss:  -1.7571 | PDE Loss:  -2.6297 | Function Loss:  -2.8196\n",
      "Total loss:  -1.7573 | PDE Loss:  -2.6293 | Function Loss:  -2.8199\n",
      "Total loss:  -1.7574 | PDE Loss:  -2.63 | Function Loss:  -2.82\n",
      "Total loss:  -1.7576 | PDE Loss:  -2.6311 | Function Loss:  -2.82\n",
      "Total loss:  -1.7577 | PDE Loss:  -2.6321 | Function Loss:  -2.8199\n",
      "Total loss:  -1.7578 | PDE Loss:  -2.6327 | Function Loss:  -2.82\n",
      "Total loss:  -1.7579 | PDE Loss:  -2.633 | Function Loss:  -2.8201\n",
      "Total loss:  -1.7581 | PDE Loss:  -2.6322 | Function Loss:  -2.8204\n",
      "Total loss:  -1.7583 | PDE Loss:  -2.6297 | Function Loss:  -2.821\n",
      "Total loss:  -1.7584 | PDE Loss:  -2.6289 | Function Loss:  -2.8213\n",
      "Total loss:  -1.7587 | PDE Loss:  -2.6258 | Function Loss:  -2.8221\n",
      "Total loss:  -1.7589 | PDE Loss:  -2.6225 | Function Loss:  -2.8229\n",
      "Total loss:  -1.7592 | PDE Loss:  -2.6194 | Function Loss:  -2.8236\n",
      "Total loss:  -1.7594 | PDE Loss:  -2.6167 | Function Loss:  -2.8244\n",
      "Total loss:  -1.7599 | PDE Loss:  -2.6137 | Function Loss:  -2.8254\n",
      "Total loss:  -1.7603 | PDE Loss:  -2.6056 | Function Loss:  -2.8272\n",
      "Total loss:  -1.7611 | PDE Loss:  -2.6075 | Function Loss:  -2.8278\n",
      "Total loss:  -1.7618 | PDE Loss:  -2.6112 | Function Loss:  -2.828\n",
      "Total loss:  -1.7628 | PDE Loss:  -2.6187 | Function Loss:  -2.8279\n",
      "Total loss:  -1.7635 | PDE Loss:  -2.6241 | Function Loss:  -2.8279\n",
      "Total loss:  -1.764 | PDE Loss:  -2.6287 | Function Loss:  -2.8278\n",
      "Total loss:  -1.7645 | PDE Loss:  -2.6313 | Function Loss:  -2.8279\n",
      "Total loss:  -1.7649 | PDE Loss:  -2.6326 | Function Loss:  -2.8282\n",
      "Total loss:  -1.7654 | PDE Loss:  -2.6331 | Function Loss:  -2.8287\n",
      "Total loss:  -1.7659 | PDE Loss:  -2.6306 | Function Loss:  -2.8297\n",
      "Total loss:  -1.7666 | PDE Loss:  -2.6284 | Function Loss:  -2.8309\n",
      "Total loss:  -1.7674 | PDE Loss:  -2.6234 | Function Loss:  -2.8326\n",
      "Total loss:  -1.7684 | PDE Loss:  -2.6254 | Function Loss:  -2.8334\n",
      "Total loss:  -1.7694 | PDE Loss:  -2.6205 | Function Loss:  -2.8354\n",
      "Total loss:  -1.7711 | PDE Loss:  -2.6174 | Function Loss:  -2.8379\n",
      "Total loss:  -1.773 | PDE Loss:  -2.6148 | Function Loss:  -2.8405\n",
      "Total loss:  -1.7748 | PDE Loss:  -2.6187 | Function Loss:  -2.842\n",
      "Total loss:  -1.776 | PDE Loss:  -2.6228 | Function Loss:  -2.8427\n",
      "Total loss:  -1.7778 | PDE Loss:  -2.6353 | Function Loss:  -2.8427\n",
      "Total loss:  -1.779 | PDE Loss:  -2.6357 | Function Loss:  -2.844\n",
      "Total loss:  -1.7801 | PDE Loss:  -2.6422 | Function Loss:  -2.8443\n",
      "Total loss:  -1.7816 | PDE Loss:  -2.6556 | Function Loss:  -2.8439\n",
      "Total loss:  -1.7827 | PDE Loss:  -2.6617 | Function Loss:  -2.8443\n",
      "Total loss:  -1.7837 | PDE Loss:  -2.6659 | Function Loss:  -2.8447\n",
      "Total loss:  -1.7846 | PDE Loss:  -2.6662 | Function Loss:  -2.8458\n",
      "Total loss:  -1.7853 | PDE Loss:  -2.6693 | Function Loss:  -2.8461\n",
      "Total loss:  -1.7856 | PDE Loss:  -2.6721 | Function Loss:  -2.846\n",
      "Total loss:  -1.7859 | PDE Loss:  -2.6714 | Function Loss:  -2.8464\n",
      "Total loss:  -1.786 | PDE Loss:  -2.6719 | Function Loss:  -2.8465\n",
      "Total loss:  -1.7862 | PDE Loss:  -2.6726 | Function Loss:  -2.8467\n",
      "Total loss:  -1.7864 | PDE Loss:  -2.6741 | Function Loss:  -2.8466\n",
      "Total loss:  -1.7866 | PDE Loss:  -2.6744 | Function Loss:  -2.8468\n",
      "Total loss:  -1.7868 | PDE Loss:  -2.6759 | Function Loss:  -2.8468\n",
      "Total loss:  -1.7871 | PDE Loss:  -2.6756 | Function Loss:  -2.8472\n",
      "Total loss:  -1.7873 | PDE Loss:  -2.6747 | Function Loss:  -2.8476\n",
      "Total loss:  -1.7876 | PDE Loss:  -2.6725 | Function Loss:  -2.8483\n",
      "Total loss:  -1.7878 | PDE Loss:  -2.6696 | Function Loss:  -2.849\n",
      "Total loss:  -1.7881 | PDE Loss:  -2.6618 | Function Loss:  -2.8505\n",
      "Total loss:  -1.7884 | PDE Loss:  -2.6591 | Function Loss:  -2.8512\n",
      "Total loss:  -1.7886 | PDE Loss:  -2.6564 | Function Loss:  -2.8519\n",
      "Total loss:  -1.7891 | PDE Loss:  -2.652 | Function Loss:  -2.8531\n",
      "Total loss:  -1.7895 | PDE Loss:  -2.6477 | Function Loss:  -2.8543\n",
      "Total loss:  -1.7899 | PDE Loss:  -2.6441 | Function Loss:  -2.8553\n",
      "Total loss:  -1.7902 | PDE Loss:  -2.6413 | Function Loss:  -2.8562\n",
      "Total loss:  -1.7905 | PDE Loss:  -2.6391 | Function Loss:  -2.8569\n",
      "Total loss:  -1.7909 | PDE Loss:  -2.6402 | Function Loss:  -2.8571\n",
      "Total loss:  -1.7913 | PDE Loss:  -2.6404 | Function Loss:  -2.8576\n",
      "Total loss:  -1.7918 | PDE Loss:  -2.6423 | Function Loss:  -2.8578\n",
      "Total loss:  -1.792 | PDE Loss:  -2.6456 | Function Loss:  -2.8576\n",
      "Total loss:  -1.7927 | PDE Loss:  -2.6479 | Function Loss:  -2.858\n",
      "Total loss:  -1.7934 | PDE Loss:  -2.6498 | Function Loss:  -2.8585\n",
      "Total loss:  -1.7941 | PDE Loss:  -2.652 | Function Loss:  -2.8589\n",
      "Total loss:  -1.7947 | PDE Loss:  -2.6535 | Function Loss:  -2.8594\n",
      "Total loss:  -1.7951 | PDE Loss:  -2.6556 | Function Loss:  -2.8595\n",
      "Total loss:  -1.7955 | PDE Loss:  -2.6582 | Function Loss:  -2.8596\n",
      "Total loss:  -1.796 | PDE Loss:  -2.6606 | Function Loss:  -2.8598\n",
      "Total loss:  -1.7966 | PDE Loss:  -2.6659 | Function Loss:  -2.8597\n",
      "Total loss:  -1.7967 | PDE Loss:  -2.6548 | Function Loss:  -2.8615\n",
      "Total loss:  -1.7969 | PDE Loss:  -2.6614 | Function Loss:  -2.8607\n",
      "Total loss:  -1.7975 | PDE Loss:  -2.6667 | Function Loss:  -2.8605\n",
      "Total loss:  -1.7978 | PDE Loss:  -2.6694 | Function Loss:  -2.8605\n",
      "Total loss:  -1.7983 | PDE Loss:  -2.6709 | Function Loss:  -2.8608\n",
      "Total loss:  -1.7987 | PDE Loss:  -2.6722 | Function Loss:  -2.8611\n",
      "Total loss:  -1.7991 | PDE Loss:  -2.6727 | Function Loss:  -2.8614\n",
      "Total loss:  -1.7993 | PDE Loss:  -2.6719 | Function Loss:  -2.8619\n",
      "Total loss:  -1.7996 | PDE Loss:  -2.6716 | Function Loss:  -2.8622\n",
      "Total loss:  -1.7998 | PDE Loss:  -2.6703 | Function Loss:  -2.8626\n",
      "Total loss:  -1.8 | PDE Loss:  -2.6698 | Function Loss:  -2.8629\n",
      "Total loss:  -1.8001 | PDE Loss:  -2.6689 | Function Loss:  -2.8632\n",
      "Total loss:  -1.8003 | PDE Loss:  -2.6684 | Function Loss:  -2.8635\n",
      "Total loss:  -1.8004 | PDE Loss:  -2.6686 | Function Loss:  -2.8636\n",
      "Total loss:  -1.8006 | PDE Loss:  -2.6683 | Function Loss:  -2.8639\n",
      "Total loss:  -1.8009 | PDE Loss:  -2.6696 | Function Loss:  -2.864\n",
      "Total loss:  -1.8012 | PDE Loss:  -2.6698 | Function Loss:  -2.8643\n",
      "Total loss:  -1.8014 | PDE Loss:  -2.6708 | Function Loss:  -2.8644\n",
      "Total loss:  -1.8016 | PDE Loss:  -2.6713 | Function Loss:  -2.8646\n",
      "Total loss:  -1.8018 | PDE Loss:  -2.6721 | Function Loss:  -2.8646\n",
      "Total loss:  -1.8019 | PDE Loss:  -2.6726 | Function Loss:  -2.8647\n",
      "Total loss:  -1.802 | PDE Loss:  -2.6733 | Function Loss:  -2.8647\n",
      "Total loss:  -1.8021 | PDE Loss:  -2.6744 | Function Loss:  -2.8647\n",
      "Total loss:  -1.8024 | PDE Loss:  -2.6762 | Function Loss:  -2.8647\n",
      "Total loss:  -1.8027 | PDE Loss:  -2.6779 | Function Loss:  -2.8648\n",
      "Total loss:  -1.802 | PDE Loss:  -2.6808 | Function Loss:  -2.8636\n",
      "Total loss:  -1.8031 | PDE Loss:  -2.6821 | Function Loss:  -2.8647\n",
      "Total loss:  -1.8035 | PDE Loss:  -2.6841 | Function Loss:  -2.8648\n",
      "Total loss:  -1.8046 | PDE Loss:  -2.689 | Function Loss:  -2.8653\n",
      "Total loss:  -1.8056 | PDE Loss:  -2.6944 | Function Loss:  -2.8657\n",
      "Total loss:  -1.8066 | PDE Loss:  -2.6985 | Function Loss:  -2.8662\n",
      "Total loss:  -1.8075 | PDE Loss:  -2.7035 | Function Loss:  -2.8666\n",
      "Total loss:  -1.8085 | PDE Loss:  -2.705 | Function Loss:  -2.8675\n",
      "Total loss:  -1.8094 | PDE Loss:  -2.7101 | Function Loss:  -2.8677\n",
      "Total loss:  -1.8098 | PDE Loss:  -2.709 | Function Loss:  -2.8684\n",
      "Total loss:  -1.8104 | PDE Loss:  -2.7068 | Function Loss:  -2.8693\n",
      "Total loss:  -1.8108 | PDE Loss:  -2.707 | Function Loss:  -2.8698\n",
      "Total loss:  -1.8111 | PDE Loss:  -2.7059 | Function Loss:  -2.8703\n",
      "Total loss:  -1.8114 | PDE Loss:  -2.7043 | Function Loss:  -2.8709\n",
      "Total loss:  -1.8117 | PDE Loss:  -2.7029 | Function Loss:  -2.8714\n",
      "Total loss:  -1.8119 | PDE Loss:  -2.7012 | Function Loss:  -2.8718\n",
      "Total loss:  -1.8121 | PDE Loss:  -2.6998 | Function Loss:  -2.8723\n",
      "Total loss:  -1.8123 | PDE Loss:  -2.699 | Function Loss:  -2.8726\n",
      "Total loss:  -1.8125 | PDE Loss:  -2.6974 | Function Loss:  -2.8731\n",
      "Total loss:  -1.8126 | PDE Loss:  -2.6976 | Function Loss:  -2.8733\n",
      "Total loss:  -1.8127 | PDE Loss:  -2.6972 | Function Loss:  -2.8735\n",
      "Total loss:  -1.8129 | PDE Loss:  -2.698 | Function Loss:  -2.8735\n",
      "Total loss:  -1.8131 | PDE Loss:  -2.698 | Function Loss:  -2.8737\n",
      "Total loss:  -1.8132 | PDE Loss:  -2.6985 | Function Loss:  -2.8738\n",
      "Total loss:  -1.8134 | PDE Loss:  -2.6989 | Function Loss:  -2.874\n",
      "Total loss:  -1.8137 | PDE Loss:  -2.6992 | Function Loss:  -2.8743\n",
      "Total loss:  -1.814 | PDE Loss:  -2.6993 | Function Loss:  -2.8746\n",
      "Total loss:  -1.8143 | PDE Loss:  -2.6991 | Function Loss:  -2.875\n",
      "Total loss:  -1.8147 | PDE Loss:  -2.6988 | Function Loss:  -2.8754\n",
      "Total loss:  -1.8148 | PDE Loss:  -2.7022 | Function Loss:  -2.8751\n",
      "Total loss:  -1.8152 | PDE Loss:  -2.699 | Function Loss:  -2.876\n",
      "Total loss:  -1.8156 | PDE Loss:  -2.6996 | Function Loss:  -2.8763\n",
      "Total loss:  -1.8159 | PDE Loss:  -2.6992 | Function Loss:  -2.8768\n",
      "Total loss:  -1.8161 | PDE Loss:  -2.6996 | Function Loss:  -2.877\n",
      "Total loss:  -1.8163 | PDE Loss:  -2.7002 | Function Loss:  -2.8772\n",
      "Total loss:  -1.8165 | PDE Loss:  -2.7009 | Function Loss:  -2.8772\n",
      "Total loss:  -1.8166 | PDE Loss:  -2.7012 | Function Loss:  -2.8773\n",
      "Total loss:  -1.8167 | PDE Loss:  -2.7015 | Function Loss:  -2.8774\n",
      "Total loss:  -1.8168 | PDE Loss:  -2.7016 | Function Loss:  -2.8775\n",
      "Total loss:  -1.8171 | PDE Loss:  -2.702 | Function Loss:  -2.8777\n",
      "Total loss:  -1.8174 | PDE Loss:  -2.702 | Function Loss:  -2.8781\n",
      "Total loss:  -1.8178 | PDE Loss:  -2.7026 | Function Loss:  -2.8785\n",
      "Total loss:  -1.8183 | PDE Loss:  -2.7012 | Function Loss:  -2.8792\n",
      "Total loss:  -1.8174 | PDE Loss:  -2.6893 | Function Loss:  -2.88\n",
      "Total loss:  -1.8186 | PDE Loss:  -2.6995 | Function Loss:  -2.8798\n",
      "Total loss:  -1.8191 | PDE Loss:  -2.7016 | Function Loss:  -2.8801\n",
      "Total loss:  -1.82 | PDE Loss:  -2.7035 | Function Loss:  -2.8808\n",
      "Total loss:  -1.8209 | PDE Loss:  -2.7049 | Function Loss:  -2.8817\n",
      "Total loss:  -1.8217 | PDE Loss:  -2.7029 | Function Loss:  -2.8829\n",
      "Total loss:  -1.8224 | PDE Loss:  -2.7024 | Function Loss:  -2.8838\n",
      "Total loss:  -1.823 | PDE Loss:  -2.7009 | Function Loss:  -2.8847\n",
      "Total loss:  -1.8239 | PDE Loss:  -2.701 | Function Loss:  -2.8857\n",
      "Total loss:  -1.8246 | PDE Loss:  -2.6978 | Function Loss:  -2.887\n",
      "Total loss:  -1.8251 | PDE Loss:  -2.6999 | Function Loss:  -2.8873\n",
      "Total loss:  -1.8256 | PDE Loss:  -2.7014 | Function Loss:  -2.8876\n",
      "Total loss:  -1.8261 | PDE Loss:  -2.7052 | Function Loss:  -2.8877\n",
      "Total loss:  -1.8266 | PDE Loss:  -2.7054 | Function Loss:  -2.8882\n",
      "Total loss:  -1.8269 | PDE Loss:  -2.7059 | Function Loss:  -2.8884\n",
      "Total loss:  -1.8272 | PDE Loss:  -2.7063 | Function Loss:  -2.8888\n",
      "Total loss:  -1.8276 | PDE Loss:  -2.7056 | Function Loss:  -2.8893\n",
      "Total loss:  -1.828 | PDE Loss:  -2.7049 | Function Loss:  -2.8898\n",
      "Total loss:  -1.8282 | PDE Loss:  -2.7031 | Function Loss:  -2.8903\n",
      "Total loss:  -1.8284 | PDE Loss:  -2.7016 | Function Loss:  -2.8908\n",
      "Total loss:  -1.8277 | PDE Loss:  -2.6944 | Function Loss:  -2.8911\n",
      "Total loss:  -1.8284 | PDE Loss:  -2.701 | Function Loss:  -2.891\n",
      "Total loss:  -1.8286 | PDE Loss:  -2.6983 | Function Loss:  -2.8916\n",
      "Total loss:  -1.8287 | PDE Loss:  -2.697 | Function Loss:  -2.8919\n",
      "Total loss:  -1.8289 | PDE Loss:  -2.6955 | Function Loss:  -2.8923\n",
      "Total loss:  -1.829 | PDE Loss:  -2.6944 | Function Loss:  -2.8927\n",
      "Total loss:  -1.8292 | PDE Loss:  -2.6935 | Function Loss:  -2.893\n",
      "Total loss:  -1.8294 | PDE Loss:  -2.6917 | Function Loss:  -2.8935\n",
      "Total loss:  -1.8296 | PDE Loss:  -2.6903 | Function Loss:  -2.8939\n",
      "Total loss:  -1.8297 | PDE Loss:  -2.6916 | Function Loss:  -2.8939\n",
      "Total loss:  -1.8299 | PDE Loss:  -2.6933 | Function Loss:  -2.8938\n",
      "Total loss:  -1.83 | PDE Loss:  -2.6942 | Function Loss:  -2.8939\n",
      "Total loss:  -1.8302 | PDE Loss:  -2.6949 | Function Loss:  -2.8939\n",
      "Total loss:  -1.8303 | PDE Loss:  -2.6949 | Function Loss:  -2.8941\n",
      "Total loss:  -1.8306 | PDE Loss:  -2.6947 | Function Loss:  -2.8944\n",
      "Total loss:  -1.8309 | PDE Loss:  -2.6941 | Function Loss:  -2.8949\n",
      "Total loss:  -1.8312 | PDE Loss:  -2.6935 | Function Loss:  -2.8953\n",
      "Total loss:  -1.8315 | PDE Loss:  -2.6929 | Function Loss:  -2.8958\n",
      "Total loss:  -1.8319 | PDE Loss:  -2.6936 | Function Loss:  -2.8961\n",
      "Total loss:  -1.8321 | PDE Loss:  -2.6927 | Function Loss:  -2.8966\n",
      "Total loss:  -1.8324 | PDE Loss:  -2.6938 | Function Loss:  -2.8967\n",
      "Total loss:  -1.8325 | PDE Loss:  -2.6942 | Function Loss:  -2.8967\n",
      "Total loss:  -1.8326 | PDE Loss:  -2.6948 | Function Loss:  -2.8968\n",
      "Total loss:  -1.8328 | PDE Loss:  -2.6953 | Function Loss:  -2.8969\n",
      "Total loss:  -1.8329 | PDE Loss:  -2.6957 | Function Loss:  -2.897\n",
      "Total loss:  -1.8331 | PDE Loss:  -2.6951 | Function Loss:  -2.8973\n",
      "Total loss:  -1.8332 | PDE Loss:  -2.6939 | Function Loss:  -2.8976\n",
      "Total loss:  -1.8333 | PDE Loss:  -2.6937 | Function Loss:  -2.8977\n",
      "Total loss:  -1.8334 | PDE Loss:  -2.6926 | Function Loss:  -2.8981\n",
      "Total loss:  -1.8336 | PDE Loss:  -2.6921 | Function Loss:  -2.8983\n",
      "Total loss:  -1.8337 | PDE Loss:  -2.6909 | Function Loss:  -2.8987\n",
      "Total loss:  -1.8338 | PDE Loss:  -2.6902 | Function Loss:  -2.8989\n",
      "Total loss:  -1.8339 | PDE Loss:  -2.6893 | Function Loss:  -2.8992\n",
      "Total loss:  -1.834 | PDE Loss:  -2.689 | Function Loss:  -2.8993\n",
      "Total loss:  -1.8341 | PDE Loss:  -2.689 | Function Loss:  -2.8994\n",
      "Total loss:  -1.8342 | PDE Loss:  -2.6889 | Function Loss:  -2.8995\n",
      "Total loss:  -1.8343 | PDE Loss:  -2.6889 | Function Loss:  -2.8996\n",
      "Total loss:  -1.8343 | PDE Loss:  -2.689 | Function Loss:  -2.8997\n",
      "Total loss:  -1.8344 | PDE Loss:  -2.688 | Function Loss:  -2.9\n",
      "Total loss:  -1.8345 | PDE Loss:  -2.6883 | Function Loss:  -2.9\n",
      "Total loss:  -1.8346 | PDE Loss:  -2.6885 | Function Loss:  -2.9001\n",
      "Total loss:  -1.8347 | PDE Loss:  -2.6889 | Function Loss:  -2.9002\n",
      "Total loss:  -1.8349 | PDE Loss:  -2.6891 | Function Loss:  -2.9003\n",
      "Total loss:  -1.835 | PDE Loss:  -2.6891 | Function Loss:  -2.9005\n",
      "Total loss:  -1.8351 | PDE Loss:  -2.6871 | Function Loss:  -2.9009\n",
      "Total loss:  -1.8353 | PDE Loss:  -2.6862 | Function Loss:  -2.9013\n",
      "Total loss:  -1.8354 | PDE Loss:  -2.6863 | Function Loss:  -2.9014\n",
      "Total loss:  -1.8357 | PDE Loss:  -2.6849 | Function Loss:  -2.9019\n",
      "Total loss:  -1.8358 | PDE Loss:  -2.6842 | Function Loss:  -2.9022\n",
      "Total loss:  -1.836 | PDE Loss:  -2.6831 | Function Loss:  -2.9026\n",
      "Total loss:  -1.8362 | PDE Loss:  -2.6832 | Function Loss:  -2.9028\n",
      "Total loss:  -1.8364 | PDE Loss:  -2.6829 | Function Loss:  -2.9031\n",
      "Total loss:  -1.8366 | PDE Loss:  -2.6839 | Function Loss:  -2.9032\n",
      "Total loss:  -1.8368 | PDE Loss:  -2.6851 | Function Loss:  -2.9033\n",
      "Total loss:  -1.8371 | PDE Loss:  -2.6865 | Function Loss:  -2.9033\n",
      "Total loss:  -1.8373 | PDE Loss:  -2.689 | Function Loss:  -2.9031\n",
      "Total loss:  -1.8375 | PDE Loss:  -2.6906 | Function Loss:  -2.9031\n",
      "Total loss:  -1.8376 | PDE Loss:  -2.6936 | Function Loss:  -2.9028\n",
      "Total loss:  -1.8378 | PDE Loss:  -2.6957 | Function Loss:  -2.9027\n",
      "Total loss:  -1.8381 | PDE Loss:  -2.6986 | Function Loss:  -2.9025\n",
      "Total loss:  -1.8385 | PDE Loss:  -2.7018 | Function Loss:  -2.9025\n",
      "Total loss:  -1.8389 | PDE Loss:  -2.7045 | Function Loss:  -2.9025\n",
      "Total loss:  -1.8393 | PDE Loss:  -2.7069 | Function Loss:  -2.9026\n",
      "Total loss:  -1.8398 | PDE Loss:  -2.7079 | Function Loss:  -2.903\n",
      "Total loss:  -1.8402 | PDE Loss:  -2.7064 | Function Loss:  -2.9038\n",
      "Total loss:  -1.8406 | PDE Loss:  -2.7041 | Function Loss:  -2.9046\n",
      "Total loss:  -1.8409 | PDE Loss:  -2.7029 | Function Loss:  -2.9051\n",
      "Total loss:  -1.8412 | PDE Loss:  -2.7015 | Function Loss:  -2.9057\n",
      "Total loss:  -1.8416 | PDE Loss:  -2.7004 | Function Loss:  -2.9064\n",
      "Total loss:  -1.8421 | PDE Loss:  -2.6986 | Function Loss:  -2.9072\n",
      "Total loss:  -1.8425 | PDE Loss:  -2.6981 | Function Loss:  -2.9078\n",
      "Total loss:  -1.843 | PDE Loss:  -2.6975 | Function Loss:  -2.9084\n",
      "Total loss:  -1.8436 | PDE Loss:  -2.6989 | Function Loss:  -2.9089\n",
      "Total loss:  -1.8443 | PDE Loss:  -2.7 | Function Loss:  -2.9095\n",
      "Total loss:  -1.845 | PDE Loss:  -2.7037 | Function Loss:  -2.9098\n",
      "Total loss:  -1.8456 | PDE Loss:  -2.7057 | Function Loss:  -2.9101\n",
      "Total loss:  -1.846 | PDE Loss:  -2.7095 | Function Loss:  -2.9099\n",
      "Total loss:  -1.8464 | PDE Loss:  -2.7095 | Function Loss:  -2.9104\n",
      "Total loss:  -1.8467 | PDE Loss:  -2.7092 | Function Loss:  -2.9108\n",
      "Total loss:  -1.8469 | PDE Loss:  -2.7078 | Function Loss:  -2.9113\n",
      "Total loss:  -1.8471 | PDE Loss:  -2.7063 | Function Loss:  -2.9118\n",
      "Total loss:  -1.8473 | PDE Loss:  -2.704 | Function Loss:  -2.9123\n",
      "Total loss:  -1.8474 | PDE Loss:  -2.7032 | Function Loss:  -2.9126\n",
      "Total loss:  -1.8475 | PDE Loss:  -2.7027 | Function Loss:  -2.9128\n",
      "Total loss:  -1.8476 | PDE Loss:  -2.7029 | Function Loss:  -2.9128\n",
      "Total loss:  -1.8477 | PDE Loss:  -2.703 | Function Loss:  -2.9129\n",
      "Total loss:  -1.8477 | PDE Loss:  -2.7039 | Function Loss:  -2.9128\n",
      "Total loss:  -1.8478 | PDE Loss:  -2.7042 | Function Loss:  -2.9128\n",
      "Total loss:  -1.8478 | PDE Loss:  -2.7047 | Function Loss:  -2.9128\n",
      "Total loss:  -1.8478 | PDE Loss:  -2.7051 | Function Loss:  -2.9128\n",
      "Total loss:  -1.8479 | PDE Loss:  -2.7048 | Function Loss:  -2.9129\n",
      "Total loss:  -1.848 | PDE Loss:  -2.7044 | Function Loss:  -2.913\n",
      "Total loss:  -1.848 | PDE Loss:  -2.7034 | Function Loss:  -2.9133\n",
      "Total loss:  -1.8482 | PDE Loss:  -2.7018 | Function Loss:  -2.9137\n",
      "Total loss:  -1.8483 | PDE Loss:  -2.7007 | Function Loss:  -2.914\n",
      "Total loss:  -1.8485 | PDE Loss:  -2.6983 | Function Loss:  -2.9146\n",
      "Total loss:  -1.8487 | PDE Loss:  -2.6966 | Function Loss:  -2.9152\n",
      "Total loss:  -1.8489 | PDE Loss:  -2.6942 | Function Loss:  -2.9159\n",
      "Total loss:  -1.8492 | PDE Loss:  -2.692 | Function Loss:  -2.9165\n",
      "Total loss:  -1.8494 | PDE Loss:  -2.6879 | Function Loss:  -2.9175\n",
      "Total loss:  -1.8496 | PDE Loss:  -2.6879 | Function Loss:  -2.9177\n",
      "Total loss:  -1.8501 | PDE Loss:  -2.6872 | Function Loss:  -2.9184\n",
      "Total loss:  -1.8505 | PDE Loss:  -2.6876 | Function Loss:  -2.9188\n",
      "Total loss:  -1.8507 | PDE Loss:  -2.6872 | Function Loss:  -2.9192\n",
      "Total loss:  -1.851 | PDE Loss:  -2.6878 | Function Loss:  -2.9193\n",
      "Total loss:  -1.8513 | PDE Loss:  -2.6867 | Function Loss:  -2.9198\n",
      "Total loss:  -1.8516 | PDE Loss:  -2.6877 | Function Loss:  -2.92\n",
      "Total loss:  -1.8519 | PDE Loss:  -2.6868 | Function Loss:  -2.9205\n",
      "Total loss:  -1.8522 | PDE Loss:  -2.688 | Function Loss:  -2.9207\n",
      "Total loss:  -1.8527 | PDE Loss:  -2.6899 | Function Loss:  -2.9209\n",
      "Total loss:  -1.8532 | PDE Loss:  -2.6943 | Function Loss:  -2.9208\n",
      "Total loss:  -1.8536 | PDE Loss:  -2.6961 | Function Loss:  -2.921\n",
      "Total loss:  -1.854 | PDE Loss:  -2.6983 | Function Loss:  -2.921\n",
      "Total loss:  -1.8543 | PDE Loss:  -2.7023 | Function Loss:  -2.9208\n",
      "Total loss:  -1.8545 | PDE Loss:  -2.7042 | Function Loss:  -2.9207\n",
      "Total loss:  -1.8547 | PDE Loss:  -2.7056 | Function Loss:  -2.9207\n",
      "Total loss:  -1.8549 | PDE Loss:  -2.7073 | Function Loss:  -2.9206\n",
      "Total loss:  -1.8551 | PDE Loss:  -2.7092 | Function Loss:  -2.9205\n",
      "Total loss:  -1.8552 | PDE Loss:  -2.7106 | Function Loss:  -2.9205\n",
      "Total loss:  -1.8554 | PDE Loss:  -2.7132 | Function Loss:  -2.9203\n",
      "Total loss:  -1.8557 | PDE Loss:  -2.715 | Function Loss:  -2.9203\n",
      "Total loss:  -1.856 | PDE Loss:  -2.7176 | Function Loss:  -2.9202\n",
      "Total loss:  -1.8563 | PDE Loss:  -2.7192 | Function Loss:  -2.9203\n",
      "Total loss:  -1.8565 | PDE Loss:  -2.7204 | Function Loss:  -2.9204\n",
      "Total loss:  -1.8568 | PDE Loss:  -2.7222 | Function Loss:  -2.9204\n",
      "Total loss:  -1.8571 | PDE Loss:  -2.7238 | Function Loss:  -2.9206\n",
      "Total loss:  -1.8574 | PDE Loss:  -2.7253 | Function Loss:  -2.9206\n",
      "Total loss:  -1.8576 | PDE Loss:  -2.7268 | Function Loss:  -2.9206\n",
      "Total loss:  -1.8578 | PDE Loss:  -2.7274 | Function Loss:  -2.9207\n",
      "Total loss:  -1.8579 | PDE Loss:  -2.7283 | Function Loss:  -2.9207\n",
      "Total loss:  -1.858 | PDE Loss:  -2.7287 | Function Loss:  -2.9208\n",
      "Total loss:  -1.8581 | PDE Loss:  -2.7295 | Function Loss:  -2.9208\n",
      "Total loss:  -1.8583 | PDE Loss:  -2.7305 | Function Loss:  -2.9208\n",
      "Total loss:  -1.8584 | PDE Loss:  -2.7311 | Function Loss:  -2.9209\n",
      "Total loss:  -1.8585 | PDE Loss:  -2.7329 | Function Loss:  -2.9207\n",
      "Total loss:  -1.8587 | PDE Loss:  -2.7345 | Function Loss:  -2.9207\n",
      "Total loss:  -1.8589 | PDE Loss:  -2.7366 | Function Loss:  -2.9207\n",
      "Total loss:  -1.8592 | PDE Loss:  -2.7413 | Function Loss:  -2.9203\n",
      "Total loss:  -1.8595 | PDE Loss:  -2.7419 | Function Loss:  -2.9205\n",
      "Total loss:  -1.8596 | PDE Loss:  -2.7427 | Function Loss:  -2.9206\n",
      "Total loss:  -1.8599 | PDE Loss:  -2.7441 | Function Loss:  -2.9206\n",
      "Total loss:  -1.8601 | PDE Loss:  -2.7452 | Function Loss:  -2.9207\n",
      "Total loss:  -1.8603 | PDE Loss:  -2.7456 | Function Loss:  -2.9209\n",
      "Total loss:  -1.8605 | PDE Loss:  -2.7464 | Function Loss:  -2.921\n",
      "Total loss:  -1.8606 | PDE Loss:  -2.7462 | Function Loss:  -2.9212\n",
      "Total loss:  -1.8607 | PDE Loss:  -2.7463 | Function Loss:  -2.9213\n",
      "Total loss:  -1.8608 | PDE Loss:  -2.7456 | Function Loss:  -2.9215\n",
      "Total loss:  -1.8609 | PDE Loss:  -2.7453 | Function Loss:  -2.9216\n",
      "Total loss:  -1.861 | PDE Loss:  -2.7448 | Function Loss:  -2.9218\n",
      "Total loss:  -1.8611 | PDE Loss:  -2.7444 | Function Loss:  -2.922\n",
      "Total loss:  -1.8613 | PDE Loss:  -2.7437 | Function Loss:  -2.9223\n",
      "Total loss:  -1.8614 | PDE Loss:  -2.7428 | Function Loss:  -2.9226\n",
      "Total loss:  -1.8602 | PDE Loss:  -2.7347 | Function Loss:  -2.9224\n",
      "Total loss:  -1.8615 | PDE Loss:  -2.7427 | Function Loss:  -2.9227\n",
      "Total loss:  -1.8616 | PDE Loss:  -2.7426 | Function Loss:  -2.9228\n",
      "Total loss:  -1.8618 | PDE Loss:  -2.7421 | Function Loss:  -2.9231\n",
      "Total loss:  -1.862 | PDE Loss:  -2.7419 | Function Loss:  -2.9234\n",
      "Total loss:  -1.8622 | PDE Loss:  -2.7405 | Function Loss:  -2.9239\n",
      "Total loss:  -1.8624 | PDE Loss:  -2.7402 | Function Loss:  -2.9241\n",
      "Total loss:  -1.8626 | PDE Loss:  -2.7391 | Function Loss:  -2.9245\n",
      "Total loss:  -1.8628 | PDE Loss:  -2.7368 | Function Loss:  -2.9251\n",
      "Total loss:  -1.8631 | PDE Loss:  -2.7357 | Function Loss:  -2.9256\n",
      "Total loss:  -1.8633 | PDE Loss:  -2.7335 | Function Loss:  -2.9263\n",
      "Total loss:  -1.8636 | PDE Loss:  -2.7332 | Function Loss:  -2.9266\n",
      "Total loss:  -1.8637 | PDE Loss:  -2.7318 | Function Loss:  -2.927\n",
      "Total loss:  -1.8639 | PDE Loss:  -2.7312 | Function Loss:  -2.9273\n",
      "Total loss:  -1.8641 | PDE Loss:  -2.7302 | Function Loss:  -2.9276\n",
      "Total loss:  -1.8642 | PDE Loss:  -2.7293 | Function Loss:  -2.9279\n",
      "Total loss:  -1.8643 | PDE Loss:  -2.7278 | Function Loss:  -2.9283\n",
      "Total loss:  -1.8644 | PDE Loss:  -2.7276 | Function Loss:  -2.9284\n",
      "Total loss:  -1.8645 | PDE Loss:  -2.7275 | Function Loss:  -2.9285\n",
      "Total loss:  -1.8646 | PDE Loss:  -2.728 | Function Loss:  -2.9285\n",
      "Total loss:  -1.8647 | PDE Loss:  -2.7296 | Function Loss:  -2.9284\n",
      "Total loss:  -1.8647 | PDE Loss:  -2.7302 | Function Loss:  -2.9284\n",
      "Total loss:  -1.8648 | PDE Loss:  -2.7313 | Function Loss:  -2.9283\n",
      "Total loss:  -1.8649 | PDE Loss:  -2.7321 | Function Loss:  -2.9283\n",
      "Total loss:  -1.865 | PDE Loss:  -2.7338 | Function Loss:  -2.9281\n",
      "Total loss:  -1.8651 | PDE Loss:  -2.7341 | Function Loss:  -2.9282\n",
      "Total loss:  -1.8652 | PDE Loss:  -2.7352 | Function Loss:  -2.9281\n",
      "Total loss:  -1.8653 | PDE Loss:  -2.7353 | Function Loss:  -2.9283\n",
      "Total loss:  -1.8655 | PDE Loss:  -2.7355 | Function Loss:  -2.9285\n",
      "Total loss:  -1.8658 | PDE Loss:  -2.737 | Function Loss:  -2.9286\n",
      "Total loss:  -1.8661 | PDE Loss:  -2.7388 | Function Loss:  -2.9286\n",
      "Total loss:  -1.8664 | PDE Loss:  -2.7387 | Function Loss:  -2.9289\n",
      "Total loss:  -1.8665 | PDE Loss:  -2.7396 | Function Loss:  -2.929\n",
      "Total loss:  -1.8667 | PDE Loss:  -2.7394 | Function Loss:  -2.9292\n",
      "Total loss:  -1.8668 | PDE Loss:  -2.74 | Function Loss:  -2.9292\n",
      "Total loss:  -1.8669 | PDE Loss:  -2.7399 | Function Loss:  -2.9293\n",
      "Total loss:  -1.867 | PDE Loss:  -2.7402 | Function Loss:  -2.9294\n",
      "Total loss:  -1.8671 | PDE Loss:  -2.7404 | Function Loss:  -2.9295\n",
      "Total loss:  -1.8673 | PDE Loss:  -2.7418 | Function Loss:  -2.9295\n",
      "Total loss:  -1.8674 | PDE Loss:  -2.7416 | Function Loss:  -2.9297\n",
      "Total loss:  -1.8676 | PDE Loss:  -2.7426 | Function Loss:  -2.9297\n",
      "Total loss:  -1.8678 | PDE Loss:  -2.7435 | Function Loss:  -2.9299\n",
      "Total loss:  -1.8681 | PDE Loss:  -2.7448 | Function Loss:  -2.93\n",
      "Total loss:  -1.8685 | PDE Loss:  -2.7462 | Function Loss:  -2.9303\n",
      "Total loss:  -1.8689 | PDE Loss:  -2.7479 | Function Loss:  -2.9304\n",
      "Total loss:  -1.8692 | PDE Loss:  -2.7494 | Function Loss:  -2.9306\n",
      "Total loss:  -1.8694 | PDE Loss:  -2.7501 | Function Loss:  -2.9307\n",
      "Total loss:  -1.8696 | PDE Loss:  -2.7512 | Function Loss:  -2.9307\n",
      "Total loss:  -1.8697 | PDE Loss:  -2.7511 | Function Loss:  -2.9309\n",
      "Total loss:  -1.8699 | PDE Loss:  -2.7512 | Function Loss:  -2.9311\n",
      "Total loss:  -1.8701 | PDE Loss:  -2.751 | Function Loss:  -2.9313\n",
      "Total loss:  -1.8703 | PDE Loss:  -2.7493 | Function Loss:  -2.9318\n",
      "Total loss:  -1.8705 | PDE Loss:  -2.7486 | Function Loss:  -2.9322\n",
      "Total loss:  -1.8707 | PDE Loss:  -2.7478 | Function Loss:  -2.9326\n",
      "Total loss:  -1.871 | PDE Loss:  -2.748 | Function Loss:  -2.9329\n",
      "Total loss:  -1.8713 | PDE Loss:  -2.7479 | Function Loss:  -2.9332\n",
      "Total loss:  -1.8717 | PDE Loss:  -2.7503 | Function Loss:  -2.9333\n",
      "Total loss:  -1.8721 | PDE Loss:  -2.75 | Function Loss:  -2.9338\n",
      "Total loss:  -1.8725 | PDE Loss:  -2.7525 | Function Loss:  -2.9339\n",
      "Total loss:  -1.873 | PDE Loss:  -2.7553 | Function Loss:  -2.9341\n",
      "Total loss:  -1.8737 | PDE Loss:  -2.7581 | Function Loss:  -2.9344\n",
      "Total loss:  -1.8744 | PDE Loss:  -2.7615 | Function Loss:  -2.9347\n",
      "Total loss:  -1.8749 | PDE Loss:  -2.7638 | Function Loss:  -2.9349\n",
      "Total loss:  -1.8753 | PDE Loss:  -2.7653 | Function Loss:  -2.9352\n",
      "Total loss:  -1.8756 | PDE Loss:  -2.7665 | Function Loss:  -2.9354\n",
      "Total loss:  -1.876 | PDE Loss:  -2.7672 | Function Loss:  -2.9358\n",
      "Total loss:  -1.8765 | PDE Loss:  -2.7677 | Function Loss:  -2.9362\n",
      "Total loss:  -1.877 | PDE Loss:  -2.7685 | Function Loss:  -2.9367\n",
      "Total loss:  -1.8772 | PDE Loss:  -2.7692 | Function Loss:  -2.9369\n",
      "Total loss:  -1.8778 | PDE Loss:  -2.7715 | Function Loss:  -2.9371\n",
      "Total loss:  -1.8781 | PDE Loss:  -2.7738 | Function Loss:  -2.9372\n",
      "Total loss:  -1.8785 | PDE Loss:  -2.7755 | Function Loss:  -2.9373\n",
      "Total loss:  -1.8789 | PDE Loss:  -2.778 | Function Loss:  -2.9374\n",
      "Total loss:  -1.8793 | PDE Loss:  -2.78 | Function Loss:  -2.9376\n",
      "Total loss:  -1.8798 | PDE Loss:  -2.7831 | Function Loss:  -2.9378\n",
      "Total loss:  -1.8802 | PDE Loss:  -2.7844 | Function Loss:  -2.9381\n",
      "Total loss:  -1.8806 | PDE Loss:  -2.7872 | Function Loss:  -2.9381\n",
      "Total loss:  -1.8809 | PDE Loss:  -2.7883 | Function Loss:  -2.9383\n",
      "Total loss:  -1.8813 | PDE Loss:  -2.7903 | Function Loss:  -2.9385\n",
      "Total loss:  -1.8818 | PDE Loss:  -2.7929 | Function Loss:  -2.9386\n",
      "Total loss:  -1.8821 | PDE Loss:  -2.7935 | Function Loss:  -2.9389\n",
      "Total loss:  -1.8824 | PDE Loss:  -2.7949 | Function Loss:  -2.9391\n",
      "Total loss:  -1.8828 | PDE Loss:  -2.7969 | Function Loss:  -2.9392\n",
      "Total loss:  -1.8831 | PDE Loss:  -2.7981 | Function Loss:  -2.9394\n",
      "Total loss:  -1.8835 | PDE Loss:  -2.7995 | Function Loss:  -2.9397\n",
      "Total loss:  -1.8838 | PDE Loss:  -2.8 | Function Loss:  -2.94\n",
      "Total loss:  -1.8842 | PDE Loss:  -2.8002 | Function Loss:  -2.9404\n",
      "Total loss:  -1.8845 | PDE Loss:  -2.7988 | Function Loss:  -2.941\n",
      "Total loss:  -1.885 | PDE Loss:  -2.7994 | Function Loss:  -2.9414\n",
      "Total loss:  -1.8853 | PDE Loss:  -2.799 | Function Loss:  -2.9418\n",
      "Total loss:  -1.8859 | PDE Loss:  -2.7997 | Function Loss:  -2.9423\n",
      "Total loss:  -1.8863 | PDE Loss:  -2.8016 | Function Loss:  -2.9426\n",
      "Total loss:  -1.8867 | PDE Loss:  -2.8023 | Function Loss:  -2.9429\n",
      "Total loss:  -1.8869 | PDE Loss:  -2.8047 | Function Loss:  -2.9428\n",
      "Total loss:  -1.8871 | PDE Loss:  -2.8057 | Function Loss:  -2.9429\n",
      "Total loss:  -1.8872 | PDE Loss:  -2.8074 | Function Loss:  -2.9428\n",
      "Total loss:  -1.8873 | PDE Loss:  -2.8084 | Function Loss:  -2.9428\n",
      "Total loss:  -1.8875 | PDE Loss:  -2.8099 | Function Loss:  -2.9428\n",
      "Total loss:  -1.8876 | PDE Loss:  -2.8108 | Function Loss:  -2.9428\n",
      "Total loss:  -1.8877 | PDE Loss:  -2.8112 | Function Loss:  -2.9428\n",
      "Total loss:  -1.8878 | PDE Loss:  -2.812 | Function Loss:  -2.9429\n",
      "Total loss:  -1.8879 | PDE Loss:  -2.8117 | Function Loss:  -2.943\n",
      "Total loss:  -1.888 | PDE Loss:  -2.8123 | Function Loss:  -2.9431\n",
      "Total loss:  -1.8881 | PDE Loss:  -2.8118 | Function Loss:  -2.9433\n",
      "Total loss:  -1.8882 | PDE Loss:  -2.8118 | Function Loss:  -2.9434\n",
      "Total loss:  -1.8883 | PDE Loss:  -2.812 | Function Loss:  -2.9435\n",
      "Total loss:  -1.8884 | PDE Loss:  -2.8124 | Function Loss:  -2.9435\n",
      "Total loss:  -1.8885 | PDE Loss:  -2.8126 | Function Loss:  -2.9435\n",
      "Total loss:  -1.8885 | PDE Loss:  -2.813 | Function Loss:  -2.9435\n",
      "Total loss:  -1.8886 | PDE Loss:  -2.8133 | Function Loss:  -2.9435\n",
      "Total loss:  -1.8886 | PDE Loss:  -2.8137 | Function Loss:  -2.9436\n",
      "Total loss:  -1.8884 | PDE Loss:  -2.8125 | Function Loss:  -2.9435\n",
      "Total loss:  -1.8887 | PDE Loss:  -2.8139 | Function Loss:  -2.9436\n",
      "Total loss:  -1.8887 | PDE Loss:  -2.8148 | Function Loss:  -2.9435\n",
      "Total loss:  -1.8885 | PDE Loss:  -2.8081 | Function Loss:  -2.9442\n",
      "Total loss:  -1.8888 | PDE Loss:  -2.8137 | Function Loss:  -2.9437\n",
      "Total loss:  -1.8888 | PDE Loss:  -2.8142 | Function Loss:  -2.9437\n",
      "Total loss:  -1.8889 | PDE Loss:  -2.815 | Function Loss:  -2.9437\n",
      "Total loss:  -1.889 | PDE Loss:  -2.8154 | Function Loss:  -2.9438\n",
      "Total loss:  -1.8891 | PDE Loss:  -2.8157 | Function Loss:  -2.9438\n",
      "Total loss:  -1.8892 | PDE Loss:  -2.8153 | Function Loss:  -2.944\n",
      "Total loss:  -1.8893 | PDE Loss:  -2.8154 | Function Loss:  -2.9442\n",
      "Total loss:  -1.8895 | PDE Loss:  -2.8136 | Function Loss:  -2.9446\n",
      "Total loss:  -1.8897 | PDE Loss:  -2.8136 | Function Loss:  -2.9448\n",
      "Total loss:  -1.8898 | PDE Loss:  -2.8136 | Function Loss:  -2.945\n",
      "Total loss:  -1.89 | PDE Loss:  -2.8133 | Function Loss:  -2.9452\n",
      "Total loss:  -1.8903 | PDE Loss:  -2.8136 | Function Loss:  -2.9455\n",
      "Total loss:  -1.8905 | PDE Loss:  -2.8129 | Function Loss:  -2.9458\n",
      "Total loss:  -1.8907 | PDE Loss:  -2.8129 | Function Loss:  -2.9461\n",
      "Total loss:  -1.8911 | PDE Loss:  -2.8128 | Function Loss:  -2.9465\n",
      "Total loss:  -1.8912 | PDE Loss:  -2.8116 | Function Loss:  -2.9468\n",
      "Total loss:  -1.8915 | PDE Loss:  -2.8132 | Function Loss:  -2.9468\n",
      "Total loss:  -1.8918 | PDE Loss:  -2.8143 | Function Loss:  -2.9471\n",
      "Total loss:  -1.8922 | PDE Loss:  -2.8143 | Function Loss:  -2.9476\n",
      "Total loss:  -1.8925 | PDE Loss:  -2.8161 | Function Loss:  -2.9477\n",
      "Total loss:  -1.8928 | PDE Loss:  -2.8164 | Function Loss:  -2.9479\n",
      "Total loss:  -1.893 | PDE Loss:  -2.8167 | Function Loss:  -2.9482\n",
      "Total loss:  -1.8932 | PDE Loss:  -2.8165 | Function Loss:  -2.9484\n",
      "Total loss:  -1.8934 | PDE Loss:  -2.8155 | Function Loss:  -2.9487\n",
      "Total loss:  -1.8935 | PDE Loss:  -2.8148 | Function Loss:  -2.949\n",
      "Total loss:  -1.8937 | PDE Loss:  -2.8137 | Function Loss:  -2.9493\n",
      "Total loss:  -1.8938 | PDE Loss:  -2.8129 | Function Loss:  -2.9496\n",
      "Total loss:  -1.894 | PDE Loss:  -2.8123 | Function Loss:  -2.9499\n",
      "Total loss:  -1.8943 | PDE Loss:  -2.811 | Function Loss:  -2.9504\n",
      "Total loss:  -1.8946 | PDE Loss:  -2.8102 | Function Loss:  -2.9508\n",
      "Total loss:  -1.8948 | PDE Loss:  -2.8098 | Function Loss:  -2.9511\n",
      "Total loss:  -1.895 | PDE Loss:  -2.8099 | Function Loss:  -2.9514\n",
      "Total loss:  -1.8953 | PDE Loss:  -2.8107 | Function Loss:  -2.9515\n",
      "Total loss:  -1.8955 | PDE Loss:  -2.8124 | Function Loss:  -2.9516\n",
      "Total loss:  -1.8957 | PDE Loss:  -2.8132 | Function Loss:  -2.9516\n",
      "Total loss:  -1.8958 | PDE Loss:  -2.8141 | Function Loss:  -2.9516\n",
      "Total loss:  -1.8959 | PDE Loss:  -2.8148 | Function Loss:  -2.9517\n",
      "Total loss:  -1.896 | PDE Loss:  -2.8153 | Function Loss:  -2.9518\n",
      "Total loss:  -1.8962 | PDE Loss:  -2.8162 | Function Loss:  -2.9518\n",
      "Total loss:  -1.8963 | PDE Loss:  -2.8169 | Function Loss:  -2.9519\n",
      "Total loss:  -1.8964 | PDE Loss:  -2.8174 | Function Loss:  -2.9519\n",
      "Total loss:  -1.8965 | PDE Loss:  -2.818 | Function Loss:  -2.952\n",
      "Total loss:  -1.8967 | PDE Loss:  -2.8183 | Function Loss:  -2.9521\n",
      "Total loss:  -1.8968 | PDE Loss:  -2.8191 | Function Loss:  -2.9521\n",
      "Total loss:  -1.8969 | PDE Loss:  -2.8195 | Function Loss:  -2.9521\n",
      "Total loss:  -1.897 | PDE Loss:  -2.8196 | Function Loss:  -2.9522\n",
      "Total loss:  -1.897 | PDE Loss:  -2.82 | Function Loss:  -2.9522\n",
      "Total loss:  -1.8971 | PDE Loss:  -2.8203 | Function Loss:  -2.9523\n",
      "Total loss:  -1.8971 | PDE Loss:  -2.8208 | Function Loss:  -2.9523\n",
      "Total loss:  -1.8972 | PDE Loss:  -2.8214 | Function Loss:  -2.9523\n",
      "Total loss:  -1.8973 | PDE Loss:  -2.8221 | Function Loss:  -2.9523\n",
      "Total loss:  -1.8972 | PDE Loss:  -2.8287 | Function Loss:  -2.9513\n",
      "Total loss:  -1.8974 | PDE Loss:  -2.8252 | Function Loss:  -2.9519\n",
      "Total loss:  -1.8975 | PDE Loss:  -2.8248 | Function Loss:  -2.9522\n",
      "Total loss:  -1.8977 | PDE Loss:  -2.8251 | Function Loss:  -2.9523\n",
      "Total loss:  -1.8978 | PDE Loss:  -2.8247 | Function Loss:  -2.9525\n",
      "Total loss:  -1.8976 | PDE Loss:  -2.8236 | Function Loss:  -2.9524\n",
      "Total loss:  -1.8979 | PDE Loss:  -2.825 | Function Loss:  -2.9525\n",
      "Total loss:  -1.898 | PDE Loss:  -2.8249 | Function Loss:  -2.9527\n",
      "Total loss:  -1.8982 | PDE Loss:  -2.8242 | Function Loss:  -2.953\n",
      "Total loss:  -1.8983 | PDE Loss:  -2.8234 | Function Loss:  -2.9532\n",
      "Total loss:  -1.8984 | PDE Loss:  -2.8221 | Function Loss:  -2.9536\n",
      "Total loss:  -1.8986 | PDE Loss:  -2.8204 | Function Loss:  -2.954\n",
      "Total loss:  -1.8989 | PDE Loss:  -2.8181 | Function Loss:  -2.9546\n",
      "Total loss:  -1.8991 | PDE Loss:  -2.8158 | Function Loss:  -2.9552\n",
      "Total loss:  -1.8994 | PDE Loss:  -2.8141 | Function Loss:  -2.9558\n",
      "Total loss:  -1.8997 | PDE Loss:  -2.8117 | Function Loss:  -2.9564\n",
      "Total loss:  -1.8999 | PDE Loss:  -2.8104 | Function Loss:  -2.9568\n",
      "Total loss:  -1.9 | PDE Loss:  -2.8095 | Function Loss:  -2.9571\n",
      "Total loss:  -1.9001 | PDE Loss:  -2.809 | Function Loss:  -2.9573\n",
      "Total loss:  -1.9002 | PDE Loss:  -2.8087 | Function Loss:  -2.9575\n",
      "Total loss:  -1.9003 | PDE Loss:  -2.8097 | Function Loss:  -2.9574\n",
      "Total loss:  -1.9004 | PDE Loss:  -2.8098 | Function Loss:  -2.9575\n",
      "Total loss:  -1.9005 | PDE Loss:  -2.8096 | Function Loss:  -2.9576\n",
      "Total loss:  -1.9006 | PDE Loss:  -2.8099 | Function Loss:  -2.9577\n",
      "Total loss:  -1.9007 | PDE Loss:  -2.81 | Function Loss:  -2.9578\n",
      "Total loss:  -1.9007 | PDE Loss:  -2.8065 | Function Loss:  -2.9582\n",
      "Total loss:  -1.9008 | PDE Loss:  -2.8089 | Function Loss:  -2.9581\n",
      "Total loss:  -1.9009 | PDE Loss:  -2.8093 | Function Loss:  -2.9581\n",
      "Total loss:  -1.901 | PDE Loss:  -2.8096 | Function Loss:  -2.9582\n",
      "Total loss:  -1.9011 | PDE Loss:  -2.8097 | Function Loss:  -2.9583\n",
      "Total loss:  -1.9012 | PDE Loss:  -2.81 | Function Loss:  -2.9584\n",
      "Total loss:  -1.9014 | PDE Loss:  -2.8099 | Function Loss:  -2.9586\n",
      "Total loss:  -1.9015 | PDE Loss:  -2.8103 | Function Loss:  -2.9587\n",
      "Total loss:  -1.9017 | PDE Loss:  -2.8102 | Function Loss:  -2.9589\n",
      "Total loss:  -1.9019 | PDE Loss:  -2.8105 | Function Loss:  -2.9591\n",
      "Total loss:  -1.9022 | PDE Loss:  -2.8074 | Function Loss:  -2.9599\n",
      "Total loss:  -1.9025 | PDE Loss:  -2.8071 | Function Loss:  -2.9603\n",
      "Total loss:  -1.9027 | PDE Loss:  -2.8049 | Function Loss:  -2.9609\n",
      "Total loss:  -1.9029 | PDE Loss:  -2.8036 | Function Loss:  -2.9612\n",
      "Total loss:  -1.9031 | PDE Loss:  -2.8048 | Function Loss:  -2.9613\n",
      "Total loss:  -1.9033 | PDE Loss:  -2.8056 | Function Loss:  -2.9614\n",
      "Total loss:  -1.9035 | PDE Loss:  -2.8062 | Function Loss:  -2.9615\n",
      "Total loss:  -1.9037 | PDE Loss:  -2.8069 | Function Loss:  -2.9617\n",
      "Total loss:  -1.9039 | PDE Loss:  -2.8077 | Function Loss:  -2.9618\n",
      "Total loss:  -1.9041 | PDE Loss:  -2.8079 | Function Loss:  -2.962\n",
      "Total loss:  -1.9043 | PDE Loss:  -2.8082 | Function Loss:  -2.9622\n",
      "Total loss:  -1.9044 | PDE Loss:  -2.8078 | Function Loss:  -2.9624\n",
      "Total loss:  -1.9046 | PDE Loss:  -2.8072 | Function Loss:  -2.9626\n",
      "Total loss:  -1.9047 | PDE Loss:  -2.8069 | Function Loss:  -2.9628\n",
      "Total loss:  -1.9048 | PDE Loss:  -2.8059 | Function Loss:  -2.9631\n",
      "Total loss:  -1.9049 | PDE Loss:  -2.8054 | Function Loss:  -2.9633\n",
      "Total loss:  -1.9051 | PDE Loss:  -2.8038 | Function Loss:  -2.9637\n",
      "Total loss:  -1.9052 | PDE Loss:  -2.8019 | Function Loss:  -2.9641\n",
      "Total loss:  -1.9053 | PDE Loss:  -2.8003 | Function Loss:  -2.9645\n",
      "Total loss:  -1.9054 | PDE Loss:  -2.7989 | Function Loss:  -2.9648\n",
      "Total loss:  -1.9055 | PDE Loss:  -2.7966 | Function Loss:  -2.9652\n",
      "Total loss:  -1.9056 | PDE Loss:  -2.7954 | Function Loss:  -2.9655\n",
      "Total loss:  -1.9057 | PDE Loss:  -2.7949 | Function Loss:  -2.9657\n",
      "Total loss:  -1.9058 | PDE Loss:  -2.7951 | Function Loss:  -2.9658\n",
      "Total loss:  -1.9058 | PDE Loss:  -2.7953 | Function Loss:  -2.9658\n",
      "Total loss:  -1.9059 | PDE Loss:  -2.7955 | Function Loss:  -2.9658\n",
      "Total loss:  -1.9059 | PDE Loss:  -2.7958 | Function Loss:  -2.9659\n",
      "Total loss:  -1.906 | PDE Loss:  -2.7958 | Function Loss:  -2.9659\n",
      "Total loss:  -1.9061 | PDE Loss:  -2.7975 | Function Loss:  -2.9658\n",
      "Total loss:  -1.9062 | PDE Loss:  -2.797 | Function Loss:  -2.966\n",
      "Total loss:  -1.9063 | PDE Loss:  -2.7972 | Function Loss:  -2.966\n",
      "Total loss:  -1.9064 | PDE Loss:  -2.7973 | Function Loss:  -2.9661\n",
      "Total loss:  -1.9065 | PDE Loss:  -2.7977 | Function Loss:  -2.9662\n",
      "Total loss:  -1.9066 | PDE Loss:  -2.7979 | Function Loss:  -2.9664\n",
      "Total loss:  -1.9068 | PDE Loss:  -2.7982 | Function Loss:  -2.9665\n",
      "Total loss:  -1.907 | PDE Loss:  -2.7989 | Function Loss:  -2.9666\n",
      "Total loss:  -1.9069 | PDE Loss:  -2.7962 | Function Loss:  -2.9669\n",
      "Total loss:  -1.9071 | PDE Loss:  -2.7984 | Function Loss:  -2.9668\n",
      "Total loss:  -1.9072 | PDE Loss:  -2.7992 | Function Loss:  -2.9668\n",
      "Total loss:  -1.9073 | PDE Loss:  -2.8 | Function Loss:  -2.9668\n",
      "Total loss:  -1.9075 | PDE Loss:  -2.8006 | Function Loss:  -2.9669\n",
      "Total loss:  -1.9075 | PDE Loss:  -2.8015 | Function Loss:  -2.9669\n",
      "Total loss:  -1.9076 | PDE Loss:  -2.8015 | Function Loss:  -2.9669\n",
      "Total loss:  -1.9077 | PDE Loss:  -2.8016 | Function Loss:  -2.967\n",
      "Total loss:  -1.9077 | PDE Loss:  -2.8016 | Function Loss:  -2.967\n",
      "Total loss:  -1.9078 | PDE Loss:  -2.8018 | Function Loss:  -2.9672\n",
      "Total loss:  -1.908 | PDE Loss:  -2.8009 | Function Loss:  -2.9674\n",
      "Total loss:  -1.9081 | PDE Loss:  -2.8012 | Function Loss:  -2.9676\n",
      "Total loss:  -1.9082 | PDE Loss:  -2.8004 | Function Loss:  -2.9678\n",
      "Total loss:  -1.9085 | PDE Loss:  -2.7996 | Function Loss:  -2.9682\n",
      "Total loss:  -1.9087 | PDE Loss:  -2.7993 | Function Loss:  -2.9685\n",
      "Total loss:  -1.9089 | PDE Loss:  -2.7992 | Function Loss:  -2.9687\n",
      "Total loss:  -1.9091 | PDE Loss:  -2.7999 | Function Loss:  -2.9688\n",
      "Total loss:  -1.9092 | PDE Loss:  -2.8008 | Function Loss:  -2.9689\n",
      "Total loss:  -1.9093 | PDE Loss:  -2.8019 | Function Loss:  -2.9689\n",
      "Total loss:  -1.9095 | PDE Loss:  -2.8034 | Function Loss:  -2.9688\n",
      "Total loss:  -1.909 | PDE Loss:  -2.7989 | Function Loss:  -2.9689\n",
      "Total loss:  -1.9096 | PDE Loss:  -2.8028 | Function Loss:  -2.969\n",
      "Total loss:  -1.9098 | PDE Loss:  -2.8045 | Function Loss:  -2.969\n",
      "Total loss:  -1.9099 | PDE Loss:  -2.8059 | Function Loss:  -2.969\n",
      "Total loss:  -1.9101 | PDE Loss:  -2.8071 | Function Loss:  -2.969\n",
      "Total loss:  -1.9103 | PDE Loss:  -2.8078 | Function Loss:  -2.969\n",
      "Total loss:  -1.9104 | PDE Loss:  -2.8074 | Function Loss:  -2.9693\n",
      "Total loss:  -1.9106 | PDE Loss:  -2.808 | Function Loss:  -2.9694\n",
      "Total loss:  -1.9108 | PDE Loss:  -2.8076 | Function Loss:  -2.9697\n",
      "Total loss:  -1.911 | PDE Loss:  -2.8068 | Function Loss:  -2.9701\n",
      "Total loss:  -1.9113 | PDE Loss:  -2.806 | Function Loss:  -2.9705\n",
      "Total loss:  -1.9115 | PDE Loss:  -2.8049 | Function Loss:  -2.9709\n",
      "Total loss:  -1.9117 | PDE Loss:  -2.8039 | Function Loss:  -2.9713\n",
      "Total loss:  -1.912 | PDE Loss:  -2.803 | Function Loss:  -2.9717\n",
      "Total loss:  -1.9122 | PDE Loss:  -2.8015 | Function Loss:  -2.9722\n",
      "Total loss:  -1.9124 | PDE Loss:  -2.7996 | Function Loss:  -2.9727\n",
      "Total loss:  -1.9126 | PDE Loss:  -2.7997 | Function Loss:  -2.973\n",
      "Total loss:  -1.9128 | PDE Loss:  -2.7982 | Function Loss:  -2.9734\n",
      "Total loss:  -1.913 | PDE Loss:  -2.7983 | Function Loss:  -2.9736\n",
      "Total loss:  -1.9132 | PDE Loss:  -2.7984 | Function Loss:  -2.9738\n",
      "Total loss:  -1.9134 | PDE Loss:  -2.7984 | Function Loss:  -2.974\n",
      "Total loss:  -1.9136 | PDE Loss:  -2.7988 | Function Loss:  -2.9742\n",
      "Total loss:  -1.9137 | PDE Loss:  -2.7991 | Function Loss:  -2.9743\n",
      "Total loss:  -1.9139 | PDE Loss:  -2.7991 | Function Loss:  -2.9745\n",
      "Total loss:  -1.9141 | PDE Loss:  -2.8003 | Function Loss:  -2.9745\n",
      "Total loss:  -1.9142 | PDE Loss:  -2.8009 | Function Loss:  -2.9746\n",
      "Total loss:  -1.9144 | PDE Loss:  -2.8024 | Function Loss:  -2.9745\n",
      "Total loss:  -1.9145 | PDE Loss:  -2.8036 | Function Loss:  -2.9746\n",
      "Total loss:  -1.9147 | PDE Loss:  -2.8049 | Function Loss:  -2.9746\n",
      "Total loss:  -1.9149 | PDE Loss:  -2.8066 | Function Loss:  -2.9746\n",
      "Total loss:  -1.9151 | PDE Loss:  -2.8063 | Function Loss:  -2.9749\n",
      "Total loss:  -1.9153 | PDE Loss:  -2.8075 | Function Loss:  -2.9749\n",
      "Total loss:  -1.9155 | PDE Loss:  -2.8076 | Function Loss:  -2.9751\n",
      "Total loss:  -1.9157 | PDE Loss:  -2.8058 | Function Loss:  -2.9756\n",
      "Total loss:  -1.9159 | PDE Loss:  -2.8037 | Function Loss:  -2.9761\n",
      "Total loss:  -1.916 | PDE Loss:  -2.8022 | Function Loss:  -2.9764\n",
      "Total loss:  -1.9161 | PDE Loss:  -2.8 | Function Loss:  -2.9769\n",
      "Total loss:  -1.9162 | PDE Loss:  -2.7967 | Function Loss:  -2.9776\n",
      "Total loss:  -1.914 | PDE Loss:  -2.7712 | Function Loss:  -2.979\n",
      "Total loss:  -1.9164 | PDE Loss:  -2.7939 | Function Loss:  -2.9782\n",
      "Total loss:  -1.9165 | PDE Loss:  -2.7934 | Function Loss:  -2.9784\n",
      "Total loss:  -1.9167 | PDE Loss:  -2.793 | Function Loss:  -2.9787\n",
      "Total loss:  -1.9169 | PDE Loss:  -2.7932 | Function Loss:  -2.9788\n",
      "Total loss:  -1.917 | PDE Loss:  -2.7934 | Function Loss:  -2.979\n",
      "Total loss:  -1.9171 | PDE Loss:  -2.7937 | Function Loss:  -2.9791\n",
      "Total loss:  -1.9173 | PDE Loss:  -2.794 | Function Loss:  -2.9792\n",
      "Total loss:  -1.9174 | PDE Loss:  -2.794 | Function Loss:  -2.9793\n",
      "Total loss:  -1.9175 | PDE Loss:  -2.7944 | Function Loss:  -2.9793\n",
      "Total loss:  -1.9176 | PDE Loss:  -2.7946 | Function Loss:  -2.9794\n",
      "Total loss:  -1.9176 | PDE Loss:  -2.7951 | Function Loss:  -2.9794\n",
      "Total loss:  -1.9176 | PDE Loss:  -2.7953 | Function Loss:  -2.9794\n",
      "Total loss:  -1.9177 | PDE Loss:  -2.7955 | Function Loss:  -2.9794\n",
      "Total loss:  -1.9177 | PDE Loss:  -2.7955 | Function Loss:  -2.9794\n",
      "Total loss:  -1.9177 | PDE Loss:  -2.7949 | Function Loss:  -2.9796\n",
      "Total loss:  -1.9178 | PDE Loss:  -2.7947 | Function Loss:  -2.9797\n",
      "Total loss:  -1.9179 | PDE Loss:  -2.7943 | Function Loss:  -2.9798\n",
      "Total loss:  -1.918 | PDE Loss:  -2.793 | Function Loss:  -2.9802\n",
      "Total loss:  -1.9181 | PDE Loss:  -2.7924 | Function Loss:  -2.9804\n",
      "Total loss:  -1.9181 | PDE Loss:  -2.7914 | Function Loss:  -2.9806\n",
      "Total loss:  -1.9182 | PDE Loss:  -2.7907 | Function Loss:  -2.9808\n",
      "Total loss:  -1.9183 | PDE Loss:  -2.7896 | Function Loss:  -2.981\n",
      "Total loss:  -1.9184 | PDE Loss:  -2.7892 | Function Loss:  -2.9812\n",
      "Total loss:  -1.9184 | PDE Loss:  -2.7891 | Function Loss:  -2.9813\n",
      "Total loss:  -1.9185 | PDE Loss:  -2.7893 | Function Loss:  -2.9813\n",
      "Total loss:  -1.9186 | PDE Loss:  -2.7893 | Function Loss:  -2.9814\n",
      "Total loss:  -1.9187 | PDE Loss:  -2.7899 | Function Loss:  -2.9814\n",
      "Total loss:  -1.9187 | PDE Loss:  -2.7904 | Function Loss:  -2.9814\n",
      "Total loss:  -1.9188 | PDE Loss:  -2.791 | Function Loss:  -2.9814\n",
      "Total loss:  -1.9189 | PDE Loss:  -2.7917 | Function Loss:  -2.9814\n",
      "Total loss:  -1.9191 | PDE Loss:  -2.7923 | Function Loss:  -2.9815\n",
      "Total loss:  -1.9191 | PDE Loss:  -2.7911 | Function Loss:  -2.9817\n",
      "Total loss:  -1.9192 | PDE Loss:  -2.7919 | Function Loss:  -2.9817\n",
      "Total loss:  -1.9193 | PDE Loss:  -2.7925 | Function Loss:  -2.9818\n",
      "Total loss:  -1.9195 | PDE Loss:  -2.7928 | Function Loss:  -2.9819\n",
      "Total loss:  -1.9196 | PDE Loss:  -2.7932 | Function Loss:  -2.982\n",
      "Total loss:  -1.9198 | PDE Loss:  -2.7934 | Function Loss:  -2.9822\n",
      "Total loss:  -1.9201 | PDE Loss:  -2.7942 | Function Loss:  -2.9824\n",
      "Total loss:  -1.9203 | PDE Loss:  -2.7958 | Function Loss:  -2.9824\n",
      "Total loss:  -1.9205 | PDE Loss:  -2.7971 | Function Loss:  -2.9824\n",
      "Total loss:  -1.9207 | PDE Loss:  -2.7989 | Function Loss:  -2.9823\n",
      "Total loss:  -1.9209 | PDE Loss:  -2.8003 | Function Loss:  -2.9823\n",
      "Total loss:  -1.921 | PDE Loss:  -2.8021 | Function Loss:  -2.9822\n",
      "Total loss:  -1.9211 | PDE Loss:  -2.8033 | Function Loss:  -2.9821\n",
      "Total loss:  -1.9212 | PDE Loss:  -2.8045 | Function Loss:  -2.9821\n",
      "Total loss:  -1.9213 | PDE Loss:  -2.8071 | Function Loss:  -2.9818\n",
      "Total loss:  -1.9214 | PDE Loss:  -2.808 | Function Loss:  -2.9818\n",
      "Total loss:  -1.9216 | PDE Loss:  -2.8094 | Function Loss:  -2.9818\n",
      "Total loss:  -1.9217 | PDE Loss:  -2.8105 | Function Loss:  -2.9818\n",
      "Total loss:  -1.922 | PDE Loss:  -2.812 | Function Loss:  -2.9818\n",
      "Total loss:  -1.9223 | PDE Loss:  -2.8135 | Function Loss:  -2.982\n",
      "Total loss:  -1.9226 | PDE Loss:  -2.8156 | Function Loss:  -2.9821\n",
      "Total loss:  -1.9229 | PDE Loss:  -2.8168 | Function Loss:  -2.9822\n",
      "Total loss:  -1.923 | PDE Loss:  -2.8176 | Function Loss:  -2.9822\n",
      "Total loss:  -1.9232 | PDE Loss:  -2.818 | Function Loss:  -2.9824\n",
      "Total loss:  -1.9235 | PDE Loss:  -2.8183 | Function Loss:  -2.9827\n",
      "Total loss:  -1.9235 | PDE Loss:  -2.8128 | Function Loss:  -2.9835\n",
      "Total loss:  -1.9237 | PDE Loss:  -2.8161 | Function Loss:  -2.9832\n",
      "Total loss:  -1.9238 | PDE Loss:  -2.8155 | Function Loss:  -2.9834\n",
      "Total loss:  -1.924 | PDE Loss:  -2.8143 | Function Loss:  -2.9839\n",
      "Total loss:  -1.9243 | PDE Loss:  -2.8128 | Function Loss:  -2.9844\n",
      "Total loss:  -1.9245 | PDE Loss:  -2.8118 | Function Loss:  -2.9847\n",
      "Total loss:  -1.9246 | PDE Loss:  -2.8107 | Function Loss:  -2.9851\n",
      "Total loss:  -1.9248 | PDE Loss:  -2.8104 | Function Loss:  -2.9853\n",
      "Total loss:  -1.925 | PDE Loss:  -2.8101 | Function Loss:  -2.9856\n",
      "Total loss:  -1.9251 | PDE Loss:  -2.8106 | Function Loss:  -2.9857\n",
      "Total loss:  -1.9252 | PDE Loss:  -2.811 | Function Loss:  -2.9857\n",
      "Total loss:  -1.9253 | PDE Loss:  -2.8117 | Function Loss:  -2.9857\n",
      "Total loss:  -1.9254 | PDE Loss:  -2.8126 | Function Loss:  -2.9857\n",
      "Total loss:  -1.9255 | PDE Loss:  -2.8133 | Function Loss:  -2.9857\n",
      "Total loss:  -1.9256 | PDE Loss:  -2.8136 | Function Loss:  -2.9858\n",
      "Total loss:  -1.9257 | PDE Loss:  -2.8133 | Function Loss:  -2.9859\n",
      "Total loss:  -1.9257 | PDE Loss:  -2.8129 | Function Loss:  -2.986\n",
      "Total loss:  -1.9258 | PDE Loss:  -2.8122 | Function Loss:  -2.9862\n",
      "Total loss:  -1.9259 | PDE Loss:  -2.8116 | Function Loss:  -2.9864\n",
      "Total loss:  -1.926 | PDE Loss:  -2.8102 | Function Loss:  -2.9867\n",
      "Total loss:  -1.9261 | PDE Loss:  -2.8097 | Function Loss:  -2.987\n",
      "Total loss:  -1.9262 | PDE Loss:  -2.8115 | Function Loss:  -2.9868\n",
      "Total loss:  -1.9263 | PDE Loss:  -2.812 | Function Loss:  -2.9868\n",
      "Total loss:  -1.9264 | PDE Loss:  -2.8118 | Function Loss:  -2.9869\n",
      "Total loss:  -1.9265 | PDE Loss:  -2.8122 | Function Loss:  -2.987\n",
      "Total loss:  -1.9266 | PDE Loss:  -2.8124 | Function Loss:  -2.9871\n",
      "Total loss:  -1.9267 | PDE Loss:  -2.8132 | Function Loss:  -2.9872\n",
      "Total loss:  -1.9268 | PDE Loss:  -2.8135 | Function Loss:  -2.9872\n",
      "Total loss:  -1.9269 | PDE Loss:  -2.8141 | Function Loss:  -2.9872\n",
      "Total loss:  -1.9271 | PDE Loss:  -2.8141 | Function Loss:  -2.9874\n",
      "Total loss:  -1.9272 | PDE Loss:  -2.8157 | Function Loss:  -2.9874\n",
      "Total loss:  -1.9274 | PDE Loss:  -2.8173 | Function Loss:  -2.9873\n",
      "Total loss:  -1.9276 | PDE Loss:  -2.8184 | Function Loss:  -2.9873\n",
      "Total loss:  -1.9277 | PDE Loss:  -2.8193 | Function Loss:  -2.9874\n",
      "Total loss:  -1.9278 | PDE Loss:  -2.8211 | Function Loss:  -2.9872\n",
      "Total loss:  -1.928 | PDE Loss:  -2.8214 | Function Loss:  -2.9873\n",
      "Total loss:  -1.928 | PDE Loss:  -2.8215 | Function Loss:  -2.9874\n",
      "Total loss:  -1.9281 | PDE Loss:  -2.8216 | Function Loss:  -2.9875\n",
      "Total loss:  -1.9282 | PDE Loss:  -2.8218 | Function Loss:  -2.9876\n",
      "Total loss:  -1.9283 | PDE Loss:  -2.8217 | Function Loss:  -2.9876\n",
      "Total loss:  -1.9283 | PDE Loss:  -2.8215 | Function Loss:  -2.9878\n",
      "Total loss:  -1.9284 | PDE Loss:  -2.8215 | Function Loss:  -2.9878\n",
      "Total loss:  -1.9285 | PDE Loss:  -2.8211 | Function Loss:  -2.988\n",
      "Total loss:  -1.9286 | PDE Loss:  -2.8209 | Function Loss:  -2.9881\n",
      "Total loss:  -1.9287 | PDE Loss:  -2.8197 | Function Loss:  -2.9884\n",
      "Total loss:  -1.9284 | PDE Loss:  -2.8195 | Function Loss:  -2.9881\n",
      "Total loss:  -1.9288 | PDE Loss:  -2.8204 | Function Loss:  -2.9885\n",
      "Total loss:  -1.9289 | PDE Loss:  -2.8206 | Function Loss:  -2.9885\n",
      "Total loss:  -1.9291 | PDE Loss:  -2.8209 | Function Loss:  -2.9887\n",
      "Total loss:  -1.9293 | PDE Loss:  -2.8226 | Function Loss:  -2.9887\n",
      "Total loss:  -1.9295 | PDE Loss:  -2.8229 | Function Loss:  -2.9888\n",
      "Total loss:  -1.9296 | PDE Loss:  -2.8241 | Function Loss:  -2.9889\n",
      "Total loss:  -1.9298 | PDE Loss:  -2.8249 | Function Loss:  -2.9889\n",
      "Total loss:  -1.9299 | PDE Loss:  -2.8257 | Function Loss:  -2.989\n",
      "Total loss:  -1.9301 | PDE Loss:  -2.8269 | Function Loss:  -2.989\n",
      "Total loss:  -1.9303 | PDE Loss:  -2.8283 | Function Loss:  -2.989\n",
      "Total loss:  -1.9304 | PDE Loss:  -2.8298 | Function Loss:  -2.989\n",
      "Total loss:  -1.9306 | PDE Loss:  -2.8318 | Function Loss:  -2.9888\n",
      "Total loss:  -1.9307 | PDE Loss:  -2.8336 | Function Loss:  -2.9887\n",
      "Total loss:  -1.9308 | PDE Loss:  -2.8368 | Function Loss:  -2.9884\n",
      "Total loss:  -1.931 | PDE Loss:  -2.8402 | Function Loss:  -2.9881\n",
      "Total loss:  -1.9311 | PDE Loss:  -2.8432 | Function Loss:  -2.9879\n",
      "Total loss:  -1.9313 | PDE Loss:  -2.8466 | Function Loss:  -2.9876\n",
      "Total loss:  -1.9315 | PDE Loss:  -2.8489 | Function Loss:  -2.9875\n",
      "Total loss:  -1.9317 | PDE Loss:  -2.8503 | Function Loss:  -2.9875\n",
      "Total loss:  -1.9314 | PDE Loss:  -2.85 | Function Loss:  -2.9872\n",
      "Total loss:  -1.9318 | PDE Loss:  -2.8513 | Function Loss:  -2.9875\n",
      "Total loss:  -1.9319 | PDE Loss:  -2.8512 | Function Loss:  -2.9876\n",
      "Total loss:  -1.9321 | PDE Loss:  -2.8507 | Function Loss:  -2.9879\n",
      "Total loss:  -1.9322 | PDE Loss:  -2.8502 | Function Loss:  -2.9881\n",
      "Total loss:  -1.9323 | PDE Loss:  -2.849 | Function Loss:  -2.9883\n",
      "Total loss:  -1.9323 | PDE Loss:  -2.8487 | Function Loss:  -2.9885\n",
      "Total loss:  -1.9324 | PDE Loss:  -2.8483 | Function Loss:  -2.9886\n",
      "Total loss:  -1.9324 | PDE Loss:  -2.8485 | Function Loss:  -2.9886\n",
      "Total loss:  -1.9325 | PDE Loss:  -2.8487 | Function Loss:  -2.9886\n",
      "Total loss:  -1.9325 | PDE Loss:  -2.8496 | Function Loss:  -2.9886\n",
      "Total loss:  -1.9326 | PDE Loss:  -2.8501 | Function Loss:  -2.9885\n",
      "Total loss:  -1.9326 | PDE Loss:  -2.8501 | Function Loss:  -2.9886\n",
      "Total loss:  -1.9327 | PDE Loss:  -2.8501 | Function Loss:  -2.9887\n",
      "Total loss:  -1.9327 | PDE Loss:  -2.8497 | Function Loss:  -2.9888\n",
      "Total loss:  -1.9328 | PDE Loss:  -2.8493 | Function Loss:  -2.9889\n",
      "Total loss:  -1.9328 | PDE Loss:  -2.849 | Function Loss:  -2.989\n",
      "Total loss:  -1.9329 | PDE Loss:  -2.8488 | Function Loss:  -2.9891\n",
      "Total loss:  -1.9329 | PDE Loss:  -2.8493 | Function Loss:  -2.9891\n",
      "Total loss:  -1.933 | PDE Loss:  -2.8502 | Function Loss:  -2.9891\n",
      "Total loss:  -1.9331 | PDE Loss:  -2.8516 | Function Loss:  -2.989\n",
      "Total loss:  -1.9332 | PDE Loss:  -2.8536 | Function Loss:  -2.9888\n",
      "Total loss:  -1.9334 | PDE Loss:  -2.8556 | Function Loss:  -2.9887\n",
      "Total loss:  -1.9334 | PDE Loss:  -2.8574 | Function Loss:  -2.9885\n",
      "Total loss:  -1.9335 | PDE Loss:  -2.8595 | Function Loss:  -2.9884\n",
      "Total loss:  -1.9337 | PDE Loss:  -2.8614 | Function Loss:  -2.9882\n",
      "Total loss:  -1.9338 | PDE Loss:  -2.8629 | Function Loss:  -2.9882\n",
      "Total loss:  -1.9339 | PDE Loss:  -2.8646 | Function Loss:  -2.9881\n",
      "Total loss:  -1.9341 | PDE Loss:  -2.8662 | Function Loss:  -2.9881\n",
      "Total loss:  -1.9342 | PDE Loss:  -2.8661 | Function Loss:  -2.9883\n",
      "Total loss:  -1.9346 | PDE Loss:  -2.8657 | Function Loss:  -2.9887\n",
      "Total loss:  -1.9349 | PDE Loss:  -2.8664 | Function Loss:  -2.989\n",
      "Total loss:  -1.9352 | PDE Loss:  -2.8667 | Function Loss:  -2.9893\n",
      "Total loss:  -1.9354 | PDE Loss:  -2.8677 | Function Loss:  -2.9894\n",
      "Total loss:  -1.9356 | PDE Loss:  -2.8697 | Function Loss:  -2.9893\n",
      "Total loss:  -1.9357 | PDE Loss:  -2.872 | Function Loss:  -2.9892\n",
      "Total loss:  -1.9358 | PDE Loss:  -2.8751 | Function Loss:  -2.9889\n",
      "Total loss:  -1.9359 | PDE Loss:  -2.8773 | Function Loss:  -2.9887\n",
      "Total loss:  -1.936 | PDE Loss:  -2.8787 | Function Loss:  -2.9886\n",
      "Total loss:  -1.936 | PDE Loss:  -2.8795 | Function Loss:  -2.9885\n",
      "Total loss:  -1.9361 | PDE Loss:  -2.8797 | Function Loss:  -2.9885\n",
      "Total loss:  -1.9361 | PDE Loss:  -2.8794 | Function Loss:  -2.9886\n",
      "Total loss:  -1.9362 | PDE Loss:  -2.879 | Function Loss:  -2.9888\n",
      "Total loss:  -1.9362 | PDE Loss:  -2.8774 | Function Loss:  -2.989\n",
      "Total loss:  -1.9363 | PDE Loss:  -2.8751 | Function Loss:  -2.9894\n",
      "Total loss:  -1.9363 | PDE Loss:  -2.8758 | Function Loss:  -2.9894\n",
      "Total loss:  -1.9365 | PDE Loss:  -2.8775 | Function Loss:  -2.9893\n",
      "Total loss:  -1.9366 | PDE Loss:  -2.8788 | Function Loss:  -2.9893\n",
      "Total loss:  -1.9367 | PDE Loss:  -2.88 | Function Loss:  -2.9893\n",
      "Total loss:  -1.9368 | PDE Loss:  -2.8811 | Function Loss:  -2.9892\n",
      "Total loss:  -1.937 | PDE Loss:  -2.883 | Function Loss:  -2.9891\n",
      "Total loss:  -1.9371 | PDE Loss:  -2.8852 | Function Loss:  -2.9891\n",
      "Total loss:  -1.9373 | PDE Loss:  -2.8886 | Function Loss:  -2.9889\n",
      "Total loss:  -1.9376 | PDE Loss:  -2.8917 | Function Loss:  -2.9887\n",
      "Total loss:  -1.9378 | PDE Loss:  -2.8955 | Function Loss:  -2.9885\n",
      "Total loss:  -1.9381 | PDE Loss:  -2.8979 | Function Loss:  -2.9885\n",
      "Total loss:  -1.9384 | PDE Loss:  -2.8992 | Function Loss:  -2.9887\n",
      "Total loss:  -1.9386 | PDE Loss:  -2.8996 | Function Loss:  -2.9889\n",
      "Total loss:  -1.9388 | PDE Loss:  -2.8986 | Function Loss:  -2.9893\n",
      "Total loss:  -1.939 | PDE Loss:  -2.8977 | Function Loss:  -2.9896\n",
      "Total loss:  -1.9392 | PDE Loss:  -2.8964 | Function Loss:  -2.9899\n",
      "Total loss:  -1.9393 | PDE Loss:  -2.8955 | Function Loss:  -2.9902\n",
      "Total loss:  -1.9395 | PDE Loss:  -2.895 | Function Loss:  -2.9904\n",
      "Total loss:  -1.9397 | PDE Loss:  -2.8954 | Function Loss:  -2.9906\n",
      "Total loss:  -1.9399 | PDE Loss:  -2.8965 | Function Loss:  -2.9907\n",
      "Total loss:  -1.9401 | PDE Loss:  -2.8985 | Function Loss:  -2.9908\n",
      "Total loss:  -1.9403 | PDE Loss:  -2.8998 | Function Loss:  -2.9908\n",
      "Total loss:  -1.9405 | PDE Loss:  -2.9025 | Function Loss:  -2.9907\n",
      "Total loss:  -1.9408 | PDE Loss:  -2.9068 | Function Loss:  -2.9905\n",
      "Total loss:  -1.941 | PDE Loss:  -2.9119 | Function Loss:  -2.9901\n",
      "Total loss:  -1.9413 | PDE Loss:  -2.9165 | Function Loss:  -2.9899\n",
      "Total loss:  -1.9416 | PDE Loss:  -2.921 | Function Loss:  -2.9897\n",
      "Total loss:  -1.9419 | PDE Loss:  -2.9244 | Function Loss:  -2.9896\n",
      "Total loss:  -1.9424 | PDE Loss:  -2.9273 | Function Loss:  -2.9898\n",
      "Total loss:  -1.9428 | PDE Loss:  -2.9279 | Function Loss:  -2.9902\n",
      "Total loss:  -1.9431 | PDE Loss:  -2.9285 | Function Loss:  -2.9905\n",
      "Total loss:  -1.9433 | PDE Loss:  -2.9262 | Function Loss:  -2.991\n",
      "Total loss:  -1.9435 | PDE Loss:  -2.9263 | Function Loss:  -2.9912\n",
      "Total loss:  -1.9438 | PDE Loss:  -2.9265 | Function Loss:  -2.9915\n",
      "Total loss:  -1.9441 | PDE Loss:  -2.9255 | Function Loss:  -2.992\n",
      "Total loss:  -1.9444 | PDE Loss:  -2.9267 | Function Loss:  -2.9922\n",
      "Total loss:  -1.9447 | PDE Loss:  -2.9277 | Function Loss:  -2.9924\n",
      "Total loss:  -1.945 | PDE Loss:  -2.9285 | Function Loss:  -2.9926\n",
      "Total loss:  -1.9451 | PDE Loss:  -2.9294 | Function Loss:  -2.9927\n",
      "Total loss:  -1.9453 | PDE Loss:  -2.9304 | Function Loss:  -2.9927\n",
      "Total loss:  -1.9454 | PDE Loss:  -2.9312 | Function Loss:  -2.9928\n",
      "Total loss:  -1.9455 | PDE Loss:  -2.9283 | Function Loss:  -2.9933\n",
      "Total loss:  -1.9457 | PDE Loss:  -2.9303 | Function Loss:  -2.9932\n",
      "Total loss:  -1.9458 | PDE Loss:  -2.9304 | Function Loss:  -2.9933\n",
      "Total loss:  -1.946 | PDE Loss:  -2.931 | Function Loss:  -2.9935\n",
      "Total loss:  -1.9461 | PDE Loss:  -2.9309 | Function Loss:  -2.9936\n",
      "Total loss:  -1.9463 | PDE Loss:  -2.9303 | Function Loss:  -2.9938\n",
      "Total loss:  -1.9464 | PDE Loss:  -2.9299 | Function Loss:  -2.994\n",
      "Total loss:  -1.9465 | PDE Loss:  -2.9296 | Function Loss:  -2.9942\n",
      "Total loss:  -1.9466 | PDE Loss:  -2.9297 | Function Loss:  -2.9942\n",
      "Total loss:  -1.9467 | PDE Loss:  -2.93 | Function Loss:  -2.9943\n",
      "Total loss:  -1.9468 | PDE Loss:  -2.9312 | Function Loss:  -2.9943\n",
      "Total loss:  -1.947 | PDE Loss:  -2.9324 | Function Loss:  -2.9944\n",
      "Total loss:  -1.9471 | PDE Loss:  -2.9344 | Function Loss:  -2.9943\n",
      "Total loss:  -1.9473 | PDE Loss:  -2.9361 | Function Loss:  -2.9943\n",
      "Total loss:  -1.9474 | PDE Loss:  -2.938 | Function Loss:  -2.9942\n",
      "Total loss:  -1.9475 | PDE Loss:  -2.9399 | Function Loss:  -2.9941\n",
      "Total loss:  -1.9476 | PDE Loss:  -2.9403 | Function Loss:  -2.9942\n",
      "Total loss:  -1.9477 | PDE Loss:  -2.941 | Function Loss:  -2.9942\n",
      "Total loss:  -1.9478 | PDE Loss:  -2.9407 | Function Loss:  -2.9944\n",
      "Total loss:  -1.9479 | PDE Loss:  -2.9412 | Function Loss:  -2.9944\n",
      "Total loss:  -1.9481 | PDE Loss:  -2.9419 | Function Loss:  -2.9945\n",
      "Total loss:  -1.9482 | PDE Loss:  -2.9427 | Function Loss:  -2.9946\n",
      "Total loss:  -1.9483 | PDE Loss:  -2.9435 | Function Loss:  -2.9946\n",
      "Total loss:  -1.9484 | PDE Loss:  -2.9441 | Function Loss:  -2.9946\n",
      "Total loss:  -1.9483 | PDE Loss:  -2.9427 | Function Loss:  -2.9947\n",
      "Total loss:  -1.9484 | PDE Loss:  -2.9442 | Function Loss:  -2.9947\n",
      "Total loss:  -1.9485 | PDE Loss:  -2.9443 | Function Loss:  -2.9948\n",
      "Total loss:  -1.9487 | PDE Loss:  -2.9438 | Function Loss:  -2.9949\n",
      "Total loss:  -1.9488 | PDE Loss:  -2.9423 | Function Loss:  -2.9953\n",
      "Total loss:  -1.9489 | PDE Loss:  -2.9403 | Function Loss:  -2.9956\n",
      "Total loss:  -1.949 | PDE Loss:  -2.9382 | Function Loss:  -2.996\n",
      "Total loss:  -1.9492 | PDE Loss:  -2.9359 | Function Loss:  -2.9964\n",
      "Total loss:  -1.9493 | PDE Loss:  -2.9345 | Function Loss:  -2.9967\n",
      "Total loss:  -1.9493 | PDE Loss:  -2.9327 | Function Loss:  -2.997\n",
      "Total loss:  -1.9494 | PDE Loss:  -2.9327 | Function Loss:  -2.9971\n",
      "Total loss:  -1.9495 | PDE Loss:  -2.9331 | Function Loss:  -2.9971\n",
      "Total loss:  -1.9495 | PDE Loss:  -2.9341 | Function Loss:  -2.997\n",
      "Total loss:  -1.9496 | PDE Loss:  -2.9354 | Function Loss:  -2.9969\n",
      "Total loss:  -1.9496 | PDE Loss:  -2.9367 | Function Loss:  -2.9968\n",
      "Total loss:  -1.9497 | PDE Loss:  -2.938 | Function Loss:  -2.9967\n",
      "Total loss:  -1.9497 | PDE Loss:  -2.9391 | Function Loss:  -2.9967\n",
      "Total loss:  -1.9498 | PDE Loss:  -2.9379 | Function Loss:  -2.9969\n",
      "Total loss:  -1.95 | PDE Loss:  -2.9393 | Function Loss:  -2.9969\n",
      "Total loss:  -1.9501 | PDE Loss:  -2.9404 | Function Loss:  -2.997\n",
      "Total loss:  -1.9503 | PDE Loss:  -2.9404 | Function Loss:  -2.9972\n",
      "Total loss:  -1.9505 | PDE Loss:  -2.9404 | Function Loss:  -2.9974\n",
      "Total loss:  -1.9507 | PDE Loss:  -2.9404 | Function Loss:  -2.9976\n",
      "Total loss:  -1.9509 | PDE Loss:  -2.94 | Function Loss:  -2.9978\n",
      "Total loss:  -1.9511 | PDE Loss:  -2.9404 | Function Loss:  -2.998\n",
      "Total loss:  -1.9513 | PDE Loss:  -2.9403 | Function Loss:  -2.9982\n",
      "Total loss:  -1.9514 | PDE Loss:  -2.9412 | Function Loss:  -2.9984\n",
      "Total loss:  -1.9516 | PDE Loss:  -2.9416 | Function Loss:  -2.9985\n",
      "Total loss:  -1.9518 | PDE Loss:  -2.9426 | Function Loss:  -2.9985\n",
      "Total loss:  -1.9519 | PDE Loss:  -2.9439 | Function Loss:  -2.9986\n",
      "Total loss:  -1.9521 | PDE Loss:  -2.9455 | Function Loss:  -2.9986\n",
      "Total loss:  -1.9522 | PDE Loss:  -2.9477 | Function Loss:  -2.9985\n",
      "Total loss:  -1.9524 | PDE Loss:  -2.95 | Function Loss:  -2.9984\n",
      "Total loss:  -1.9526 | PDE Loss:  -2.9516 | Function Loss:  -2.9984\n",
      "Total loss:  -1.9528 | PDE Loss:  -2.9545 | Function Loss:  -2.9984\n",
      "Total loss:  -1.9531 | PDE Loss:  -2.9563 | Function Loss:  -2.9985\n",
      "Total loss:  -1.9532 | PDE Loss:  -2.9579 | Function Loss:  -2.9985\n",
      "Total loss:  -1.9534 | PDE Loss:  -2.9587 | Function Loss:  -2.9985\n",
      "Total loss:  -1.9535 | PDE Loss:  -2.9595 | Function Loss:  -2.9986\n",
      "Total loss:  -1.9536 | PDE Loss:  -2.9605 | Function Loss:  -2.9986\n",
      "Total loss:  -1.9538 | PDE Loss:  -2.9614 | Function Loss:  -2.9987\n",
      "Total loss:  -1.9539 | PDE Loss:  -2.9627 | Function Loss:  -2.9987\n",
      "Total loss:  -1.9541 | PDE Loss:  -2.9633 | Function Loss:  -2.9988\n",
      "Total loss:  -1.9542 | PDE Loss:  -2.9659 | Function Loss:  -2.9987\n",
      "Total loss:  -1.9543 | PDE Loss:  -2.9668 | Function Loss:  -2.9987\n",
      "Total loss:  -1.9544 | PDE Loss:  -2.968 | Function Loss:  -2.9987\n",
      "Total loss:  -1.9546 | PDE Loss:  -2.9704 | Function Loss:  -2.9987\n",
      "Total loss:  -1.9548 | PDE Loss:  -2.9738 | Function Loss:  -2.9985\n",
      "Total loss:  -1.955 | PDE Loss:  -2.9767 | Function Loss:  -2.9984\n",
      "Total loss:  -1.9552 | PDE Loss:  -2.9792 | Function Loss:  -2.9984\n",
      "Total loss:  -1.9554 | PDE Loss:  -2.9807 | Function Loss:  -2.9984\n",
      "Total loss:  -1.9555 | PDE Loss:  -2.9813 | Function Loss:  -2.9985\n",
      "Total loss:  -1.9557 | PDE Loss:  -2.9813 | Function Loss:  -2.9987\n",
      "Total loss:  -1.9559 | PDE Loss:  -2.9811 | Function Loss:  -2.9989\n",
      "Total loss:  -1.9561 | PDE Loss:  -2.9811 | Function Loss:  -2.9992\n",
      "Total loss:  -1.9564 | PDE Loss:  -2.9812 | Function Loss:  -2.9995\n",
      "Total loss:  -1.9569 | PDE Loss:  -2.9823 | Function Loss:  -2.9999\n",
      "Total loss:  -1.9573 | PDE Loss:  -2.9836 | Function Loss:  -3.0002\n",
      "Total loss:  -1.9578 | PDE Loss:  -2.9855 | Function Loss:  -3.0005\n",
      "Total loss:  -1.9582 | PDE Loss:  -2.9866 | Function Loss:  -3.0009\n",
      "Total loss:  -1.9585 | PDE Loss:  -2.988 | Function Loss:  -3.0011\n",
      "Total loss:  -1.9588 | PDE Loss:  -2.9897 | Function Loss:  -3.0012\n",
      "Total loss:  -1.959 | PDE Loss:  -2.9911 | Function Loss:  -3.0013\n",
      "Total loss:  -1.9592 | PDE Loss:  -2.9922 | Function Loss:  -3.0015\n",
      "Total loss:  -1.9594 | PDE Loss:  -2.9933 | Function Loss:  -3.0016\n",
      "Total loss:  -1.9596 | PDE Loss:  -2.9937 | Function Loss:  -3.0017\n",
      "Total loss:  -1.9599 | PDE Loss:  -2.9932 | Function Loss:  -3.0021\n",
      "Total loss:  -1.9602 | PDE Loss:  -2.9925 | Function Loss:  -3.0025\n",
      "Total loss:  -1.9604 | PDE Loss:  -2.9914 | Function Loss:  -3.0029\n",
      "Total loss:  -1.9607 | PDE Loss:  -2.9893 | Function Loss:  -3.0034\n",
      "Total loss:  -1.961 | PDE Loss:  -2.9875 | Function Loss:  -3.0039\n",
      "Total loss:  -1.9612 | PDE Loss:  -2.986 | Function Loss:  -3.0043\n",
      "Total loss:  -1.9614 | PDE Loss:  -2.985 | Function Loss:  -3.0046\n",
      "Total loss:  -1.9616 | PDE Loss:  -2.9844 | Function Loss:  -3.0049\n",
      "Total loss:  -1.9619 | PDE Loss:  -2.9842 | Function Loss:  -3.0052\n",
      "Total loss:  -1.9622 | PDE Loss:  -2.9841 | Function Loss:  -3.0056\n",
      "Total loss:  -1.9626 | PDE Loss:  -2.9855 | Function Loss:  -3.0059\n",
      "Total loss:  -1.9629 | PDE Loss:  -2.9869 | Function Loss:  -3.0061\n",
      "Total loss:  -1.9632 | PDE Loss:  -2.9895 | Function Loss:  -3.0062\n",
      "Total loss:  -1.9635 | PDE Loss:  -2.992 | Function Loss:  -3.0062\n",
      "Total loss:  -1.9637 | PDE Loss:  -2.9934 | Function Loss:  -3.0063\n",
      "Total loss:  -1.9638 | PDE Loss:  -2.9961 | Function Loss:  -3.0061\n",
      "Total loss:  -1.9639 | PDE Loss:  -2.9975 | Function Loss:  -3.0061\n",
      "Total loss:  -1.9641 | PDE Loss:  -2.9986 | Function Loss:  -3.0062\n",
      "Total loss:  -1.9642 | PDE Loss:  -2.9998 | Function Loss:  -3.0062\n",
      "Total loss:  -1.9644 | PDE Loss:  -3.0007 | Function Loss:  -3.0063\n",
      "Total loss:  -1.9646 | PDE Loss:  -3.0017 | Function Loss:  -3.0064\n",
      "Total loss:  -1.9648 | PDE Loss:  -3.0028 | Function Loss:  -3.0065\n",
      "Total loss:  -1.9649 | PDE Loss:  -3.0046 | Function Loss:  -3.0065\n",
      "Total loss:  -1.9652 | PDE Loss:  -3.0074 | Function Loss:  -3.0065\n",
      "Total loss:  -1.9654 | PDE Loss:  -3.0107 | Function Loss:  -3.0064\n",
      "Total loss:  -1.9656 | PDE Loss:  -3.0134 | Function Loss:  -3.0063\n",
      "Total loss:  -1.9657 | PDE Loss:  -3.0161 | Function Loss:  -3.0062\n",
      "Total loss:  -1.9659 | PDE Loss:  -3.0185 | Function Loss:  -3.0061\n",
      "Total loss:  -1.966 | PDE Loss:  -3.021 | Function Loss:  -3.0061\n",
      "Total loss:  -1.9662 | PDE Loss:  -3.0224 | Function Loss:  -3.0061\n",
      "Total loss:  -1.9663 | PDE Loss:  -3.0236 | Function Loss:  -3.0061\n",
      "Total loss:  -1.9664 | PDE Loss:  -3.0239 | Function Loss:  -3.0062\n",
      "Total loss:  -1.9664 | PDE Loss:  -3.0235 | Function Loss:  -3.0063\n",
      "Total loss:  -1.9665 | PDE Loss:  -3.0231 | Function Loss:  -3.0064\n",
      "Total loss:  -1.9666 | PDE Loss:  -3.022 | Function Loss:  -3.0066\n",
      "Total loss:  -1.9667 | PDE Loss:  -3.0209 | Function Loss:  -3.0068\n",
      "Total loss:  -1.9667 | PDE Loss:  -3.02 | Function Loss:  -3.007\n",
      "Total loss:  -1.9668 | PDE Loss:  -3.0194 | Function Loss:  -3.0071\n",
      "Total loss:  -1.967 | PDE Loss:  -3.0176 | Function Loss:  -3.0075\n",
      "Total loss:  -1.9671 | PDE Loss:  -3.0176 | Function Loss:  -3.0076\n",
      "Total loss:  -1.9672 | PDE Loss:  -3.0175 | Function Loss:  -3.0077\n",
      "Total loss:  -1.9674 | PDE Loss:  -3.0185 | Function Loss:  -3.0078\n",
      "Total loss:  -1.9675 | PDE Loss:  -3.0194 | Function Loss:  -3.0079\n",
      "Total loss:  -1.9676 | PDE Loss:  -3.02 | Function Loss:  -3.0079\n",
      "Total loss:  -1.9677 | PDE Loss:  -3.0216 | Function Loss:  -3.0079\n",
      "Total loss:  -1.9678 | PDE Loss:  -3.0226 | Function Loss:  -3.0079\n",
      "Total loss:  -1.9679 | PDE Loss:  -3.0234 | Function Loss:  -3.0079\n",
      "Total loss:  -1.968 | PDE Loss:  -3.0241 | Function Loss:  -3.0079\n",
      "Total loss:  -1.9681 | PDE Loss:  -3.0234 | Function Loss:  -3.0081\n",
      "Total loss:  -1.9681 | PDE Loss:  -3.0233 | Function Loss:  -3.0082\n",
      "Total loss:  -1.9682 | PDE Loss:  -3.0228 | Function Loss:  -3.0083\n",
      "Total loss:  -1.9682 | PDE Loss:  -3.0221 | Function Loss:  -3.0084\n",
      "Total loss:  -1.9683 | PDE Loss:  -3.0218 | Function Loss:  -3.0085\n",
      "Total loss:  -1.9683 | PDE Loss:  -3.0206 | Function Loss:  -3.0086\n",
      "Total loss:  -1.9684 | PDE Loss:  -3.0217 | Function Loss:  -3.0086\n",
      "Total loss:  -1.9685 | PDE Loss:  -3.0221 | Function Loss:  -3.0086\n",
      "Total loss:  -1.9685 | PDE Loss:  -3.0231 | Function Loss:  -3.0086\n",
      "Total loss:  -1.9687 | PDE Loss:  -3.025 | Function Loss:  -3.0086\n",
      "Total loss:  -1.9689 | PDE Loss:  -3.0272 | Function Loss:  -3.0086\n",
      "Total loss:  -1.9691 | PDE Loss:  -3.0279 | Function Loss:  -3.0088\n",
      "Total loss:  -1.9692 | PDE Loss:  -3.0292 | Function Loss:  -3.0088\n",
      "Total loss:  -1.9693 | PDE Loss:  -3.03 | Function Loss:  -3.0088\n",
      "Total loss:  -1.9694 | PDE Loss:  -3.031 | Function Loss:  -3.0088\n",
      "Total loss:  -1.9695 | PDE Loss:  -3.0313 | Function Loss:  -3.0089\n",
      "Total loss:  -1.9696 | PDE Loss:  -3.0315 | Function Loss:  -3.009\n",
      "Total loss:  -1.9696 | PDE Loss:  -3.0301 | Function Loss:  -3.0091\n",
      "Total loss:  -1.9697 | PDE Loss:  -3.0316 | Function Loss:  -3.0091\n",
      "Total loss:  -1.9697 | PDE Loss:  -3.0314 | Function Loss:  -3.0092\n",
      "Total loss:  -1.9698 | PDE Loss:  -3.031 | Function Loss:  -3.0093\n",
      "Total loss:  -1.9699 | PDE Loss:  -3.0301 | Function Loss:  -3.0094\n",
      "Total loss:  -1.9699 | PDE Loss:  -3.0292 | Function Loss:  -3.0096\n",
      "Total loss:  -1.97 | PDE Loss:  -3.0283 | Function Loss:  -3.0097\n",
      "Total loss:  -1.97 | PDE Loss:  -3.0273 | Function Loss:  -3.0099\n",
      "Total loss:  -1.9701 | PDE Loss:  -3.0266 | Function Loss:  -3.01\n",
      "Total loss:  -1.9701 | PDE Loss:  -3.0255 | Function Loss:  -3.0102\n",
      "Total loss:  -1.9702 | PDE Loss:  -3.0251 | Function Loss:  -3.0103\n",
      "Total loss:  -1.9703 | PDE Loss:  -3.0246 | Function Loss:  -3.0104\n",
      "Total loss:  -1.9703 | PDE Loss:  -3.0245 | Function Loss:  -3.0104\n",
      "Total loss:  -1.9703 | PDE Loss:  -3.0249 | Function Loss:  -3.0104\n",
      "Total loss:  -1.9704 | PDE Loss:  -3.0258 | Function Loss:  -3.0104\n",
      "Total loss:  -1.9705 | PDE Loss:  -3.0264 | Function Loss:  -3.0105\n",
      "Total loss:  -1.9707 | PDE Loss:  -3.0288 | Function Loss:  -3.0104\n",
      "Total loss:  -1.9708 | PDE Loss:  -3.0308 | Function Loss:  -3.0104\n",
      "Total loss:  -1.971 | PDE Loss:  -3.0321 | Function Loss:  -3.0105\n",
      "Total loss:  -1.9712 | PDE Loss:  -3.0339 | Function Loss:  -3.0105\n",
      "Total loss:  -1.9714 | PDE Loss:  -3.0352 | Function Loss:  -3.0106\n",
      "Total loss:  -1.9715 | PDE Loss:  -3.0369 | Function Loss:  -3.0106\n",
      "Total loss:  -1.9717 | PDE Loss:  -3.0379 | Function Loss:  -3.0107\n",
      "Total loss:  -1.9719 | PDE Loss:  -3.0396 | Function Loss:  -3.0107\n",
      "Total loss:  -1.9721 | PDE Loss:  -3.0399 | Function Loss:  -3.0109\n",
      "Total loss:  -1.9723 | PDE Loss:  -3.0398 | Function Loss:  -3.0112\n",
      "Total loss:  -1.9725 | PDE Loss:  -3.0373 | Function Loss:  -3.0116\n",
      "Total loss:  -1.9726 | PDE Loss:  -3.0362 | Function Loss:  -3.0118\n",
      "Total loss:  -1.9727 | PDE Loss:  -3.0333 | Function Loss:  -3.0122\n",
      "Total loss:  -1.9728 | PDE Loss:  -3.0318 | Function Loss:  -3.0125\n",
      "Total loss:  -1.9729 | PDE Loss:  -3.0302 | Function Loss:  -3.0127\n",
      "Total loss:  -1.973 | PDE Loss:  -3.0278 | Function Loss:  -3.013\n",
      "Total loss:  -1.9731 | PDE Loss:  -3.0244 | Function Loss:  -3.0135\n",
      "Total loss:  -1.9732 | PDE Loss:  -3.0213 | Function Loss:  -3.014\n",
      "Total loss:  -1.9733 | PDE Loss:  -3.0194 | Function Loss:  -3.0143\n",
      "Total loss:  -1.9735 | PDE Loss:  -3.0181 | Function Loss:  -3.0146\n",
      "Total loss:  -1.9737 | PDE Loss:  -3.0169 | Function Loss:  -3.0149\n",
      "Total loss:  -1.9739 | PDE Loss:  -3.0169 | Function Loss:  -3.0151\n",
      "Total loss:  -1.974 | PDE Loss:  -3.0186 | Function Loss:  -3.0151\n",
      "Total loss:  -1.9743 | PDE Loss:  -3.0215 | Function Loss:  -3.0151\n",
      "Total loss:  -1.9745 | PDE Loss:  -3.0259 | Function Loss:  -3.0149\n",
      "Total loss:  -1.9747 | PDE Loss:  -3.0285 | Function Loss:  -3.0149\n",
      "Total loss:  -1.9749 | PDE Loss:  -3.0304 | Function Loss:  -3.0149\n",
      "Total loss:  -1.9751 | PDE Loss:  -3.0308 | Function Loss:  -3.0151\n",
      "Total loss:  -1.9753 | PDE Loss:  -3.0319 | Function Loss:  -3.0152\n",
      "Total loss:  -1.9755 | PDE Loss:  -3.0312 | Function Loss:  -3.0155\n",
      "Total loss:  -1.9757 | PDE Loss:  -3.0308 | Function Loss:  -3.0157\n",
      "Total loss:  -1.9759 | PDE Loss:  -3.0307 | Function Loss:  -3.016\n",
      "Total loss:  -1.9761 | PDE Loss:  -3.0267 | Function Loss:  -3.0166\n",
      "Total loss:  -1.9763 | PDE Loss:  -3.0274 | Function Loss:  -3.0167\n",
      "Total loss:  -1.9764 | PDE Loss:  -3.0292 | Function Loss:  -3.0166\n",
      "Total loss:  -1.9765 | PDE Loss:  -3.0307 | Function Loss:  -3.0166\n",
      "Total loss:  -1.9766 | PDE Loss:  -3.0313 | Function Loss:  -3.0167\n",
      "Total loss:  -1.9767 | PDE Loss:  -3.0316 | Function Loss:  -3.0167\n",
      "Total loss:  -1.9768 | PDE Loss:  -3.0316 | Function Loss:  -3.0168\n",
      "Total loss:  -1.9769 | PDE Loss:  -3.0313 | Function Loss:  -3.017\n",
      "Total loss:  -1.9769 | PDE Loss:  -3.0307 | Function Loss:  -3.0171\n",
      "Total loss:  -1.977 | PDE Loss:  -3.0298 | Function Loss:  -3.0173\n",
      "Total loss:  -1.9771 | PDE Loss:  -3.0292 | Function Loss:  -3.0174\n",
      "Total loss:  -1.9772 | PDE Loss:  -3.0283 | Function Loss:  -3.0176\n",
      "Total loss:  -1.9773 | PDE Loss:  -3.0279 | Function Loss:  -3.0178\n",
      "Total loss:  -1.9774 | PDE Loss:  -3.0278 | Function Loss:  -3.018\n",
      "Total loss:  -1.9776 | PDE Loss:  -3.029 | Function Loss:  -3.018\n",
      "Total loss:  -1.9778 | PDE Loss:  -3.0304 | Function Loss:  -3.0181\n",
      "Total loss:  -1.978 | PDE Loss:  -3.0323 | Function Loss:  -3.0181\n",
      "Total loss:  -1.9782 | PDE Loss:  -3.0341 | Function Loss:  -3.0182\n",
      "Total loss:  -1.9785 | PDE Loss:  -3.0363 | Function Loss:  -3.0182\n",
      "Total loss:  -1.9787 | PDE Loss:  -3.0377 | Function Loss:  -3.0184\n",
      "Total loss:  -1.9789 | PDE Loss:  -3.0395 | Function Loss:  -3.0184\n",
      "Total loss:  -1.9792 | PDE Loss:  -3.0399 | Function Loss:  -3.0187\n",
      "Total loss:  -1.9795 | PDE Loss:  -3.0426 | Function Loss:  -3.0188\n",
      "Total loss:  -1.9797 | PDE Loss:  -3.0438 | Function Loss:  -3.0189\n",
      "Total loss:  -1.9799 | PDE Loss:  -3.0442 | Function Loss:  -3.0191\n",
      "Total loss:  -1.9801 | PDE Loss:  -3.0446 | Function Loss:  -3.0192\n",
      "Total loss:  -1.9802 | PDE Loss:  -3.0438 | Function Loss:  -3.0194\n",
      "Total loss:  -1.9802 | PDE Loss:  -3.0436 | Function Loss:  -3.0195\n",
      "Total loss:  -1.9803 | PDE Loss:  -3.0433 | Function Loss:  -3.0196\n",
      "Total loss:  -1.9804 | PDE Loss:  -3.0433 | Function Loss:  -3.0196\n",
      "Total loss:  -1.9805 | PDE Loss:  -3.0434 | Function Loss:  -3.0198\n",
      "Total loss:  -1.9806 | PDE Loss:  -3.0444 | Function Loss:  -3.0198\n",
      "Total loss:  -1.9807 | PDE Loss:  -3.0453 | Function Loss:  -3.0199\n",
      "Total loss:  -1.9808 | PDE Loss:  -3.0463 | Function Loss:  -3.0199\n",
      "Total loss:  -1.9809 | PDE Loss:  -3.0476 | Function Loss:  -3.0199\n",
      "Total loss:  -1.981 | PDE Loss:  -3.0477 | Function Loss:  -3.02\n",
      "Total loss:  -1.9811 | PDE Loss:  -3.0482 | Function Loss:  -3.02\n",
      "Total loss:  -1.9812 | PDE Loss:  -3.0479 | Function Loss:  -3.0201\n",
      "Total loss:  -1.9812 | PDE Loss:  -3.0475 | Function Loss:  -3.0202\n",
      "Total loss:  -1.9813 | PDE Loss:  -3.0462 | Function Loss:  -3.0204\n",
      "Total loss:  -1.9813 | PDE Loss:  -3.0462 | Function Loss:  -3.0204\n",
      "Total loss:  -1.9813 | PDE Loss:  -3.046 | Function Loss:  -3.0205\n",
      "Total loss:  -1.9814 | PDE Loss:  -3.046 | Function Loss:  -3.0205\n",
      "Total loss:  -1.9814 | PDE Loss:  -3.0462 | Function Loss:  -3.0206\n",
      "Total loss:  -1.9815 | PDE Loss:  -3.0469 | Function Loss:  -3.0206\n",
      "Total loss:  -1.9815 | PDE Loss:  -3.0474 | Function Loss:  -3.0206\n",
      "Total loss:  -1.9816 | PDE Loss:  -3.0479 | Function Loss:  -3.0206\n",
      "Total loss:  -1.9817 | PDE Loss:  -3.049 | Function Loss:  -3.0205\n",
      "Total loss:  -1.9817 | PDE Loss:  -3.0488 | Function Loss:  -3.0206\n",
      "Total loss:  -1.9818 | PDE Loss:  -3.0489 | Function Loss:  -3.0207\n",
      "Total loss:  -1.9819 | PDE Loss:  -3.0486 | Function Loss:  -3.0208\n",
      "Total loss:  -1.982 | PDE Loss:  -3.0477 | Function Loss:  -3.0211\n",
      "Total loss:  -1.9821 | PDE Loss:  -3.0468 | Function Loss:  -3.0213\n",
      "Total loss:  -1.9822 | PDE Loss:  -3.0463 | Function Loss:  -3.0214\n",
      "Total loss:  -1.9822 | PDE Loss:  -3.0461 | Function Loss:  -3.0214\n",
      "Total loss:  -1.9823 | PDE Loss:  -3.046 | Function Loss:  -3.0215\n",
      "Total loss:  -1.9823 | PDE Loss:  -3.0462 | Function Loss:  -3.0215\n",
      "Total loss:  -1.9824 | PDE Loss:  -3.0467 | Function Loss:  -3.0215\n",
      "Total loss:  -1.9824 | PDE Loss:  -3.0472 | Function Loss:  -3.0215\n",
      "Total loss:  -1.9824 | PDE Loss:  -3.0482 | Function Loss:  -3.0215\n",
      "Total loss:  -1.9825 | PDE Loss:  -3.0495 | Function Loss:  -3.0214\n",
      "Total loss:  -1.9825 | PDE Loss:  -3.0505 | Function Loss:  -3.0214\n",
      "Total loss:  -1.9826 | PDE Loss:  -3.0512 | Function Loss:  -3.0213\n",
      "Total loss:  -1.9826 | PDE Loss:  -3.0516 | Function Loss:  -3.0213\n",
      "Total loss:  -1.9826 | PDE Loss:  -3.0518 | Function Loss:  -3.0213\n",
      "Total loss:  -1.9827 | PDE Loss:  -3.0519 | Function Loss:  -3.0214\n",
      "Total loss:  -1.9827 | PDE Loss:  -3.0522 | Function Loss:  -3.0214\n",
      "Total loss:  -1.9828 | PDE Loss:  -3.0521 | Function Loss:  -3.0215\n",
      "Total loss:  -1.9829 | PDE Loss:  -3.0525 | Function Loss:  -3.0215\n",
      "Total loss:  -1.9829 | PDE Loss:  -3.0529 | Function Loss:  -3.0216\n",
      "Total loss:  -1.983 | PDE Loss:  -3.0538 | Function Loss:  -3.0216\n",
      "Total loss:  -1.9831 | PDE Loss:  -3.054 | Function Loss:  -3.0217\n",
      "Total loss:  -1.9832 | PDE Loss:  -3.0563 | Function Loss:  -3.0215\n",
      "Total loss:  -1.9833 | PDE Loss:  -3.0569 | Function Loss:  -3.0216\n",
      "Total loss:  -1.9834 | PDE Loss:  -3.0572 | Function Loss:  -3.0217\n",
      "Total loss:  -1.9834 | PDE Loss:  -3.0556 | Function Loss:  -3.0219\n",
      "Total loss:  -1.9836 | PDE Loss:  -3.0561 | Function Loss:  -3.022\n",
      "Total loss:  -1.9837 | PDE Loss:  -3.0568 | Function Loss:  -3.022\n",
      "Total loss:  -1.9838 | PDE Loss:  -3.057 | Function Loss:  -3.0221\n",
      "Total loss:  -1.9839 | PDE Loss:  -3.0568 | Function Loss:  -3.0223\n",
      "Total loss:  -1.984 | PDE Loss:  -3.0564 | Function Loss:  -3.0224\n",
      "Total loss:  -1.9841 | PDE Loss:  -3.0554 | Function Loss:  -3.0226\n",
      "Total loss:  -1.9842 | PDE Loss:  -3.0545 | Function Loss:  -3.0228\n",
      "Total loss:  -1.9842 | PDE Loss:  -3.0541 | Function Loss:  -3.0229\n",
      "Total loss:  -1.9843 | PDE Loss:  -3.0533 | Function Loss:  -3.023\n",
      "Total loss:  -1.9843 | PDE Loss:  -3.0533 | Function Loss:  -3.0231\n",
      "Total loss:  -1.9844 | PDE Loss:  -3.0532 | Function Loss:  -3.0231\n",
      "Total loss:  -1.9845 | PDE Loss:  -3.0537 | Function Loss:  -3.0232\n",
      "Total loss:  -1.9845 | PDE Loss:  -3.0538 | Function Loss:  -3.0232\n",
      "Total loss:  -1.9846 | PDE Loss:  -3.0544 | Function Loss:  -3.0233\n",
      "Total loss:  -1.9847 | PDE Loss:  -3.0543 | Function Loss:  -3.0234\n",
      "Total loss:  -1.9848 | PDE Loss:  -3.0545 | Function Loss:  -3.0235\n",
      "Total loss:  -1.9849 | PDE Loss:  -3.0544 | Function Loss:  -3.0236\n",
      "Total loss:  -1.985 | PDE Loss:  -3.0542 | Function Loss:  -3.0237\n",
      "Total loss:  -1.9851 | PDE Loss:  -3.0535 | Function Loss:  -3.0239\n",
      "Total loss:  -1.9852 | PDE Loss:  -3.053 | Function Loss:  -3.024\n",
      "Total loss:  -1.9853 | PDE Loss:  -3.0521 | Function Loss:  -3.0242\n",
      "Total loss:  -1.9853 | PDE Loss:  -3.0516 | Function Loss:  -3.0243\n",
      "Total loss:  -1.9854 | PDE Loss:  -3.0511 | Function Loss:  -3.0245\n",
      "Total loss:  -1.9855 | PDE Loss:  -3.0509 | Function Loss:  -3.0246\n",
      "Total loss:  -1.9857 | PDE Loss:  -3.0514 | Function Loss:  -3.0247\n",
      "Total loss:  -1.9852 | PDE Loss:  -3.0495 | Function Loss:  -3.0243\n",
      "Total loss:  -1.9857 | PDE Loss:  -3.0519 | Function Loss:  -3.0247\n",
      "Total loss:  -1.9859 | PDE Loss:  -3.0534 | Function Loss:  -3.0247\n",
      "Total loss:  -1.9861 | PDE Loss:  -3.0566 | Function Loss:  -3.0247\n",
      "Total loss:  -1.9864 | PDE Loss:  -3.0604 | Function Loss:  -3.0246\n",
      "Total loss:  -1.9866 | PDE Loss:  -3.0641 | Function Loss:  -3.0245\n",
      "Total loss:  -1.9868 | PDE Loss:  -3.0673 | Function Loss:  -3.0244\n",
      "Total loss:  -1.9869 | PDE Loss:  -3.0697 | Function Loss:  -3.0244\n",
      "Total loss:  -1.9872 | PDE Loss:  -3.07 | Function Loss:  -3.0246\n",
      "Total loss:  -1.9874 | PDE Loss:  -3.0695 | Function Loss:  -3.025\n",
      "Total loss:  -1.9876 | PDE Loss:  -3.0667 | Function Loss:  -3.0254\n",
      "Total loss:  -1.9878 | PDE Loss:  -3.0642 | Function Loss:  -3.0258\n",
      "Total loss:  -1.9879 | PDE Loss:  -3.0613 | Function Loss:  -3.0263\n",
      "Total loss:  -1.9881 | PDE Loss:  -3.0585 | Function Loss:  -3.0267\n",
      "Total loss:  -1.9882 | PDE Loss:  -3.0564 | Function Loss:  -3.027\n",
      "Total loss:  -1.9884 | PDE Loss:  -3.0551 | Function Loss:  -3.0273\n",
      "Total loss:  -1.9885 | PDE Loss:  -3.055 | Function Loss:  -3.0275\n",
      "Total loss:  -1.9888 | PDE Loss:  -3.0558 | Function Loss:  -3.0277\n",
      "Total loss:  -1.989 | PDE Loss:  -3.0582 | Function Loss:  -3.0278\n",
      "Total loss:  -1.9893 | PDE Loss:  -3.0611 | Function Loss:  -3.0278\n",
      "Total loss:  -1.9896 | PDE Loss:  -3.0637 | Function Loss:  -3.0278\n",
      "Total loss:  -1.9898 | PDE Loss:  -3.066 | Function Loss:  -3.0278\n",
      "Total loss:  -1.9899 | PDE Loss:  -3.0674 | Function Loss:  -3.0279\n",
      "Total loss:  -1.9901 | PDE Loss:  -3.0693 | Function Loss:  -3.0279\n",
      "Total loss:  -1.9902 | PDE Loss:  -3.0693 | Function Loss:  -3.028\n",
      "Total loss:  -1.9904 | PDE Loss:  -3.0688 | Function Loss:  -3.0283\n",
      "Total loss:  -1.9906 | PDE Loss:  -3.0679 | Function Loss:  -3.0285\n",
      "Total loss:  -1.9908 | PDE Loss:  -3.066 | Function Loss:  -3.0289\n",
      "Total loss:  -1.991 | PDE Loss:  -3.0651 | Function Loss:  -3.0293\n",
      "Total loss:  -1.9913 | PDE Loss:  -3.062 | Function Loss:  -3.0298\n",
      "Total loss:  -1.9915 | PDE Loss:  -3.0612 | Function Loss:  -3.0301\n",
      "Total loss:  -1.9917 | PDE Loss:  -3.0609 | Function Loss:  -3.0304\n",
      "Total loss:  -1.992 | PDE Loss:  -3.061 | Function Loss:  -3.0307\n",
      "Total loss:  -1.9922 | PDE Loss:  -3.0602 | Function Loss:  -3.031\n",
      "Total loss:  -1.9924 | PDE Loss:  -3.0601 | Function Loss:  -3.0312\n",
      "Total loss:  -1.9924 | PDE Loss:  -3.0538 | Function Loss:  -3.0318\n",
      "Total loss:  -1.9925 | PDE Loss:  -3.0577 | Function Loss:  -3.0316\n",
      "Total loss:  -1.9927 | PDE Loss:  -3.0571 | Function Loss:  -3.0319\n",
      "Total loss:  -1.9929 | PDE Loss:  -3.0562 | Function Loss:  -3.0321\n",
      "Total loss:  -1.9932 | PDE Loss:  -3.0549 | Function Loss:  -3.0326\n",
      "Total loss:  -1.9934 | PDE Loss:  -3.0524 | Function Loss:  -3.0331\n",
      "Total loss:  -1.9936 | PDE Loss:  -3.0503 | Function Loss:  -3.0335\n",
      "Total loss:  -1.9938 | PDE Loss:  -3.0484 | Function Loss:  -3.0339\n",
      "Total loss:  -1.9941 | PDE Loss:  -3.0461 | Function Loss:  -3.0344\n",
      "Total loss:  -1.9942 | PDE Loss:  -3.0376 | Function Loss:  -3.0354\n",
      "Total loss:  -1.9944 | PDE Loss:  -3.04 | Function Loss:  -3.0354\n",
      "Total loss:  -1.9946 | PDE Loss:  -3.0414 | Function Loss:  -3.0355\n",
      "Total loss:  -1.9948 | PDE Loss:  -3.0424 | Function Loss:  -3.0356\n",
      "Total loss:  -1.995 | PDE Loss:  -3.0406 | Function Loss:  -3.0359\n",
      "Total loss:  -1.9951 | PDE Loss:  -3.0383 | Function Loss:  -3.0364\n",
      "Total loss:  -1.9953 | PDE Loss:  -3.0335 | Function Loss:  -3.037\n",
      "Total loss:  -1.9954 | PDE Loss:  -3.0323 | Function Loss:  -3.0372\n",
      "Total loss:  -1.9955 | PDE Loss:  -3.0286 | Function Loss:  -3.0377\n",
      "Total loss:  -1.9956 | PDE Loss:  -3.0274 | Function Loss:  -3.0379\n",
      "Total loss:  -1.9956 | PDE Loss:  -3.0276 | Function Loss:  -3.038\n",
      "Total loss:  -1.9957 | PDE Loss:  -3.027 | Function Loss:  -3.0381\n",
      "Total loss:  -1.9958 | PDE Loss:  -3.0266 | Function Loss:  -3.0383\n",
      "Total loss:  -1.9957 | PDE Loss:  -3.0291 | Function Loss:  -3.0379\n",
      "Total loss:  -1.9959 | PDE Loss:  -3.0283 | Function Loss:  -3.0382\n",
      "Total loss:  -1.996 | PDE Loss:  -3.0279 | Function Loss:  -3.0384\n",
      "Total loss:  -1.9961 | PDE Loss:  -3.0276 | Function Loss:  -3.0385\n",
      "Total loss:  -1.9963 | PDE Loss:  -3.0265 | Function Loss:  -3.0388\n",
      "Total loss:  -1.9964 | PDE Loss:  -3.0258 | Function Loss:  -3.039\n",
      "Total loss:  -1.9966 | PDE Loss:  -3.0237 | Function Loss:  -3.0394\n",
      "Total loss:  -1.9967 | PDE Loss:  -3.024 | Function Loss:  -3.0396\n",
      "Total loss:  -1.9969 | PDE Loss:  -3.0203 | Function Loss:  -3.0401\n",
      "Total loss:  -1.997 | PDE Loss:  -3.0199 | Function Loss:  -3.0402\n",
      "Total loss:  -1.9971 | PDE Loss:  -3.0196 | Function Loss:  -3.0404\n",
      "Total loss:  -1.9973 | PDE Loss:  -3.0181 | Function Loss:  -3.0408\n",
      "Total loss:  -1.9974 | PDE Loss:  -3.0171 | Function Loss:  -3.0411\n",
      "Total loss:  -1.9976 | PDE Loss:  -3.0159 | Function Loss:  -3.0414\n",
      "Total loss:  -1.9978 | PDE Loss:  -3.0153 | Function Loss:  -3.0417\n",
      "Total loss:  -1.9981 | PDE Loss:  -3.0162 | Function Loss:  -3.0419\n",
      "Total loss:  -1.9982 | PDE Loss:  -3.0167 | Function Loss:  -3.042\n",
      "Total loss:  -1.9984 | PDE Loss:  -3.0181 | Function Loss:  -3.042\n",
      "Total loss:  -1.9985 | PDE Loss:  -3.0217 | Function Loss:  -3.0417\n",
      "Total loss:  -1.9986 | PDE Loss:  -3.0226 | Function Loss:  -3.0418\n",
      "Total loss:  -1.9987 | PDE Loss:  -3.0252 | Function Loss:  -3.0416\n",
      "Total loss:  -1.9988 | PDE Loss:  -3.0283 | Function Loss:  -3.0414\n",
      "Total loss:  -1.999 | PDE Loss:  -3.0321 | Function Loss:  -3.0412\n",
      "Total loss:  -1.9991 | PDE Loss:  -3.0358 | Function Loss:  -3.0409\n",
      "Total loss:  -1.9991 | PDE Loss:  -3.0369 | Function Loss:  -3.0408\n",
      "Total loss:  -1.9992 | PDE Loss:  -3.0368 | Function Loss:  -3.0409\n",
      "Total loss:  -1.9992 | PDE Loss:  -3.0376 | Function Loss:  -3.0409\n",
      "Total loss:  -1.9993 | PDE Loss:  -3.0372 | Function Loss:  -3.0411\n",
      "Total loss:  -1.9994 | PDE Loss:  -3.0366 | Function Loss:  -3.0412\n",
      "Total loss:  -1.9994 | PDE Loss:  -3.0361 | Function Loss:  -3.0413\n",
      "Total loss:  -1.9995 | PDE Loss:  -3.0357 | Function Loss:  -3.0414\n",
      "Total loss:  -1.9995 | PDE Loss:  -3.0357 | Function Loss:  -3.0414\n",
      "Total loss:  -1.9996 | PDE Loss:  -3.0355 | Function Loss:  -3.0415\n",
      "Total loss:  -1.9996 | PDE Loss:  -3.0361 | Function Loss:  -3.0415\n",
      "Total loss:  -1.9997 | PDE Loss:  -3.0365 | Function Loss:  -3.0415\n",
      "Total loss:  -1.9997 | PDE Loss:  -3.0375 | Function Loss:  -3.0415\n",
      "Total loss:  -1.9998 | PDE Loss:  -3.0384 | Function Loss:  -3.0415\n",
      "Total loss:  -1.9998 | PDE Loss:  -3.0391 | Function Loss:  -3.0414\n",
      "Total loss:  -1.9999 | PDE Loss:  -3.0396 | Function Loss:  -3.0414\n",
      "Total loss:  -1.9999 | PDE Loss:  -3.0399 | Function Loss:  -3.0414\n",
      "Total loss:  -1.9999 | PDE Loss:  -3.0399 | Function Loss:  -3.0415\n",
      "Total loss:  -2.0 | PDE Loss:  -3.0397 | Function Loss:  -3.0415\n",
      "Total loss:  -2.0 | PDE Loss:  -3.0396 | Function Loss:  -3.0416\n",
      "Total loss:  -2.0001 | PDE Loss:  -3.0393 | Function Loss:  -3.0417\n",
      "Total loss:  -2.0001 | PDE Loss:  -3.0389 | Function Loss:  -3.0418\n",
      "Total loss:  -2.0002 | PDE Loss:  -3.0389 | Function Loss:  -3.0419\n",
      "Total loss:  -2.0003 | PDE Loss:  -3.0387 | Function Loss:  -3.0419\n",
      "Total loss:  -2.0003 | PDE Loss:  -3.039 | Function Loss:  -3.042\n",
      "Total loss:  -2.0004 | PDE Loss:  -3.0391 | Function Loss:  -3.042\n",
      "Total loss:  -2.0004 | PDE Loss:  -3.0395 | Function Loss:  -3.0421\n",
      "Total loss:  -2.0005 | PDE Loss:  -3.0405 | Function Loss:  -3.0421\n",
      "Total loss:  -2.0007 | PDE Loss:  -3.0405 | Function Loss:  -3.0422\n",
      "Total loss:  -2.0007 | PDE Loss:  -3.0411 | Function Loss:  -3.0422\n",
      "Total loss:  -2.0009 | PDE Loss:  -3.0411 | Function Loss:  -3.0424\n",
      "Total loss:  -2.001 | PDE Loss:  -3.0413 | Function Loss:  -3.0425\n",
      "Total loss:  -2.0012 | PDE Loss:  -3.04 | Function Loss:  -3.0429\n",
      "Total loss:  -2.0014 | PDE Loss:  -3.0389 | Function Loss:  -3.0432\n",
      "Total loss:  -2.0016 | PDE Loss:  -3.0376 | Function Loss:  -3.0436\n",
      "Total loss:  -2.0019 | PDE Loss:  -3.035 | Function Loss:  -3.0442\n",
      "Total loss:  -2.0023 | PDE Loss:  -3.0359 | Function Loss:  -3.0445\n",
      "Total loss:  -2.0027 | PDE Loss:  -3.0314 | Function Loss:  -3.0454\n",
      "Total loss:  -2.003 | PDE Loss:  -3.0314 | Function Loss:  -3.0458\n",
      "Total loss:  -2.0034 | PDE Loss:  -3.0298 | Function Loss:  -3.0463\n",
      "Total loss:  -2.0038 | PDE Loss:  -3.0324 | Function Loss:  -3.0465\n",
      "Total loss:  -2.0041 | PDE Loss:  -3.0336 | Function Loss:  -3.0467\n",
      "Total loss:  -2.0044 | PDE Loss:  -3.0342 | Function Loss:  -3.047\n",
      "Total loss:  -2.0048 | PDE Loss:  -3.0338 | Function Loss:  -3.0474\n",
      "Total loss:  -2.0051 | PDE Loss:  -3.0313 | Function Loss:  -3.0481\n",
      "Total loss:  -2.0055 | PDE Loss:  -3.0311 | Function Loss:  -3.0485\n",
      "Total loss:  -2.0058 | PDE Loss:  -3.026 | Function Loss:  -3.0494\n",
      "Total loss:  -2.006 | PDE Loss:  -3.025 | Function Loss:  -3.0497\n",
      "Total loss:  -2.0063 | PDE Loss:  -3.0238 | Function Loss:  -3.0501\n",
      "Total loss:  -2.0065 | PDE Loss:  -3.0236 | Function Loss:  -3.0504\n",
      "Total loss:  -2.0067 | PDE Loss:  -3.0241 | Function Loss:  -3.0506\n",
      "Total loss:  -2.0069 | PDE Loss:  -3.0244 | Function Loss:  -3.0507\n",
      "Total loss:  -2.0071 | PDE Loss:  -3.0267 | Function Loss:  -3.0507\n",
      "Total loss:  -2.0073 | PDE Loss:  -3.0296 | Function Loss:  -3.0507\n",
      "Total loss:  -2.0075 | PDE Loss:  -3.0306 | Function Loss:  -3.0507\n",
      "Total loss:  -2.0076 | PDE Loss:  -3.0327 | Function Loss:  -3.0507\n",
      "Total loss:  -2.0078 | PDE Loss:  -3.0343 | Function Loss:  -3.0507\n",
      "Total loss:  -2.008 | PDE Loss:  -3.0346 | Function Loss:  -3.051\n",
      "Total loss:  -2.0083 | PDE Loss:  -3.0355 | Function Loss:  -3.0511\n",
      "Total loss:  -2.0084 | PDE Loss:  -3.0357 | Function Loss:  -3.0512\n",
      "Total loss:  -2.0086 | PDE Loss:  -3.0352 | Function Loss:  -3.0515\n",
      "Total loss:  -2.0088 | PDE Loss:  -3.0352 | Function Loss:  -3.0517\n",
      "Total loss:  -2.0089 | PDE Loss:  -3.0351 | Function Loss:  -3.0519\n",
      "Total loss:  -2.0091 | PDE Loss:  -3.035 | Function Loss:  -3.052\n",
      "Total loss:  -2.0092 | PDE Loss:  -3.0352 | Function Loss:  -3.0522\n",
      "Total loss:  -2.0094 | PDE Loss:  -3.0352 | Function Loss:  -3.0524\n",
      "Total loss:  -2.0095 | PDE Loss:  -3.0352 | Function Loss:  -3.0525\n",
      "Total loss:  -2.0097 | PDE Loss:  -3.0354 | Function Loss:  -3.0527\n",
      "Total loss:  -2.0099 | PDE Loss:  -3.035 | Function Loss:  -3.0529\n",
      "Total loss:  -2.01 | PDE Loss:  -3.0354 | Function Loss:  -3.053\n",
      "Total loss:  -2.0101 | PDE Loss:  -3.0363 | Function Loss:  -3.0531\n",
      "Total loss:  -2.0103 | PDE Loss:  -3.0359 | Function Loss:  -3.0533\n",
      "Total loss:  -2.0104 | PDE Loss:  -3.0373 | Function Loss:  -3.0533\n",
      "Total loss:  -2.0107 | PDE Loss:  -3.0392 | Function Loss:  -3.0534\n",
      "Total loss:  -2.0109 | PDE Loss:  -3.0419 | Function Loss:  -3.0533\n",
      "Total loss:  -2.011 | PDE Loss:  -3.0439 | Function Loss:  -3.0533\n",
      "Total loss:  -2.0112 | PDE Loss:  -3.0462 | Function Loss:  -3.0532\n",
      "Total loss:  -2.0113 | PDE Loss:  -3.0474 | Function Loss:  -3.0533\n",
      "Total loss:  -2.0114 | PDE Loss:  -3.0488 | Function Loss:  -3.0532\n",
      "Total loss:  -2.0115 | PDE Loss:  -3.0497 | Function Loss:  -3.0532\n",
      "Total loss:  -2.0116 | PDE Loss:  -3.0499 | Function Loss:  -3.0533\n",
      "Total loss:  -2.0116 | PDE Loss:  -3.0505 | Function Loss:  -3.0533\n",
      "Total loss:  -2.0117 | PDE Loss:  -3.0505 | Function Loss:  -3.0533\n",
      "Total loss:  -2.0118 | PDE Loss:  -3.0503 | Function Loss:  -3.0535\n",
      "Total loss:  -2.0119 | PDE Loss:  -3.0496 | Function Loss:  -3.0536\n",
      "Total loss:  -2.012 | PDE Loss:  -3.0492 | Function Loss:  -3.0538\n",
      "Total loss:  -2.0121 | PDE Loss:  -3.0485 | Function Loss:  -3.0539\n",
      "Total loss:  -2.0122 | PDE Loss:  -3.0488 | Function Loss:  -3.054\n",
      "Total loss:  -2.0123 | PDE Loss:  -3.0483 | Function Loss:  -3.0542\n",
      "Total loss:  -2.0123 | PDE Loss:  -3.0486 | Function Loss:  -3.0542\n",
      "Total loss:  -2.0124 | PDE Loss:  -3.0497 | Function Loss:  -3.0542\n",
      "Total loss:  -2.0125 | PDE Loss:  -3.0505 | Function Loss:  -3.0543\n",
      "Total loss:  -2.0127 | PDE Loss:  -3.0517 | Function Loss:  -3.0543\n",
      "Total loss:  -2.0128 | PDE Loss:  -3.0525 | Function Loss:  -3.0544\n",
      "Total loss:  -2.013 | PDE Loss:  -3.0534 | Function Loss:  -3.0545\n",
      "Total loss:  -2.0133 | PDE Loss:  -3.054 | Function Loss:  -3.0547\n",
      "Total loss:  -2.0135 | PDE Loss:  -3.054 | Function Loss:  -3.055\n",
      "Total loss:  -2.0136 | PDE Loss:  -3.0542 | Function Loss:  -3.0551\n",
      "Total loss:  -2.0139 | PDE Loss:  -3.0525 | Function Loss:  -3.0555\n",
      "Total loss:  -2.014 | PDE Loss:  -3.0517 | Function Loss:  -3.0558\n",
      "Total loss:  -2.0142 | PDE Loss:  -3.0496 | Function Loss:  -3.0562\n",
      "Total loss:  -2.0143 | PDE Loss:  -3.0486 | Function Loss:  -3.0564\n",
      "Total loss:  -2.0144 | PDE Loss:  -3.0474 | Function Loss:  -3.0567\n",
      "Total loss:  -2.0145 | PDE Loss:  -3.0462 | Function Loss:  -3.0569\n",
      "Total loss:  -2.0146 | PDE Loss:  -3.0451 | Function Loss:  -3.0571\n",
      "Total loss:  -2.0148 | PDE Loss:  -3.044 | Function Loss:  -3.0574\n",
      "Total loss:  -2.0149 | PDE Loss:  -3.0424 | Function Loss:  -3.0577\n",
      "Total loss:  -2.0151 | PDE Loss:  -3.0421 | Function Loss:  -3.0579\n",
      "Total loss:  -2.0152 | PDE Loss:  -3.0417 | Function Loss:  -3.0582\n",
      "Total loss:  -2.0155 | PDE Loss:  -3.0415 | Function Loss:  -3.0585\n",
      "Total loss:  -2.0159 | PDE Loss:  -3.0407 | Function Loss:  -3.0589\n",
      "Total loss:  -2.0162 | PDE Loss:  -3.0407 | Function Loss:  -3.0593\n",
      "Total loss:  -2.0164 | PDE Loss:  -3.0393 | Function Loss:  -3.0597\n",
      "Total loss:  -2.0166 | PDE Loss:  -3.0391 | Function Loss:  -3.06\n",
      "Total loss:  -2.0168 | PDE Loss:  -3.0374 | Function Loss:  -3.0604\n",
      "Total loss:  -2.017 | PDE Loss:  -3.0361 | Function Loss:  -3.0607\n",
      "Total loss:  -2.0171 | PDE Loss:  -3.0355 | Function Loss:  -3.0609\n",
      "Total loss:  -2.0172 | PDE Loss:  -3.0347 | Function Loss:  -3.0611\n",
      "Total loss:  -2.0173 | PDE Loss:  -3.034 | Function Loss:  -3.0613\n",
      "Total loss:  -2.0175 | PDE Loss:  -3.0345 | Function Loss:  -3.0614\n",
      "Total loss:  -2.0176 | PDE Loss:  -3.0343 | Function Loss:  -3.0615\n",
      "Total loss:  -2.0177 | PDE Loss:  -3.0341 | Function Loss:  -3.0617\n",
      "Total loss:  -2.0179 | PDE Loss:  -3.0353 | Function Loss:  -3.0618\n",
      "Total loss:  -2.0178 | PDE Loss:  -3.03 | Function Loss:  -3.0622\n",
      "Total loss:  -2.018 | PDE Loss:  -3.034 | Function Loss:  -3.062\n",
      "Total loss:  -2.0181 | PDE Loss:  -3.0349 | Function Loss:  -3.0621\n",
      "Total loss:  -2.0183 | PDE Loss:  -3.0374 | Function Loss:  -3.062\n",
      "Total loss:  -2.0185 | PDE Loss:  -3.0386 | Function Loss:  -3.062\n",
      "Total loss:  -2.0186 | PDE Loss:  -3.0397 | Function Loss:  -3.0621\n",
      "Total loss:  -2.0188 | PDE Loss:  -3.0408 | Function Loss:  -3.0622\n",
      "Total loss:  -2.019 | PDE Loss:  -3.0398 | Function Loss:  -3.0625\n",
      "Total loss:  -2.0193 | PDE Loss:  -3.0386 | Function Loss:  -3.063\n",
      "Total loss:  -2.0196 | PDE Loss:  -3.0355 | Function Loss:  -3.0636\n",
      "Total loss:  -2.0201 | PDE Loss:  -3.0339 | Function Loss:  -3.0643\n",
      "Total loss:  -2.0206 | PDE Loss:  -3.0285 | Function Loss:  -3.0655\n",
      "Total loss:  -2.0211 | PDE Loss:  -3.0223 | Function Loss:  -3.0667\n",
      "Total loss:  -2.0214 | PDE Loss:  -3.022 | Function Loss:  -3.0671\n",
      "Total loss:  -2.0219 | PDE Loss:  -3.0244 | Function Loss:  -3.0674\n",
      "Total loss:  -2.0223 | PDE Loss:  -3.0254 | Function Loss:  -3.0677\n",
      "Total loss:  -2.0226 | PDE Loss:  -3.0271 | Function Loss:  -3.0678\n",
      "Total loss:  -2.0229 | PDE Loss:  -3.0296 | Function Loss:  -3.0679\n",
      "Total loss:  -2.0232 | PDE Loss:  -3.032 | Function Loss:  -3.068\n",
      "Total loss:  -2.0236 | PDE Loss:  -3.0345 | Function Loss:  -3.0681\n",
      "Total loss:  -2.0238 | PDE Loss:  -3.0347 | Function Loss:  -3.0684\n",
      "Total loss:  -2.0241 | PDE Loss:  -3.0347 | Function Loss:  -3.0687\n",
      "Total loss:  -2.0245 | PDE Loss:  -3.0345 | Function Loss:  -3.0692\n",
      "Total loss:  -2.0249 | PDE Loss:  -3.0303 | Function Loss:  -3.07\n",
      "Total loss:  -2.0251 | PDE Loss:  -3.0304 | Function Loss:  -3.0702\n",
      "Total loss:  -2.0253 | PDE Loss:  -3.0291 | Function Loss:  -3.0706\n",
      "Total loss:  -2.0255 | PDE Loss:  -3.0284 | Function Loss:  -3.0709\n",
      "Total loss:  -2.0257 | PDE Loss:  -3.0289 | Function Loss:  -3.0711\n",
      "Total loss:  -2.0259 | PDE Loss:  -3.0285 | Function Loss:  -3.0713\n",
      "Total loss:  -2.026 | PDE Loss:  -3.0288 | Function Loss:  -3.0715\n",
      "Total loss:  -2.0262 | PDE Loss:  -3.0286 | Function Loss:  -3.0717\n",
      "Total loss:  -2.0264 | PDE Loss:  -3.0286 | Function Loss:  -3.0719\n",
      "Total loss:  -2.0266 | PDE Loss:  -3.0278 | Function Loss:  -3.0722\n",
      "Total loss:  -2.0269 | PDE Loss:  -3.0281 | Function Loss:  -3.0725\n",
      "Total loss:  -2.0271 | PDE Loss:  -3.0276 | Function Loss:  -3.0728\n",
      "Total loss:  -2.0274 | PDE Loss:  -3.0272 | Function Loss:  -3.0731\n",
      "Total loss:  -2.0277 | PDE Loss:  -3.0269 | Function Loss:  -3.0736\n",
      "Total loss:  -2.0282 | PDE Loss:  -3.0263 | Function Loss:  -3.0741\n",
      "Total loss:  -2.0286 | PDE Loss:  -3.026 | Function Loss:  -3.0746\n",
      "Total loss:  -2.0292 | PDE Loss:  -3.0276 | Function Loss:  -3.0751\n",
      "Total loss:  -2.0297 | PDE Loss:  -3.0256 | Function Loss:  -3.076\n",
      "Total loss:  -2.0302 | PDE Loss:  -3.0269 | Function Loss:  -3.0763\n",
      "Total loss:  -2.0306 | PDE Loss:  -3.0303 | Function Loss:  -3.0764\n",
      "Total loss:  -2.0308 | PDE Loss:  -3.0254 | Function Loss:  -3.0771\n",
      "Total loss:  -2.031 | PDE Loss:  -3.0285 | Function Loss:  -3.077\n",
      "Total loss:  -2.0315 | PDE Loss:  -3.0281 | Function Loss:  -3.0776\n",
      "Total loss:  -2.0318 | PDE Loss:  -3.0297 | Function Loss:  -3.0777\n",
      "Total loss:  -2.032 | PDE Loss:  -3.0281 | Function Loss:  -3.0782\n",
      "Total loss:  -2.0323 | PDE Loss:  -3.0259 | Function Loss:  -3.0788\n",
      "Total loss:  -2.0325 | PDE Loss:  -3.0243 | Function Loss:  -3.0792\n",
      "Total loss:  -2.0327 | PDE Loss:  -3.0213 | Function Loss:  -3.0798\n",
      "Total loss:  -2.033 | PDE Loss:  -3.0192 | Function Loss:  -3.0803\n",
      "Total loss:  -2.0332 | PDE Loss:  -3.0172 | Function Loss:  -3.0808\n",
      "Total loss:  -2.0334 | PDE Loss:  -3.0152 | Function Loss:  -3.0812\n",
      "Total loss:  -2.0336 | PDE Loss:  -3.0149 | Function Loss:  -3.0815\n",
      "Total loss:  -2.0339 | PDE Loss:  -3.0141 | Function Loss:  -3.0819\n",
      "Total loss:  -2.0342 | PDE Loss:  -3.0154 | Function Loss:  -3.0821\n",
      "Total loss:  -2.0344 | PDE Loss:  -3.013 | Function Loss:  -3.0826\n",
      "Total loss:  -2.0346 | PDE Loss:  -3.0129 | Function Loss:  -3.0828\n",
      "Total loss:  -2.0347 | PDE Loss:  -3.013 | Function Loss:  -3.083\n",
      "Total loss:  -2.0348 | PDE Loss:  -3.0123 | Function Loss:  -3.0832\n",
      "Total loss:  -2.0349 | PDE Loss:  -3.0124 | Function Loss:  -3.0832\n",
      "Total loss:  -2.0349 | PDE Loss:  -3.0121 | Function Loss:  -3.0833\n",
      "Total loss:  -2.035 | PDE Loss:  -3.0127 | Function Loss:  -3.0833\n",
      "Total loss:  -2.035 | PDE Loss:  -3.0132 | Function Loss:  -3.0833\n",
      "Total loss:  -2.0351 | PDE Loss:  -3.0142 | Function Loss:  -3.0832\n",
      "Total loss:  -2.0351 | PDE Loss:  -3.0154 | Function Loss:  -3.0831\n",
      "Total loss:  -2.0352 | PDE Loss:  -3.0166 | Function Loss:  -3.0831\n",
      "Total loss:  -2.0353 | PDE Loss:  -3.0184 | Function Loss:  -3.0829\n",
      "Total loss:  -2.0352 | PDE Loss:  -3.0188 | Function Loss:  -3.0828\n",
      "Total loss:  -2.0353 | PDE Loss:  -3.019 | Function Loss:  -3.0829\n",
      "Total loss:  -2.0353 | PDE Loss:  -3.0196 | Function Loss:  -3.0829\n",
      "Total loss:  -2.0354 | PDE Loss:  -3.02 | Function Loss:  -3.0829\n",
      "Total loss:  -2.0355 | PDE Loss:  -3.0204 | Function Loss:  -3.083\n",
      "Total loss:  -2.0356 | PDE Loss:  -3.0202 | Function Loss:  -3.0831\n",
      "Total loss:  -2.0356 | PDE Loss:  -3.0202 | Function Loss:  -3.0832\n",
      "Total loss:  -2.0358 | PDE Loss:  -3.0199 | Function Loss:  -3.0833\n",
      "Total loss:  -2.0359 | PDE Loss:  -3.0195 | Function Loss:  -3.0835\n",
      "Total loss:  -2.036 | PDE Loss:  -3.0194 | Function Loss:  -3.0836\n",
      "Total loss:  -2.0361 | PDE Loss:  -3.0202 | Function Loss:  -3.0836\n",
      "Total loss:  -2.0362 | PDE Loss:  -3.0202 | Function Loss:  -3.0838\n",
      "Total loss:  -2.0363 | PDE Loss:  -3.0209 | Function Loss:  -3.0838\n",
      "Total loss:  -2.0364 | PDE Loss:  -3.0199 | Function Loss:  -3.084\n",
      "Total loss:  -2.0365 | PDE Loss:  -3.0203 | Function Loss:  -3.0841\n",
      "Total loss:  -2.0366 | PDE Loss:  -3.0201 | Function Loss:  -3.0842\n",
      "Total loss:  -2.0367 | PDE Loss:  -3.0201 | Function Loss:  -3.0843\n",
      "Total loss:  -2.0368 | PDE Loss:  -3.0202 | Function Loss:  -3.0844\n",
      "Total loss:  -2.0369 | PDE Loss:  -3.0198 | Function Loss:  -3.0846\n",
      "Total loss:  -2.037 | PDE Loss:  -3.0206 | Function Loss:  -3.0846\n",
      "Total loss:  -2.0371 | PDE Loss:  -3.0194 | Function Loss:  -3.0849\n",
      "Total loss:  -2.0372 | PDE Loss:  -3.0188 | Function Loss:  -3.0851\n",
      "Total loss:  -2.0373 | PDE Loss:  -3.0188 | Function Loss:  -3.0852\n",
      "Total loss:  -2.0374 | PDE Loss:  -3.0181 | Function Loss:  -3.0854\n",
      "Total loss:  -2.0375 | PDE Loss:  -3.0178 | Function Loss:  -3.0855\n",
      "Total loss:  -2.0375 | PDE Loss:  -3.0177 | Function Loss:  -3.0855\n",
      "Total loss:  -2.0375 | PDE Loss:  -3.0175 | Function Loss:  -3.0856\n",
      "Total loss:  -2.0376 | PDE Loss:  -3.0178 | Function Loss:  -3.0856\n",
      "Total loss:  -2.0377 | PDE Loss:  -3.0171 | Function Loss:  -3.0858\n",
      "Total loss:  -2.0377 | PDE Loss:  -3.0169 | Function Loss:  -3.0858\n",
      "Total loss:  -2.0378 | PDE Loss:  -3.0169 | Function Loss:  -3.0859\n",
      "Total loss:  -2.0378 | PDE Loss:  -3.0167 | Function Loss:  -3.086\n",
      "Total loss:  -2.0379 | PDE Loss:  -3.0171 | Function Loss:  -3.086\n",
      "Total loss:  -2.0379 | PDE Loss:  -3.0169 | Function Loss:  -3.0861\n",
      "Total loss:  -2.038 | PDE Loss:  -3.017 | Function Loss:  -3.0862\n",
      "Total loss:  -2.0381 | PDE Loss:  -3.0173 | Function Loss:  -3.0862\n",
      "Total loss:  -2.0382 | PDE Loss:  -3.0174 | Function Loss:  -3.0863\n",
      "Total loss:  -2.0383 | PDE Loss:  -3.0177 | Function Loss:  -3.0864\n",
      "Total loss:  -2.0384 | PDE Loss:  -3.0177 | Function Loss:  -3.0865\n",
      "Total loss:  -2.0385 | PDE Loss:  -3.0171 | Function Loss:  -3.0867\n",
      "Total loss:  -2.0386 | PDE Loss:  -3.0168 | Function Loss:  -3.0869\n",
      "Total loss:  -2.0387 | PDE Loss:  -3.0152 | Function Loss:  -3.0872\n",
      "Total loss:  -2.0389 | PDE Loss:  -3.0149 | Function Loss:  -3.0874\n",
      "Total loss:  -2.0389 | PDE Loss:  -3.0133 | Function Loss:  -3.0877\n",
      "Total loss:  -2.039 | PDE Loss:  -3.0126 | Function Loss:  -3.0878\n",
      "Total loss:  -2.0391 | PDE Loss:  -3.0118 | Function Loss:  -3.088\n",
      "Total loss:  -2.0393 | PDE Loss:  -3.0109 | Function Loss:  -3.0883\n",
      "Total loss:  -2.0394 | PDE Loss:  -3.0103 | Function Loss:  -3.0885\n",
      "Total loss:  -2.0395 | PDE Loss:  -3.0092 | Function Loss:  -3.0888\n",
      "Total loss:  -2.0397 | PDE Loss:  -3.0083 | Function Loss:  -3.089\n",
      "Total loss:  -2.0398 | PDE Loss:  -3.0072 | Function Loss:  -3.0893\n",
      "Total loss:  -2.04 | PDE Loss:  -3.0056 | Function Loss:  -3.0897\n",
      "Total loss:  -2.0402 | PDE Loss:  -3.0042 | Function Loss:  -3.0901\n",
      "Total loss:  -2.0404 | PDE Loss:  -3.0017 | Function Loss:  -3.0906\n",
      "Total loss:  -2.0406 | PDE Loss:  -2.9996 | Function Loss:  -3.0912\n",
      "Total loss:  -2.0408 | PDE Loss:  -2.9973 | Function Loss:  -3.0917\n",
      "Total loss:  -2.041 | PDE Loss:  -2.9951 | Function Loss:  -3.0922\n",
      "Total loss:  -2.0412 | PDE Loss:  -2.9932 | Function Loss:  -3.0927\n",
      "Total loss:  -2.0414 | PDE Loss:  -2.9928 | Function Loss:  -3.0929\n",
      "Total loss:  -2.0415 | PDE Loss:  -2.9911 | Function Loss:  -3.0932\n",
      "Total loss:  -2.0416 | PDE Loss:  -2.9916 | Function Loss:  -3.0933\n",
      "Total loss:  -2.0417 | PDE Loss:  -2.9922 | Function Loss:  -3.0933\n",
      "Total loss:  -2.0418 | PDE Loss:  -2.992 | Function Loss:  -3.0934\n",
      "Total loss:  -2.0419 | PDE Loss:  -2.9927 | Function Loss:  -3.0934\n",
      "Total loss:  -2.0419 | PDE Loss:  -2.9924 | Function Loss:  -3.0936\n",
      "Total loss:  -2.0421 | PDE Loss:  -2.9916 | Function Loss:  -3.0938\n",
      "Total loss:  -2.0422 | PDE Loss:  -2.9911 | Function Loss:  -3.0941\n",
      "Total loss:  -2.0425 | PDE Loss:  -2.9899 | Function Loss:  -3.0945\n",
      "Total loss:  -2.0427 | PDE Loss:  -2.9889 | Function Loss:  -3.0948\n",
      "Total loss:  -2.0429 | PDE Loss:  -2.9898 | Function Loss:  -3.095\n",
      "Total loss:  -2.0432 | PDE Loss:  -2.9898 | Function Loss:  -3.0953\n",
      "Total loss:  -2.0435 | PDE Loss:  -2.9902 | Function Loss:  -3.0956\n",
      "Total loss:  -2.0437 | PDE Loss:  -2.9896 | Function Loss:  -3.0959\n",
      "Total loss:  -2.0439 | PDE Loss:  -2.9893 | Function Loss:  -3.0962\n",
      "Total loss:  -2.0441 | PDE Loss:  -2.9877 | Function Loss:  -3.0966\n",
      "Total loss:  -2.0444 | PDE Loss:  -2.987 | Function Loss:  -3.097\n",
      "Total loss:  -2.0447 | PDE Loss:  -2.9847 | Function Loss:  -3.0976\n",
      "Total loss:  -2.0449 | PDE Loss:  -2.9836 | Function Loss:  -3.0981\n",
      "Total loss:  -2.0452 | PDE Loss:  -2.9817 | Function Loss:  -3.0986\n",
      "Total loss:  -2.0454 | PDE Loss:  -2.9823 | Function Loss:  -3.0988\n",
      "Total loss:  -2.0456 | PDE Loss:  -2.9815 | Function Loss:  -3.0991\n",
      "Total loss:  -2.0459 | PDE Loss:  -2.9822 | Function Loss:  -3.0993\n",
      "Total loss:  -2.0461 | PDE Loss:  -2.9813 | Function Loss:  -3.0997\n",
      "Total loss:  -2.0463 | PDE Loss:  -2.983 | Function Loss:  -3.0997\n",
      "Total loss:  -2.0465 | PDE Loss:  -2.9824 | Function Loss:  -3.1\n",
      "Total loss:  -2.0468 | PDE Loss:  -2.9818 | Function Loss:  -3.1004\n",
      "Total loss:  -2.0471 | PDE Loss:  -2.9813 | Function Loss:  -3.1009\n",
      "Total loss:  -2.0475 | PDE Loss:  -2.9811 | Function Loss:  -3.1013\n",
      "Total loss:  -2.0478 | PDE Loss:  -2.9806 | Function Loss:  -3.1017\n",
      "Total loss:  -2.0481 | PDE Loss:  -2.9811 | Function Loss:  -3.102\n",
      "Total loss:  -2.0483 | PDE Loss:  -2.9808 | Function Loss:  -3.1023\n",
      "Total loss:  -2.0485 | PDE Loss:  -2.9816 | Function Loss:  -3.1024\n",
      "Total loss:  -2.0486 | PDE Loss:  -2.9812 | Function Loss:  -3.1026\n",
      "Total loss:  -2.0488 | PDE Loss:  -2.9832 | Function Loss:  -3.1025\n",
      "Total loss:  -2.0489 | PDE Loss:  -2.9839 | Function Loss:  -3.1025\n",
      "Total loss:  -2.049 | PDE Loss:  -2.9857 | Function Loss:  -3.1024\n",
      "Total loss:  -2.0492 | PDE Loss:  -2.9869 | Function Loss:  -3.1024\n",
      "Total loss:  -2.0493 | PDE Loss:  -2.9879 | Function Loss:  -3.1024\n",
      "Total loss:  -2.0494 | PDE Loss:  -2.9885 | Function Loss:  -3.1025\n",
      "Total loss:  -2.0495 | PDE Loss:  -2.9894 | Function Loss:  -3.1025\n",
      "Total loss:  -2.0497 | PDE Loss:  -2.9897 | Function Loss:  -3.1026\n",
      "Total loss:  -2.0498 | PDE Loss:  -2.9909 | Function Loss:  -3.1027\n",
      "Total loss:  -2.05 | PDE Loss:  -2.992 | Function Loss:  -3.1027\n",
      "Total loss:  -2.0503 | PDE Loss:  -2.9932 | Function Loss:  -3.1029\n",
      "Total loss:  -2.0507 | PDE Loss:  -2.9966 | Function Loss:  -3.1029\n",
      "Total loss:  -2.051 | PDE Loss:  -2.9965 | Function Loss:  -3.1032\n",
      "Total loss:  -2.0514 | PDE Loss:  -2.9969 | Function Loss:  -3.1037\n",
      "Total loss:  -2.0519 | PDE Loss:  -2.998 | Function Loss:  -3.104\n",
      "Total loss:  -2.0522 | PDE Loss:  -2.9983 | Function Loss:  -3.1043\n",
      "Total loss:  -2.0524 | PDE Loss:  -2.9981 | Function Loss:  -3.1047\n",
      "Total loss:  -2.0528 | PDE Loss:  -2.9979 | Function Loss:  -3.1051\n",
      "Total loss:  -2.0532 | PDE Loss:  -2.9955 | Function Loss:  -3.1059\n",
      "Total loss:  -2.0538 | PDE Loss:  -2.9956 | Function Loss:  -3.1065\n",
      "Total loss:  -2.0542 | PDE Loss:  -2.9922 | Function Loss:  -3.1074\n",
      "Total loss:  -2.0547 | PDE Loss:  -2.9931 | Function Loss:  -3.1079\n",
      "Total loss:  -2.0551 | PDE Loss:  -2.9917 | Function Loss:  -3.1085\n",
      "Total loss:  -2.0556 | PDE Loss:  -2.9926 | Function Loss:  -3.1089\n",
      "Total loss:  -2.0558 | PDE Loss:  -2.9935 | Function Loss:  -3.1091\n",
      "Total loss:  -2.0561 | PDE Loss:  -2.9938 | Function Loss:  -3.1093\n",
      "Total loss:  -2.0563 | PDE Loss:  -2.9949 | Function Loss:  -3.1095\n",
      "Total loss:  -2.0566 | PDE Loss:  -2.9947 | Function Loss:  -3.1098\n",
      "Total loss:  -2.0568 | PDE Loss:  -2.9951 | Function Loss:  -3.11\n",
      "Total loss:  -2.057 | PDE Loss:  -2.9944 | Function Loss:  -3.1103\n",
      "Total loss:  -2.0572 | PDE Loss:  -2.9935 | Function Loss:  -3.1107\n",
      "Total loss:  -2.0573 | PDE Loss:  -2.9931 | Function Loss:  -3.1109\n",
      "Total loss:  -2.0574 | PDE Loss:  -2.992 | Function Loss:  -3.1111\n",
      "Total loss:  -2.0576 | PDE Loss:  -2.9915 | Function Loss:  -3.1113\n",
      "Total loss:  -2.0577 | PDE Loss:  -2.9905 | Function Loss:  -3.1116\n",
      "Total loss:  -2.0578 | PDE Loss:  -2.9903 | Function Loss:  -3.1117\n",
      "Total loss:  -2.0579 | PDE Loss:  -2.9888 | Function Loss:  -3.1121\n",
      "Total loss:  -2.058 | PDE Loss:  -2.9889 | Function Loss:  -3.1122\n",
      "Total loss:  -2.0581 | PDE Loss:  -2.9896 | Function Loss:  -3.1122\n",
      "Total loss:  -2.0582 | PDE Loss:  -2.9906 | Function Loss:  -3.1122\n",
      "Total loss:  -2.0584 | PDE Loss:  -2.9928 | Function Loss:  -3.1121\n",
      "Total loss:  -2.0586 | PDE Loss:  -2.9949 | Function Loss:  -3.112\n",
      "Total loss:  -2.0587 | PDE Loss:  -2.9965 | Function Loss:  -3.112\n",
      "Total loss:  -2.0589 | PDE Loss:  -2.9999 | Function Loss:  -3.1118\n",
      "Total loss:  -2.0591 | PDE Loss:  -3.0022 | Function Loss:  -3.1117\n",
      "Total loss:  -2.0593 | PDE Loss:  -3.0044 | Function Loss:  -3.1116\n",
      "Total loss:  -2.0594 | PDE Loss:  -3.0065 | Function Loss:  -3.1114\n",
      "Total loss:  -2.0595 | PDE Loss:  -3.0082 | Function Loss:  -3.1113\n",
      "Total loss:  -2.0596 | PDE Loss:  -3.0097 | Function Loss:  -3.1113\n",
      "Total loss:  -2.0597 | PDE Loss:  -3.0114 | Function Loss:  -3.1111\n",
      "Total loss:  -2.0598 | PDE Loss:  -3.0124 | Function Loss:  -3.1111\n",
      "Total loss:  -2.0598 | PDE Loss:  -3.0134 | Function Loss:  -3.1111\n",
      "Total loss:  -2.0599 | PDE Loss:  -3.0148 | Function Loss:  -3.111\n",
      "Total loss:  -2.06 | PDE Loss:  -3.0152 | Function Loss:  -3.111\n",
      "Total loss:  -2.06 | PDE Loss:  -3.0161 | Function Loss:  -3.1109\n",
      "Total loss:  -2.0601 | PDE Loss:  -3.0169 | Function Loss:  -3.1109\n",
      "Total loss:  -2.0601 | PDE Loss:  -3.0185 | Function Loss:  -3.1108\n",
      "Total loss:  -2.0602 | PDE Loss:  -3.0193 | Function Loss:  -3.1108\n",
      "Total loss:  -2.0603 | PDE Loss:  -3.0202 | Function Loss:  -3.1108\n",
      "Total loss:  -2.0605 | PDE Loss:  -3.0212 | Function Loss:  -3.1109\n",
      "Total loss:  -2.0607 | PDE Loss:  -3.0222 | Function Loss:  -3.111\n",
      "Total loss:  -2.061 | PDE Loss:  -3.023 | Function Loss:  -3.1112\n",
      "Total loss:  -2.0613 | PDE Loss:  -3.0249 | Function Loss:  -3.1112\n",
      "Total loss:  -2.0615 | PDE Loss:  -3.0252 | Function Loss:  -3.1115\n",
      "Total loss:  -2.0619 | PDE Loss:  -3.0274 | Function Loss:  -3.1117\n",
      "Total loss:  -2.0623 | PDE Loss:  -3.0292 | Function Loss:  -3.1119\n",
      "Total loss:  -2.0628 | PDE Loss:  -3.0325 | Function Loss:  -3.112\n",
      "Total loss:  -2.0632 | PDE Loss:  -3.0343 | Function Loss:  -3.1123\n",
      "Total loss:  -2.0635 | PDE Loss:  -3.0363 | Function Loss:  -3.1124\n",
      "Total loss:  -2.0638 | PDE Loss:  -3.0369 | Function Loss:  -3.1126\n",
      "Total loss:  -2.0641 | PDE Loss:  -3.0394 | Function Loss:  -3.1127\n",
      "Total loss:  -2.0643 | PDE Loss:  -3.0407 | Function Loss:  -3.1128\n",
      "Total loss:  -2.0646 | PDE Loss:  -3.041 | Function Loss:  -3.1131\n",
      "Total loss:  -2.065 | PDE Loss:  -3.0435 | Function Loss:  -3.1132\n",
      "Total loss:  -2.0654 | PDE Loss:  -3.0419 | Function Loss:  -3.1138\n",
      "Total loss:  -2.0657 | PDE Loss:  -3.0423 | Function Loss:  -3.1141\n",
      "Total loss:  -2.066 | PDE Loss:  -3.0424 | Function Loss:  -3.1144\n",
      "Total loss:  -2.0664 | PDE Loss:  -3.0419 | Function Loss:  -3.1149\n",
      "Total loss:  -2.0667 | PDE Loss:  -3.0405 | Function Loss:  -3.1155\n",
      "Total loss:  -2.067 | PDE Loss:  -3.0394 | Function Loss:  -3.1159\n",
      "Total loss:  -2.0671 | PDE Loss:  -3.0397 | Function Loss:  -3.116\n",
      "Total loss:  -2.0674 | PDE Loss:  -3.0388 | Function Loss:  -3.1165\n",
      "Total loss:  -2.0678 | PDE Loss:  -3.0379 | Function Loss:  -3.1171\n",
      "Total loss:  -2.0683 | PDE Loss:  -3.0355 | Function Loss:  -3.1178\n",
      "Total loss:  -2.0687 | PDE Loss:  -3.0333 | Function Loss:  -3.1185\n",
      "Total loss:  -2.069 | PDE Loss:  -3.03 | Function Loss:  -3.1193\n",
      "Total loss:  -2.0693 | PDE Loss:  -3.0289 | Function Loss:  -3.1198\n",
      "Total loss:  -2.0696 | PDE Loss:  -3.0262 | Function Loss:  -3.1205\n",
      "Total loss:  -2.0699 | PDE Loss:  -3.0271 | Function Loss:  -3.1207\n",
      "Total loss:  -2.0703 | PDE Loss:  -3.0281 | Function Loss:  -3.121\n",
      "Total loss:  -2.0706 | PDE Loss:  -3.0305 | Function Loss:  -3.121\n",
      "Total loss:  -2.0708 | PDE Loss:  -3.0315 | Function Loss:  -3.1212\n",
      "Total loss:  -2.071 | PDE Loss:  -3.0327 | Function Loss:  -3.1212\n",
      "Total loss:  -2.0712 | PDE Loss:  -3.0333 | Function Loss:  -3.1214\n",
      "Total loss:  -2.0714 | PDE Loss:  -3.0339 | Function Loss:  -3.1215\n",
      "Total loss:  -2.0716 | PDE Loss:  -3.034 | Function Loss:  -3.1217\n",
      "Total loss:  -2.0718 | PDE Loss:  -3.0339 | Function Loss:  -3.1219\n",
      "Total loss:  -2.0719 | PDE Loss:  -3.0339 | Function Loss:  -3.1221\n",
      "Total loss:  -2.0721 | PDE Loss:  -3.0336 | Function Loss:  -3.1224\n",
      "Total loss:  -2.0725 | PDE Loss:  -3.0332 | Function Loss:  -3.1228\n",
      "Total loss:  -2.0728 | PDE Loss:  -3.0345 | Function Loss:  -3.123\n",
      "Total loss:  -2.0732 | PDE Loss:  -3.0361 | Function Loss:  -3.1233\n",
      "Total loss:  -2.0735 | PDE Loss:  -3.0371 | Function Loss:  -3.1235\n",
      "Total loss:  -2.0738 | PDE Loss:  -3.0395 | Function Loss:  -3.1236\n",
      "Total loss:  -2.074 | PDE Loss:  -3.0401 | Function Loss:  -3.1237\n",
      "Total loss:  -2.0742 | PDE Loss:  -3.0407 | Function Loss:  -3.1239\n",
      "Total loss:  -2.0744 | PDE Loss:  -3.041 | Function Loss:  -3.124\n",
      "Total loss:  -2.0746 | PDE Loss:  -3.0409 | Function Loss:  -3.1242\n",
      "Total loss:  -2.0747 | PDE Loss:  -3.0412 | Function Loss:  -3.1244\n",
      "Total loss:  -2.0749 | PDE Loss:  -3.0412 | Function Loss:  -3.1246\n",
      "Total loss:  -2.0751 | PDE Loss:  -3.0418 | Function Loss:  -3.1247\n",
      "Total loss:  -2.0753 | PDE Loss:  -3.0416 | Function Loss:  -3.1249\n",
      "Total loss:  -2.0754 | PDE Loss:  -3.0423 | Function Loss:  -3.125\n",
      "Total loss:  -2.0755 | PDE Loss:  -3.0423 | Function Loss:  -3.1251\n",
      "Total loss:  -2.0757 | PDE Loss:  -3.0429 | Function Loss:  -3.1253\n",
      "Total loss:  -2.0759 | PDE Loss:  -3.0431 | Function Loss:  -3.1254\n",
      "Total loss:  -2.0761 | PDE Loss:  -3.0433 | Function Loss:  -3.1256\n",
      "Total loss:  -2.0762 | PDE Loss:  -3.0437 | Function Loss:  -3.1258\n",
      "Total loss:  -2.0765 | PDE Loss:  -3.0437 | Function Loss:  -3.126\n",
      "Total loss:  -2.0767 | PDE Loss:  -3.0442 | Function Loss:  -3.1262\n",
      "Total loss:  -2.0768 | PDE Loss:  -3.0441 | Function Loss:  -3.1264\n",
      "Total loss:  -2.077 | PDE Loss:  -3.0442 | Function Loss:  -3.1266\n",
      "Total loss:  -2.0772 | PDE Loss:  -3.0447 | Function Loss:  -3.1267\n",
      "Total loss:  -2.0773 | PDE Loss:  -3.0449 | Function Loss:  -3.1268\n",
      "Total loss:  -2.0774 | PDE Loss:  -3.046 | Function Loss:  -3.1268\n",
      "Total loss:  -2.0775 | PDE Loss:  -3.0473 | Function Loss:  -3.1268\n",
      "Total loss:  -2.0777 | PDE Loss:  -3.0487 | Function Loss:  -3.1268\n",
      "Total loss:  -2.0778 | PDE Loss:  -3.0517 | Function Loss:  -3.1266\n",
      "Total loss:  -2.0779 | PDE Loss:  -3.0534 | Function Loss:  -3.1265\n",
      "Total loss:  -2.078 | PDE Loss:  -3.0553 | Function Loss:  -3.1264\n",
      "Total loss:  -2.0782 | PDE Loss:  -3.0574 | Function Loss:  -3.1263\n",
      "Total loss:  -2.0784 | PDE Loss:  -3.0594 | Function Loss:  -3.1263\n",
      "Total loss:  -2.0785 | PDE Loss:  -3.0605 | Function Loss:  -3.1263\n",
      "Total loss:  -2.0786 | PDE Loss:  -3.0614 | Function Loss:  -3.1263\n",
      "Total loss:  -2.0787 | PDE Loss:  -3.0612 | Function Loss:  -3.1265\n",
      "Total loss:  -2.0789 | PDE Loss:  -3.0608 | Function Loss:  -3.1267\n",
      "Total loss:  -2.079 | PDE Loss:  -3.0602 | Function Loss:  -3.1268\n",
      "Total loss:  -2.079 | PDE Loss:  -3.0594 | Function Loss:  -3.127\n",
      "Total loss:  -2.0792 | PDE Loss:  -3.0595 | Function Loss:  -3.1271\n",
      "Total loss:  -2.0793 | PDE Loss:  -3.0577 | Function Loss:  -3.1275\n",
      "Total loss:  -2.0793 | PDE Loss:  -3.0583 | Function Loss:  -3.1275\n",
      "Total loss:  -2.0794 | PDE Loss:  -3.0586 | Function Loss:  -3.1275\n",
      "Total loss:  -2.0794 | PDE Loss:  -3.0595 | Function Loss:  -3.1274\n",
      "Total loss:  -2.0794 | PDE Loss:  -3.0593 | Function Loss:  -3.1275\n",
      "Total loss:  -2.0795 | PDE Loss:  -3.0601 | Function Loss:  -3.1275\n",
      "Total loss:  -2.0796 | PDE Loss:  -3.0609 | Function Loss:  -3.1274\n",
      "Total loss:  -2.0796 | PDE Loss:  -3.062 | Function Loss:  -3.1274\n",
      "Total loss:  -2.0797 | PDE Loss:  -3.063 | Function Loss:  -3.1273\n",
      "Total loss:  -2.0797 | PDE Loss:  -3.0639 | Function Loss:  -3.1273\n",
      "Total loss:  -2.0798 | PDE Loss:  -3.0648 | Function Loss:  -3.1272\n",
      "Total loss:  -2.0799 | PDE Loss:  -3.0656 | Function Loss:  -3.1273\n",
      "Total loss:  -2.0801 | PDE Loss:  -3.0668 | Function Loss:  -3.1273\n",
      "Total loss:  -2.0802 | PDE Loss:  -3.0679 | Function Loss:  -3.1274\n",
      "Total loss:  -2.08 | PDE Loss:  -3.0672 | Function Loss:  -3.1272\n",
      "Total loss:  -2.0804 | PDE Loss:  -3.0693 | Function Loss:  -3.1274\n",
      "Total loss:  -2.0805 | PDE Loss:  -3.0691 | Function Loss:  -3.1276\n",
      "Total loss:  -2.0808 | PDE Loss:  -3.069 | Function Loss:  -3.1278\n",
      "Total loss:  -2.0809 | PDE Loss:  -3.0679 | Function Loss:  -3.1282\n",
      "Total loss:  -2.081 | PDE Loss:  -3.0677 | Function Loss:  -3.1283\n",
      "Total loss:  -2.0811 | PDE Loss:  -3.0668 | Function Loss:  -3.1285\n",
      "Total loss:  -2.0813 | PDE Loss:  -3.0666 | Function Loss:  -3.1287\n",
      "Total loss:  -2.0814 | PDE Loss:  -3.0662 | Function Loss:  -3.1289\n",
      "Total loss:  -2.0815 | PDE Loss:  -3.066 | Function Loss:  -3.129\n",
      "Total loss:  -2.0817 | PDE Loss:  -3.0666 | Function Loss:  -3.1291\n",
      "Total loss:  -2.0818 | PDE Loss:  -3.0671 | Function Loss:  -3.1293\n",
      "Total loss:  -2.082 | PDE Loss:  -3.068 | Function Loss:  -3.1293\n",
      "Total loss:  -2.0821 | PDE Loss:  -3.0688 | Function Loss:  -3.1294\n",
      "Total loss:  -2.0823 | PDE Loss:  -3.0699 | Function Loss:  -3.1295\n",
      "Total loss:  -2.0825 | PDE Loss:  -3.071 | Function Loss:  -3.1295\n",
      "Total loss:  -2.0826 | PDE Loss:  -3.0721 | Function Loss:  -3.1295\n",
      "Total loss:  -2.0827 | PDE Loss:  -3.0731 | Function Loss:  -3.1296\n",
      "Total loss:  -2.0828 | PDE Loss:  -3.0742 | Function Loss:  -3.1296\n",
      "Total loss:  -2.0829 | PDE Loss:  -3.0749 | Function Loss:  -3.1296\n",
      "Total loss:  -2.083 | PDE Loss:  -3.0759 | Function Loss:  -3.1296\n",
      "Total loss:  -2.0832 | PDE Loss:  -3.0769 | Function Loss:  -3.1296\n",
      "Total loss:  -2.0833 | PDE Loss:  -3.077 | Function Loss:  -3.1297\n",
      "Total loss:  -2.0834 | PDE Loss:  -3.078 | Function Loss:  -3.1297\n",
      "Total loss:  -2.0835 | PDE Loss:  -3.0779 | Function Loss:  -3.1298\n",
      "Total loss:  -2.0836 | PDE Loss:  -3.0773 | Function Loss:  -3.1301\n",
      "Total loss:  -2.0838 | PDE Loss:  -3.0762 | Function Loss:  -3.1304\n",
      "Total loss:  -2.0839 | PDE Loss:  -3.0748 | Function Loss:  -3.1307\n",
      "Total loss:  -2.084 | PDE Loss:  -3.0737 | Function Loss:  -3.131\n",
      "Total loss:  -2.0842 | PDE Loss:  -3.0728 | Function Loss:  -3.1312\n",
      "Total loss:  -2.0843 | PDE Loss:  -3.0724 | Function Loss:  -3.1314\n",
      "Total loss:  -2.0845 | PDE Loss:  -3.0721 | Function Loss:  -3.1316\n",
      "Total loss:  -2.0846 | PDE Loss:  -3.0719 | Function Loss:  -3.1318\n",
      "Total loss:  -2.0847 | PDE Loss:  -3.0719 | Function Loss:  -3.1319\n",
      "Total loss:  -2.0848 | PDE Loss:  -3.0719 | Function Loss:  -3.1321\n",
      "Total loss:  -2.085 | PDE Loss:  -3.0719 | Function Loss:  -3.1322\n",
      "Total loss:  -2.0852 | PDE Loss:  -3.0716 | Function Loss:  -3.1324\n",
      "Total loss:  -2.0854 | PDE Loss:  -3.0709 | Function Loss:  -3.1328\n",
      "Total loss:  -2.0857 | PDE Loss:  -3.0695 | Function Loss:  -3.1333\n",
      "Total loss:  -2.086 | PDE Loss:  -3.0679 | Function Loss:  -3.1338\n",
      "Total loss:  -2.0862 | PDE Loss:  -3.0639 | Function Loss:  -3.1345\n",
      "Total loss:  -2.0864 | PDE Loss:  -3.063 | Function Loss:  -3.1349\n",
      "Total loss:  -2.0866 | PDE Loss:  -3.0622 | Function Loss:  -3.1352\n",
      "Total loss:  -2.0868 | PDE Loss:  -3.0606 | Function Loss:  -3.1356\n",
      "Total loss:  -2.087 | PDE Loss:  -3.0596 | Function Loss:  -3.1359\n",
      "Total loss:  -2.0872 | PDE Loss:  -3.0581 | Function Loss:  -3.1363\n",
      "Total loss:  -2.0873 | PDE Loss:  -3.0573 | Function Loss:  -3.1365\n",
      "Total loss:  -2.0875 | PDE Loss:  -3.0556 | Function Loss:  -3.1369\n",
      "Total loss:  -2.0876 | PDE Loss:  -3.0552 | Function Loss:  -3.1371\n",
      "Total loss:  -2.0877 | PDE Loss:  -3.0551 | Function Loss:  -3.1372\n",
      "Total loss:  -2.0878 | PDE Loss:  -3.0557 | Function Loss:  -3.1373\n",
      "Total loss:  -2.088 | PDE Loss:  -3.056 | Function Loss:  -3.1375\n",
      "Total loss:  -2.0882 | PDE Loss:  -3.0571 | Function Loss:  -3.1376\n",
      "Total loss:  -2.0884 | PDE Loss:  -3.0577 | Function Loss:  -3.1377\n",
      "Total loss:  -2.0887 | PDE Loss:  -3.0582 | Function Loss:  -3.138\n",
      "Total loss:  -2.089 | PDE Loss:  -3.0583 | Function Loss:  -3.1383\n",
      "Total loss:  -2.0893 | PDE Loss:  -3.0578 | Function Loss:  -3.1387\n",
      "Total loss:  -2.0897 | PDE Loss:  -3.0565 | Function Loss:  -3.1393\n",
      "Total loss:  -2.09 | PDE Loss:  -3.0557 | Function Loss:  -3.1398\n",
      "Total loss:  -2.0904 | PDE Loss:  -3.0546 | Function Loss:  -3.1404\n",
      "Total loss:  -2.0909 | PDE Loss:  -3.0546 | Function Loss:  -3.1409\n",
      "Total loss:  -2.0912 | PDE Loss:  -3.0521 | Function Loss:  -3.1416\n",
      "Total loss:  -2.0916 | PDE Loss:  -3.054 | Function Loss:  -3.1417\n",
      "Total loss:  -2.0918 | PDE Loss:  -3.0542 | Function Loss:  -3.142\n",
      "Total loss:  -2.0921 | PDE Loss:  -3.0553 | Function Loss:  -3.1421\n",
      "Total loss:  -2.0924 | PDE Loss:  -3.0559 | Function Loss:  -3.1424\n",
      "Total loss:  -2.0928 | PDE Loss:  -3.0588 | Function Loss:  -3.1425\n",
      "Total loss:  -2.0931 | PDE Loss:  -3.0586 | Function Loss:  -3.1428\n",
      "Total loss:  -2.0934 | PDE Loss:  -3.0578 | Function Loss:  -3.1433\n",
      "Total loss:  -2.0938 | PDE Loss:  -3.0563 | Function Loss:  -3.1439\n",
      "Total loss:  -2.0942 | PDE Loss:  -3.0526 | Function Loss:  -3.1449\n",
      "Total loss:  -2.0947 | PDE Loss:  -3.0487 | Function Loss:  -3.1458\n",
      "Total loss:  -2.0949 | PDE Loss:  -3.0449 | Function Loss:  -3.1466\n",
      "Total loss:  -2.0952 | PDE Loss:  -3.042 | Function Loss:  -3.1473\n",
      "Total loss:  -2.0955 | PDE Loss:  -3.0395 | Function Loss:  -3.1479\n",
      "Total loss:  -2.0957 | PDE Loss:  -3.0368 | Function Loss:  -3.1486\n",
      "Total loss:  -2.0961 | PDE Loss:  -3.0334 | Function Loss:  -3.1494\n",
      "Total loss:  -2.0963 | PDE Loss:  -3.0308 | Function Loss:  -3.15\n",
      "Total loss:  -2.0965 | PDE Loss:  -3.028 | Function Loss:  -3.1506\n",
      "Total loss:  -2.0967 | PDE Loss:  -3.0263 | Function Loss:  -3.151\n",
      "Total loss:  -2.0969 | PDE Loss:  -3.024 | Function Loss:  -3.1516\n",
      "Total loss:  -2.0972 | PDE Loss:  -3.0218 | Function Loss:  -3.1521\n",
      "Total loss:  -2.0973 | PDE Loss:  -3.0212 | Function Loss:  -3.1524\n",
      "Total loss:  -2.0975 | PDE Loss:  -3.0215 | Function Loss:  -3.1526\n",
      "Total loss:  -2.0977 | PDE Loss:  -3.0197 | Function Loss:  -3.153\n",
      "Total loss:  -2.0978 | PDE Loss:  -3.0208 | Function Loss:  -3.153\n",
      "Total loss:  -2.0979 | PDE Loss:  -3.0203 | Function Loss:  -3.1532\n",
      "Total loss:  -2.0981 | PDE Loss:  -3.0195 | Function Loss:  -3.1536\n",
      "Total loss:  -2.0984 | PDE Loss:  -3.0177 | Function Loss:  -3.1541\n",
      "Total loss:  -2.0986 | PDE Loss:  -3.0168 | Function Loss:  -3.1545\n",
      "Total loss:  -2.0989 | PDE Loss:  -3.0147 | Function Loss:  -3.1551\n",
      "Total loss:  -2.0991 | PDE Loss:  -3.0138 | Function Loss:  -3.1554\n",
      "Total loss:  -2.0993 | PDE Loss:  -3.014 | Function Loss:  -3.1557\n",
      "Total loss:  -2.0996 | PDE Loss:  -3.0153 | Function Loss:  -3.1558\n",
      "Total loss:  -2.0998 | PDE Loss:  -3.0159 | Function Loss:  -3.156\n",
      "Total loss:  -2.1 | PDE Loss:  -3.0173 | Function Loss:  -3.156\n",
      "Total loss:  -2.1002 | PDE Loss:  -3.0174 | Function Loss:  -3.1562\n",
      "Total loss:  -2.1004 | PDE Loss:  -3.0172 | Function Loss:  -3.1565\n",
      "Total loss:  -2.1006 | PDE Loss:  -3.0171 | Function Loss:  -3.1568\n",
      "Total loss:  -2.1008 | PDE Loss:  -3.0153 | Function Loss:  -3.1572\n",
      "Total loss:  -2.1011 | PDE Loss:  -3.0133 | Function Loss:  -3.1578\n",
      "Total loss:  -2.1015 | PDE Loss:  -3.0103 | Function Loss:  -3.1586\n",
      "Total loss:  -2.1018 | PDE Loss:  -3.0089 | Function Loss:  -3.1592\n",
      "Total loss:  -2.102 | PDE Loss:  -3.0058 | Function Loss:  -3.1599\n",
      "Total loss:  -2.1022 | PDE Loss:  -3.0044 | Function Loss:  -3.1603\n",
      "Total loss:  -2.1024 | PDE Loss:  -3.0023 | Function Loss:  -3.1608\n",
      "Total loss:  -2.1027 | PDE Loss:  -3.0009 | Function Loss:  -3.1614\n",
      "Total loss:  -2.1029 | PDE Loss:  -2.9986 | Function Loss:  -3.162\n",
      "Total loss:  -2.1031 | PDE Loss:  -2.998 | Function Loss:  -3.1623\n",
      "Total loss:  -2.1034 | PDE Loss:  -2.9964 | Function Loss:  -3.1629\n",
      "Total loss:  -2.1037 | PDE Loss:  -2.9968 | Function Loss:  -3.1632\n",
      "Total loss:  -2.104 | PDE Loss:  -2.9977 | Function Loss:  -3.1634\n",
      "Total loss:  -2.1045 | PDE Loss:  -2.9967 | Function Loss:  -3.1641\n",
      "Total loss:  -2.1049 | PDE Loss:  -2.9991 | Function Loss:  -3.1642\n",
      "Total loss:  -2.1052 | PDE Loss:  -2.9984 | Function Loss:  -3.1647\n",
      "Total loss:  -2.1056 | PDE Loss:  -2.9992 | Function Loss:  -3.165\n",
      "Total loss:  -2.1058 | PDE Loss:  -2.9993 | Function Loss:  -3.1652\n",
      "Total loss:  -2.106 | PDE Loss:  -2.9995 | Function Loss:  -3.1654\n",
      "Total loss:  -2.1061 | PDE Loss:  -2.9991 | Function Loss:  -3.1656\n",
      "Total loss:  -2.1062 | PDE Loss:  -2.9991 | Function Loss:  -3.1657\n",
      "Total loss:  -2.1063 | PDE Loss:  -2.9988 | Function Loss:  -3.1658\n",
      "Total loss:  -2.1064 | PDE Loss:  -2.9979 | Function Loss:  -3.166\n",
      "Total loss:  -2.1064 | PDE Loss:  -2.9975 | Function Loss:  -3.1662\n",
      "Total loss:  -2.1065 | PDE Loss:  -2.9967 | Function Loss:  -3.1664\n",
      "Total loss:  -2.1066 | PDE Loss:  -2.9957 | Function Loss:  -3.1666\n",
      "Total loss:  -2.1066 | PDE Loss:  -2.9949 | Function Loss:  -3.1668\n",
      "Total loss:  -2.1067 | PDE Loss:  -2.993 | Function Loss:  -3.1672\n",
      "Total loss:  -2.1068 | PDE Loss:  -2.992 | Function Loss:  -3.1674\n",
      "Total loss:  -2.1069 | PDE Loss:  -2.9905 | Function Loss:  -3.1677\n",
      "Total loss:  -2.1067 | PDE Loss:  -2.9862 | Function Loss:  -3.1681\n",
      "Total loss:  -2.1069 | PDE Loss:  -2.9895 | Function Loss:  -3.1679\n",
      "Total loss:  -2.107 | PDE Loss:  -2.9885 | Function Loss:  -3.1682\n",
      "Total loss:  -2.1072 | PDE Loss:  -2.9871 | Function Loss:  -3.1686\n",
      "Total loss:  -2.1074 | PDE Loss:  -2.9852 | Function Loss:  -3.1691\n",
      "Total loss:  -2.1076 | PDE Loss:  -2.9828 | Function Loss:  -3.1697\n",
      "Total loss:  -2.1078 | PDE Loss:  -2.9816 | Function Loss:  -3.1701\n",
      "Total loss:  -2.108 | PDE Loss:  -2.9788 | Function Loss:  -3.1709\n",
      "Total loss:  -2.1083 | PDE Loss:  -2.9786 | Function Loss:  -3.1712\n",
      "Total loss:  -2.1084 | PDE Loss:  -2.9767 | Function Loss:  -3.1716\n",
      "Total loss:  -2.1086 | PDE Loss:  -2.9758 | Function Loss:  -3.172\n",
      "Total loss:  -2.1088 | PDE Loss:  -2.9756 | Function Loss:  -3.1722\n",
      "Total loss:  -2.1089 | PDE Loss:  -2.9758 | Function Loss:  -3.1723\n",
      "Total loss:  -2.1091 | PDE Loss:  -2.9757 | Function Loss:  -3.1725\n",
      "Total loss:  -2.1093 | PDE Loss:  -2.9754 | Function Loss:  -3.1728\n",
      "Total loss:  -2.1095 | PDE Loss:  -2.975 | Function Loss:  -3.1731\n",
      "Total loss:  -2.1097 | PDE Loss:  -2.9741 | Function Loss:  -3.1735\n",
      "Total loss:  -2.1099 | PDE Loss:  -2.9737 | Function Loss:  -3.1738\n",
      "Total loss:  -2.1101 | PDE Loss:  -2.9732 | Function Loss:  -3.1741\n",
      "Total loss:  -2.1103 | PDE Loss:  -2.9721 | Function Loss:  -3.1745\n",
      "Total loss:  -2.1104 | PDE Loss:  -2.9717 | Function Loss:  -3.1748\n",
      "Total loss:  -2.1106 | PDE Loss:  -2.9708 | Function Loss:  -3.1751\n",
      "Total loss:  -2.1107 | PDE Loss:  -2.9699 | Function Loss:  -3.1754\n",
      "Total loss:  -2.1108 | PDE Loss:  -2.9695 | Function Loss:  -3.1756\n",
      "Total loss:  -2.1109 | PDE Loss:  -2.9694 | Function Loss:  -3.1757\n",
      "Total loss:  -2.1111 | PDE Loss:  -2.9698 | Function Loss:  -3.1758\n",
      "Total loss:  -2.1113 | PDE Loss:  -2.9697 | Function Loss:  -3.176\n",
      "Total loss:  -2.1115 | PDE Loss:  -2.9705 | Function Loss:  -3.1761\n",
      "Total loss:  -2.1117 | PDE Loss:  -2.9698 | Function Loss:  -3.1765\n",
      "Total loss:  -2.1119 | PDE Loss:  -2.9711 | Function Loss:  -3.1765\n",
      "Total loss:  -2.112 | PDE Loss:  -2.9705 | Function Loss:  -3.1768\n",
      "Total loss:  -2.1122 | PDE Loss:  -2.9704 | Function Loss:  -3.177\n",
      "Total loss:  -2.1124 | PDE Loss:  -2.9706 | Function Loss:  -3.1772\n",
      "Total loss:  -2.1126 | PDE Loss:  -2.9698 | Function Loss:  -3.1776\n",
      "Total loss:  -2.1129 | PDE Loss:  -2.97 | Function Loss:  -3.1779\n",
      "Total loss:  -2.1132 | PDE Loss:  -2.9692 | Function Loss:  -3.1783\n",
      "Total loss:  -2.1135 | PDE Loss:  -2.9688 | Function Loss:  -3.1787\n",
      "Total loss:  -2.1137 | PDE Loss:  -2.9679 | Function Loss:  -3.1792\n",
      "Total loss:  -2.1141 | PDE Loss:  -2.9665 | Function Loss:  -3.1798\n",
      "Total loss:  -2.1145 | PDE Loss:  -2.9649 | Function Loss:  -3.1805\n",
      "Total loss:  -2.115 | PDE Loss:  -2.9633 | Function Loss:  -3.1814\n",
      "Total loss:  -2.1157 | PDE Loss:  -2.9618 | Function Loss:  -3.1824\n",
      "Total loss:  -2.1163 | PDE Loss:  -2.9594 | Function Loss:  -3.1836\n",
      "Total loss:  -2.117 | PDE Loss:  -2.9588 | Function Loss:  -3.1845\n",
      "Total loss:  -2.1176 | PDE Loss:  -2.9564 | Function Loss:  -3.1856\n",
      "Total loss:  -2.1181 | PDE Loss:  -2.9566 | Function Loss:  -3.1862\n",
      "Total loss:  -2.1187 | PDE Loss:  -2.9544 | Function Loss:  -3.1872\n",
      "Total loss:  -2.1192 | PDE Loss:  -2.9556 | Function Loss:  -3.1876\n",
      "Total loss:  -2.1197 | PDE Loss:  -2.9556 | Function Loss:  -3.1882\n",
      "Total loss:  -2.1202 | PDE Loss:  -2.9575 | Function Loss:  -3.1885\n",
      "Total loss:  -2.1208 | PDE Loss:  -2.9569 | Function Loss:  -3.1892\n",
      "Total loss:  -2.1212 | PDE Loss:  -2.9577 | Function Loss:  -3.1896\n",
      "Total loss:  -2.1215 | PDE Loss:  -2.9568 | Function Loss:  -3.1901\n",
      "Total loss:  -2.1219 | PDE Loss:  -2.9563 | Function Loss:  -3.1906\n",
      "Total loss:  -2.1222 | PDE Loss:  -2.9547 | Function Loss:  -3.1912\n",
      "Total loss:  -2.1224 | PDE Loss:  -2.9543 | Function Loss:  -3.1916\n",
      "Total loss:  -2.1227 | PDE Loss:  -2.9525 | Function Loss:  -3.1923\n",
      "Total loss:  -2.1232 | PDE Loss:  -2.9513 | Function Loss:  -3.193\n",
      "Total loss:  -2.1236 | PDE Loss:  -2.9481 | Function Loss:  -3.1941\n",
      "Total loss:  -2.124 | PDE Loss:  -2.9466 | Function Loss:  -3.1948\n",
      "Total loss:  -2.1245 | PDE Loss:  -2.9442 | Function Loss:  -3.1958\n",
      "Total loss:  -2.125 | PDE Loss:  -2.9422 | Function Loss:  -3.1967\n",
      "Total loss:  -2.1254 | PDE Loss:  -2.9418 | Function Loss:  -3.1973\n",
      "Total loss:  -2.1259 | PDE Loss:  -2.9395 | Function Loss:  -3.1983\n",
      "Total loss:  -2.1265 | PDE Loss:  -2.9392 | Function Loss:  -3.1991\n",
      "Total loss:  -2.1269 | PDE Loss:  -2.9332 | Function Loss:  -3.2007\n",
      "Total loss:  -2.1273 | PDE Loss:  -2.9323 | Function Loss:  -3.2014\n",
      "Total loss:  -2.1277 | PDE Loss:  -2.9317 | Function Loss:  -3.2019\n",
      "Total loss:  -2.1282 | PDE Loss:  -2.9308 | Function Loss:  -3.2026\n",
      "Total loss:  -2.1286 | PDE Loss:  -2.9275 | Function Loss:  -3.2037\n",
      "Total loss:  -2.1289 | PDE Loss:  -2.926 | Function Loss:  -3.2044\n",
      "Total loss:  -2.1293 | PDE Loss:  -2.9238 | Function Loss:  -3.2053\n",
      "Total loss:  -2.1299 | PDE Loss:  -2.9228 | Function Loss:  -3.2062\n",
      "Total loss:  -2.1305 | PDE Loss:  -2.9214 | Function Loss:  -3.2072\n",
      "Total loss:  -2.1312 | PDE Loss:  -2.9201 | Function Loss:  -3.2083\n",
      "Total loss:  -2.1318 | PDE Loss:  -2.9219 | Function Loss:  -3.2087\n",
      "Total loss:  -2.1324 | PDE Loss:  -2.9191 | Function Loss:  -3.2099\n",
      "Total loss:  -2.133 | PDE Loss:  -2.9237 | Function Loss:  -3.2097\n",
      "Total loss:  -2.1333 | PDE Loss:  -2.9225 | Function Loss:  -3.2103\n",
      "Total loss:  -2.1336 | PDE Loss:  -2.9206 | Function Loss:  -3.2111\n",
      "Total loss:  -2.134 | PDE Loss:  -2.9194 | Function Loss:  -3.2118\n",
      "Total loss:  -2.1345 | PDE Loss:  -2.9164 | Function Loss:  -3.2129\n",
      "Total loss:  -2.135 | PDE Loss:  -2.9137 | Function Loss:  -3.214\n",
      "Total loss:  -2.1354 | PDE Loss:  -2.9114 | Function Loss:  -3.215\n",
      "Total loss:  -2.1357 | PDE Loss:  -2.9096 | Function Loss:  -3.2158\n",
      "Total loss:  -2.1362 | PDE Loss:  -2.9093 | Function Loss:  -3.2164\n",
      "Total loss:  -2.1365 | PDE Loss:  -2.9084 | Function Loss:  -3.217\n",
      "Total loss:  -2.1367 | PDE Loss:  -2.9079 | Function Loss:  -3.2173\n",
      "Total loss:  -2.1369 | PDE Loss:  -2.9088 | Function Loss:  -3.2174\n",
      "Total loss:  -2.1371 | PDE Loss:  -2.9087 | Function Loss:  -3.2176\n",
      "Total loss:  -2.1373 | PDE Loss:  -2.9091 | Function Loss:  -3.2177\n",
      "Total loss:  -2.1375 | PDE Loss:  -2.9086 | Function Loss:  -3.2181\n",
      "Total loss:  -2.1376 | PDE Loss:  -2.907 | Function Loss:  -3.2186\n",
      "Total loss:  -2.1378 | PDE Loss:  -2.9073 | Function Loss:  -3.2187\n",
      "Total loss:  -2.138 | PDE Loss:  -2.9048 | Function Loss:  -3.2194\n",
      "Total loss:  -2.1382 | PDE Loss:  -2.9018 | Function Loss:  -3.2203\n",
      "Total loss:  -2.1384 | PDE Loss:  -2.8997 | Function Loss:  -3.221\n",
      "Total loss:  -2.1386 | PDE Loss:  -2.8971 | Function Loss:  -3.2218\n",
      "Total loss:  -2.1389 | PDE Loss:  -2.8947 | Function Loss:  -3.2226\n",
      "Total loss:  -2.1392 | PDE Loss:  -2.8906 | Function Loss:  -3.224\n",
      "Total loss:  -2.1396 | PDE Loss:  -2.8879 | Function Loss:  -3.225\n",
      "Total loss:  -2.1401 | PDE Loss:  -2.8872 | Function Loss:  -3.2258\n",
      "Total loss:  -2.1407 | PDE Loss:  -2.8819 | Function Loss:  -3.2276\n",
      "Total loss:  -2.1412 | PDE Loss:  -2.8837 | Function Loss:  -3.2279\n",
      "Total loss:  -2.1417 | PDE Loss:  -2.883 | Function Loss:  -3.2286\n",
      "Total loss:  -2.1424 | PDE Loss:  -2.8842 | Function Loss:  -3.2292\n",
      "Total loss:  -2.1431 | PDE Loss:  -2.881 | Function Loss:  -3.2308\n",
      "Total loss:  -2.144 | PDE Loss:  -2.8792 | Function Loss:  -3.2322\n",
      "Total loss:  -2.1449 | PDE Loss:  -2.8759 | Function Loss:  -3.2341\n",
      "Total loss:  -2.146 | PDE Loss:  -2.8715 | Function Loss:  -3.2366\n",
      "Total loss:  -2.147 | PDE Loss:  -2.8634 | Function Loss:  -3.2397\n",
      "Total loss:  -2.1478 | PDE Loss:  -2.8609 | Function Loss:  -3.2413\n",
      "Total loss:  -2.1487 | PDE Loss:  -2.855 | Function Loss:  -3.2438\n",
      "Total loss:  -2.1494 | PDE Loss:  -2.8553 | Function Loss:  -3.2446\n",
      "Total loss:  -2.1506 | PDE Loss:  -2.8557 | Function Loss:  -3.246\n",
      "Total loss:  -2.1513 | PDE Loss:  -2.8589 | Function Loss:  -3.2461\n",
      "Total loss:  -2.152 | PDE Loss:  -2.8585 | Function Loss:  -3.247\n",
      "Total loss:  -2.1528 | PDE Loss:  -2.857 | Function Loss:  -3.2484\n",
      "Total loss:  -2.1535 | PDE Loss:  -2.857 | Function Loss:  -3.2493\n",
      "Total loss:  -2.154 | PDE Loss:  -2.8437 | Function Loss:  -3.2532\n",
      "Total loss:  -2.1549 | PDE Loss:  -2.8443 | Function Loss:  -3.2543\n",
      "Total loss:  -2.1556 | PDE Loss:  -2.8488 | Function Loss:  -3.254\n",
      "Total loss:  -2.156 | PDE Loss:  -2.8473 | Function Loss:  -3.2548\n",
      "Total loss:  -2.1565 | PDE Loss:  -2.8461 | Function Loss:  -3.2557\n",
      "Total loss:  -2.157 | PDE Loss:  -2.8446 | Function Loss:  -3.2568\n",
      "Total loss:  -2.1576 | PDE Loss:  -2.8438 | Function Loss:  -3.2578\n",
      "Total loss:  -2.1585 | PDE Loss:  -2.8436 | Function Loss:  -3.259\n",
      "Total loss:  -2.1595 | PDE Loss:  -2.8414 | Function Loss:  -3.2608\n",
      "Total loss:  -2.1606 | PDE Loss:  -2.8405 | Function Loss:  -3.2625\n",
      "Total loss:  -2.1617 | PDE Loss:  -2.8402 | Function Loss:  -3.2639\n",
      "Total loss:  -2.1629 | PDE Loss:  -2.8408 | Function Loss:  -3.2653\n",
      "Total loss:  -2.1638 | PDE Loss:  -2.8343 | Function Loss:  -3.2681\n",
      "Total loss:  -2.1644 | PDE Loss:  -2.8333 | Function Loss:  -3.2692\n",
      "Total loss:  -2.165 | PDE Loss:  -2.8328 | Function Loss:  -3.2701\n",
      "Total loss:  -2.1657 | PDE Loss:  -2.831 | Function Loss:  -3.2714\n",
      "Total loss:  -2.1664 | PDE Loss:  -2.8284 | Function Loss:  -3.273\n",
      "Total loss:  -2.1674 | PDE Loss:  -2.8268 | Function Loss:  -3.2748\n",
      "Total loss:  -2.1685 | PDE Loss:  -2.8232 | Function Loss:  -3.2772\n",
      "Total loss:  -2.1695 | PDE Loss:  -2.8242 | Function Loss:  -3.2782\n",
      "Total loss:  -2.1709 | PDE Loss:  -2.8261 | Function Loss:  -3.2795\n",
      "Total loss:  -2.1722 | PDE Loss:  -2.8292 | Function Loss:  -3.2803\n",
      "Total loss:  -2.1733 | PDE Loss:  -2.8307 | Function Loss:  -3.2812\n",
      "Total loss:  -2.1743 | PDE Loss:  -2.8327 | Function Loss:  -3.282\n",
      "Total loss:  -2.1757 | PDE Loss:  -2.8297 | Function Loss:  -3.2846\n",
      "Total loss:  -2.1772 | PDE Loss:  -2.8302 | Function Loss:  -3.2864\n",
      "Total loss:  -2.1785 | PDE Loss:  -2.8269 | Function Loss:  -3.289\n",
      "Total loss:  -2.1799 | PDE Loss:  -2.8255 | Function Loss:  -3.2912\n",
      "Total loss:  -2.1811 | PDE Loss:  -2.8198 | Function Loss:  -3.2945\n",
      "Total loss:  -2.1817 | PDE Loss:  -2.8216 | Function Loss:  -3.2947\n",
      "Total loss:  -2.1823 | PDE Loss:  -2.8228 | Function Loss:  -3.2951\n",
      "Total loss:  -2.1828 | PDE Loss:  -2.825 | Function Loss:  -3.2952\n",
      "Total loss:  -2.1834 | PDE Loss:  -2.8291 | Function Loss:  -3.2947\n",
      "Total loss:  -2.1839 | PDE Loss:  -2.833 | Function Loss:  -3.2943\n",
      "Total loss:  -2.1846 | PDE Loss:  -2.8378 | Function Loss:  -3.2938\n",
      "Total loss:  -2.1855 | PDE Loss:  -2.8428 | Function Loss:  -3.2934\n",
      "Total loss:  -2.1864 | PDE Loss:  -2.8442 | Function Loss:  -3.2943\n",
      "Total loss:  -2.1875 | PDE Loss:  -2.8473 | Function Loss:  -3.2947\n",
      "Total loss:  -2.1887 | PDE Loss:  -2.8482 | Function Loss:  -3.2961\n",
      "Total loss:  -2.1903 | PDE Loss:  -2.8466 | Function Loss:  -3.2985\n",
      "Total loss:  -2.1916 | PDE Loss:  -2.847 | Function Loss:  -3.3001\n",
      "Total loss:  -2.1924 | PDE Loss:  -2.8448 | Function Loss:  -3.3018\n",
      "Total loss:  -2.1931 | PDE Loss:  -2.8429 | Function Loss:  -3.3032\n",
      "Total loss:  -2.1938 | PDE Loss:  -2.8422 | Function Loss:  -3.3043\n",
      "Total loss:  -2.1945 | PDE Loss:  -2.8433 | Function Loss:  -3.3049\n",
      "Total loss:  -2.1955 | PDE Loss:  -2.8459 | Function Loss:  -3.3054\n",
      "Total loss:  -2.1966 | PDE Loss:  -2.8511 | Function Loss:  -3.3054\n",
      "Total loss:  -2.1977 | PDE Loss:  -2.8553 | Function Loss:  -3.3056\n",
      "Total loss:  -2.1987 | PDE Loss:  -2.8638 | Function Loss:  -3.3045\n",
      "Total loss:  -2.1994 | PDE Loss:  -2.8673 | Function Loss:  -3.3045\n",
      "Total loss:  -2.2001 | PDE Loss:  -2.8698 | Function Loss:  -3.3046\n",
      "Total loss:  -2.2009 | PDE Loss:  -2.8731 | Function Loss:  -3.3048\n",
      "Total loss:  -2.2017 | PDE Loss:  -2.8756 | Function Loss:  -3.3051\n",
      "Total loss:  -2.2025 | PDE Loss:  -2.8779 | Function Loss:  -3.3056\n",
      "Total loss:  -2.2034 | PDE Loss:  -2.8805 | Function Loss:  -3.306\n",
      "Total loss:  -2.2042 | PDE Loss:  -2.8824 | Function Loss:  -3.3065\n",
      "Total loss:  -2.2049 | PDE Loss:  -2.884 | Function Loss:  -3.3069\n",
      "Total loss:  -2.2054 | PDE Loss:  -2.8853 | Function Loss:  -3.3073\n",
      "Total loss:  -2.206 | PDE Loss:  -2.8863 | Function Loss:  -3.3077\n",
      "Total loss:  -2.2065 | PDE Loss:  -2.8875 | Function Loss:  -3.308\n",
      "Total loss:  -2.207 | PDE Loss:  -2.8874 | Function Loss:  -3.3087\n",
      "Total loss:  -2.2074 | PDE Loss:  -2.888 | Function Loss:  -3.3091\n",
      "Total loss:  -2.208 | PDE Loss:  -2.8875 | Function Loss:  -3.31\n",
      "Total loss:  -2.2087 | PDE Loss:  -2.8879 | Function Loss:  -3.3107\n",
      "Total loss:  -2.2092 | PDE Loss:  -2.8878 | Function Loss:  -3.3113\n",
      "Total loss:  -2.2098 | PDE Loss:  -2.8881 | Function Loss:  -3.312\n",
      "Total loss:  -2.2103 | PDE Loss:  -2.8887 | Function Loss:  -3.3125\n",
      "Total loss:  -2.2108 | PDE Loss:  -2.889 | Function Loss:  -3.3131\n",
      "Total loss:  -2.2114 | PDE Loss:  -2.8901 | Function Loss:  -3.3135\n",
      "Total loss:  -2.2121 | PDE Loss:  -2.891 | Function Loss:  -3.3142\n",
      "Total loss:  -2.2129 | PDE Loss:  -2.8938 | Function Loss:  -3.3145\n",
      "Total loss:  -2.2136 | PDE Loss:  -2.8947 | Function Loss:  -3.3151\n",
      "Total loss:  -2.2141 | PDE Loss:  -2.8965 | Function Loss:  -3.3152\n",
      "Total loss:  -2.2145 | PDE Loss:  -2.8994 | Function Loss:  -3.315\n",
      "Total loss:  -2.2149 | PDE Loss:  -2.9018 | Function Loss:  -3.3149\n",
      "Total loss:  -2.2154 | PDE Loss:  -2.9047 | Function Loss:  -3.3148\n",
      "Total loss:  -2.2161 | PDE Loss:  -2.9064 | Function Loss:  -3.3152\n",
      "Total loss:  -2.217 | PDE Loss:  -2.9086 | Function Loss:  -3.3157\n",
      "Total loss:  -2.2179 | PDE Loss:  -2.9094 | Function Loss:  -3.3167\n",
      "Total loss:  -2.2188 | PDE Loss:  -2.9092 | Function Loss:  -3.3179\n",
      "Total loss:  -2.2197 | PDE Loss:  -2.9099 | Function Loss:  -3.3188\n",
      "Total loss:  -2.2207 | PDE Loss:  -2.9073 | Function Loss:  -3.3207\n",
      "Total loss:  -2.2215 | PDE Loss:  -2.9056 | Function Loss:  -3.3223\n",
      "Total loss:  -2.2225 | PDE Loss:  -2.9028 | Function Loss:  -3.3242\n",
      "Total loss:  -2.2234 | PDE Loss:  -2.8999 | Function Loss:  -3.3261\n",
      "Total loss:  -2.2243 | PDE Loss:  -2.899 | Function Loss:  -3.3275\n",
      "Total loss:  -2.2253 | PDE Loss:  -2.8941 | Function Loss:  -3.3301\n",
      "Total loss:  -2.226 | PDE Loss:  -2.8924 | Function Loss:  -3.3315\n",
      "Total loss:  -2.2271 | PDE Loss:  -2.8904 | Function Loss:  -3.3333\n",
      "Total loss:  -2.2279 | PDE Loss:  -2.8906 | Function Loss:  -3.3343\n",
      "Total loss:  -2.2285 | PDE Loss:  -2.8895 | Function Loss:  -3.3355\n",
      "Total loss:  -2.2291 | PDE Loss:  -2.8894 | Function Loss:  -3.3363\n",
      "Total loss:  -2.2297 | PDE Loss:  -2.8891 | Function Loss:  -3.3371\n",
      "Total loss:  -2.2304 | PDE Loss:  -2.888 | Function Loss:  -3.3383\n",
      "Total loss:  -2.2313 | PDE Loss:  -2.8871 | Function Loss:  -3.3397\n",
      "Total loss:  -2.2324 | PDE Loss:  -2.8861 | Function Loss:  -3.3413\n",
      "Total loss:  -2.2336 | PDE Loss:  -2.8852 | Function Loss:  -3.3432\n",
      "Total loss:  -2.235 | PDE Loss:  -2.8856 | Function Loss:  -3.3449\n",
      "Total loss:  -2.2364 | PDE Loss:  -2.8852 | Function Loss:  -3.3468\n",
      "Total loss:  -2.2379 | PDE Loss:  -2.887 | Function Loss:  -3.3482\n",
      "Total loss:  -2.2393 | PDE Loss:  -2.8867 | Function Loss:  -3.3501\n",
      "Total loss:  -2.2405 | PDE Loss:  -2.8869 | Function Loss:  -3.3516\n",
      "Total loss:  -2.2416 | PDE Loss:  -2.8874 | Function Loss:  -3.3528\n",
      "Total loss:  -2.2425 | PDE Loss:  -2.8862 | Function Loss:  -3.3545\n",
      "Total loss:  -2.2434 | PDE Loss:  -2.8872 | Function Loss:  -3.3553\n",
      "Total loss:  -2.2442 | PDE Loss:  -2.8881 | Function Loss:  -3.356\n",
      "Total loss:  -2.2452 | PDE Loss:  -2.8889 | Function Loss:  -3.3571\n",
      "Total loss:  -2.2462 | PDE Loss:  -2.8893 | Function Loss:  -3.3583\n",
      "Total loss:  -2.2471 | PDE Loss:  -2.8877 | Function Loss:  -3.36\n",
      "Total loss:  -2.2479 | PDE Loss:  -2.887 | Function Loss:  -3.3611\n",
      "Total loss:  -2.2487 | PDE Loss:  -2.8862 | Function Loss:  -3.3624\n",
      "Total loss:  -2.2498 | PDE Loss:  -2.8839 | Function Loss:  -3.3645\n",
      "Total loss:  -2.2512 | PDE Loss:  -2.884 | Function Loss:  -3.3663\n",
      "Total loss:  -2.2525 | PDE Loss:  -2.882 | Function Loss:  -3.3687\n",
      "Total loss:  -2.2539 | PDE Loss:  -2.8823 | Function Loss:  -3.3705\n",
      "Total loss:  -2.2553 | PDE Loss:  -2.8808 | Function Loss:  -3.3727\n",
      "Total loss:  -2.2567 | PDE Loss:  -2.8819 | Function Loss:  -3.3742\n",
      "Total loss:  -2.2577 | PDE Loss:  -2.8791 | Function Loss:  -3.3764\n",
      "Total loss:  -2.2586 | PDE Loss:  -2.8804 | Function Loss:  -3.3771\n",
      "Total loss:  -2.2594 | PDE Loss:  -2.8799 | Function Loss:  -3.3783\n",
      "Total loss:  -2.2601 | PDE Loss:  -2.8788 | Function Loss:  -3.3796\n",
      "Total loss:  -2.2606 | PDE Loss:  -2.8797 | Function Loss:  -3.38\n",
      "Total loss:  -2.261 | PDE Loss:  -2.8783 | Function Loss:  -3.3809\n",
      "Total loss:  -2.2614 | PDE Loss:  -2.8774 | Function Loss:  -3.3818\n",
      "Total loss:  -2.2619 | PDE Loss:  -2.8753 | Function Loss:  -3.3831\n",
      "Total loss:  -2.2623 | PDE Loss:  -2.8737 | Function Loss:  -3.3842\n",
      "Total loss:  -2.2628 | PDE Loss:  -2.8726 | Function Loss:  -3.3851\n",
      "Total loss:  -2.2633 | PDE Loss:  -2.8718 | Function Loss:  -3.3861\n",
      "Total loss:  -2.2639 | PDE Loss:  -2.8721 | Function Loss:  -3.3869\n",
      "Total loss:  -2.2648 | PDE Loss:  -2.8721 | Function Loss:  -3.388\n",
      "Total loss:  -2.2658 | PDE Loss:  -2.8727 | Function Loss:  -3.3891\n",
      "Total loss:  -2.2661 | PDE Loss:  -2.8703 | Function Loss:  -3.3903\n",
      "Total loss:  -2.2677 | PDE Loss:  -2.87 | Function Loss:  -3.3926\n",
      "Total loss:  -2.2687 | PDE Loss:  -2.8736 | Function Loss:  -3.3927\n",
      "Total loss:  -2.2693 | PDE Loss:  -2.8743 | Function Loss:  -3.3932\n",
      "Total loss:  -2.2699 | PDE Loss:  -2.8749 | Function Loss:  -3.3939\n",
      "Total loss:  -2.2705 | PDE Loss:  -2.8747 | Function Loss:  -3.3947\n",
      "Total loss:  -2.2712 | PDE Loss:  -2.8752 | Function Loss:  -3.3954\n",
      "Total loss:  -2.2719 | PDE Loss:  -2.8732 | Function Loss:  -3.397\n",
      "Total loss:  -2.2724 | PDE Loss:  -2.8719 | Function Loss:  -3.3982\n",
      "Total loss:  -2.2731 | PDE Loss:  -2.8701 | Function Loss:  -3.3998\n",
      "Total loss:  -2.2739 | PDE Loss:  -2.868 | Function Loss:  -3.4015\n",
      "Total loss:  -2.2746 | PDE Loss:  -2.8659 | Function Loss:  -3.4031\n",
      "Total loss:  -2.2752 | PDE Loss:  -2.8649 | Function Loss:  -3.4043\n",
      "Total loss:  -2.2758 | PDE Loss:  -2.8617 | Function Loss:  -3.4062\n",
      "Total loss:  -2.2762 | PDE Loss:  -2.8607 | Function Loss:  -3.4071\n",
      "Total loss:  -2.2767 | PDE Loss:  -2.8587 | Function Loss:  -3.4085\n",
      "Total loss:  -2.2772 | PDE Loss:  -2.8561 | Function Loss:  -3.4101\n",
      "Total loss:  -2.2777 | PDE Loss:  -2.8548 | Function Loss:  -3.4112\n",
      "Total loss:  -2.2781 | PDE Loss:  -2.8511 | Function Loss:  -3.4132\n",
      "Total loss:  -2.2785 | PDE Loss:  -2.8494 | Function Loss:  -3.4143\n",
      "Total loss:  -2.2789 | PDE Loss:  -2.8477 | Function Loss:  -3.4155\n",
      "Total loss:  -2.2794 | PDE Loss:  -2.8456 | Function Loss:  -3.417\n",
      "Total loss:  -2.2798 | PDE Loss:  -2.8442 | Function Loss:  -3.418\n",
      "Total loss:  -2.2803 | PDE Loss:  -2.8441 | Function Loss:  -3.4187\n",
      "Total loss:  -2.2806 | PDE Loss:  -2.8434 | Function Loss:  -3.4194\n",
      "Total loss:  -2.281 | PDE Loss:  -2.845 | Function Loss:  -3.4195\n",
      "Total loss:  -2.2815 | PDE Loss:  -2.8468 | Function Loss:  -3.4194\n",
      "Total loss:  -2.2817 | PDE Loss:  -2.848 | Function Loss:  -3.4193\n",
      "Total loss:  -2.2819 | PDE Loss:  -2.8487 | Function Loss:  -3.4193\n",
      "Total loss:  -2.2821 | PDE Loss:  -2.8494 | Function Loss:  -3.4193\n",
      "Total loss:  -2.2825 | PDE Loss:  -2.8488 | Function Loss:  -3.4201\n",
      "Total loss:  -2.2835 | PDE Loss:  -2.851 | Function Loss:  -3.4205\n",
      "Total loss:  -2.2838 | PDE Loss:  -2.8483 | Function Loss:  -3.4221\n",
      "Total loss:  -2.2848 | PDE Loss:  -2.8497 | Function Loss:  -3.4228\n",
      "Total loss:  -2.2864 | PDE Loss:  -2.8524 | Function Loss:  -3.424\n",
      "Total loss:  -2.2877 | PDE Loss:  -2.8524 | Function Loss:  -3.4258\n",
      "Total loss:  -2.2887 | PDE Loss:  -2.8518 | Function Loss:  -3.4274\n",
      "Total loss:  -2.2895 | PDE Loss:  -2.8495 | Function Loss:  -3.4294\n",
      "Total loss:  -2.2901 | PDE Loss:  -2.8468 | Function Loss:  -3.4313\n",
      "Total loss:  -2.291 | PDE Loss:  -2.8442 | Function Loss:  -3.4335\n",
      "Total loss:  -2.2921 | PDE Loss:  -2.8388 | Function Loss:  -3.4372\n",
      "Total loss:  -2.2932 | PDE Loss:  -2.8363 | Function Loss:  -3.4397\n",
      "Total loss:  -2.2944 | PDE Loss:  -2.832 | Function Loss:  -3.4431\n",
      "Total loss:  -2.2956 | PDE Loss:  -2.8293 | Function Loss:  -3.4459\n",
      "Total loss:  -2.2967 | PDE Loss:  -2.8297 | Function Loss:  -3.4474\n",
      "Total loss:  -2.2978 | PDE Loss:  -2.8279 | Function Loss:  -3.4497\n",
      "Total loss:  -2.2987 | PDE Loss:  -2.8299 | Function Loss:  -3.4501\n",
      "Total loss:  -2.2996 | PDE Loss:  -2.8334 | Function Loss:  -3.4499\n",
      "Total loss:  -2.3006 | PDE Loss:  -2.8367 | Function Loss:  -3.45\n",
      "Total loss:  -2.3013 | PDE Loss:  -2.8367 | Function Loss:  -3.451\n",
      "Total loss:  -2.302 | PDE Loss:  -2.8396 | Function Loss:  -3.4507\n",
      "Total loss:  -2.3023 | PDE Loss:  -2.8384 | Function Loss:  -3.4517\n",
      "Total loss:  -2.3028 | PDE Loss:  -2.8387 | Function Loss:  -3.4523\n",
      "Total loss:  -2.3033 | PDE Loss:  -2.8389 | Function Loss:  -3.4528\n",
      "Total loss:  -2.3031 | PDE Loss:  -2.8355 | Function Loss:  -3.454\n",
      "Total loss:  -2.3036 | PDE Loss:  -2.8382 | Function Loss:  -3.4536\n",
      "Total loss:  -2.3043 | PDE Loss:  -2.8394 | Function Loss:  -3.454\n",
      "Total loss:  -2.3048 | PDE Loss:  -2.8389 | Function Loss:  -3.455\n",
      "Total loss:  -2.3055 | PDE Loss:  -2.8409 | Function Loss:  -3.4552\n",
      "Total loss:  -2.3061 | PDE Loss:  -2.8407 | Function Loss:  -3.4561\n",
      "Total loss:  -2.3071 | PDE Loss:  -2.8403 | Function Loss:  -3.4576\n",
      "Total loss:  -2.3082 | PDE Loss:  -2.8395 | Function Loss:  -3.4596\n",
      "Total loss:  -2.3093 | PDE Loss:  -2.8366 | Function Loss:  -3.4623\n",
      "Total loss:  -2.31 | PDE Loss:  -2.8355 | Function Loss:  -3.4638\n",
      "Total loss:  -2.3113 | PDE Loss:  -2.8332 | Function Loss:  -3.4666\n",
      "Total loss:  -2.3125 | PDE Loss:  -2.8322 | Function Loss:  -3.4688\n",
      "Total loss:  -2.3141 | PDE Loss:  -2.8302 | Function Loss:  -3.4719\n",
      "Total loss:  -2.3151 | PDE Loss:  -2.8303 | Function Loss:  -3.4734\n",
      "Total loss:  -2.317 | PDE Loss:  -2.8322 | Function Loss:  -3.4752\n",
      "Total loss:  -2.3187 | PDE Loss:  -2.8359 | Function Loss:  -3.4761\n",
      "Total loss:  -2.3204 | PDE Loss:  -2.8384 | Function Loss:  -3.4774\n",
      "Total loss:  -2.322 | PDE Loss:  -2.8443 | Function Loss:  -3.4772\n",
      "Total loss:  -2.3233 | PDE Loss:  -2.8457 | Function Loss:  -3.4784\n",
      "Total loss:  -2.3246 | PDE Loss:  -2.8478 | Function Loss:  -3.4793\n",
      "Total loss:  -2.3258 | PDE Loss:  -2.8481 | Function Loss:  -3.4809\n",
      "Total loss:  -2.3269 | PDE Loss:  -2.8486 | Function Loss:  -3.4823\n",
      "Total loss:  -2.3276 | PDE Loss:  -2.8481 | Function Loss:  -3.4834\n",
      "Total loss:  -2.3285 | PDE Loss:  -2.8476 | Function Loss:  -3.485\n",
      "Total loss:  -2.3295 | PDE Loss:  -2.8448 | Function Loss:  -3.4877\n",
      "Total loss:  -2.3304 | PDE Loss:  -2.8443 | Function Loss:  -3.4893\n",
      "Total loss:  -2.3313 | PDE Loss:  -2.8432 | Function Loss:  -3.491\n",
      "Total loss:  -2.3323 | PDE Loss:  -2.8425 | Function Loss:  -3.4928\n",
      "Total loss:  -2.3332 | PDE Loss:  -2.8434 | Function Loss:  -3.4937\n",
      "Total loss:  -2.334 | PDE Loss:  -2.844 | Function Loss:  -3.4945\n",
      "Total loss:  -2.3348 | PDE Loss:  -2.8464 | Function Loss:  -3.4946\n",
      "Total loss:  -2.3356 | PDE Loss:  -2.8477 | Function Loss:  -3.4952\n",
      "Total loss:  -2.3362 | PDE Loss:  -2.8492 | Function Loss:  -3.4954\n",
      "Total loss:  -2.3368 | PDE Loss:  -2.8506 | Function Loss:  -3.4956\n",
      "Total loss:  -2.3373 | PDE Loss:  -2.8506 | Function Loss:  -3.4964\n",
      "Total loss:  -2.3377 | PDE Loss:  -2.8511 | Function Loss:  -3.4967\n",
      "Total loss:  -2.338 | PDE Loss:  -2.8511 | Function Loss:  -3.4972\n",
      "Total loss:  -2.3385 | PDE Loss:  -2.8501 | Function Loss:  -3.4983\n",
      "Total loss:  -2.339 | PDE Loss:  -2.8505 | Function Loss:  -3.4989\n",
      "Total loss:  -2.3395 | PDE Loss:  -2.8499 | Function Loss:  -3.4999\n",
      "Total loss:  -2.34 | PDE Loss:  -2.8495 | Function Loss:  -3.5007\n",
      "Total loss:  -2.3405 | PDE Loss:  -2.8495 | Function Loss:  -3.5015\n",
      "Total loss:  -2.341 | PDE Loss:  -2.8492 | Function Loss:  -3.5023\n",
      "Total loss:  -2.3414 | PDE Loss:  -2.8493 | Function Loss:  -3.5028\n",
      "Total loss:  -2.3417 | PDE Loss:  -2.8486 | Function Loss:  -3.5036\n",
      "Total loss:  -2.3419 | PDE Loss:  -2.8485 | Function Loss:  -3.504\n",
      "Total loss:  -2.3422 | PDE Loss:  -2.8474 | Function Loss:  -3.5049\n",
      "Total loss:  -2.3424 | PDE Loss:  -2.847 | Function Loss:  -3.5053\n",
      "Total loss:  -2.3425 | PDE Loss:  -2.8464 | Function Loss:  -3.5058\n",
      "Total loss:  -2.3427 | PDE Loss:  -2.8461 | Function Loss:  -3.5062\n",
      "Total loss:  -2.3429 | PDE Loss:  -2.846 | Function Loss:  -3.5066\n",
      "Total loss:  -2.3432 | PDE Loss:  -2.8462 | Function Loss:  -3.5069\n",
      "Total loss:  -2.3437 | PDE Loss:  -2.8468 | Function Loss:  -3.5073\n",
      "Total loss:  -2.3442 | PDE Loss:  -2.8473 | Function Loss:  -3.5079\n",
      "Total loss:  -2.3448 | PDE Loss:  -2.8479 | Function Loss:  -3.5084\n",
      "Total loss:  -2.3457 | PDE Loss:  -2.8499 | Function Loss:  -3.5089\n",
      "Total loss:  -2.3471 | PDE Loss:  -2.8521 | Function Loss:  -3.5099\n",
      "Total loss:  -2.3485 | PDE Loss:  -2.8554 | Function Loss:  -3.5104\n",
      "Total loss:  -2.3498 | PDE Loss:  -2.8569 | Function Loss:  -3.5116\n",
      "Total loss:  -2.3511 | PDE Loss:  -2.8591 | Function Loss:  -3.5125\n",
      "Total loss:  -2.3524 | PDE Loss:  -2.8595 | Function Loss:  -3.5142\n",
      "Total loss:  -2.3538 | PDE Loss:  -2.8614 | Function Loss:  -3.5154\n",
      "Total loss:  -2.3551 | PDE Loss:  -2.8604 | Function Loss:  -3.5178\n",
      "Total loss:  -2.3561 | PDE Loss:  -2.8633 | Function Loss:  -3.5179\n",
      "Total loss:  -2.3569 | PDE Loss:  -2.8636 | Function Loss:  -3.5189\n",
      "Total loss:  -2.3578 | PDE Loss:  -2.8661 | Function Loss:  -3.5191\n",
      "Total loss:  -2.3586 | PDE Loss:  -2.8681 | Function Loss:  -3.5194\n",
      "Total loss:  -2.3594 | PDE Loss:  -2.8703 | Function Loss:  -3.5195\n",
      "Total loss:  -2.3603 | PDE Loss:  -2.8743 | Function Loss:  -3.519\n",
      "Total loss:  -2.3614 | PDE Loss:  -2.8777 | Function Loss:  -3.5191\n",
      "Total loss:  -2.3624 | PDE Loss:  -2.8805 | Function Loss:  -3.5194\n",
      "Total loss:  -2.3579 | PDE Loss:  -2.877 | Function Loss:  -3.5144\n",
      "Total loss:  -2.3628 | PDE Loss:  -2.8827 | Function Loss:  -3.519\n",
      "Total loss:  -2.3635 | PDE Loss:  -2.8852 | Function Loss:  -3.5189\n",
      "Total loss:  -2.3646 | PDE Loss:  -2.888 | Function Loss:  -3.5193\n",
      "Total loss:  -2.3657 | PDE Loss:  -2.8926 | Function Loss:  -3.5189\n",
      "Total loss:  -2.3667 | PDE Loss:  -2.8954 | Function Loss:  -3.5191\n",
      "Total loss:  -2.3674 | PDE Loss:  -2.8992 | Function Loss:  -3.5185\n",
      "Total loss:  -2.368 | PDE Loss:  -2.9032 | Function Loss:  -3.5178\n",
      "Total loss:  -2.3685 | PDE Loss:  -2.9054 | Function Loss:  -3.5175\n",
      "Total loss:  -2.3689 | PDE Loss:  -2.9069 | Function Loss:  -3.5174\n",
      "Total loss:  -2.3692 | PDE Loss:  -2.91 | Function Loss:  -3.5166\n",
      "Total loss:  -2.3694 | PDE Loss:  -2.9107 | Function Loss:  -3.5166\n",
      "Total loss:  -2.3695 | PDE Loss:  -2.9114 | Function Loss:  -3.5166\n",
      "Total loss:  -2.3698 | PDE Loss:  -2.9124 | Function Loss:  -3.5165\n",
      "Total loss:  -2.3703 | PDE Loss:  -2.9141 | Function Loss:  -3.5165\n",
      "Total loss:  -2.3708 | PDE Loss:  -2.9162 | Function Loss:  -3.5164\n",
      "Total loss:  -2.3709 | PDE Loss:  -2.9184 | Function Loss:  -3.5157\n",
      "Total loss:  -2.3713 | PDE Loss:  -2.9181 | Function Loss:  -3.5163\n",
      "Total loss:  -2.3718 | PDE Loss:  -2.9198 | Function Loss:  -3.5164\n",
      "Total loss:  -2.3726 | PDE Loss:  -2.9218 | Function Loss:  -3.5167\n",
      "Total loss:  -2.3733 | PDE Loss:  -2.9219 | Function Loss:  -3.5177\n",
      "Total loss:  -2.374 | PDE Loss:  -2.9236 | Function Loss:  -3.518\n",
      "Total loss:  -2.3746 | PDE Loss:  -2.9229 | Function Loss:  -3.519\n",
      "Total loss:  -2.3755 | PDE Loss:  -2.9211 | Function Loss:  -3.521\n",
      "Total loss:  -2.3765 | PDE Loss:  -2.9163 | Function Loss:  -3.5243\n",
      "Total loss:  -2.3773 | PDE Loss:  -2.9155 | Function Loss:  -3.5258\n",
      "Total loss:  -2.3786 | PDE Loss:  -2.9151 | Function Loss:  -3.5278\n",
      "Total loss:  -2.3802 | PDE Loss:  -2.9151 | Function Loss:  -3.5301\n",
      "Total loss:  -2.3822 | PDE Loss:  -2.9156 | Function Loss:  -3.5327\n",
      "Total loss:  -2.3842 | PDE Loss:  -2.9149 | Function Loss:  -3.5358\n",
      "Total loss:  -2.3859 | PDE Loss:  -2.9155 | Function Loss:  -3.538\n",
      "Total loss:  -2.3872 | PDE Loss:  -2.9139 | Function Loss:  -3.5405\n",
      "Total loss:  -2.388 | PDE Loss:  -2.9142 | Function Loss:  -3.5415\n",
      "Total loss:  -2.3887 | PDE Loss:  -2.9139 | Function Loss:  -3.5425\n",
      "Total loss:  -2.3892 | PDE Loss:  -2.9145 | Function Loss:  -3.5431\n",
      "Total loss:  -2.3899 | PDE Loss:  -2.9152 | Function Loss:  -3.5437\n",
      "Total loss:  -2.3904 | PDE Loss:  -2.9148 | Function Loss:  -3.5446\n",
      "Total loss:  -2.3908 | PDE Loss:  -2.9148 | Function Loss:  -3.5452\n",
      "Total loss:  -2.3913 | PDE Loss:  -2.914 | Function Loss:  -3.5463\n",
      "Total loss:  -2.3917 | PDE Loss:  -2.9125 | Function Loss:  -3.5475\n",
      "Total loss:  -2.3921 | PDE Loss:  -2.9119 | Function Loss:  -3.5484\n",
      "Total loss:  -2.3925 | PDE Loss:  -2.9095 | Function Loss:  -3.55\n",
      "Total loss:  -2.3929 | PDE Loss:  -2.9087 | Function Loss:  -3.551\n",
      "Total loss:  -2.3935 | PDE Loss:  -2.9081 | Function Loss:  -3.552\n",
      "Total loss:  -2.3942 | PDE Loss:  -2.9073 | Function Loss:  -3.5533\n",
      "Total loss:  -2.3949 | PDE Loss:  -2.9071 | Function Loss:  -3.5544\n",
      "Total loss:  -2.3955 | PDE Loss:  -2.9073 | Function Loss:  -3.5553\n",
      "Total loss:  -2.396 | PDE Loss:  -2.907 | Function Loss:  -3.5561\n",
      "Total loss:  -2.3966 | PDE Loss:  -2.9084 | Function Loss:  -3.5564\n",
      "Total loss:  -2.3972 | PDE Loss:  -2.9085 | Function Loss:  -3.5571\n",
      "Total loss:  -2.3977 | PDE Loss:  -2.9095 | Function Loss:  -3.5575\n",
      "Total loss:  -2.3984 | PDE Loss:  -2.9091 | Function Loss:  -3.5586\n",
      "Total loss:  -2.3992 | PDE Loss:  -2.9097 | Function Loss:  -3.5595\n",
      "Total loss:  -2.4001 | PDE Loss:  -2.9083 | Function Loss:  -3.5615\n",
      "Total loss:  -2.401 | PDE Loss:  -2.9076 | Function Loss:  -3.563\n",
      "Total loss:  -2.4025 | PDE Loss:  -2.9081 | Function Loss:  -3.565\n",
      "Total loss:  -2.4041 | PDE Loss:  -2.9088 | Function Loss:  -3.567\n",
      "Total loss:  -2.4053 | PDE Loss:  -2.9103 | Function Loss:  -3.568\n",
      "Total loss:  -2.4068 | PDE Loss:  -2.9153 | Function Loss:  -3.568\n",
      "Total loss:  -2.4084 | PDE Loss:  -2.9203 | Function Loss:  -3.5681\n",
      "Total loss:  -2.4095 | PDE Loss:  -2.9244 | Function Loss:  -3.5679\n",
      "Total loss:  -2.4104 | PDE Loss:  -2.932 | Function Loss:  -3.5658\n",
      "Total loss:  -2.4114 | PDE Loss:  -2.9352 | Function Loss:  -3.5659\n",
      "Total loss:  -2.4121 | PDE Loss:  -2.936 | Function Loss:  -3.5666\n",
      "Total loss:  -2.4129 | PDE Loss:  -2.937 | Function Loss:  -3.5672\n",
      "Total loss:  -2.4135 | PDE Loss:  -2.9371 | Function Loss:  -3.5681\n",
      "Total loss:  -2.4143 | PDE Loss:  -2.937 | Function Loss:  -3.5693\n",
      "Total loss:  -2.4152 | PDE Loss:  -2.936 | Function Loss:  -3.571\n",
      "Total loss:  -2.4161 | PDE Loss:  -2.9331 | Function Loss:  -3.5736\n",
      "Total loss:  -2.4168 | PDE Loss:  -2.9317 | Function Loss:  -3.5752\n",
      "Total loss:  -2.4175 | PDE Loss:  -2.9302 | Function Loss:  -3.5768\n",
      "Total loss:  -2.4183 | PDE Loss:  -2.9306 | Function Loss:  -3.5779\n",
      "Total loss:  -2.4192 | PDE Loss:  -2.9298 | Function Loss:  -3.5795\n",
      "Total loss:  -2.42 | PDE Loss:  -2.9298 | Function Loss:  -3.5806\n",
      "Total loss:  -2.4208 | PDE Loss:  -2.9306 | Function Loss:  -3.5815\n",
      "Total loss:  -2.4215 | PDE Loss:  -2.9304 | Function Loss:  -3.5826\n",
      "Total loss:  -2.4219 | PDE Loss:  -2.931 | Function Loss:  -3.5829\n",
      "Total loss:  -2.4225 | PDE Loss:  -2.9325 | Function Loss:  -3.583\n",
      "Total loss:  -2.4232 | PDE Loss:  -2.9324 | Function Loss:  -3.584\n",
      "Total loss:  -2.4238 | PDE Loss:  -2.9338 | Function Loss:  -3.5843\n",
      "Total loss:  -2.4244 | PDE Loss:  -2.9339 | Function Loss:  -3.5852\n",
      "Total loss:  -2.425 | PDE Loss:  -2.9315 | Function Loss:  -3.5871\n",
      "Total loss:  -2.4255 | PDE Loss:  -2.9325 | Function Loss:  -3.5875\n",
      "Total loss:  -2.4261 | PDE Loss:  -2.9326 | Function Loss:  -3.5882\n",
      "Total loss:  -2.4266 | PDE Loss:  -2.9337 | Function Loss:  -3.5884\n",
      "Total loss:  -2.427 | PDE Loss:  -2.9342 | Function Loss:  -3.5888\n",
      "Total loss:  -2.4274 | PDE Loss:  -2.9347 | Function Loss:  -3.5891\n",
      "Total loss:  -2.4277 | PDE Loss:  -2.9356 | Function Loss:  -3.5892\n",
      "Total loss:  -2.4281 | PDE Loss:  -2.9361 | Function Loss:  -3.5895\n",
      "Total loss:  -2.4286 | PDE Loss:  -2.9375 | Function Loss:  -3.5897\n",
      "Total loss:  -2.4294 | PDE Loss:  -2.9385 | Function Loss:  -3.5903\n",
      "Total loss:  -2.4301 | PDE Loss:  -2.9396 | Function Loss:  -3.5909\n",
      "Total loss:  -2.4305 | PDE Loss:  -2.9414 | Function Loss:  -3.5906\n",
      "Total loss:  -2.4308 | PDE Loss:  -2.9411 | Function Loss:  -3.5911\n",
      "Total loss:  -2.4311 | PDE Loss:  -2.9409 | Function Loss:  -3.5917\n",
      "Total loss:  -2.4313 | PDE Loss:  -2.9407 | Function Loss:  -3.5922\n",
      "Total loss:  -2.4316 | PDE Loss:  -2.941 | Function Loss:  -3.5924\n",
      "Total loss:  -2.4318 | PDE Loss:  -2.9413 | Function Loss:  -3.5926\n",
      "Total loss:  -2.4321 | PDE Loss:  -2.9423 | Function Loss:  -3.5925\n",
      "Total loss:  -2.4324 | PDE Loss:  -2.9443 | Function Loss:  -3.5921\n",
      "Total loss:  -2.4328 | PDE Loss:  -2.9471 | Function Loss:  -3.5915\n",
      "Total loss:  -2.4333 | PDE Loss:  -2.9502 | Function Loss:  -3.5908\n",
      "Total loss:  -2.4338 | PDE Loss:  -2.9534 | Function Loss:  -3.59\n",
      "Total loss:  -2.4342 | PDE Loss:  -2.9565 | Function Loss:  -3.5893\n",
      "Total loss:  -2.4346 | PDE Loss:  -2.9594 | Function Loss:  -3.5887\n",
      "Total loss:  -2.435 | PDE Loss:  -2.9617 | Function Loss:  -3.5883\n",
      "Total loss:  -2.4356 | PDE Loss:  -2.964 | Function Loss:  -3.5881\n",
      "Total loss:  -2.4363 | PDE Loss:  -2.9665 | Function Loss:  -3.588\n",
      "Total loss:  -2.437 | PDE Loss:  -2.9686 | Function Loss:  -3.5882\n",
      "Total loss:  -2.4377 | PDE Loss:  -2.9701 | Function Loss:  -3.5885\n",
      "Total loss:  -2.4384 | PDE Loss:  -2.9712 | Function Loss:  -3.5891\n",
      "Total loss:  -2.4391 | PDE Loss:  -2.972 | Function Loss:  -3.5897\n",
      "Total loss:  -2.4398 | PDE Loss:  -2.9733 | Function Loss:  -3.5903\n",
      "Total loss:  -2.4405 | PDE Loss:  -2.9756 | Function Loss:  -3.5902\n",
      "Total loss:  -2.4412 | PDE Loss:  -2.9762 | Function Loss:  -3.591\n",
      "Total loss:  -2.442 | PDE Loss:  -2.979 | Function Loss:  -3.591\n",
      "Total loss:  -2.4428 | PDE Loss:  -2.9802 | Function Loss:  -3.5917\n",
      "Total loss:  -2.4435 | PDE Loss:  -2.9827 | Function Loss:  -3.5916\n",
      "Total loss:  -2.444 | PDE Loss:  -2.9838 | Function Loss:  -3.5918\n",
      "Total loss:  -2.4446 | PDE Loss:  -2.986 | Function Loss:  -3.5918\n",
      "Total loss:  -2.4453 | PDE Loss:  -2.9873 | Function Loss:  -3.5922\n",
      "Total loss:  -2.4459 | PDE Loss:  -2.9884 | Function Loss:  -3.5926\n",
      "Total loss:  -2.4463 | PDE Loss:  -2.9892 | Function Loss:  -3.5929\n",
      "Total loss:  -2.4467 | PDE Loss:  -2.9887 | Function Loss:  -3.5936\n",
      "Total loss:  -2.4469 | PDE Loss:  -2.989 | Function Loss:  -3.5938\n",
      "Total loss:  -2.4472 | PDE Loss:  -2.9891 | Function Loss:  -3.5942\n",
      "Total loss:  -2.4475 | PDE Loss:  -2.9898 | Function Loss:  -3.5944\n",
      "Total loss:  -2.4479 | PDE Loss:  -2.991 | Function Loss:  -3.5944\n",
      "Total loss:  -2.4482 | PDE Loss:  -2.9916 | Function Loss:  -3.5946\n",
      "Total loss:  -2.4485 | PDE Loss:  -2.9926 | Function Loss:  -3.5946\n",
      "Total loss:  -2.4487 | PDE Loss:  -2.9931 | Function Loss:  -3.5947\n",
      "Total loss:  -2.449 | PDE Loss:  -2.9936 | Function Loss:  -3.5949\n",
      "Total loss:  -2.4494 | PDE Loss:  -2.9948 | Function Loss:  -3.5949\n",
      "Total loss:  -2.4497 | PDE Loss:  -2.9942 | Function Loss:  -3.5957\n",
      "Total loss:  -2.4502 | PDE Loss:  -2.9941 | Function Loss:  -3.5965\n",
      "Total loss:  -2.4509 | PDE Loss:  -2.9933 | Function Loss:  -3.5977\n",
      "Total loss:  -2.4517 | PDE Loss:  -2.9926 | Function Loss:  -3.599\n",
      "Total loss:  -2.4524 | PDE Loss:  -2.9918 | Function Loss:  -3.6004\n",
      "Total loss:  -2.4533 | PDE Loss:  -2.9909 | Function Loss:  -3.602\n",
      "Total loss:  -2.4541 | PDE Loss:  -2.99 | Function Loss:  -3.6036\n",
      "Total loss:  -2.4551 | PDE Loss:  -2.9883 | Function Loss:  -3.6056\n",
      "Total loss:  -2.4559 | PDE Loss:  -2.9882 | Function Loss:  -3.6068\n",
      "Total loss:  -2.4566 | PDE Loss:  -2.9876 | Function Loss:  -3.6081\n",
      "Total loss:  -2.4576 | PDE Loss:  -2.9882 | Function Loss:  -3.6093\n",
      "Total loss:  -2.4585 | PDE Loss:  -2.9872 | Function Loss:  -3.6109\n",
      "Total loss:  -2.4593 | PDE Loss:  -2.9874 | Function Loss:  -3.612\n",
      "Total loss:  -2.4603 | PDE Loss:  -2.987 | Function Loss:  -3.6135\n",
      "Total loss:  -2.4613 | PDE Loss:  -2.9871 | Function Loss:  -3.6149\n",
      "Total loss:  -2.4618 | PDE Loss:  -2.9846 | Function Loss:  -3.6168\n",
      "Total loss:  -2.4623 | PDE Loss:  -2.9839 | Function Loss:  -3.6177\n",
      "Total loss:  -2.4626 | PDE Loss:  -2.9826 | Function Loss:  -3.6187\n",
      "Total loss:  -2.4629 | PDE Loss:  -2.9812 | Function Loss:  -3.6198\n",
      "Total loss:  -2.4632 | PDE Loss:  -2.9795 | Function Loss:  -3.621\n",
      "Total loss:  -2.4635 | PDE Loss:  -2.9787 | Function Loss:  -3.6217\n",
      "Total loss:  -2.4638 | PDE Loss:  -2.977 | Function Loss:  -3.623\n",
      "Total loss:  -2.4642 | PDE Loss:  -2.9774 | Function Loss:  -3.6233\n",
      "Total loss:  -2.4645 | PDE Loss:  -2.9776 | Function Loss:  -3.6236\n",
      "Total loss:  -2.4649 | PDE Loss:  -2.9791 | Function Loss:  -3.6236\n",
      "Total loss:  -2.4639 | PDE Loss:  -2.9793 | Function Loss:  -3.622\n",
      "Total loss:  -2.4651 | PDE Loss:  -2.9801 | Function Loss:  -3.6234\n",
      "Total loss:  -2.4657 | PDE Loss:  -2.98 | Function Loss:  -3.6243\n",
      "Total loss:  -2.4661 | PDE Loss:  -2.9815 | Function Loss:  -3.6242\n",
      "Total loss:  -2.4664 | PDE Loss:  -2.9825 | Function Loss:  -3.6243\n",
      "Total loss:  -2.467 | PDE Loss:  -2.9837 | Function Loss:  -3.6246\n",
      "Total loss:  -2.4676 | PDE Loss:  -2.9844 | Function Loss:  -3.6251\n",
      "Total loss:  -2.468 | PDE Loss:  -2.9857 | Function Loss:  -3.6251\n",
      "Total loss:  -2.4683 | PDE Loss:  -2.9861 | Function Loss:  -3.6254\n",
      "Total loss:  -2.4688 | PDE Loss:  -2.9881 | Function Loss:  -3.6252\n",
      "Total loss:  -2.4694 | PDE Loss:  -2.9887 | Function Loss:  -3.6258\n",
      "Total loss:  -2.47 | PDE Loss:  -2.9892 | Function Loss:  -3.6264\n",
      "Total loss:  -2.4709 | PDE Loss:  -2.9901 | Function Loss:  -3.6274\n",
      "Total loss:  -2.4718 | PDE Loss:  -2.9913 | Function Loss:  -3.6281\n",
      "Total loss:  -2.4725 | PDE Loss:  -2.9923 | Function Loss:  -3.6287\n",
      "Total loss:  -2.4733 | PDE Loss:  -2.994 | Function Loss:  -3.6292\n",
      "Total loss:  -2.4741 | PDE Loss:  -2.9954 | Function Loss:  -3.6296\n",
      "Total loss:  -2.4746 | PDE Loss:  -2.9965 | Function Loss:  -3.63\n",
      "Total loss:  -2.475 | PDE Loss:  -2.9971 | Function Loss:  -3.6302\n",
      "Total loss:  -2.4754 | PDE Loss:  -2.9974 | Function Loss:  -3.6306\n",
      "Total loss:  -2.4758 | PDE Loss:  -2.998 | Function Loss:  -3.631\n",
      "Total loss:  -2.4762 | PDE Loss:  -2.9973 | Function Loss:  -3.6318\n",
      "Total loss:  -2.4765 | PDE Loss:  -2.9973 | Function Loss:  -3.6322\n",
      "Total loss:  -2.4767 | PDE Loss:  -2.9968 | Function Loss:  -3.6329\n",
      "Total loss:  -2.4772 | PDE Loss:  -2.997 | Function Loss:  -3.6333\n",
      "Total loss:  -2.4778 | PDE Loss:  -2.998 | Function Loss:  -3.6338\n",
      "Total loss:  -2.4785 | PDE Loss:  -2.9983 | Function Loss:  -3.6347\n",
      "Total loss:  -2.4791 | PDE Loss:  -2.9993 | Function Loss:  -3.6351\n",
      "Total loss:  -2.4795 | PDE Loss:  -2.9979 | Function Loss:  -3.6363\n",
      "Total loss:  -2.4802 | PDE Loss:  -2.9985 | Function Loss:  -3.6371\n",
      "Total loss:  -2.4807 | PDE Loss:  -2.9986 | Function Loss:  -3.6378\n",
      "Total loss:  -2.4815 | PDE Loss:  -2.9985 | Function Loss:  -3.6389\n",
      "Total loss:  -2.4823 | PDE Loss:  -2.998 | Function Loss:  -3.6404\n",
      "Total loss:  -2.4833 | PDE Loss:  -2.9978 | Function Loss:  -3.6418\n",
      "Total loss:  -2.4846 | PDE Loss:  -2.9979 | Function Loss:  -3.6436\n",
      "Total loss:  -2.486 | PDE Loss:  -2.9989 | Function Loss:  -3.6453\n",
      "Total loss:  -2.4874 | PDE Loss:  -2.9998 | Function Loss:  -3.647\n",
      "Total loss:  -2.489 | PDE Loss:  -3.0002 | Function Loss:  -3.649\n",
      "Total loss:  -2.49 | PDE Loss:  -3.0018 | Function Loss:  -3.6498\n",
      "Total loss:  -2.4917 | PDE Loss:  -3.0039 | Function Loss:  -3.6513\n",
      "Total loss:  -2.4932 | PDE Loss:  -3.0069 | Function Loss:  -3.6521\n",
      "Total loss:  -2.4947 | PDE Loss:  -3.0095 | Function Loss:  -3.6532\n",
      "Total loss:  -2.4966 | PDE Loss:  -3.0121 | Function Loss:  -3.6547\n",
      "Total loss:  -2.4986 | PDE Loss:  -3.0157 | Function Loss:  -3.6561\n",
      "Total loss:  -2.5009 | PDE Loss:  -3.0165 | Function Loss:  -3.659\n",
      "Total loss:  -2.5029 | PDE Loss:  -3.0189 | Function Loss:  -3.6608\n",
      "Total loss:  -2.5048 | PDE Loss:  -3.0184 | Function Loss:  -3.6637\n",
      "Total loss:  -2.5063 | PDE Loss:  -3.0189 | Function Loss:  -3.6656\n",
      "Total loss:  -2.5071 | PDE Loss:  -3.02 | Function Loss:  -3.6663\n",
      "Total loss:  -2.5079 | PDE Loss:  -3.0203 | Function Loss:  -3.6674\n",
      "Total loss:  -2.5087 | PDE Loss:  -3.0209 | Function Loss:  -3.6682\n",
      "Total loss:  -2.5093 | PDE Loss:  -3.0219 | Function Loss:  -3.6686\n",
      "Total loss:  -2.5097 | PDE Loss:  -3.0229 | Function Loss:  -3.6689\n",
      "Total loss:  -2.5103 | PDE Loss:  -3.0242 | Function Loss:  -3.6691\n",
      "Total loss:  -2.5108 | PDE Loss:  -3.0267 | Function Loss:  -3.6687\n",
      "Total loss:  -2.5112 | PDE Loss:  -3.0277 | Function Loss:  -3.6688\n",
      "Total loss:  -2.5116 | PDE Loss:  -3.0295 | Function Loss:  -3.6686\n",
      "Total loss:  -2.5118 | PDE Loss:  -3.0307 | Function Loss:  -3.6684\n",
      "Total loss:  -2.5121 | PDE Loss:  -3.031 | Function Loss:  -3.6687\n",
      "Total loss:  -2.5125 | PDE Loss:  -3.0311 | Function Loss:  -3.6692\n",
      "Total loss:  -2.5129 | PDE Loss:  -3.0306 | Function Loss:  -3.67\n",
      "Total loss:  -2.5132 | PDE Loss:  -3.0299 | Function Loss:  -3.6708\n",
      "Total loss:  -2.5137 | PDE Loss:  -3.028 | Function Loss:  -3.6723\n",
      "Total loss:  -2.5143 | PDE Loss:  -3.0273 | Function Loss:  -3.6736\n",
      "Total loss:  -2.515 | PDE Loss:  -3.0271 | Function Loss:  -3.6746\n",
      "Total loss:  -2.5158 | PDE Loss:  -3.0283 | Function Loss:  -3.6752\n",
      "Total loss:  -2.5169 | PDE Loss:  -3.0317 | Function Loss:  -3.6753\n",
      "Total loss:  -2.5177 | PDE Loss:  -3.0352 | Function Loss:  -3.6749\n",
      "Total loss:  -2.518 | PDE Loss:  -3.0373 | Function Loss:  -3.6745\n",
      "Total loss:  -2.5185 | PDE Loss:  -3.0401 | Function Loss:  -3.674\n",
      "Total loss:  -2.519 | PDE Loss:  -3.0426 | Function Loss:  -3.6737\n",
      "Total loss:  -2.5194 | PDE Loss:  -3.0453 | Function Loss:  -3.6731\n",
      "Total loss:  -2.5198 | PDE Loss:  -3.046 | Function Loss:  -3.6733\n",
      "Total loss:  -2.5201 | PDE Loss:  -3.0478 | Function Loss:  -3.6729\n",
      "Total loss:  -2.5203 | PDE Loss:  -3.0484 | Function Loss:  -3.673\n",
      "Total loss:  -2.5205 | PDE Loss:  -3.0484 | Function Loss:  -3.6733\n",
      "Total loss:  -2.5208 | PDE Loss:  -3.0484 | Function Loss:  -3.6736\n",
      "Total loss:  -2.521 | PDE Loss:  -3.0483 | Function Loss:  -3.674\n",
      "Total loss:  -2.5212 | PDE Loss:  -3.0485 | Function Loss:  -3.6743\n",
      "Total loss:  -2.5215 | PDE Loss:  -3.0489 | Function Loss:  -3.6744\n",
      "Total loss:  -2.5217 | PDE Loss:  -3.0497 | Function Loss:  -3.6745\n",
      "Total loss:  -2.5221 | PDE Loss:  -3.0506 | Function Loss:  -3.6746\n",
      "Total loss:  -2.5224 | PDE Loss:  -3.0527 | Function Loss:  -3.6741\n",
      "Total loss:  -2.5228 | PDE Loss:  -3.0539 | Function Loss:  -3.6742\n",
      "Total loss:  -2.523 | PDE Loss:  -3.0545 | Function Loss:  -3.6743\n",
      "Total loss:  -2.5235 | PDE Loss:  -3.0553 | Function Loss:  -3.6746\n",
      "Total loss:  -2.5239 | PDE Loss:  -3.0555 | Function Loss:  -3.6751\n",
      "Total loss:  -2.5244 | PDE Loss:  -3.0555 | Function Loss:  -3.6758\n",
      "Total loss:  -2.5249 | PDE Loss:  -3.0546 | Function Loss:  -3.6769\n",
      "Total loss:  -2.5253 | PDE Loss:  -3.0543 | Function Loss:  -3.6776\n",
      "Total loss:  -2.5258 | PDE Loss:  -3.0539 | Function Loss:  -3.6785\n",
      "Total loss:  -2.5263 | PDE Loss:  -3.0533 | Function Loss:  -3.6794\n",
      "Total loss:  -2.5267 | PDE Loss:  -3.0529 | Function Loss:  -3.6802\n",
      "Total loss:  -2.5271 | PDE Loss:  -3.0526 | Function Loss:  -3.6809\n",
      "Total loss:  -2.5275 | PDE Loss:  -3.0522 | Function Loss:  -3.6816\n",
      "Total loss:  -2.5278 | PDE Loss:  -3.0523 | Function Loss:  -3.682\n",
      "Total loss:  -2.5281 | PDE Loss:  -3.0527 | Function Loss:  -3.6823\n",
      "Total loss:  -2.5284 | PDE Loss:  -3.0533 | Function Loss:  -3.6825\n",
      "Total loss:  -2.5288 | PDE Loss:  -3.0541 | Function Loss:  -3.6826\n",
      "Total loss:  -2.5291 | PDE Loss:  -3.055 | Function Loss:  -3.6827\n",
      "Total loss:  -2.5294 | PDE Loss:  -3.056 | Function Loss:  -3.6828\n",
      "Total loss:  -2.5297 | PDE Loss:  -3.057 | Function Loss:  -3.6827\n",
      "Total loss:  -2.53 | PDE Loss:  -3.0579 | Function Loss:  -3.6828\n",
      "Total loss:  -2.5303 | PDE Loss:  -3.0589 | Function Loss:  -3.6827\n",
      "Total loss:  -2.5305 | PDE Loss:  -3.0595 | Function Loss:  -3.6828\n",
      "Total loss:  -2.5307 | PDE Loss:  -3.06 | Function Loss:  -3.6829\n",
      "Total loss:  -2.5309 | PDE Loss:  -3.0601 | Function Loss:  -3.6832\n",
      "Total loss:  -2.5311 | PDE Loss:  -3.0597 | Function Loss:  -3.6837\n",
      "Total loss:  -2.5314 | PDE Loss:  -3.0591 | Function Loss:  -3.6843\n",
      "Total loss:  -2.5316 | PDE Loss:  -3.0585 | Function Loss:  -3.6848\n",
      "Total loss:  -2.5319 | PDE Loss:  -3.0574 | Function Loss:  -3.6857\n",
      "Total loss:  -2.5322 | PDE Loss:  -3.0568 | Function Loss:  -3.6864\n",
      "Total loss:  -2.5324 | PDE Loss:  -3.0564 | Function Loss:  -3.6868\n",
      "Total loss:  -2.5325 | PDE Loss:  -3.0563 | Function Loss:  -3.687\n",
      "Total loss:  -2.5326 | PDE Loss:  -3.0562 | Function Loss:  -3.6872\n",
      "Total loss:  -2.5327 | PDE Loss:  -3.0562 | Function Loss:  -3.6873\n",
      "Total loss:  -2.5328 | PDE Loss:  -3.0562 | Function Loss:  -3.6875\n",
      "Total loss:  -2.533 | PDE Loss:  -3.0564 | Function Loss:  -3.6877\n",
      "Total loss:  -2.5332 | PDE Loss:  -3.0567 | Function Loss:  -3.6878\n",
      "Total loss:  -2.5334 | PDE Loss:  -3.0569 | Function Loss:  -3.6881\n",
      "Total loss:  -2.5337 | PDE Loss:  -3.0574 | Function Loss:  -3.6882\n",
      "Total loss:  -2.5339 | PDE Loss:  -3.0581 | Function Loss:  -3.6883\n",
      "Total loss:  -2.5342 | PDE Loss:  -3.0588 | Function Loss:  -3.6883\n",
      "Total loss:  -2.5344 | PDE Loss:  -3.0594 | Function Loss:  -3.6884\n",
      "Total loss:  -2.5346 | PDE Loss:  -3.06 | Function Loss:  -3.6884\n",
      "Total loss:  -2.5348 | PDE Loss:  -3.0607 | Function Loss:  -3.6884\n",
      "Total loss:  -2.535 | PDE Loss:  -3.0617 | Function Loss:  -3.6883\n",
      "Total loss:  -2.5353 | PDE Loss:  -3.0634 | Function Loss:  -3.688\n",
      "Total loss:  -2.5356 | PDE Loss:  -3.065 | Function Loss:  -3.6878\n",
      "Total loss:  -2.5359 | PDE Loss:  -3.0668 | Function Loss:  -3.6874\n",
      "Total loss:  -2.5363 | PDE Loss:  -3.0688 | Function Loss:  -3.6871\n",
      "Total loss:  -2.5368 | PDE Loss:  -3.0705 | Function Loss:  -3.6871\n",
      "Total loss:  -2.5373 | PDE Loss:  -3.0722 | Function Loss:  -3.6872\n",
      "Total loss:  -2.5379 | PDE Loss:  -3.0737 | Function Loss:  -3.6874\n",
      "Total loss:  -2.5383 | PDE Loss:  -3.0735 | Function Loss:  -3.688\n",
      "Total loss:  -2.5393 | PDE Loss:  -3.0765 | Function Loss:  -3.6882\n",
      "Total loss:  -2.5398 | PDE Loss:  -3.0772 | Function Loss:  -3.6886\n",
      "Total loss:  -2.5408 | PDE Loss:  -3.0789 | Function Loss:  -3.6893\n",
      "Total loss:  -2.5417 | PDE Loss:  -3.0801 | Function Loss:  -3.6901\n",
      "Total loss:  -2.5426 | PDE Loss:  -3.0809 | Function Loss:  -3.691\n",
      "Total loss:  -2.5435 | PDE Loss:  -3.082 | Function Loss:  -3.6919\n",
      "Total loss:  -2.5445 | PDE Loss:  -3.083 | Function Loss:  -3.6929\n",
      "Total loss:  -2.5456 | PDE Loss:  -3.0854 | Function Loss:  -3.6935\n",
      "Total loss:  -2.5467 | PDE Loss:  -3.0877 | Function Loss:  -3.6941\n",
      "Total loss:  -2.5476 | PDE Loss:  -3.0929 | Function Loss:  -3.6932\n",
      "Total loss:  -2.5491 | PDE Loss:  -3.0956 | Function Loss:  -3.6943\n",
      "Total loss:  -2.5507 | PDE Loss:  -3.0979 | Function Loss:  -3.6956\n",
      "Total loss:  -2.5519 | PDE Loss:  -3.0993 | Function Loss:  -3.6967\n",
      "Total loss:  -2.5531 | PDE Loss:  -3.1012 | Function Loss:  -3.6976\n",
      "Total loss:  -2.5541 | PDE Loss:  -3.103 | Function Loss:  -3.6983\n",
      "Total loss:  -2.5548 | PDE Loss:  -3.1035 | Function Loss:  -3.6991\n",
      "Total loss:  -2.5556 | PDE Loss:  -3.105 | Function Loss:  -3.6996\n",
      "Total loss:  -2.5562 | PDE Loss:  -3.1056 | Function Loss:  -3.7002\n",
      "Total loss:  -2.5571 | PDE Loss:  -3.1081 | Function Loss:  -3.7006\n",
      "Total loss:  -2.5583 | PDE Loss:  -3.1095 | Function Loss:  -3.7016\n",
      "Total loss:  -2.5592 | PDE Loss:  -3.1141 | Function Loss:  -3.701\n",
      "Total loss:  -2.5602 | PDE Loss:  -3.1192 | Function Loss:  -3.7005\n",
      "Total loss:  -2.561 | PDE Loss:  -3.1213 | Function Loss:  -3.7008\n",
      "Total loss:  -2.5628 | PDE Loss:  -3.1274 | Function Loss:  -3.701\n",
      "Total loss:  -2.5642 | PDE Loss:  -3.1304 | Function Loss:  -3.7018\n",
      "Total loss:  -2.5652 | PDE Loss:  -3.1339 | Function Loss:  -3.7018\n",
      "Total loss:  -2.5659 | PDE Loss:  -3.1355 | Function Loss:  -3.7023\n",
      "Total loss:  -2.5666 | PDE Loss:  -3.1358 | Function Loss:  -3.7031\n",
      "Total loss:  -2.5676 | PDE Loss:  -3.1369 | Function Loss:  -3.704\n",
      "Total loss:  -2.5687 | PDE Loss:  -3.1374 | Function Loss:  -3.7054\n",
      "Total loss:  -2.5697 | PDE Loss:  -3.1398 | Function Loss:  -3.7058\n",
      "Total loss:  -2.5706 | PDE Loss:  -3.1406 | Function Loss:  -3.7068\n",
      "Total loss:  -2.5715 | PDE Loss:  -3.143 | Function Loss:  -3.7071\n",
      "Total loss:  -2.5723 | PDE Loss:  -3.1457 | Function Loss:  -3.7072\n",
      "Total loss:  -2.5732 | PDE Loss:  -3.1485 | Function Loss:  -3.7074\n",
      "Total loss:  -2.574 | PDE Loss:  -3.1542 | Function Loss:  -3.7064\n",
      "Total loss:  -2.5746 | PDE Loss:  -3.1562 | Function Loss:  -3.7066\n",
      "Total loss:  -2.5751 | PDE Loss:  -3.1591 | Function Loss:  -3.7062\n",
      "Total loss:  -2.5756 | PDE Loss:  -3.163 | Function Loss:  -3.7055\n",
      "Total loss:  -2.5762 | PDE Loss:  -3.1664 | Function Loss:  -3.7052\n",
      "Total loss:  -2.5768 | PDE Loss:  -3.1696 | Function Loss:  -3.7049\n",
      "Total loss:  -2.5775 | PDE Loss:  -3.1708 | Function Loss:  -3.7053\n",
      "Total loss:  -2.5778 | PDE Loss:  -3.171 | Function Loss:  -3.7058\n",
      "Total loss:  -2.5784 | PDE Loss:  -3.1718 | Function Loss:  -3.7062\n",
      "Total loss:  -2.5789 | PDE Loss:  -3.172 | Function Loss:  -3.7069\n",
      "Total loss:  -2.5794 | PDE Loss:  -3.1714 | Function Loss:  -3.7078\n",
      "Total loss:  -2.5799 | PDE Loss:  -3.1706 | Function Loss:  -3.7088\n",
      "Total loss:  -2.5804 | PDE Loss:  -3.1699 | Function Loss:  -3.7096\n",
      "Total loss:  -2.5809 | PDE Loss:  -3.1699 | Function Loss:  -3.7103\n",
      "Total loss:  -2.5813 | PDE Loss:  -3.1699 | Function Loss:  -3.7108\n",
      "Total loss:  -2.5817 | PDE Loss:  -3.171 | Function Loss:  -3.7109\n",
      "Total loss:  -2.5819 | PDE Loss:  -3.1718 | Function Loss:  -3.711\n",
      "Total loss:  -2.5823 | PDE Loss:  -3.1732 | Function Loss:  -3.711\n",
      "Total loss:  -2.5826 | PDE Loss:  -3.1747 | Function Loss:  -3.7109\n",
      "Total loss:  -2.5829 | PDE Loss:  -3.1755 | Function Loss:  -3.7111\n",
      "Total loss:  -2.5832 | PDE Loss:  -3.1756 | Function Loss:  -3.7114\n",
      "Total loss:  -2.5835 | PDE Loss:  -3.1756 | Function Loss:  -3.7118\n",
      "Total loss:  -2.5837 | PDE Loss:  -3.1751 | Function Loss:  -3.7123\n",
      "Total loss:  -2.5839 | PDE Loss:  -3.1744 | Function Loss:  -3.7128\n",
      "Total loss:  -2.5843 | PDE Loss:  -3.1729 | Function Loss:  -3.7138\n",
      "Total loss:  -2.5847 | PDE Loss:  -3.1714 | Function Loss:  -3.7149\n",
      "Total loss:  -2.585 | PDE Loss:  -3.1676 | Function Loss:  -3.7167\n",
      "Total loss:  -2.5854 | PDE Loss:  -3.1674 | Function Loss:  -3.7173\n",
      "Total loss:  -2.5857 | PDE Loss:  -3.1652 | Function Loss:  -3.7185\n",
      "Total loss:  -2.586 | PDE Loss:  -3.1653 | Function Loss:  -3.7188\n",
      "Total loss:  -2.5864 | PDE Loss:  -3.1661 | Function Loss:  -3.7191\n",
      "Total loss:  -2.5868 | PDE Loss:  -3.1666 | Function Loss:  -3.7194\n",
      "Total loss:  -2.5872 | PDE Loss:  -3.1672 | Function Loss:  -3.7197\n",
      "Total loss:  -2.5875 | PDE Loss:  -3.1675 | Function Loss:  -3.72\n",
      "Total loss:  -2.5878 | PDE Loss:  -3.1673 | Function Loss:  -3.7205\n",
      "Total loss:  -2.5881 | PDE Loss:  -3.1672 | Function Loss:  -3.721\n",
      "Total loss:  -2.5885 | PDE Loss:  -3.1667 | Function Loss:  -3.7217\n",
      "Total loss:  -2.5889 | PDE Loss:  -3.1665 | Function Loss:  -3.7224\n",
      "Total loss:  -2.5893 | PDE Loss:  -3.166 | Function Loss:  -3.7231\n",
      "Total loss:  -2.5897 | PDE Loss:  -3.1659 | Function Loss:  -3.7236\n",
      "Total loss:  -2.5902 | PDE Loss:  -3.1643 | Function Loss:  -3.7249\n",
      "Total loss:  -2.5907 | PDE Loss:  -3.1647 | Function Loss:  -3.7254\n",
      "Total loss:  -2.5911 | PDE Loss:  -3.1645 | Function Loss:  -3.726\n",
      "Total loss:  -2.5916 | PDE Loss:  -3.1645 | Function Loss:  -3.7268\n",
      "Total loss:  -2.5921 | PDE Loss:  -3.1644 | Function Loss:  -3.7275\n",
      "Total loss:  -2.5926 | PDE Loss:  -3.1643 | Function Loss:  -3.7282\n",
      "Total loss:  -2.5931 | PDE Loss:  -3.1641 | Function Loss:  -3.7289\n",
      "Total loss:  -2.5936 | PDE Loss:  -3.164 | Function Loss:  -3.7297\n",
      "Total loss:  -2.5941 | PDE Loss:  -3.1634 | Function Loss:  -3.7306\n",
      "Total loss:  -2.5945 | PDE Loss:  -3.1631 | Function Loss:  -3.7312\n",
      "Total loss:  -2.5948 | PDE Loss:  -3.1626 | Function Loss:  -3.7317\n",
      "Total loss:  -2.595 | PDE Loss:  -3.1625 | Function Loss:  -3.7321\n",
      "Total loss:  -2.5952 | PDE Loss:  -3.1619 | Function Loss:  -3.7326\n",
      "Total loss:  -2.5953 | PDE Loss:  -3.1617 | Function Loss:  -3.7328\n",
      "Total loss:  -2.5955 | PDE Loss:  -3.1614 | Function Loss:  -3.7331\n",
      "Total loss:  -2.5957 | PDE Loss:  -3.1608 | Function Loss:  -3.7337\n",
      "Total loss:  -2.5961 | PDE Loss:  -3.1601 | Function Loss:  -3.7345\n",
      "Total loss:  -2.5964 | PDE Loss:  -3.1597 | Function Loss:  -3.7351\n",
      "Total loss:  -2.5968 | PDE Loss:  -3.1591 | Function Loss:  -3.7359\n",
      "Total loss:  -2.5972 | PDE Loss:  -3.1594 | Function Loss:  -3.7363\n",
      "Total loss:  -2.5976 | PDE Loss:  -3.1587 | Function Loss:  -3.7371\n",
      "Total loss:  -2.5979 | PDE Loss:  -3.1589 | Function Loss:  -3.7375\n",
      "Total loss:  -2.5982 | PDE Loss:  -3.1594 | Function Loss:  -3.7376\n",
      "Total loss:  -2.5986 | PDE Loss:  -3.1612 | Function Loss:  -3.7376\n",
      "Total loss:  -2.5991 | PDE Loss:  -3.1628 | Function Loss:  -3.7376\n",
      "Total loss:  -2.5996 | PDE Loss:  -3.1641 | Function Loss:  -3.7378\n",
      "Total loss:  -2.6001 | PDE Loss:  -3.1656 | Function Loss:  -3.7379\n",
      "Total loss:  -2.6008 | PDE Loss:  -3.1651 | Function Loss:  -3.739\n",
      "Total loss:  -2.6015 | PDE Loss:  -3.1693 | Function Loss:  -3.7384\n",
      "Total loss:  -2.6019 | PDE Loss:  -3.1696 | Function Loss:  -3.7389\n",
      "Total loss:  -2.6023 | PDE Loss:  -3.1705 | Function Loss:  -3.7392\n",
      "Total loss:  -2.6026 | PDE Loss:  -3.171 | Function Loss:  -3.7393\n",
      "Total loss:  -2.6027 | PDE Loss:  -3.1716 | Function Loss:  -3.7393\n",
      "Total loss:  -2.6029 | PDE Loss:  -3.1722 | Function Loss:  -3.7393\n",
      "Total loss:  -2.603 | PDE Loss:  -3.1727 | Function Loss:  -3.7393\n",
      "Total loss:  -2.603 | PDE Loss:  -3.1735 | Function Loss:  -3.739\n",
      "Total loss:  -2.6033 | PDE Loss:  -3.174 | Function Loss:  -3.7392\n",
      "Total loss:  -2.6035 | PDE Loss:  -3.1741 | Function Loss:  -3.7394\n",
      "Total loss:  -2.6036 | PDE Loss:  -3.1745 | Function Loss:  -3.7395\n",
      "Total loss:  -2.6038 | PDE Loss:  -3.1744 | Function Loss:  -3.7397\n",
      "Total loss:  -2.6039 | PDE Loss:  -3.1746 | Function Loss:  -3.7398\n",
      "Total loss:  -2.6041 | PDE Loss:  -3.1745 | Function Loss:  -3.7401\n",
      "Total loss:  -2.6042 | PDE Loss:  -3.1747 | Function Loss:  -3.7403\n",
      "Total loss:  -2.6045 | PDE Loss:  -3.1749 | Function Loss:  -3.7406\n",
      "Total loss:  -2.6048 | PDE Loss:  -3.1752 | Function Loss:  -3.7408\n",
      "Total loss:  -2.6051 | PDE Loss:  -3.1759 | Function Loss:  -3.741\n",
      "Total loss:  -2.6054 | PDE Loss:  -3.1769 | Function Loss:  -3.741\n",
      "Total loss:  -2.6056 | PDE Loss:  -3.178 | Function Loss:  -3.7409\n",
      "Total loss:  -2.6059 | PDE Loss:  -3.1794 | Function Loss:  -3.7407\n",
      "Total loss:  -2.6062 | PDE Loss:  -3.181 | Function Loss:  -3.7406\n",
      "Total loss:  -2.6065 | PDE Loss:  -3.1834 | Function Loss:  -3.7402\n",
      "Total loss:  -2.6068 | PDE Loss:  -3.185 | Function Loss:  -3.7401\n",
      "Total loss:  -2.6072 | PDE Loss:  -3.1868 | Function Loss:  -3.7399\n",
      "Total loss:  -2.6075 | PDE Loss:  -3.1879 | Function Loss:  -3.7399\n",
      "Total loss:  -2.6078 | PDE Loss:  -3.1884 | Function Loss:  -3.7401\n",
      "Total loss:  -2.6079 | PDE Loss:  -3.1884 | Function Loss:  -3.7403\n",
      "Total loss:  -2.6081 | PDE Loss:  -3.1879 | Function Loss:  -3.7408\n",
      "Total loss:  -2.6084 | PDE Loss:  -3.1872 | Function Loss:  -3.7414\n",
      "Total loss:  -2.6088 | PDE Loss:  -3.1864 | Function Loss:  -3.7422\n",
      "Total loss:  -2.6093 | PDE Loss:  -3.1853 | Function Loss:  -3.7433\n",
      "Total loss:  -2.6098 | PDE Loss:  -3.1844 | Function Loss:  -3.7444\n",
      "Total loss:  -2.6105 | PDE Loss:  -3.1839 | Function Loss:  -3.7454\n",
      "Total loss:  -2.6112 | PDE Loss:  -3.1833 | Function Loss:  -3.7465\n",
      "Total loss:  -2.612 | PDE Loss:  -3.1847 | Function Loss:  -3.7472\n",
      "Total loss:  -2.613 | PDE Loss:  -3.1854 | Function Loss:  -3.7483\n",
      "Total loss:  -2.6141 | PDE Loss:  -3.1878 | Function Loss:  -3.7489\n",
      "Total loss:  -2.6151 | PDE Loss:  -3.1903 | Function Loss:  -3.7493\n",
      "Total loss:  -2.616 | PDE Loss:  -3.1955 | Function Loss:  -3.7488\n",
      "Total loss:  -2.6171 | PDE Loss:  -3.2011 | Function Loss:  -3.7482\n",
      "Total loss:  -2.618 | PDE Loss:  -3.208 | Function Loss:  -3.747\n",
      "Total loss:  -2.6186 | PDE Loss:  -3.2128 | Function Loss:  -3.7462\n",
      "Total loss:  -2.6192 | PDE Loss:  -3.2166 | Function Loss:  -3.7458\n",
      "Total loss:  -2.6201 | PDE Loss:  -3.2198 | Function Loss:  -3.7458\n",
      "Total loss:  -2.6212 | PDE Loss:  -3.2249 | Function Loss:  -3.7455\n",
      "Total loss:  -2.622 | PDE Loss:  -3.2266 | Function Loss:  -3.7461\n",
      "Total loss:  -2.6228 | PDE Loss:  -3.2271 | Function Loss:  -3.747\n",
      "Total loss:  -2.6234 | PDE Loss:  -3.2278 | Function Loss:  -3.7476\n",
      "Total loss:  -2.6238 | PDE Loss:  -3.2281 | Function Loss:  -3.748\n",
      "Total loss:  -2.6242 | PDE Loss:  -3.2278 | Function Loss:  -3.7487\n",
      "Total loss:  -2.6246 | PDE Loss:  -3.229 | Function Loss:  -3.7487\n",
      "Total loss:  -2.625 | PDE Loss:  -3.2303 | Function Loss:  -3.7488\n",
      "Total loss:  -2.6254 | PDE Loss:  -3.2324 | Function Loss:  -3.7487\n",
      "Total loss:  -2.6258 | PDE Loss:  -3.2346 | Function Loss:  -3.7485\n",
      "Total loss:  -2.6262 | PDE Loss:  -3.2366 | Function Loss:  -3.7484\n",
      "Total loss:  -2.6266 | PDE Loss:  -3.2386 | Function Loss:  -3.7482\n",
      "Total loss:  -2.627 | PDE Loss:  -3.2407 | Function Loss:  -3.7481\n",
      "Total loss:  -2.6275 | PDE Loss:  -3.2416 | Function Loss:  -3.7485\n",
      "Total loss:  -2.6279 | PDE Loss:  -3.2421 | Function Loss:  -3.7489\n",
      "Total loss:  -2.6285 | PDE Loss:  -3.2421 | Function Loss:  -3.7496\n",
      "Total loss:  -2.629 | PDE Loss:  -3.2412 | Function Loss:  -3.7506\n",
      "Total loss:  -2.6294 | PDE Loss:  -3.241 | Function Loss:  -3.7512\n",
      "Total loss:  -2.6299 | PDE Loss:  -3.2412 | Function Loss:  -3.7517\n",
      "Total loss:  -2.6304 | PDE Loss:  -3.242 | Function Loss:  -3.7521\n",
      "Total loss:  -2.6308 | PDE Loss:  -3.2431 | Function Loss:  -3.7523\n",
      "Total loss:  -2.6311 | PDE Loss:  -3.2447 | Function Loss:  -3.7523\n",
      "Total loss:  -2.6314 | PDE Loss:  -3.2459 | Function Loss:  -3.7523\n",
      "Total loss:  -2.6317 | PDE Loss:  -3.2471 | Function Loss:  -3.7523\n",
      "Total loss:  -2.632 | PDE Loss:  -3.2482 | Function Loss:  -3.7523\n",
      "Total loss:  -2.6322 | PDE Loss:  -3.2487 | Function Loss:  -3.7525\n",
      "Total loss:  -2.6325 | PDE Loss:  -3.249 | Function Loss:  -3.7528\n",
      "Total loss:  -2.6327 | PDE Loss:  -3.248 | Function Loss:  -3.7534\n",
      "Total loss:  -2.633 | PDE Loss:  -3.2474 | Function Loss:  -3.7539\n",
      "Total loss:  -2.6331 | PDE Loss:  -3.2472 | Function Loss:  -3.7541\n",
      "Total loss:  -2.6335 | PDE Loss:  -3.2466 | Function Loss:  -3.7548\n",
      "Total loss:  -2.6338 | PDE Loss:  -3.2462 | Function Loss:  -3.7553\n",
      "Total loss:  -2.634 | PDE Loss:  -3.2463 | Function Loss:  -3.7556\n",
      "Total loss:  -2.6341 | PDE Loss:  -3.2458 | Function Loss:  -3.7559\n",
      "Total loss:  -2.6342 | PDE Loss:  -3.2463 | Function Loss:  -3.7559\n",
      "Total loss:  -2.6344 | PDE Loss:  -3.2471 | Function Loss:  -3.7558\n",
      "Total loss:  -2.6346 | PDE Loss:  -3.2484 | Function Loss:  -3.7556\n",
      "Total loss:  -2.6348 | PDE Loss:  -3.2502 | Function Loss:  -3.7553\n",
      "Total loss:  -2.6349 | PDE Loss:  -3.2516 | Function Loss:  -3.7551\n",
      "Total loss:  -2.6351 | PDE Loss:  -3.2528 | Function Loss:  -3.755\n",
      "Total loss:  -2.6353 | PDE Loss:  -3.2529 | Function Loss:  -3.7551\n",
      "Total loss:  -2.6356 | PDE Loss:  -3.2578 | Function Loss:  -3.754\n",
      "Total loss:  -2.6358 | PDE Loss:  -3.2562 | Function Loss:  -3.7548\n",
      "Total loss:  -2.6361 | PDE Loss:  -3.2556 | Function Loss:  -3.7554\n",
      "Total loss:  -2.6367 | PDE Loss:  -3.2538 | Function Loss:  -3.7567\n",
      "Total loss:  -2.637 | PDE Loss:  -3.254 | Function Loss:  -3.7571\n",
      "Total loss:  -2.6372 | PDE Loss:  -3.2543 | Function Loss:  -3.7573\n",
      "Total loss:  -2.6374 | PDE Loss:  -3.2548 | Function Loss:  -3.7574\n",
      "Total loss:  -2.6376 | PDE Loss:  -3.2558 | Function Loss:  -3.7573\n",
      "Total loss:  -2.6378 | PDE Loss:  -3.2559 | Function Loss:  -3.7575\n",
      "Total loss:  -2.6378 | PDE Loss:  -3.2564 | Function Loss:  -3.7574\n",
      "Total loss:  -2.6379 | PDE Loss:  -3.2565 | Function Loss:  -3.7575\n",
      "Total loss:  -2.638 | PDE Loss:  -3.2565 | Function Loss:  -3.7576\n",
      "Total loss:  -2.6381 | PDE Loss:  -3.2563 | Function Loss:  -3.7577\n",
      "Total loss:  -2.6381 | PDE Loss:  -3.2559 | Function Loss:  -3.758\n",
      "Total loss:  -2.6382 | PDE Loss:  -3.2554 | Function Loss:  -3.7582\n",
      "Total loss:  -2.6383 | PDE Loss:  -3.2546 | Function Loss:  -3.7586\n",
      "Total loss:  -2.6384 | PDE Loss:  -3.2539 | Function Loss:  -3.7589\n",
      "Total loss:  -2.6385 | PDE Loss:  -3.253 | Function Loss:  -3.7593\n",
      "Total loss:  -2.6385 | PDE Loss:  -3.2524 | Function Loss:  -3.7596\n",
      "Total loss:  -2.6386 | PDE Loss:  -3.2519 | Function Loss:  -3.7599\n",
      "Total loss:  -2.6387 | PDE Loss:  -3.2514 | Function Loss:  -3.7602\n",
      "Total loss:  -2.6388 | PDE Loss:  -3.2513 | Function Loss:  -3.7603\n",
      "Total loss:  -2.6389 | PDE Loss:  -3.2512 | Function Loss:  -3.7604\n",
      "Total loss:  -2.639 | PDE Loss:  -3.2517 | Function Loss:  -3.7605\n",
      "Total loss:  -2.6391 | PDE Loss:  -3.252 | Function Loss:  -3.7605\n",
      "Total loss:  -2.6392 | PDE Loss:  -3.2531 | Function Loss:  -3.7603\n",
      "Total loss:  -2.6394 | PDE Loss:  -3.2537 | Function Loss:  -3.7604\n",
      "Total loss:  -2.6396 | PDE Loss:  -3.2534 | Function Loss:  -3.7607\n",
      "Total loss:  -2.6398 | PDE Loss:  -3.2531 | Function Loss:  -3.7611\n",
      "Total loss:  -2.6401 | PDE Loss:  -3.2527 | Function Loss:  -3.7616\n",
      "Total loss:  -2.6404 | PDE Loss:  -3.2524 | Function Loss:  -3.7621\n",
      "Total loss:  -2.6407 | PDE Loss:  -3.2522 | Function Loss:  -3.7625\n",
      "Total loss:  -2.6409 | PDE Loss:  -3.2522 | Function Loss:  -3.7628\n",
      "Total loss:  -2.6412 | PDE Loss:  -3.2535 | Function Loss:  -3.7628\n",
      "Total loss:  -2.6415 | PDE Loss:  -3.2533 | Function Loss:  -3.7633\n",
      "Total loss:  -2.6419 | PDE Loss:  -3.2564 | Function Loss:  -3.7627\n",
      "Total loss:  -2.6421 | PDE Loss:  -3.257 | Function Loss:  -3.7629\n",
      "Total loss:  -2.6426 | PDE Loss:  -3.2584 | Function Loss:  -3.7631\n",
      "Total loss:  -2.6431 | PDE Loss:  -3.2601 | Function Loss:  -3.7631\n",
      "Total loss:  -2.6435 | PDE Loss:  -3.2616 | Function Loss:  -3.7632\n",
      "Total loss:  -2.6439 | PDE Loss:  -3.2627 | Function Loss:  -3.7634\n",
      "Total loss:  -2.6443 | PDE Loss:  -3.2639 | Function Loss:  -3.7636\n",
      "Total loss:  -2.645 | PDE Loss:  -3.2652 | Function Loss:  -3.764\n",
      "Total loss:  -2.6456 | PDE Loss:  -3.2664 | Function Loss:  -3.7645\n",
      "Total loss:  -2.6463 | PDE Loss:  -3.2667 | Function Loss:  -3.7653\n",
      "Total loss:  -2.6468 | PDE Loss:  -3.2668 | Function Loss:  -3.7659\n",
      "Total loss:  -2.6472 | PDE Loss:  -3.2665 | Function Loss:  -3.7665\n",
      "Total loss:  -2.6476 | PDE Loss:  -3.2664 | Function Loss:  -3.7671\n",
      "Total loss:  -2.6481 | PDE Loss:  -3.2665 | Function Loss:  -3.7678\n",
      "Total loss:  -2.6486 | PDE Loss:  -3.2671 | Function Loss:  -3.7682\n",
      "Total loss:  -2.6493 | PDE Loss:  -3.2683 | Function Loss:  -3.7687\n",
      "Total loss:  -2.6501 | PDE Loss:  -3.2701 | Function Loss:  -3.7692\n",
      "Total loss:  -2.651 | PDE Loss:  -3.2728 | Function Loss:  -3.7696\n",
      "Total loss:  -2.6519 | PDE Loss:  -3.2753 | Function Loss:  -3.7699\n",
      "Total loss:  -2.6527 | PDE Loss:  -3.2774 | Function Loss:  -3.7703\n",
      "Total loss:  -2.6534 | PDE Loss:  -3.2797 | Function Loss:  -3.7706\n",
      "Total loss:  -2.654 | PDE Loss:  -3.281 | Function Loss:  -3.771\n",
      "Total loss:  -2.6544 | PDE Loss:  -3.2823 | Function Loss:  -3.771\n",
      "Total loss:  -2.6546 | PDE Loss:  -3.2829 | Function Loss:  -3.7712\n",
      "Total loss:  -2.655 | PDE Loss:  -3.2833 | Function Loss:  -3.7715\n",
      "Total loss:  -2.6555 | PDE Loss:  -3.284 | Function Loss:  -3.7719\n",
      "Total loss:  -2.656 | PDE Loss:  -3.2838 | Function Loss:  -3.7727\n",
      "Total loss:  -2.6566 | PDE Loss:  -3.2842 | Function Loss:  -3.7734\n",
      "Total loss:  -2.6571 | PDE Loss:  -3.2844 | Function Loss:  -3.774\n",
      "Total loss:  -2.6578 | PDE Loss:  -3.2852 | Function Loss:  -3.7746\n",
      "Total loss:  -2.6585 | PDE Loss:  -3.2869 | Function Loss:  -3.775\n",
      "Total loss:  -2.6591 | PDE Loss:  -3.2883 | Function Loss:  -3.7754\n",
      "Total loss:  -2.6596 | PDE Loss:  -3.2902 | Function Loss:  -3.7754\n",
      "Total loss:  -2.6599 | PDE Loss:  -3.2924 | Function Loss:  -3.7751\n",
      "Total loss:  -2.6602 | PDE Loss:  -3.2936 | Function Loss:  -3.7751\n",
      "Total loss:  -2.6605 | PDE Loss:  -3.2958 | Function Loss:  -3.7749\n",
      "Total loss:  -2.6608 | PDE Loss:  -3.2976 | Function Loss:  -3.7747\n",
      "Total loss:  -2.661 | PDE Loss:  -3.2995 | Function Loss:  -3.7744\n",
      "Total loss:  -2.6611 | PDE Loss:  -3.3006 | Function Loss:  -3.7742\n",
      "Total loss:  -2.6612 | PDE Loss:  -3.3013 | Function Loss:  -3.7741\n",
      "Total loss:  -2.6613 | PDE Loss:  -3.302 | Function Loss:  -3.774\n",
      "Total loss:  -2.6614 | PDE Loss:  -3.3026 | Function Loss:  -3.774\n",
      "Total loss:  -2.6615 | PDE Loss:  -3.3034 | Function Loss:  -3.7739\n",
      "Total loss:  -2.6616 | PDE Loss:  -3.3042 | Function Loss:  -3.7738\n",
      "Total loss:  -2.6617 | PDE Loss:  -3.3038 | Function Loss:  -3.7741\n",
      "Total loss:  -2.6619 | PDE Loss:  -3.3046 | Function Loss:  -3.7741\n",
      "Total loss:  -2.662 | PDE Loss:  -3.305 | Function Loss:  -3.7741\n",
      "Total loss:  -2.6622 | PDE Loss:  -3.3048 | Function Loss:  -3.7744\n",
      "Total loss:  -2.6624 | PDE Loss:  -3.3048 | Function Loss:  -3.7747\n",
      "Total loss:  -2.6626 | PDE Loss:  -3.3049 | Function Loss:  -3.7749\n",
      "Total loss:  -2.6628 | PDE Loss:  -3.3049 | Function Loss:  -3.7752\n",
      "Total loss:  -2.663 | PDE Loss:  -3.3055 | Function Loss:  -3.7753\n",
      "Total loss:  -2.6632 | PDE Loss:  -3.3059 | Function Loss:  -3.7754\n",
      "Total loss:  -2.6634 | PDE Loss:  -3.3066 | Function Loss:  -3.7754\n",
      "Total loss:  -2.6636 | PDE Loss:  -3.3078 | Function Loss:  -3.7753\n",
      "Total loss:  -2.6637 | PDE Loss:  -3.309 | Function Loss:  -3.7751\n",
      "Total loss:  -2.6638 | PDE Loss:  -3.3102 | Function Loss:  -3.775\n",
      "Total loss:  -2.6639 | PDE Loss:  -3.3112 | Function Loss:  -3.7748\n",
      "Total loss:  -2.664 | PDE Loss:  -3.312 | Function Loss:  -3.7746\n",
      "Total loss:  -2.6641 | PDE Loss:  -3.3127 | Function Loss:  -3.7745\n",
      "Total loss:  -2.6642 | PDE Loss:  -3.3136 | Function Loss:  -3.7744\n",
      "Total loss:  -2.6643 | PDE Loss:  -3.3143 | Function Loss:  -3.7744\n",
      "Total loss:  -2.6645 | PDE Loss:  -3.3153 | Function Loss:  -3.7744\n",
      "Total loss:  -2.6648 | PDE Loss:  -3.3163 | Function Loss:  -3.7744\n",
      "Total loss:  -2.6651 | PDE Loss:  -3.3176 | Function Loss:  -3.7744\n",
      "Total loss:  -2.6655 | PDE Loss:  -3.3185 | Function Loss:  -3.7747\n",
      "Total loss:  -2.6649 | PDE Loss:  -3.3189 | Function Loss:  -3.7738\n",
      "Total loss:  -2.6656 | PDE Loss:  -3.3196 | Function Loss:  -3.7745\n",
      "Total loss:  -2.666 | PDE Loss:  -3.3202 | Function Loss:  -3.7748\n",
      "Total loss:  -2.6664 | PDE Loss:  -3.3204 | Function Loss:  -3.7753\n",
      "Total loss:  -2.6667 | PDE Loss:  -3.3205 | Function Loss:  -3.7756\n",
      "Total loss:  -2.6669 | PDE Loss:  -3.321 | Function Loss:  -3.7758\n",
      "Total loss:  -2.6672 | PDE Loss:  -3.321 | Function Loss:  -3.7762\n",
      "Total loss:  -2.6674 | PDE Loss:  -3.3211 | Function Loss:  -3.7764\n",
      "Total loss:  -2.6677 | PDE Loss:  -3.3221 | Function Loss:  -3.7764\n",
      "Total loss:  -2.6679 | PDE Loss:  -3.3229 | Function Loss:  -3.7766\n",
      "Total loss:  -2.6682 | PDE Loss:  -3.3238 | Function Loss:  -3.7767\n",
      "Total loss:  -2.6684 | PDE Loss:  -3.3244 | Function Loss:  -3.7768\n",
      "Total loss:  -2.6687 | PDE Loss:  -3.325 | Function Loss:  -3.7769\n",
      "Total loss:  -2.6689 | PDE Loss:  -3.3254 | Function Loss:  -3.7771\n",
      "Total loss:  -2.6691 | PDE Loss:  -3.3257 | Function Loss:  -3.7773\n",
      "Total loss:  -2.6693 | PDE Loss:  -3.3257 | Function Loss:  -3.7776\n",
      "Total loss:  -2.6696 | PDE Loss:  -3.3256 | Function Loss:  -3.7779\n",
      "Total loss:  -2.6698 | PDE Loss:  -3.3252 | Function Loss:  -3.7784\n",
      "Total loss:  -2.6701 | PDE Loss:  -3.325 | Function Loss:  -3.7787\n",
      "Total loss:  -2.6703 | PDE Loss:  -3.3234 | Function Loss:  -3.7795\n",
      "Total loss:  -2.6705 | PDE Loss:  -3.3237 | Function Loss:  -3.7796\n",
      "Total loss:  -2.6707 | PDE Loss:  -3.3241 | Function Loss:  -3.7798\n",
      "Total loss:  -2.6711 | PDE Loss:  -3.3247 | Function Loss:  -3.7801\n",
      "Total loss:  -2.6714 | PDE Loss:  -3.3253 | Function Loss:  -3.7803\n",
      "Total loss:  -2.6717 | PDE Loss:  -3.3259 | Function Loss:  -3.7806\n",
      "Total loss:  -2.672 | PDE Loss:  -3.3268 | Function Loss:  -3.7807\n",
      "Total loss:  -2.6723 | PDE Loss:  -3.3277 | Function Loss:  -3.7808\n",
      "Total loss:  -2.6727 | PDE Loss:  -3.329 | Function Loss:  -3.7809\n",
      "Total loss:  -2.6719 | PDE Loss:  -3.3252 | Function Loss:  -3.7809\n",
      "Total loss:  -2.6728 | PDE Loss:  -3.3288 | Function Loss:  -3.7811\n",
      "Total loss:  -2.6732 | PDE Loss:  -3.3308 | Function Loss:  -3.7811\n",
      "Total loss:  -2.6737 | PDE Loss:  -3.333 | Function Loss:  -3.7811\n",
      "Total loss:  -2.6741 | PDE Loss:  -3.3353 | Function Loss:  -3.781\n",
      "Total loss:  -2.6746 | PDE Loss:  -3.3376 | Function Loss:  -3.781\n",
      "Total loss:  -2.6749 | PDE Loss:  -3.3391 | Function Loss:  -3.781\n",
      "Total loss:  -2.6753 | PDE Loss:  -3.3402 | Function Loss:  -3.7811\n",
      "Total loss:  -2.6756 | PDE Loss:  -3.341 | Function Loss:  -3.7813\n",
      "Total loss:  -2.6758 | PDE Loss:  -3.3417 | Function Loss:  -3.7815\n",
      "Total loss:  -2.6761 | PDE Loss:  -3.3421 | Function Loss:  -3.7817\n",
      "Total loss:  -2.6764 | PDE Loss:  -3.3426 | Function Loss:  -3.7819\n",
      "Total loss:  -2.6763 | PDE Loss:  -3.3416 | Function Loss:  -3.782\n",
      "Total loss:  -2.6765 | PDE Loss:  -3.3428 | Function Loss:  -3.782\n",
      "Total loss:  -2.6769 | PDE Loss:  -3.3439 | Function Loss:  -3.7821\n",
      "Total loss:  -2.6772 | PDE Loss:  -3.3449 | Function Loss:  -3.7822\n",
      "Total loss:  -2.6775 | PDE Loss:  -3.3441 | Function Loss:  -3.7829\n",
      "Total loss:  -2.6778 | PDE Loss:  -3.3457 | Function Loss:  -3.7829\n",
      "Total loss:  -2.6781 | PDE Loss:  -3.3463 | Function Loss:  -3.783\n",
      "Total loss:  -2.6783 | PDE Loss:  -3.3482 | Function Loss:  -3.7828\n",
      "Total loss:  -2.6785 | PDE Loss:  -3.3488 | Function Loss:  -3.7829\n",
      "Total loss:  -2.6786 | PDE Loss:  -3.3496 | Function Loss:  -3.7828\n",
      "Total loss:  -2.6788 | PDE Loss:  -3.3507 | Function Loss:  -3.7827\n",
      "Total loss:  -2.6789 | PDE Loss:  -3.3517 | Function Loss:  -3.7826\n",
      "Total loss:  -2.679 | PDE Loss:  -3.3527 | Function Loss:  -3.7825\n",
      "Total loss:  -2.6791 | PDE Loss:  -3.3537 | Function Loss:  -3.7824\n",
      "Total loss:  -2.6793 | PDE Loss:  -3.3546 | Function Loss:  -3.7823\n",
      "Total loss:  -2.6794 | PDE Loss:  -3.3553 | Function Loss:  -3.7823\n",
      "Total loss:  -2.6796 | PDE Loss:  -3.3557 | Function Loss:  -3.7824\n",
      "Total loss:  -2.6797 | PDE Loss:  -3.3561 | Function Loss:  -3.7825\n",
      "Total loss:  -2.6799 | PDE Loss:  -3.3557 | Function Loss:  -3.7829\n",
      "Total loss:  -2.6801 | PDE Loss:  -3.3555 | Function Loss:  -3.7832\n",
      "Total loss:  -2.6803 | PDE Loss:  -3.3545 | Function Loss:  -3.7837\n",
      "Total loss:  -2.6805 | PDE Loss:  -3.3541 | Function Loss:  -3.784\n",
      "Total loss:  -2.6806 | PDE Loss:  -3.3519 | Function Loss:  -3.7848\n",
      "Total loss:  -2.6808 | PDE Loss:  -3.3508 | Function Loss:  -3.7852\n",
      "Total loss:  -2.6809 | PDE Loss:  -3.3489 | Function Loss:  -3.7859\n",
      "Total loss:  -2.681 | PDE Loss:  -3.348 | Function Loss:  -3.7863\n",
      "Total loss:  -2.6811 | PDE Loss:  -3.3468 | Function Loss:  -3.7867\n",
      "Total loss:  -2.6812 | PDE Loss:  -3.346 | Function Loss:  -3.7871\n",
      "Total loss:  -2.6813 | PDE Loss:  -3.3452 | Function Loss:  -3.7874\n",
      "Total loss:  -2.6814 | PDE Loss:  -3.3446 | Function Loss:  -3.7877\n",
      "Total loss:  -2.6816 | PDE Loss:  -3.3438 | Function Loss:  -3.7882\n",
      "Total loss:  -2.6817 | PDE Loss:  -3.343 | Function Loss:  -3.7886\n",
      "Total loss:  -2.682 | PDE Loss:  -3.3423 | Function Loss:  -3.7891\n",
      "Total loss:  -2.6822 | PDE Loss:  -3.3408 | Function Loss:  -3.7898\n",
      "Total loss:  -2.6825 | PDE Loss:  -3.341 | Function Loss:  -3.7901\n",
      "Total loss:  -2.6827 | PDE Loss:  -3.3405 | Function Loss:  -3.7905\n",
      "Total loss:  -2.683 | PDE Loss:  -3.3405 | Function Loss:  -3.7909\n",
      "Total loss:  -2.6834 | PDE Loss:  -3.3409 | Function Loss:  -3.7913\n",
      "Total loss:  -2.6837 | PDE Loss:  -3.3414 | Function Loss:  -3.7916\n",
      "Total loss:  -2.6841 | PDE Loss:  -3.3419 | Function Loss:  -3.7919\n",
      "Total loss:  -2.6845 | PDE Loss:  -3.343 | Function Loss:  -3.7921\n",
      "Total loss:  -2.6848 | PDE Loss:  -3.3434 | Function Loss:  -3.7924\n",
      "Total loss:  -2.6852 | PDE Loss:  -3.3441 | Function Loss:  -3.7928\n",
      "Total loss:  -2.6856 | PDE Loss:  -3.3442 | Function Loss:  -3.7932\n",
      "Total loss:  -2.6859 | PDE Loss:  -3.3441 | Function Loss:  -3.7936\n",
      "Total loss:  -2.6861 | PDE Loss:  -3.3437 | Function Loss:  -3.794\n",
      "Total loss:  -2.6862 | PDE Loss:  -3.3433 | Function Loss:  -3.7942\n",
      "Total loss:  -2.6863 | PDE Loss:  -3.343 | Function Loss:  -3.7945\n",
      "Total loss:  -2.6865 | PDE Loss:  -3.3427 | Function Loss:  -3.7948\n",
      "Total loss:  -2.6867 | PDE Loss:  -3.3425 | Function Loss:  -3.7951\n",
      "Total loss:  -2.6869 | PDE Loss:  -3.3424 | Function Loss:  -3.7954\n",
      "Total loss:  -2.687 | PDE Loss:  -3.3424 | Function Loss:  -3.7956\n",
      "Total loss:  -2.6872 | PDE Loss:  -3.3428 | Function Loss:  -3.7957\n",
      "Total loss:  -2.6875 | PDE Loss:  -3.3436 | Function Loss:  -3.7958\n",
      "Total loss:  -2.6878 | PDE Loss:  -3.3451 | Function Loss:  -3.7958\n",
      "Total loss:  -2.6882 | PDE Loss:  -3.3469 | Function Loss:  -3.7958\n",
      "Total loss:  -2.6886 | PDE Loss:  -3.3494 | Function Loss:  -3.7956\n",
      "Total loss:  -2.6889 | PDE Loss:  -3.3526 | Function Loss:  -3.7951\n",
      "Total loss:  -2.6893 | PDE Loss:  -3.3544 | Function Loss:  -3.7951\n",
      "Total loss:  -2.6897 | PDE Loss:  -3.3569 | Function Loss:  -3.795\n",
      "Total loss:  -2.6902 | PDE Loss:  -3.3594 | Function Loss:  -3.7948\n",
      "Total loss:  -2.6905 | PDE Loss:  -3.361 | Function Loss:  -3.7948\n",
      "Total loss:  -2.6907 | PDE Loss:  -3.3619 | Function Loss:  -3.7948\n",
      "Total loss:  -2.691 | PDE Loss:  -3.3628 | Function Loss:  -3.795\n",
      "Total loss:  -2.6914 | PDE Loss:  -3.3636 | Function Loss:  -3.7952\n",
      "Total loss:  -2.6917 | PDE Loss:  -3.3646 | Function Loss:  -3.7954\n",
      "Total loss:  -2.692 | PDE Loss:  -3.3651 | Function Loss:  -3.7957\n",
      "Total loss:  -2.6923 | PDE Loss:  -3.366 | Function Loss:  -3.7957\n",
      "Total loss:  -2.6925 | PDE Loss:  -3.3664 | Function Loss:  -3.7959\n",
      "Total loss:  -2.6927 | PDE Loss:  -3.3662 | Function Loss:  -3.7962\n",
      "Total loss:  -2.6929 | PDE Loss:  -3.3669 | Function Loss:  -3.7963\n",
      "Total loss:  -2.6932 | PDE Loss:  -3.3669 | Function Loss:  -3.7967\n",
      "Total loss:  -2.6933 | PDE Loss:  -3.3686 | Function Loss:  -3.7964\n",
      "Total loss:  -2.6936 | PDE Loss:  -3.3687 | Function Loss:  -3.7966\n",
      "Total loss:  -2.6939 | PDE Loss:  -3.369 | Function Loss:  -3.7969\n",
      "Total loss:  -2.6941 | PDE Loss:  -3.369 | Function Loss:  -3.7973\n",
      "Total loss:  -2.6944 | PDE Loss:  -3.369 | Function Loss:  -3.7976\n",
      "Total loss:  -2.6946 | PDE Loss:  -3.3688 | Function Loss:  -3.7979\n",
      "Total loss:  -2.6949 | PDE Loss:  -3.3693 | Function Loss:  -3.7982\n",
      "Total loss:  -2.6952 | PDE Loss:  -3.3695 | Function Loss:  -3.7985\n",
      "Total loss:  -2.6954 | PDE Loss:  -3.3698 | Function Loss:  -3.7986\n",
      "Total loss:  -2.6955 | PDE Loss:  -3.3701 | Function Loss:  -3.7988\n",
      "Total loss:  -2.6957 | PDE Loss:  -3.3708 | Function Loss:  -3.7987\n",
      "Total loss:  -2.6958 | PDE Loss:  -3.3714 | Function Loss:  -3.7987\n",
      "Total loss:  -2.6959 | PDE Loss:  -3.3724 | Function Loss:  -3.7986\n",
      "Total loss:  -2.6961 | PDE Loss:  -3.3733 | Function Loss:  -3.7986\n",
      "Total loss:  -2.6963 | PDE Loss:  -3.3752 | Function Loss:  -3.7983\n",
      "Total loss:  -2.6964 | PDE Loss:  -3.3751 | Function Loss:  -3.7986\n",
      "Total loss:  -2.6962 | PDE Loss:  -3.3804 | Function Loss:  -3.7968\n",
      "Total loss:  -2.6966 | PDE Loss:  -3.3778 | Function Loss:  -3.7981\n",
      "Total loss:  -2.6967 | PDE Loss:  -3.378 | Function Loss:  -3.7981\n",
      "Total loss:  -2.6969 | PDE Loss:  -3.3776 | Function Loss:  -3.7985\n",
      "Total loss:  -2.6971 | PDE Loss:  -3.3773 | Function Loss:  -3.7988\n",
      "Total loss:  -2.6972 | PDE Loss:  -3.3774 | Function Loss:  -3.7989\n",
      "Total loss:  -2.6973 | PDE Loss:  -3.3772 | Function Loss:  -3.7991\n",
      "Total loss:  -2.6976 | PDE Loss:  -3.3774 | Function Loss:  -3.7994\n",
      "Total loss:  -2.6978 | PDE Loss:  -3.3775 | Function Loss:  -3.7997\n",
      "Total loss:  -2.698 | PDE Loss:  -3.3776 | Function Loss:  -3.8\n",
      "Total loss:  -2.6983 | PDE Loss:  -3.3779 | Function Loss:  -3.8002\n",
      "Total loss:  -2.6984 | PDE Loss:  -3.3782 | Function Loss:  -3.8003\n",
      "Total loss:  -2.6986 | PDE Loss:  -3.3791 | Function Loss:  -3.8003\n",
      "Total loss:  -2.6988 | PDE Loss:  -3.3796 | Function Loss:  -3.8004\n",
      "Total loss:  -2.6989 | PDE Loss:  -3.3803 | Function Loss:  -3.8003\n",
      "Total loss:  -2.699 | PDE Loss:  -3.3803 | Function Loss:  -3.8005\n",
      "Total loss:  -2.6991 | PDE Loss:  -3.3802 | Function Loss:  -3.8006\n",
      "Total loss:  -2.6992 | PDE Loss:  -3.3797 | Function Loss:  -3.8009\n",
      "Total loss:  -2.6993 | PDE Loss:  -3.3792 | Function Loss:  -3.8011\n",
      "Total loss:  -2.6994 | PDE Loss:  -3.378 | Function Loss:  -3.8015\n",
      "Total loss:  -2.6994 | PDE Loss:  -3.3772 | Function Loss:  -3.8018\n",
      "Total loss:  -2.6995 | PDE Loss:  -3.3765 | Function Loss:  -3.8021\n",
      "Total loss:  -2.6996 | PDE Loss:  -3.3755 | Function Loss:  -3.8025\n",
      "Total loss:  -2.6997 | PDE Loss:  -3.3752 | Function Loss:  -3.8027\n",
      "Total loss:  -2.6998 | PDE Loss:  -3.3746 | Function Loss:  -3.8029\n",
      "Total loss:  -2.6998 | PDE Loss:  -3.3749 | Function Loss:  -3.8029\n",
      "Total loss:  -2.6999 | PDE Loss:  -3.3753 | Function Loss:  -3.8029\n",
      "Total loss:  -2.7 | PDE Loss:  -3.3763 | Function Loss:  -3.8028\n",
      "Total loss:  -2.7001 | PDE Loss:  -3.3774 | Function Loss:  -3.8026\n",
      "Total loss:  -2.7002 | PDE Loss:  -3.3785 | Function Loss:  -3.8024\n",
      "Total loss:  -2.7003 | PDE Loss:  -3.38 | Function Loss:  -3.8022\n",
      "Total loss:  -2.7004 | PDE Loss:  -3.3814 | Function Loss:  -3.802\n",
      "Total loss:  -2.7006 | PDE Loss:  -3.3828 | Function Loss:  -3.8018\n",
      "Total loss:  -2.7008 | PDE Loss:  -3.3839 | Function Loss:  -3.8018\n",
      "Total loss:  -2.701 | PDE Loss:  -3.3847 | Function Loss:  -3.8018\n",
      "Total loss:  -2.7013 | PDE Loss:  -3.3853 | Function Loss:  -3.8021\n",
      "Total loss:  -2.7017 | PDE Loss:  -3.3862 | Function Loss:  -3.8023\n",
      "Total loss:  -2.7022 | PDE Loss:  -3.3863 | Function Loss:  -3.8029\n",
      "Total loss:  -2.7027 | PDE Loss:  -3.3861 | Function Loss:  -3.8036\n",
      "Total loss:  -2.7032 | PDE Loss:  -3.3852 | Function Loss:  -3.8045\n",
      "Total loss:  -2.7036 | PDE Loss:  -3.3847 | Function Loss:  -3.8051\n",
      "Total loss:  -2.704 | PDE Loss:  -3.3838 | Function Loss:  -3.8059\n",
      "Total loss:  -2.7044 | PDE Loss:  -3.3836 | Function Loss:  -3.8064\n",
      "Total loss:  -2.7047 | PDE Loss:  -3.3836 | Function Loss:  -3.8068\n",
      "Total loss:  -2.7051 | PDE Loss:  -3.3842 | Function Loss:  -3.8071\n",
      "Total loss:  -2.7055 | PDE Loss:  -3.3856 | Function Loss:  -3.8072\n",
      "Total loss:  -2.7059 | PDE Loss:  -3.3874 | Function Loss:  -3.8073\n",
      "Total loss:  -2.7064 | PDE Loss:  -3.39 | Function Loss:  -3.8072\n",
      "Total loss:  -2.7069 | PDE Loss:  -3.3928 | Function Loss:  -3.8072\n",
      "Total loss:  -2.7074 | PDE Loss:  -3.3951 | Function Loss:  -3.8072\n",
      "Total loss:  -2.7077 | PDE Loss:  -3.3966 | Function Loss:  -3.8072\n",
      "Total loss:  -2.7079 | PDE Loss:  -3.3975 | Function Loss:  -3.8072\n",
      "Total loss:  -2.7081 | PDE Loss:  -3.3978 | Function Loss:  -3.8074\n",
      "Total loss:  -2.7083 | PDE Loss:  -3.3978 | Function Loss:  -3.8076\n",
      "Total loss:  -2.7085 | PDE Loss:  -3.3974 | Function Loss:  -3.8079\n",
      "Total loss:  -2.7088 | PDE Loss:  -3.3969 | Function Loss:  -3.8084\n",
      "Total loss:  -2.7089 | PDE Loss:  -3.3934 | Function Loss:  -3.8095\n",
      "Total loss:  -2.7093 | PDE Loss:  -3.3938 | Function Loss:  -3.8098\n",
      "Total loss:  -2.7095 | PDE Loss:  -3.3945 | Function Loss:  -3.8099\n",
      "Total loss:  -2.7097 | PDE Loss:  -3.3946 | Function Loss:  -3.8102\n",
      "Total loss:  -2.7099 | PDE Loss:  -3.3953 | Function Loss:  -3.8103\n",
      "Total loss:  -2.7102 | PDE Loss:  -3.3952 | Function Loss:  -3.8106\n",
      "Total loss:  -2.7103 | PDE Loss:  -3.3957 | Function Loss:  -3.8107\n",
      "Total loss:  -2.7104 | PDE Loss:  -3.396 | Function Loss:  -3.8108\n",
      "Total loss:  -2.7107 | PDE Loss:  -3.3972 | Function Loss:  -3.8107\n",
      "Total loss:  -2.7109 | PDE Loss:  -3.3983 | Function Loss:  -3.8108\n",
      "Total loss:  -2.7111 | PDE Loss:  -3.3997 | Function Loss:  -3.8107\n",
      "Total loss:  -2.7113 | PDE Loss:  -3.4006 | Function Loss:  -3.8107\n",
      "Total loss:  -2.7116 | PDE Loss:  -3.4013 | Function Loss:  -3.8109\n",
      "Total loss:  -2.7119 | PDE Loss:  -3.4026 | Function Loss:  -3.8109\n",
      "Total loss:  -2.7121 | PDE Loss:  -3.4 | Function Loss:  -3.8118\n",
      "Total loss:  -2.7124 | PDE Loss:  -3.4015 | Function Loss:  -3.8118\n",
      "Total loss:  -2.7128 | PDE Loss:  -3.4033 | Function Loss:  -3.8118\n",
      "Total loss:  -2.7132 | PDE Loss:  -3.4038 | Function Loss:  -3.8122\n",
      "Total loss:  -2.7136 | PDE Loss:  -3.4049 | Function Loss:  -3.8124\n",
      "Total loss:  -2.7139 | PDE Loss:  -3.4051 | Function Loss:  -3.8128\n",
      "Total loss:  -2.7143 | PDE Loss:  -3.4056 | Function Loss:  -3.8131\n",
      "Total loss:  -2.7146 | PDE Loss:  -3.4062 | Function Loss:  -3.8133\n",
      "Total loss:  -2.7148 | PDE Loss:  -3.4067 | Function Loss:  -3.8136\n",
      "Total loss:  -2.7151 | PDE Loss:  -3.4074 | Function Loss:  -3.8137\n",
      "Total loss:  -2.7153 | PDE Loss:  -3.4079 | Function Loss:  -3.8138\n",
      "Total loss:  -2.7155 | PDE Loss:  -3.4085 | Function Loss:  -3.8139\n",
      "Total loss:  -2.7156 | PDE Loss:  -3.409 | Function Loss:  -3.814\n",
      "Total loss:  -2.7159 | PDE Loss:  -3.4104 | Function Loss:  -3.8139\n",
      "Total loss:  -2.716 | PDE Loss:  -3.4107 | Function Loss:  -3.814\n",
      "Total loss:  -2.7162 | PDE Loss:  -3.4115 | Function Loss:  -3.814\n",
      "Total loss:  -2.7163 | PDE Loss:  -3.412 | Function Loss:  -3.814\n",
      "Total loss:  -2.7164 | PDE Loss:  -3.4124 | Function Loss:  -3.8141\n",
      "Total loss:  -2.7166 | PDE Loss:  -3.4126 | Function Loss:  -3.8142\n",
      "Total loss:  -2.7168 | PDE Loss:  -3.4127 | Function Loss:  -3.8144\n",
      "Total loss:  -2.7169 | PDE Loss:  -3.4124 | Function Loss:  -3.8147\n",
      "Total loss:  -2.7171 | PDE Loss:  -3.4138 | Function Loss:  -3.8145\n",
      "Total loss:  -2.7172 | PDE Loss:  -3.4132 | Function Loss:  -3.8148\n",
      "Total loss:  -2.7173 | PDE Loss:  -3.413 | Function Loss:  -3.815\n",
      "Total loss:  -2.7174 | PDE Loss:  -3.4129 | Function Loss:  -3.8152\n",
      "Total loss:  -2.7175 | PDE Loss:  -3.4128 | Function Loss:  -3.8154\n",
      "Total loss:  -2.7176 | PDE Loss:  -3.4128 | Function Loss:  -3.8155\n",
      "Total loss:  -2.7177 | PDE Loss:  -3.4132 | Function Loss:  -3.8155\n",
      "Total loss:  -2.7178 | PDE Loss:  -3.4132 | Function Loss:  -3.8156\n",
      "Total loss:  -2.718 | PDE Loss:  -3.4135 | Function Loss:  -3.8158\n",
      "Total loss:  -2.7181 | PDE Loss:  -3.4133 | Function Loss:  -3.816\n",
      "Total loss:  -2.7183 | PDE Loss:  -3.4138 | Function Loss:  -3.8161\n",
      "Total loss:  -2.7184 | PDE Loss:  -3.4137 | Function Loss:  -3.8163\n",
      "Total loss:  -2.7185 | PDE Loss:  -3.4146 | Function Loss:  -3.8161\n",
      "Total loss:  -2.7186 | PDE Loss:  -3.4152 | Function Loss:  -3.8162\n",
      "Total loss:  -2.7187 | PDE Loss:  -3.4161 | Function Loss:  -3.8161\n",
      "Total loss:  -2.7189 | PDE Loss:  -3.4177 | Function Loss:  -3.8158\n",
      "Total loss:  -2.719 | PDE Loss:  -3.4191 | Function Loss:  -3.8157\n",
      "Total loss:  -2.7192 | PDE Loss:  -3.4207 | Function Loss:  -3.8154\n",
      "Total loss:  -2.7193 | PDE Loss:  -3.4218 | Function Loss:  -3.8153\n",
      "Total loss:  -2.7193 | PDE Loss:  -3.4226 | Function Loss:  -3.8152\n",
      "Total loss:  -2.7194 | PDE Loss:  -3.4232 | Function Loss:  -3.8151\n",
      "Total loss:  -2.7195 | PDE Loss:  -3.4237 | Function Loss:  -3.8152\n",
      "Total loss:  -2.7197 | PDE Loss:  -3.424 | Function Loss:  -3.8153\n",
      "Total loss:  -2.7198 | PDE Loss:  -3.4238 | Function Loss:  -3.8155\n",
      "Total loss:  -2.72 | PDE Loss:  -3.4239 | Function Loss:  -3.8156\n",
      "Total loss:  -2.7201 | PDE Loss:  -3.4241 | Function Loss:  -3.8157\n",
      "Total loss:  -2.7202 | PDE Loss:  -3.4242 | Function Loss:  -3.8158\n",
      "Total loss:  -2.7203 | PDE Loss:  -3.4252 | Function Loss:  -3.8158\n",
      "Total loss:  -2.7205 | PDE Loss:  -3.426 | Function Loss:  -3.8158\n",
      "Total loss:  -2.7207 | PDE Loss:  -3.4265 | Function Loss:  -3.8159\n",
      "Total loss:  -2.7209 | PDE Loss:  -3.4275 | Function Loss:  -3.816\n",
      "Total loss:  -2.7211 | PDE Loss:  -3.427 | Function Loss:  -3.8163\n",
      "Total loss:  -2.7213 | PDE Loss:  -3.4272 | Function Loss:  -3.8165\n",
      "Total loss:  -2.7214 | PDE Loss:  -3.4272 | Function Loss:  -3.8167\n",
      "Total loss:  -2.7218 | PDE Loss:  -3.4272 | Function Loss:  -3.8171\n",
      "Total loss:  -2.7221 | PDE Loss:  -3.4276 | Function Loss:  -3.8174\n",
      "Total loss:  -2.7223 | PDE Loss:  -3.4279 | Function Loss:  -3.8176\n",
      "Total loss:  -2.7225 | PDE Loss:  -3.4286 | Function Loss:  -3.8176\n",
      "Total loss:  -2.7226 | PDE Loss:  -3.4294 | Function Loss:  -3.8176\n",
      "Total loss:  -2.7228 | PDE Loss:  -3.4309 | Function Loss:  -3.8175\n",
      "Total loss:  -2.7231 | PDE Loss:  -3.4324 | Function Loss:  -3.8174\n",
      "Total loss:  -2.7233 | PDE Loss:  -3.4343 | Function Loss:  -3.8173\n",
      "Total loss:  -2.7235 | PDE Loss:  -3.4361 | Function Loss:  -3.8171\n",
      "Total loss:  -2.7237 | PDE Loss:  -3.4373 | Function Loss:  -3.817\n",
      "Total loss:  -2.7239 | PDE Loss:  -3.4383 | Function Loss:  -3.817\n",
      "Total loss:  -2.724 | PDE Loss:  -3.4391 | Function Loss:  -3.817\n",
      "Total loss:  -2.7241 | PDE Loss:  -3.4394 | Function Loss:  -3.817\n",
      "Total loss:  -2.7242 | PDE Loss:  -3.4402 | Function Loss:  -3.817\n",
      "Total loss:  -2.7244 | PDE Loss:  -3.4401 | Function Loss:  -3.8172\n",
      "Total loss:  -2.7245 | PDE Loss:  -3.4421 | Function Loss:  -3.8169\n",
      "Total loss:  -2.7246 | PDE Loss:  -3.4419 | Function Loss:  -3.8171\n",
      "Total loss:  -2.7248 | PDE Loss:  -3.4416 | Function Loss:  -3.8174\n",
      "Total loss:  -2.7251 | PDE Loss:  -3.4413 | Function Loss:  -3.8178\n",
      "Total loss:  -2.7253 | PDE Loss:  -3.4409 | Function Loss:  -3.8182\n",
      "Total loss:  -2.7255 | PDE Loss:  -3.4402 | Function Loss:  -3.8186\n",
      "Total loss:  -2.7256 | PDE Loss:  -3.4393 | Function Loss:  -3.819\n",
      "Total loss:  -2.7258 | PDE Loss:  -3.4384 | Function Loss:  -3.8194\n",
      "Total loss:  -2.7259 | PDE Loss:  -3.4376 | Function Loss:  -3.8197\n",
      "Total loss:  -2.726 | PDE Loss:  -3.4369 | Function Loss:  -3.82\n",
      "Total loss:  -2.7261 | PDE Loss:  -3.4351 | Function Loss:  -3.8205\n",
      "Total loss:  -2.7262 | PDE Loss:  -3.4354 | Function Loss:  -3.8206\n",
      "Total loss:  -2.7264 | PDE Loss:  -3.4358 | Function Loss:  -3.8207\n",
      "Total loss:  -2.7266 | PDE Loss:  -3.4364 | Function Loss:  -3.8208\n",
      "Total loss:  -2.7267 | PDE Loss:  -3.4376 | Function Loss:  -3.8207\n",
      "Total loss:  -2.7269 | PDE Loss:  -3.4384 | Function Loss:  -3.8207\n",
      "Total loss:  -2.7271 | PDE Loss:  -3.4383 | Function Loss:  -3.821\n",
      "Total loss:  -2.7272 | PDE Loss:  -3.4389 | Function Loss:  -3.821\n",
      "Total loss:  -2.7273 | PDE Loss:  -3.4391 | Function Loss:  -3.8211\n",
      "Total loss:  -2.7275 | PDE Loss:  -3.4392 | Function Loss:  -3.8213\n",
      "Total loss:  -2.7276 | PDE Loss:  -3.439 | Function Loss:  -3.8215\n",
      "Total loss:  -2.7277 | PDE Loss:  -3.4387 | Function Loss:  -3.8217\n",
      "Total loss:  -2.7278 | PDE Loss:  -3.4382 | Function Loss:  -3.8219\n",
      "Total loss:  -2.7279 | PDE Loss:  -3.4379 | Function Loss:  -3.8221\n",
      "Total loss:  -2.728 | PDE Loss:  -3.4352 | Function Loss:  -3.8229\n",
      "Total loss:  -2.7281 | PDE Loss:  -3.4355 | Function Loss:  -3.8229\n",
      "Total loss:  -2.7283 | PDE Loss:  -3.436 | Function Loss:  -3.823\n",
      "Total loss:  -2.7284 | PDE Loss:  -3.4362 | Function Loss:  -3.8231\n",
      "Total loss:  -2.7285 | PDE Loss:  -3.4362 | Function Loss:  -3.8232\n",
      "Total loss:  -2.7286 | PDE Loss:  -3.4362 | Function Loss:  -3.8234\n",
      "Total loss:  -2.7287 | PDE Loss:  -3.4362 | Function Loss:  -3.8235\n",
      "Total loss:  -2.7289 | PDE Loss:  -3.4361 | Function Loss:  -3.8238\n",
      "Total loss:  -2.7291 | PDE Loss:  -3.4372 | Function Loss:  -3.8238\n",
      "Total loss:  -2.7294 | PDE Loss:  -3.4364 | Function Loss:  -3.8244\n",
      "Total loss:  -2.7297 | PDE Loss:  -3.4367 | Function Loss:  -3.8246\n",
      "Total loss:  -2.7301 | PDE Loss:  -3.4374 | Function Loss:  -3.8249\n",
      "Total loss:  -2.7304 | PDE Loss:  -3.4391 | Function Loss:  -3.8249\n",
      "Total loss:  -2.7306 | PDE Loss:  -3.4402 | Function Loss:  -3.8249\n",
      "Total loss:  -2.7309 | PDE Loss:  -3.4416 | Function Loss:  -3.8249\n",
      "Total loss:  -2.7311 | PDE Loss:  -3.4436 | Function Loss:  -3.8247\n",
      "Total loss:  -2.7314 | PDE Loss:  -3.4452 | Function Loss:  -3.8247\n",
      "Total loss:  -2.7317 | PDE Loss:  -3.447 | Function Loss:  -3.8246\n",
      "Total loss:  -2.732 | PDE Loss:  -3.449 | Function Loss:  -3.8245\n",
      "Total loss:  -2.7323 | PDE Loss:  -3.4503 | Function Loss:  -3.8246\n",
      "Total loss:  -2.7326 | PDE Loss:  -3.4511 | Function Loss:  -3.8247\n",
      "Total loss:  -2.7328 | PDE Loss:  -3.4511 | Function Loss:  -3.825\n",
      "Total loss:  -2.733 | PDE Loss:  -3.4509 | Function Loss:  -3.8253\n",
      "Total loss:  -2.7332 | PDE Loss:  -3.4505 | Function Loss:  -3.8256\n",
      "Total loss:  -2.7333 | PDE Loss:  -3.4501 | Function Loss:  -3.8259\n",
      "Total loss:  -2.7335 | PDE Loss:  -3.4499 | Function Loss:  -3.8262\n",
      "Total loss:  -2.7336 | PDE Loss:  -3.4497 | Function Loss:  -3.8264\n",
      "Total loss:  -2.7338 | PDE Loss:  -3.4499 | Function Loss:  -3.8265\n",
      "Total loss:  -2.7339 | PDE Loss:  -3.45 | Function Loss:  -3.8266\n",
      "Total loss:  -2.734 | PDE Loss:  -3.4493 | Function Loss:  -3.8269\n",
      "Total loss:  -2.7341 | PDE Loss:  -3.4498 | Function Loss:  -3.8269\n",
      "Total loss:  -2.7341 | PDE Loss:  -3.4503 | Function Loss:  -3.8269\n",
      "Total loss:  -2.7342 | PDE Loss:  -3.4505 | Function Loss:  -3.8269\n",
      "Total loss:  -2.7344 | PDE Loss:  -3.4508 | Function Loss:  -3.827\n",
      "Total loss:  -2.7345 | PDE Loss:  -3.4508 | Function Loss:  -3.8271\n",
      "Total loss:  -2.7346 | PDE Loss:  -3.4516 | Function Loss:  -3.8271\n",
      "Total loss:  -2.7347 | PDE Loss:  -3.4512 | Function Loss:  -3.8273\n",
      "Total loss:  -2.7348 | PDE Loss:  -3.4508 | Function Loss:  -3.8276\n",
      "Total loss:  -2.7349 | PDE Loss:  -3.4504 | Function Loss:  -3.8278\n",
      "Total loss:  -2.735 | PDE Loss:  -3.45 | Function Loss:  -3.8281\n",
      "Total loss:  -2.7351 | PDE Loss:  -3.45 | Function Loss:  -3.8282\n",
      "Total loss:  -2.7352 | PDE Loss:  -3.45 | Function Loss:  -3.8283\n",
      "Total loss:  -2.7353 | PDE Loss:  -3.4505 | Function Loss:  -3.8283\n",
      "Total loss:  -2.7354 | PDE Loss:  -3.4506 | Function Loss:  -3.8283\n",
      "Total loss:  -2.7355 | PDE Loss:  -3.4494 | Function Loss:  -3.8287\n",
      "Total loss:  -2.7355 | PDE Loss:  -3.4496 | Function Loss:  -3.8287\n",
      "Total loss:  -2.7356 | PDE Loss:  -3.4494 | Function Loss:  -3.8289\n",
      "Total loss:  -2.7356 | PDE Loss:  -3.449 | Function Loss:  -3.829\n",
      "Total loss:  -2.7357 | PDE Loss:  -3.4485 | Function Loss:  -3.8292\n",
      "Total loss:  -2.7357 | PDE Loss:  -3.448 | Function Loss:  -3.8294\n",
      "Total loss:  -2.7357 | PDE Loss:  -3.4472 | Function Loss:  -3.8296\n",
      "Total loss:  -2.7358 | PDE Loss:  -3.4466 | Function Loss:  -3.8298\n",
      "Total loss:  -2.7358 | PDE Loss:  -3.4462 | Function Loss:  -3.8299\n",
      "Total loss:  -2.7359 | PDE Loss:  -3.445 | Function Loss:  -3.8303\n",
      "Total loss:  -2.7359 | PDE Loss:  -3.4449 | Function Loss:  -3.8304\n",
      "Total loss:  -2.736 | PDE Loss:  -3.4449 | Function Loss:  -3.8304\n",
      "Total loss:  -2.736 | PDE Loss:  -3.4451 | Function Loss:  -3.8305\n",
      "Total loss:  -2.7361 | PDE Loss:  -3.4455 | Function Loss:  -3.8304\n",
      "Total loss:  -2.7361 | PDE Loss:  -3.4458 | Function Loss:  -3.8304\n",
      "Total loss:  -2.7362 | PDE Loss:  -3.446 | Function Loss:  -3.8304\n",
      "Total loss:  -2.7362 | PDE Loss:  -3.446 | Function Loss:  -3.8305\n",
      "Total loss:  -2.7363 | PDE Loss:  -3.4458 | Function Loss:  -3.8306\n",
      "Total loss:  -2.7364 | PDE Loss:  -3.4458 | Function Loss:  -3.8307\n",
      "Total loss:  -2.7364 | PDE Loss:  -3.4454 | Function Loss:  -3.8309\n",
      "Total loss:  -2.7365 | PDE Loss:  -3.4452 | Function Loss:  -3.831\n",
      "Total loss:  -2.7365 | PDE Loss:  -3.4448 | Function Loss:  -3.8312\n",
      "Total loss:  -2.7366 | PDE Loss:  -3.4448 | Function Loss:  -3.8312\n",
      "Total loss:  -2.7367 | PDE Loss:  -3.4443 | Function Loss:  -3.8315\n",
      "Total loss:  -2.7367 | PDE Loss:  -3.4444 | Function Loss:  -3.8315\n",
      "Total loss:  -2.7368 | PDE Loss:  -3.4444 | Function Loss:  -3.8316\n",
      "Total loss:  -2.7369 | PDE Loss:  -3.4446 | Function Loss:  -3.8317\n",
      "Total loss:  -2.7371 | PDE Loss:  -3.4448 | Function Loss:  -3.8318\n",
      "Total loss:  -2.7372 | PDE Loss:  -3.4449 | Function Loss:  -3.8319\n",
      "Total loss:  -2.7373 | PDE Loss:  -3.4451 | Function Loss:  -3.832\n",
      "Total loss:  -2.7374 | PDE Loss:  -3.4453 | Function Loss:  -3.8321\n",
      "Total loss:  -2.7375 | PDE Loss:  -3.4455 | Function Loss:  -3.8322\n",
      "Total loss:  -2.7376 | PDE Loss:  -3.4456 | Function Loss:  -3.8323\n",
      "Total loss:  -2.7377 | PDE Loss:  -3.4457 | Function Loss:  -3.8324\n",
      "Total loss:  -2.7378 | PDE Loss:  -3.4456 | Function Loss:  -3.8326\n",
      "Total loss:  -2.7379 | PDE Loss:  -3.4458 | Function Loss:  -3.8326\n",
      "Total loss:  -2.738 | PDE Loss:  -3.4453 | Function Loss:  -3.8329\n",
      "Total loss:  -2.7381 | PDE Loss:  -3.4454 | Function Loss:  -3.833\n",
      "Total loss:  -2.7382 | PDE Loss:  -3.4449 | Function Loss:  -3.8332\n",
      "Total loss:  -2.7383 | PDE Loss:  -3.4446 | Function Loss:  -3.8333\n",
      "Total loss:  -2.7384 | PDE Loss:  -3.4446 | Function Loss:  -3.8335\n",
      "Total loss:  -2.7385 | PDE Loss:  -3.4446 | Function Loss:  -3.8336\n",
      "Total loss:  -2.7386 | PDE Loss:  -3.4448 | Function Loss:  -3.8338\n",
      "Total loss:  -2.7387 | PDE Loss:  -3.4453 | Function Loss:  -3.8338\n",
      "Total loss:  -2.7389 | PDE Loss:  -3.4457 | Function Loss:  -3.8339\n",
      "Total loss:  -2.7391 | PDE Loss:  -3.447 | Function Loss:  -3.8338\n",
      "Total loss:  -2.7393 | PDE Loss:  -3.4478 | Function Loss:  -3.8339\n",
      "Total loss:  -2.7397 | PDE Loss:  -3.4493 | Function Loss:  -3.834\n",
      "Total loss:  -2.7401 | PDE Loss:  -3.4503 | Function Loss:  -3.8342\n",
      "Total loss:  -2.7405 | PDE Loss:  -3.4519 | Function Loss:  -3.8344\n",
      "Total loss:  -2.7409 | PDE Loss:  -3.4521 | Function Loss:  -3.8349\n",
      "Total loss:  -2.7413 | PDE Loss:  -3.4529 | Function Loss:  -3.8351\n",
      "Total loss:  -2.7418 | PDE Loss:  -3.4539 | Function Loss:  -3.8354\n",
      "Total loss:  -2.7422 | PDE Loss:  -3.4549 | Function Loss:  -3.8358\n",
      "Total loss:  -2.7426 | PDE Loss:  -3.455 | Function Loss:  -3.8362\n",
      "Total loss:  -2.7429 | PDE Loss:  -3.4553 | Function Loss:  -3.8365\n",
      "Total loss:  -2.7432 | PDE Loss:  -3.4554 | Function Loss:  -3.8368\n",
      "Total loss:  -2.7434 | PDE Loss:  -3.4563 | Function Loss:  -3.8369\n",
      "Total loss:  -2.7437 | PDE Loss:  -3.4575 | Function Loss:  -3.837\n",
      "Total loss:  -2.7439 | PDE Loss:  -3.4583 | Function Loss:  -3.8371\n",
      "Total loss:  -2.7442 | PDE Loss:  -3.4597 | Function Loss:  -3.837\n",
      "Total loss:  -2.7444 | PDE Loss:  -3.4608 | Function Loss:  -3.837\n",
      "Total loss:  -2.7446 | PDE Loss:  -3.4621 | Function Loss:  -3.837\n",
      "Total loss:  -2.7449 | PDE Loss:  -3.4626 | Function Loss:  -3.8372\n",
      "Total loss:  -2.7453 | PDE Loss:  -3.4632 | Function Loss:  -3.8376\n",
      "Total loss:  -2.7456 | PDE Loss:  -3.4635 | Function Loss:  -3.8379\n",
      "Total loss:  -2.746 | PDE Loss:  -3.4634 | Function Loss:  -3.8384\n",
      "Total loss:  -2.7463 | PDE Loss:  -3.4632 | Function Loss:  -3.8388\n",
      "Total loss:  -2.7466 | PDE Loss:  -3.4625 | Function Loss:  -3.8394\n",
      "Total loss:  -2.7421 | PDE Loss:  -3.4471 | Function Loss:  -3.8376\n",
      "Total loss:  -2.7467 | PDE Loss:  -3.4625 | Function Loss:  -3.8395\n",
      "Total loss:  -2.7468 | PDE Loss:  -3.4621 | Function Loss:  -3.8398\n",
      "Total loss:  -2.7471 | PDE Loss:  -3.4617 | Function Loss:  -3.8402\n",
      "Total loss:  -2.7473 | PDE Loss:  -3.4618 | Function Loss:  -3.8404\n",
      "Total loss:  -2.7475 | PDE Loss:  -3.4611 | Function Loss:  -3.8408\n",
      "Total loss:  -2.7477 | PDE Loss:  -3.4612 | Function Loss:  -3.841\n",
      "Total loss:  -2.7479 | PDE Loss:  -3.4615 | Function Loss:  -3.8412\n",
      "Total loss:  -2.7481 | PDE Loss:  -3.4623 | Function Loss:  -3.8413\n",
      "Total loss:  -2.7483 | PDE Loss:  -3.4633 | Function Loss:  -3.8413\n",
      "Total loss:  -2.7485 | PDE Loss:  -3.4644 | Function Loss:  -3.8413\n",
      "Total loss:  -2.7487 | PDE Loss:  -3.4653 | Function Loss:  -3.8413\n",
      "Total loss:  -2.7488 | PDE Loss:  -3.4675 | Function Loss:  -3.8409\n",
      "Total loss:  -2.7491 | PDE Loss:  -3.4681 | Function Loss:  -3.8411\n",
      "Total loss:  -2.7493 | PDE Loss:  -3.4683 | Function Loss:  -3.8413\n",
      "Total loss:  -2.7494 | PDE Loss:  -3.4688 | Function Loss:  -3.8414\n",
      "Total loss:  -2.7496 | PDE Loss:  -3.4691 | Function Loss:  -3.8415\n",
      "Total loss:  -2.7497 | PDE Loss:  -3.4695 | Function Loss:  -3.8415\n",
      "Total loss:  -2.7498 | PDE Loss:  -3.47 | Function Loss:  -3.8415\n",
      "Total loss:  -2.7499 | PDE Loss:  -3.4707 | Function Loss:  -3.8415\n",
      "Total loss:  -2.75 | PDE Loss:  -3.4716 | Function Loss:  -3.8415\n",
      "Total loss:  -2.7502 | PDE Loss:  -3.4722 | Function Loss:  -3.8415\n",
      "Total loss:  -2.7503 | PDE Loss:  -3.4725 | Function Loss:  -3.8415\n",
      "Total loss:  -2.7504 | PDE Loss:  -3.4728 | Function Loss:  -3.8416\n",
      "Total loss:  -2.7505 | PDE Loss:  -3.4722 | Function Loss:  -3.8419\n",
      "Total loss:  -2.7506 | PDE Loss:  -3.4718 | Function Loss:  -3.8422\n",
      "Total loss:  -2.7508 | PDE Loss:  -3.4727 | Function Loss:  -3.8422\n",
      "Total loss:  -2.751 | PDE Loss:  -3.4721 | Function Loss:  -3.8426\n",
      "Total loss:  -2.7513 | PDE Loss:  -3.4749 | Function Loss:  -3.8422\n",
      "Total loss:  -2.7513 | PDE Loss:  -3.4753 | Function Loss:  -3.8422\n",
      "Total loss:  -2.7515 | PDE Loss:  -3.4756 | Function Loss:  -3.8423\n",
      "Total loss:  -2.7516 | PDE Loss:  -3.476 | Function Loss:  -3.8424\n",
      "Total loss:  -2.7516 | PDE Loss:  -3.4762 | Function Loss:  -3.8424\n",
      "Total loss:  -2.7517 | PDE Loss:  -3.4763 | Function Loss:  -3.8424\n",
      "Total loss:  -2.7517 | PDE Loss:  -3.4766 | Function Loss:  -3.8424\n",
      "Total loss:  -2.7518 | PDE Loss:  -3.4767 | Function Loss:  -3.8425\n",
      "Total loss:  -2.7519 | PDE Loss:  -3.4769 | Function Loss:  -3.8425\n",
      "Total loss:  -2.7519 | PDE Loss:  -3.4771 | Function Loss:  -3.8425\n",
      "Total loss:  -2.752 | PDE Loss:  -3.4774 | Function Loss:  -3.8426\n",
      "Total loss:  -2.7521 | PDE Loss:  -3.4776 | Function Loss:  -3.8426\n",
      "Total loss:  -2.7522 | PDE Loss:  -3.4777 | Function Loss:  -3.8427\n",
      "Total loss:  -2.7522 | PDE Loss:  -3.478 | Function Loss:  -3.8427\n",
      "Total loss:  -2.7523 | PDE Loss:  -3.4781 | Function Loss:  -3.8428\n",
      "Total loss:  -2.7524 | PDE Loss:  -3.4783 | Function Loss:  -3.8428\n",
      "Total loss:  -2.7525 | PDE Loss:  -3.4784 | Function Loss:  -3.8429\n",
      "Total loss:  -2.7526 | PDE Loss:  -3.4786 | Function Loss:  -3.843\n",
      "Total loss:  -2.7526 | PDE Loss:  -3.4788 | Function Loss:  -3.843\n",
      "Total loss:  -2.7527 | PDE Loss:  -3.4789 | Function Loss:  -3.843\n",
      "Total loss:  -2.7527 | PDE Loss:  -3.4792 | Function Loss:  -3.843\n",
      "Total loss:  -2.7527 | PDE Loss:  -3.4795 | Function Loss:  -3.843\n",
      "Total loss:  -2.7528 | PDE Loss:  -3.4798 | Function Loss:  -3.8429\n",
      "Total loss:  -2.7528 | PDE Loss:  -3.4801 | Function Loss:  -3.8429\n",
      "Total loss:  -2.7528 | PDE Loss:  -3.4804 | Function Loss:  -3.8428\n",
      "Total loss:  -2.7528 | PDE Loss:  -3.4807 | Function Loss:  -3.8428\n",
      "Total loss:  -2.7528 | PDE Loss:  -3.481 | Function Loss:  -3.8428\n",
      "Total loss:  -2.7529 | PDE Loss:  -3.4812 | Function Loss:  -3.8427\n",
      "Total loss:  -2.7529 | PDE Loss:  -3.4815 | Function Loss:  -3.8427\n",
      "Total loss:  -2.753 | PDE Loss:  -3.4819 | Function Loss:  -3.8427\n",
      "Total loss:  -2.753 | PDE Loss:  -3.4823 | Function Loss:  -3.8427\n",
      "Total loss:  -2.7531 | PDE Loss:  -3.4822 | Function Loss:  -3.8428\n",
      "Total loss:  -2.7532 | PDE Loss:  -3.4828 | Function Loss:  -3.8428\n",
      "Total loss:  -2.7532 | PDE Loss:  -3.4828 | Function Loss:  -3.8428\n",
      "Total loss:  -2.7534 | PDE Loss:  -3.4826 | Function Loss:  -3.843\n",
      "Total loss:  -2.7535 | PDE Loss:  -3.483 | Function Loss:  -3.843\n",
      "Total loss:  -2.7535 | PDE Loss:  -3.4833 | Function Loss:  -3.8431\n",
      "Total loss:  -2.7537 | PDE Loss:  -3.4846 | Function Loss:  -3.8429\n",
      "Total loss:  -2.7537 | PDE Loss:  -3.485 | Function Loss:  -3.8429\n",
      "Total loss:  -2.7538 | PDE Loss:  -3.4857 | Function Loss:  -3.8429\n",
      "Total loss:  -2.7539 | PDE Loss:  -3.4866 | Function Loss:  -3.8428\n",
      "Total loss:  -2.754 | PDE Loss:  -3.4876 | Function Loss:  -3.8427\n",
      "Total loss:  -2.7541 | PDE Loss:  -3.4882 | Function Loss:  -3.8426\n",
      "Total loss:  -2.7542 | PDE Loss:  -3.489 | Function Loss:  -3.8425\n",
      "Total loss:  -2.7542 | PDE Loss:  -3.4896 | Function Loss:  -3.8425\n",
      "Total loss:  -2.7543 | PDE Loss:  -3.49 | Function Loss:  -3.8426\n",
      "Total loss:  -2.7545 | PDE Loss:  -3.4894 | Function Loss:  -3.8428\n",
      "Total loss:  -2.7546 | PDE Loss:  -3.4895 | Function Loss:  -3.8429\n",
      "Total loss:  -2.7547 | PDE Loss:  -3.4885 | Function Loss:  -3.8433\n",
      "Total loss:  -2.7548 | PDE Loss:  -3.4879 | Function Loss:  -3.8436\n",
      "Total loss:  -2.7549 | PDE Loss:  -3.4868 | Function Loss:  -3.8439\n",
      "Total loss:  -2.755 | PDE Loss:  -3.4857 | Function Loss:  -3.8443\n",
      "Total loss:  -2.7551 | PDE Loss:  -3.4845 | Function Loss:  -3.8447\n",
      "Total loss:  -2.7552 | PDE Loss:  -3.483 | Function Loss:  -3.8452\n",
      "Total loss:  -2.7553 | PDE Loss:  -3.4809 | Function Loss:  -3.8458\n",
      "Total loss:  -2.7553 | PDE Loss:  -3.4809 | Function Loss:  -3.8459\n",
      "Total loss:  -2.7554 | PDE Loss:  -3.4783 | Function Loss:  -3.8465\n",
      "Total loss:  -2.7555 | PDE Loss:  -3.4798 | Function Loss:  -3.8463\n",
      "Total loss:  -2.7556 | PDE Loss:  -3.4799 | Function Loss:  -3.8463\n",
      "Total loss:  -2.7557 | PDE Loss:  -3.4804 | Function Loss:  -3.8464\n",
      "Total loss:  -2.7558 | PDE Loss:  -3.4806 | Function Loss:  -3.8464\n",
      "Total loss:  -2.7559 | PDE Loss:  -3.4808 | Function Loss:  -3.8465\n",
      "Total loss:  -2.756 | PDE Loss:  -3.481 | Function Loss:  -3.8466\n",
      "Total loss:  -2.756 | PDE Loss:  -3.4807 | Function Loss:  -3.8467\n",
      "Total loss:  -2.7562 | PDE Loss:  -3.4813 | Function Loss:  -3.8468\n",
      "Total loss:  -2.7562 | PDE Loss:  -3.4815 | Function Loss:  -3.8468\n",
      "Total loss:  -2.7563 | PDE Loss:  -3.4819 | Function Loss:  -3.8468\n",
      "Total loss:  -2.7564 | PDE Loss:  -3.4823 | Function Loss:  -3.8468\n",
      "Total loss:  -2.7564 | PDE Loss:  -3.4829 | Function Loss:  -3.8467\n",
      "Total loss:  -2.7565 | PDE Loss:  -3.4835 | Function Loss:  -3.8467\n",
      "Total loss:  -2.7566 | PDE Loss:  -3.4842 | Function Loss:  -3.8467\n",
      "Total loss:  -2.7568 | PDE Loss:  -3.4851 | Function Loss:  -3.8466\n",
      "Total loss:  -2.7568 | PDE Loss:  -3.4856 | Function Loss:  -3.8466\n",
      "Total loss:  -2.757 | PDE Loss:  -3.4861 | Function Loss:  -3.8467\n",
      "Total loss:  -2.7571 | PDE Loss:  -3.4862 | Function Loss:  -3.8468\n",
      "Total loss:  -2.7572 | PDE Loss:  -3.486 | Function Loss:  -3.847\n",
      "Total loss:  -2.7573 | PDE Loss:  -3.4854 | Function Loss:  -3.8473\n",
      "Total loss:  -2.7574 | PDE Loss:  -3.4851 | Function Loss:  -3.8474\n",
      "Total loss:  -2.7574 | PDE Loss:  -3.4847 | Function Loss:  -3.8476\n",
      "Total loss:  -2.7575 | PDE Loss:  -3.4843 | Function Loss:  -3.8477\n",
      "Total loss:  -2.7575 | PDE Loss:  -3.4834 | Function Loss:  -3.848\n",
      "Total loss:  -2.7576 | PDE Loss:  -3.4832 | Function Loss:  -3.8481\n",
      "Total loss:  -2.7576 | PDE Loss:  -3.483 | Function Loss:  -3.8482\n",
      "Total loss:  -2.7577 | PDE Loss:  -3.4828 | Function Loss:  -3.8483\n",
      "Total loss:  -2.7577 | PDE Loss:  -3.4833 | Function Loss:  -3.8482\n",
      "Total loss:  -2.7578 | PDE Loss:  -3.4832 | Function Loss:  -3.8483\n",
      "Total loss:  -2.7578 | PDE Loss:  -3.4829 | Function Loss:  -3.8485\n",
      "Total loss:  -2.7579 | PDE Loss:  -3.4828 | Function Loss:  -3.8486\n",
      "Total loss:  -2.758 | PDE Loss:  -3.4828 | Function Loss:  -3.8486\n",
      "Total loss:  -2.758 | PDE Loss:  -3.4827 | Function Loss:  -3.8488\n",
      "Total loss:  -2.7581 | PDE Loss:  -3.4827 | Function Loss:  -3.8489\n",
      "Total loss:  -2.7583 | PDE Loss:  -3.4827 | Function Loss:  -3.849\n",
      "Total loss:  -2.7584 | PDE Loss:  -3.4825 | Function Loss:  -3.8492\n",
      "Total loss:  -2.7586 | PDE Loss:  -3.4827 | Function Loss:  -3.8494\n",
      "Total loss:  -2.7587 | PDE Loss:  -3.4825 | Function Loss:  -3.8496\n",
      "Total loss:  -2.7589 | PDE Loss:  -3.4825 | Function Loss:  -3.8498\n",
      "Total loss:  -2.7591 | PDE Loss:  -3.4824 | Function Loss:  -3.8501\n",
      "Total loss:  -2.7593 | PDE Loss:  -3.482 | Function Loss:  -3.8505\n",
      "Total loss:  -2.7596 | PDE Loss:  -3.4821 | Function Loss:  -3.8508\n",
      "Total loss:  -2.7598 | PDE Loss:  -3.4815 | Function Loss:  -3.8512\n",
      "Total loss:  -2.7601 | PDE Loss:  -3.4816 | Function Loss:  -3.8516\n",
      "Total loss:  -2.7604 | PDE Loss:  -3.481 | Function Loss:  -3.8521\n",
      "Total loss:  -2.7607 | PDE Loss:  -3.4807 | Function Loss:  -3.8525\n",
      "Total loss:  -2.7609 | PDE Loss:  -3.4805 | Function Loss:  -3.8528\n",
      "Total loss:  -2.7611 | PDE Loss:  -3.48 | Function Loss:  -3.8531\n",
      "Total loss:  -2.7612 | PDE Loss:  -3.4804 | Function Loss:  -3.8532\n",
      "Total loss:  -2.7614 | PDE Loss:  -3.481 | Function Loss:  -3.8533\n",
      "Total loss:  -2.7616 | PDE Loss:  -3.4813 | Function Loss:  -3.8535\n",
      "Total loss:  -2.7618 | PDE Loss:  -3.4827 | Function Loss:  -3.8534\n",
      "Total loss:  -2.7619 | PDE Loss:  -3.4831 | Function Loss:  -3.8535\n",
      "Total loss:  -2.7621 | PDE Loss:  -3.4838 | Function Loss:  -3.8535\n",
      "Total loss:  -2.7623 | PDE Loss:  -3.4841 | Function Loss:  -3.8537\n",
      "Total loss:  -2.7624 | PDE Loss:  -3.4844 | Function Loss:  -3.8538\n",
      "Total loss:  -2.7626 | PDE Loss:  -3.484 | Function Loss:  -3.8541\n",
      "Total loss:  -2.7628 | PDE Loss:  -3.4836 | Function Loss:  -3.8544\n",
      "Total loss:  -2.7629 | PDE Loss:  -3.4826 | Function Loss:  -3.8548\n",
      "Total loss:  -2.763 | PDE Loss:  -3.4817 | Function Loss:  -3.8551\n",
      "Total loss:  -2.7631 | PDE Loss:  -3.4808 | Function Loss:  -3.8554\n",
      "Total loss:  -2.7631 | PDE Loss:  -3.48 | Function Loss:  -3.8557\n",
      "Total loss:  -2.7631 | PDE Loss:  -3.4782 | Function Loss:  -3.856\n",
      "Total loss:  -2.7632 | PDE Loss:  -3.4795 | Function Loss:  -3.8558\n",
      "Total loss:  -2.7632 | PDE Loss:  -3.4786 | Function Loss:  -3.8561\n",
      "Total loss:  -2.7633 | PDE Loss:  -3.4783 | Function Loss:  -3.8563\n",
      "Total loss:  -2.7634 | PDE Loss:  -3.4781 | Function Loss:  -3.8565\n",
      "Total loss:  -2.7635 | PDE Loss:  -3.4779 | Function Loss:  -3.8566\n",
      "Total loss:  -2.7635 | PDE Loss:  -3.4777 | Function Loss:  -3.8567\n",
      "Total loss:  -2.7636 | PDE Loss:  -3.4776 | Function Loss:  -3.8568\n",
      "Total loss:  -2.7636 | PDE Loss:  -3.4758 | Function Loss:  -3.8573\n",
      "Total loss:  -2.7637 | PDE Loss:  -3.476 | Function Loss:  -3.8573\n",
      "Total loss:  -2.7637 | PDE Loss:  -3.4761 | Function Loss:  -3.8573\n",
      "Total loss:  -2.7638 | PDE Loss:  -3.476 | Function Loss:  -3.8575\n",
      "Total loss:  -2.7639 | PDE Loss:  -3.4757 | Function Loss:  -3.8576\n",
      "Total loss:  -2.764 | PDE Loss:  -3.4753 | Function Loss:  -3.8578\n",
      "Total loss:  -2.764 | PDE Loss:  -3.4744 | Function Loss:  -3.8581\n",
      "Total loss:  -2.7641 | PDE Loss:  -3.474 | Function Loss:  -3.8583\n",
      "Total loss:  -2.7642 | PDE Loss:  -3.4737 | Function Loss:  -3.8585\n",
      "Total loss:  -2.7642 | PDE Loss:  -3.4735 | Function Loss:  -3.8586\n",
      "Total loss:  -2.7643 | PDE Loss:  -3.4735 | Function Loss:  -3.8587\n",
      "Total loss:  -2.7643 | PDE Loss:  -3.4735 | Function Loss:  -3.8588\n",
      "Total loss:  -2.7644 | PDE Loss:  -3.4738 | Function Loss:  -3.8587\n",
      "Total loss:  -2.7645 | PDE Loss:  -3.4741 | Function Loss:  -3.8587\n",
      "Total loss:  -2.7645 | PDE Loss:  -3.4745 | Function Loss:  -3.8587\n",
      "Total loss:  -2.7646 | PDE Loss:  -3.4755 | Function Loss:  -3.8585\n",
      "Total loss:  -2.7646 | PDE Loss:  -3.4756 | Function Loss:  -3.8586\n",
      "Total loss:  -2.7647 | PDE Loss:  -3.476 | Function Loss:  -3.8586\n",
      "Total loss:  -2.7648 | PDE Loss:  -3.4763 | Function Loss:  -3.8586\n",
      "Total loss:  -2.7649 | PDE Loss:  -3.4766 | Function Loss:  -3.8587\n",
      "Total loss:  -2.765 | PDE Loss:  -3.477 | Function Loss:  -3.8587\n",
      "Total loss:  -2.7651 | PDE Loss:  -3.4773 | Function Loss:  -3.8588\n",
      "Total loss:  -2.7652 | PDE Loss:  -3.4777 | Function Loss:  -3.8588\n",
      "Total loss:  -2.7654 | PDE Loss:  -3.4781 | Function Loss:  -3.8589\n",
      "Total loss:  -2.7655 | PDE Loss:  -3.4786 | Function Loss:  -3.8589\n",
      "Total loss:  -2.7656 | PDE Loss:  -3.4794 | Function Loss:  -3.8589\n",
      "Total loss:  -2.7657 | PDE Loss:  -3.48 | Function Loss:  -3.8589\n",
      "Total loss:  -2.7659 | PDE Loss:  -3.4806 | Function Loss:  -3.8589\n",
      "Total loss:  -2.766 | PDE Loss:  -3.4812 | Function Loss:  -3.8589\n",
      "Total loss:  -2.7661 | PDE Loss:  -3.4815 | Function Loss:  -3.859\n",
      "Total loss:  -2.7662 | PDE Loss:  -3.4828 | Function Loss:  -3.8588\n",
      "Total loss:  -2.7662 | PDE Loss:  -3.4828 | Function Loss:  -3.8588\n",
      "Total loss:  -2.7663 | PDE Loss:  -3.4831 | Function Loss:  -3.8589\n",
      "Total loss:  -2.7663 | PDE Loss:  -3.483 | Function Loss:  -3.8589\n",
      "Total loss:  -2.7664 | PDE Loss:  -3.4831 | Function Loss:  -3.859\n",
      "Total loss:  -2.7664 | PDE Loss:  -3.4829 | Function Loss:  -3.8591\n",
      "Total loss:  -2.7665 | PDE Loss:  -3.4828 | Function Loss:  -3.8592\n",
      "Total loss:  -2.7666 | PDE Loss:  -3.4827 | Function Loss:  -3.8593\n",
      "Total loss:  -2.7667 | PDE Loss:  -3.4826 | Function Loss:  -3.8595\n",
      "Total loss:  -2.7668 | PDE Loss:  -3.4823 | Function Loss:  -3.8596\n",
      "Total loss:  -2.7669 | PDE Loss:  -3.4823 | Function Loss:  -3.8598\n",
      "Total loss:  -2.767 | PDE Loss:  -3.4824 | Function Loss:  -3.8599\n",
      "Total loss:  -2.7671 | PDE Loss:  -3.4825 | Function Loss:  -3.86\n",
      "Total loss:  -2.7672 | PDE Loss:  -3.4827 | Function Loss:  -3.86\n",
      "Total loss:  -2.7672 | PDE Loss:  -3.4829 | Function Loss:  -3.8601\n",
      "Total loss:  -2.7673 | PDE Loss:  -3.4828 | Function Loss:  -3.8602\n",
      "Total loss:  -2.7674 | PDE Loss:  -3.4829 | Function Loss:  -3.8603\n",
      "Total loss:  -2.7668 | PDE Loss:  -3.4773 | Function Loss:  -3.8609\n",
      "Total loss:  -2.7674 | PDE Loss:  -3.4824 | Function Loss:  -3.8604\n",
      "Total loss:  -2.7676 | PDE Loss:  -3.4822 | Function Loss:  -3.8607\n",
      "Total loss:  -2.7677 | PDE Loss:  -3.4822 | Function Loss:  -3.8609\n",
      "Total loss:  -2.7679 | PDE Loss:  -3.482 | Function Loss:  -3.8611\n",
      "Total loss:  -2.7681 | PDE Loss:  -3.4823 | Function Loss:  -3.8613\n",
      "Total loss:  -2.7682 | PDE Loss:  -3.482 | Function Loss:  -3.8615\n",
      "Total loss:  -2.7683 | PDE Loss:  -3.4822 | Function Loss:  -3.8615\n",
      "Total loss:  -2.7684 | PDE Loss:  -3.4823 | Function Loss:  -3.8617\n",
      "Total loss:  -2.7685 | PDE Loss:  -3.4826 | Function Loss:  -3.8618\n",
      "Total loss:  -2.7687 | PDE Loss:  -3.4826 | Function Loss:  -3.8619\n",
      "Total loss:  -2.7688 | PDE Loss:  -3.4829 | Function Loss:  -3.862\n",
      "Total loss:  -2.7689 | PDE Loss:  -3.4827 | Function Loss:  -3.8622\n",
      "Total loss:  -2.7691 | PDE Loss:  -3.483 | Function Loss:  -3.8623\n",
      "Total loss:  -2.7692 | PDE Loss:  -3.4829 | Function Loss:  -3.8624\n",
      "Total loss:  -2.7693 | PDE Loss:  -3.4829 | Function Loss:  -3.8626\n",
      "Total loss:  -2.7694 | PDE Loss:  -3.4828 | Function Loss:  -3.8628\n",
      "Total loss:  -2.7695 | PDE Loss:  -3.4827 | Function Loss:  -3.8629\n",
      "Total loss:  -2.7696 | PDE Loss:  -3.4825 | Function Loss:  -3.8631\n",
      "Total loss:  -2.7697 | PDE Loss:  -3.4824 | Function Loss:  -3.8633\n",
      "Total loss:  -2.7698 | PDE Loss:  -3.4823 | Function Loss:  -3.8634\n",
      "Total loss:  -2.7698 | PDE Loss:  -3.4821 | Function Loss:  -3.8635\n",
      "Total loss:  -2.7699 | PDE Loss:  -3.482 | Function Loss:  -3.8636\n",
      "Total loss:  -2.77 | PDE Loss:  -3.4818 | Function Loss:  -3.8638\n",
      "Total loss:  -2.7702 | PDE Loss:  -3.4818 | Function Loss:  -3.864\n",
      "Total loss:  -2.7703 | PDE Loss:  -3.4817 | Function Loss:  -3.8642\n",
      "Total loss:  -2.7705 | PDE Loss:  -3.4816 | Function Loss:  -3.8644\n",
      "Total loss:  -2.7706 | PDE Loss:  -3.4815 | Function Loss:  -3.8646\n",
      "Total loss:  -2.7708 | PDE Loss:  -3.4814 | Function Loss:  -3.8648\n",
      "Total loss:  -2.7709 | PDE Loss:  -3.4813 | Function Loss:  -3.865\n",
      "Total loss:  -2.771 | PDE Loss:  -3.4811 | Function Loss:  -3.8652\n",
      "Total loss:  -2.7711 | PDE Loss:  -3.4813 | Function Loss:  -3.8653\n",
      "Total loss:  -2.7713 | PDE Loss:  -3.4814 | Function Loss:  -3.8654\n",
      "Total loss:  -2.7714 | PDE Loss:  -3.482 | Function Loss:  -3.8654\n",
      "Total loss:  -2.7715 | PDE Loss:  -3.4825 | Function Loss:  -3.8655\n",
      "Total loss:  -2.7716 | PDE Loss:  -3.4835 | Function Loss:  -3.8654\n",
      "Total loss:  -2.7718 | PDE Loss:  -3.4843 | Function Loss:  -3.8654\n",
      "Total loss:  -2.7719 | PDE Loss:  -3.4854 | Function Loss:  -3.8653\n",
      "Total loss:  -2.7721 | PDE Loss:  -3.4863 | Function Loss:  -3.8652\n",
      "Total loss:  -2.7722 | PDE Loss:  -3.4871 | Function Loss:  -3.8652\n",
      "Total loss:  -2.7723 | PDE Loss:  -3.4885 | Function Loss:  -3.8651\n",
      "Total loss:  -2.7725 | PDE Loss:  -3.4892 | Function Loss:  -3.8651\n",
      "Total loss:  -2.7727 | PDE Loss:  -3.4898 | Function Loss:  -3.8652\n",
      "Total loss:  -2.7729 | PDE Loss:  -3.4899 | Function Loss:  -3.8654\n",
      "Total loss:  -2.7731 | PDE Loss:  -3.4895 | Function Loss:  -3.8658\n",
      "Total loss:  -2.7732 | PDE Loss:  -3.4895 | Function Loss:  -3.8658\n",
      "Total loss:  -2.7733 | PDE Loss:  -3.4889 | Function Loss:  -3.8661\n",
      "Total loss:  -2.7734 | PDE Loss:  -3.4888 | Function Loss:  -3.8663\n",
      "Total loss:  -2.7735 | PDE Loss:  -3.4889 | Function Loss:  -3.8664\n",
      "Total loss:  -2.7735 | PDE Loss:  -3.4891 | Function Loss:  -3.8664\n",
      "Total loss:  -2.7736 | PDE Loss:  -3.4893 | Function Loss:  -3.8665\n",
      "Total loss:  -2.7737 | PDE Loss:  -3.49 | Function Loss:  -3.8664\n",
      "Total loss:  -2.7738 | PDE Loss:  -3.491 | Function Loss:  -3.8663\n",
      "Total loss:  -2.774 | PDE Loss:  -3.4923 | Function Loss:  -3.8662\n",
      "Total loss:  -2.7741 | PDE Loss:  -3.4937 | Function Loss:  -3.8661\n",
      "Total loss:  -2.7742 | PDE Loss:  -3.4935 | Function Loss:  -3.8662\n",
      "Total loss:  -2.7744 | PDE Loss:  -3.4943 | Function Loss:  -3.8662\n",
      "Total loss:  -2.7745 | PDE Loss:  -3.4949 | Function Loss:  -3.8662\n",
      "Total loss:  -2.7747 | PDE Loss:  -3.4954 | Function Loss:  -3.8663\n",
      "Total loss:  -2.7748 | PDE Loss:  -3.4967 | Function Loss:  -3.8662\n",
      "Total loss:  -2.775 | PDE Loss:  -3.4977 | Function Loss:  -3.8662\n",
      "Total loss:  -2.7752 | PDE Loss:  -3.4983 | Function Loss:  -3.8663\n",
      "Total loss:  -2.7754 | PDE Loss:  -3.4998 | Function Loss:  -3.8662\n",
      "Total loss:  -2.7756 | PDE Loss:  -3.5009 | Function Loss:  -3.8662\n",
      "Total loss:  -2.7758 | PDE Loss:  -3.5021 | Function Loss:  -3.8661\n",
      "Total loss:  -2.7759 | PDE Loss:  -3.5025 | Function Loss:  -3.8661\n",
      "Total loss:  -2.7759 | PDE Loss:  -3.5028 | Function Loss:  -3.8661\n",
      "Total loss:  -2.776 | PDE Loss:  -3.5028 | Function Loss:  -3.8662\n",
      "Total loss:  -2.776 | PDE Loss:  -3.5026 | Function Loss:  -3.8663\n",
      "Total loss:  -2.7761 | PDE Loss:  -3.5024 | Function Loss:  -3.8664\n",
      "Total loss:  -2.7762 | PDE Loss:  -3.502 | Function Loss:  -3.8666\n",
      "Total loss:  -2.7762 | PDE Loss:  -3.5019 | Function Loss:  -3.8667\n",
      "Total loss:  -2.7763 | PDE Loss:  -3.5017 | Function Loss:  -3.8669\n",
      "Total loss:  -2.7764 | PDE Loss:  -3.5022 | Function Loss:  -3.8669\n",
      "Total loss:  -2.7765 | PDE Loss:  -3.5028 | Function Loss:  -3.8669\n",
      "Total loss:  -2.7766 | PDE Loss:  -3.5037 | Function Loss:  -3.8668\n",
      "Total loss:  -2.7767 | PDE Loss:  -3.5045 | Function Loss:  -3.8668\n",
      "Total loss:  -2.7768 | PDE Loss:  -3.5053 | Function Loss:  -3.8667\n",
      "Total loss:  -2.7769 | PDE Loss:  -3.5059 | Function Loss:  -3.8666\n",
      "Total loss:  -2.777 | PDE Loss:  -3.5064 | Function Loss:  -3.8666\n",
      "Total loss:  -2.7771 | PDE Loss:  -3.5067 | Function Loss:  -3.8666\n",
      "Total loss:  -2.7771 | PDE Loss:  -3.5075 | Function Loss:  -3.8665\n",
      "Total loss:  -2.7772 | PDE Loss:  -3.5081 | Function Loss:  -3.8665\n",
      "Total loss:  -2.7773 | PDE Loss:  -3.5082 | Function Loss:  -3.8666\n",
      "Total loss:  -2.7774 | PDE Loss:  -3.5083 | Function Loss:  -3.8666\n",
      "Total loss:  -2.7774 | PDE Loss:  -3.5083 | Function Loss:  -3.8667\n",
      "Total loss:  -2.7775 | PDE Loss:  -3.5082 | Function Loss:  -3.8668\n",
      "Total loss:  -2.7775 | PDE Loss:  -3.5087 | Function Loss:  -3.8668\n",
      "Total loss:  -2.7776 | PDE Loss:  -3.509 | Function Loss:  -3.8668\n",
      "Total loss:  -2.7777 | PDE Loss:  -3.5097 | Function Loss:  -3.8667\n",
      "Total loss:  -2.7778 | PDE Loss:  -3.5106 | Function Loss:  -3.8666\n",
      "Total loss:  -2.7779 | PDE Loss:  -3.5119 | Function Loss:  -3.8664\n",
      "Total loss:  -2.7779 | PDE Loss:  -3.5111 | Function Loss:  -3.8667\n",
      "Total loss:  -2.778 | PDE Loss:  -3.5133 | Function Loss:  -3.8663\n",
      "Total loss:  -2.7781 | PDE Loss:  -3.514 | Function Loss:  -3.8662\n",
      "Total loss:  -2.7781 | PDE Loss:  -3.5142 | Function Loss:  -3.8662\n",
      "Total loss:  -2.7781 | PDE Loss:  -3.5156 | Function Loss:  -3.8659\n",
      "Total loss:  -2.7782 | PDE Loss:  -3.5154 | Function Loss:  -3.866\n",
      "Total loss:  -2.7782 | PDE Loss:  -3.5152 | Function Loss:  -3.8661\n",
      "Total loss:  -2.7782 | PDE Loss:  -3.5151 | Function Loss:  -3.8662\n",
      "Total loss:  -2.7783 | PDE Loss:  -3.5152 | Function Loss:  -3.8662\n",
      "Total loss:  -2.7784 | PDE Loss:  -3.5155 | Function Loss:  -3.8663\n",
      "Total loss:  -2.7784 | PDE Loss:  -3.5151 | Function Loss:  -3.8664\n",
      "Total loss:  -2.7785 | PDE Loss:  -3.5157 | Function Loss:  -3.8664\n",
      "Total loss:  -2.7786 | PDE Loss:  -3.5165 | Function Loss:  -3.8663\n",
      "Total loss:  -2.7787 | PDE Loss:  -3.5173 | Function Loss:  -3.8663\n",
      "Total loss:  -2.7789 | PDE Loss:  -3.5181 | Function Loss:  -3.8663\n",
      "Total loss:  -2.779 | PDE Loss:  -3.5186 | Function Loss:  -3.8663\n",
      "Total loss:  -2.7789 | PDE Loss:  -3.5175 | Function Loss:  -3.8665\n",
      "Total loss:  -2.779 | PDE Loss:  -3.5184 | Function Loss:  -3.8664\n",
      "Total loss:  -2.7791 | PDE Loss:  -3.5186 | Function Loss:  -3.8665\n",
      "Total loss:  -2.7793 | PDE Loss:  -3.5184 | Function Loss:  -3.8667\n",
      "Total loss:  -2.7793 | PDE Loss:  -3.5183 | Function Loss:  -3.8668\n",
      "Total loss:  -2.7794 | PDE Loss:  -3.5177 | Function Loss:  -3.867\n",
      "Total loss:  -2.7795 | PDE Loss:  -3.5175 | Function Loss:  -3.8671\n",
      "Total loss:  -2.7795 | PDE Loss:  -3.517 | Function Loss:  -3.8673\n",
      "Total loss:  -2.7795 | PDE Loss:  -3.5174 | Function Loss:  -3.8672\n",
      "Total loss:  -2.7796 | PDE Loss:  -3.5171 | Function Loss:  -3.8673\n",
      "Total loss:  -2.7796 | PDE Loss:  -3.517 | Function Loss:  -3.8674\n",
      "Total loss:  -2.7797 | PDE Loss:  -3.5168 | Function Loss:  -3.8676\n",
      "Total loss:  -2.7797 | PDE Loss:  -3.5166 | Function Loss:  -3.8676\n",
      "Total loss:  -2.7798 | PDE Loss:  -3.5167 | Function Loss:  -3.8677\n",
      "Total loss:  -2.7798 | PDE Loss:  -3.5168 | Function Loss:  -3.8677\n",
      "Total loss:  -2.7798 | PDE Loss:  -3.517 | Function Loss:  -3.8677\n",
      "Total loss:  -2.7799 | PDE Loss:  -3.5172 | Function Loss:  -3.8677\n",
      "Total loss:  -2.7799 | PDE Loss:  -3.5172 | Function Loss:  -3.8677\n",
      "Total loss:  -2.78 | PDE Loss:  -3.5174 | Function Loss:  -3.8678\n",
      "Total loss:  -2.78 | PDE Loss:  -3.5173 | Function Loss:  -3.8678\n",
      "Total loss:  -2.7801 | PDE Loss:  -3.5172 | Function Loss:  -3.8679\n",
      "Total loss:  -2.7801 | PDE Loss:  -3.5169 | Function Loss:  -3.8681\n",
      "Total loss:  -2.7802 | PDE Loss:  -3.5167 | Function Loss:  -3.8682\n",
      "Total loss:  -2.7803 | PDE Loss:  -3.5166 | Function Loss:  -3.8683\n",
      "Total loss:  -2.7803 | PDE Loss:  -3.5164 | Function Loss:  -3.8684\n",
      "Total loss:  -2.7804 | PDE Loss:  -3.5168 | Function Loss:  -3.8684\n",
      "Total loss:  -2.7805 | PDE Loss:  -3.5165 | Function Loss:  -3.8686\n",
      "Total loss:  -2.7805 | PDE Loss:  -3.5168 | Function Loss:  -3.8686\n",
      "Total loss:  -2.7806 | PDE Loss:  -3.5171 | Function Loss:  -3.8686\n",
      "Total loss:  -2.7806 | PDE Loss:  -3.518 | Function Loss:  -3.8685\n",
      "Total loss:  -2.7807 | PDE Loss:  -3.5183 | Function Loss:  -3.8685\n",
      "Total loss:  -2.7807 | PDE Loss:  -3.5186 | Function Loss:  -3.8684\n",
      "Total loss:  -2.7808 | PDE Loss:  -3.5193 | Function Loss:  -3.8684\n",
      "Total loss:  -2.7809 | PDE Loss:  -3.5197 | Function Loss:  -3.8684\n",
      "Total loss:  -2.781 | PDE Loss:  -3.5204 | Function Loss:  -3.8684\n",
      "Total loss:  -2.781 | PDE Loss:  -3.5205 | Function Loss:  -3.8684\n",
      "Total loss:  -2.7812 | PDE Loss:  -3.5207 | Function Loss:  -3.8685\n",
      "Total loss:  -2.7812 | PDE Loss:  -3.5208 | Function Loss:  -3.8686\n",
      "Total loss:  -2.7813 | PDE Loss:  -3.5208 | Function Loss:  -3.8687\n",
      "Total loss:  -2.7814 | PDE Loss:  -3.5209 | Function Loss:  -3.8687\n",
      "Total loss:  -2.7814 | PDE Loss:  -3.5209 | Function Loss:  -3.8688\n",
      "Total loss:  -2.7815 | PDE Loss:  -3.5218 | Function Loss:  -3.8687\n",
      "Total loss:  -2.7816 | PDE Loss:  -3.5222 | Function Loss:  -3.8687\n",
      "Total loss:  -2.7817 | PDE Loss:  -3.5231 | Function Loss:  -3.8686\n",
      "Total loss:  -2.7818 | PDE Loss:  -3.5243 | Function Loss:  -3.8685\n",
      "Total loss:  -2.7819 | PDE Loss:  -3.5255 | Function Loss:  -3.8684\n",
      "Total loss:  -2.782 | PDE Loss:  -3.5267 | Function Loss:  -3.8682\n",
      "Total loss:  -2.7822 | PDE Loss:  -3.5278 | Function Loss:  -3.8681\n",
      "Total loss:  -2.7822 | PDE Loss:  -3.5286 | Function Loss:  -3.8681\n",
      "Total loss:  -2.7823 | PDE Loss:  -3.5292 | Function Loss:  -3.868\n",
      "Total loss:  -2.7824 | PDE Loss:  -3.5296 | Function Loss:  -3.8681\n",
      "Total loss:  -2.7825 | PDE Loss:  -3.5295 | Function Loss:  -3.8682\n",
      "Total loss:  -2.7826 | PDE Loss:  -3.5298 | Function Loss:  -3.8683\n",
      "Total loss:  -2.7827 | PDE Loss:  -3.5295 | Function Loss:  -3.8685\n",
      "Total loss:  -2.7828 | PDE Loss:  -3.5289 | Function Loss:  -3.8687\n",
      "Total loss:  -2.7829 | PDE Loss:  -3.5285 | Function Loss:  -3.8689\n",
      "Total loss:  -2.783 | PDE Loss:  -3.5281 | Function Loss:  -3.8691\n",
      "Total loss:  -2.7831 | PDE Loss:  -3.5281 | Function Loss:  -3.8692\n",
      "Total loss:  -2.7831 | PDE Loss:  -3.5282 | Function Loss:  -3.8692\n",
      "Total loss:  -2.7832 | PDE Loss:  -3.5286 | Function Loss:  -3.8692\n",
      "Total loss:  -2.7832 | PDE Loss:  -3.5295 | Function Loss:  -3.8691\n",
      "Total loss:  -2.7833 | PDE Loss:  -3.5301 | Function Loss:  -3.8691\n",
      "Total loss:  -2.7834 | PDE Loss:  -3.5312 | Function Loss:  -3.8689\n",
      "Total loss:  -2.7835 | PDE Loss:  -3.532 | Function Loss:  -3.8689\n",
      "Total loss:  -2.7836 | PDE Loss:  -3.5329 | Function Loss:  -3.8688\n",
      "Total loss:  -2.7837 | PDE Loss:  -3.5335 | Function Loss:  -3.8688\n",
      "Total loss:  -2.7838 | PDE Loss:  -3.5342 | Function Loss:  -3.8687\n",
      "Total loss:  -2.7839 | PDE Loss:  -3.5345 | Function Loss:  -3.8688\n",
      "Total loss:  -2.784 | PDE Loss:  -3.5346 | Function Loss:  -3.8689\n",
      "Total loss:  -2.7841 | PDE Loss:  -3.5343 | Function Loss:  -3.8691\n",
      "Total loss:  -2.7841 | PDE Loss:  -3.5351 | Function Loss:  -3.869\n",
      "Total loss:  -2.7843 | PDE Loss:  -3.5346 | Function Loss:  -3.8692\n",
      "Total loss:  -2.7843 | PDE Loss:  -3.534 | Function Loss:  -3.8694\n",
      "Total loss:  -2.7844 | PDE Loss:  -3.5336 | Function Loss:  -3.8696\n",
      "Total loss:  -2.7844 | PDE Loss:  -3.5335 | Function Loss:  -3.8697\n",
      "Total loss:  -2.7845 | PDE Loss:  -3.5333 | Function Loss:  -3.8698\n",
      "Total loss:  -2.7845 | PDE Loss:  -3.5315 | Function Loss:  -3.8702\n",
      "Total loss:  -2.7846 | PDE Loss:  -3.5324 | Function Loss:  -3.8702\n",
      "Total loss:  -2.7847 | PDE Loss:  -3.5337 | Function Loss:  -3.87\n",
      "Total loss:  -2.7849 | PDE Loss:  -3.5351 | Function Loss:  -3.8698\n",
      "Total loss:  -2.785 | PDE Loss:  -3.5371 | Function Loss:  -3.8696\n",
      "Total loss:  -2.7851 | PDE Loss:  -3.5389 | Function Loss:  -3.8694\n",
      "Total loss:  -2.7853 | PDE Loss:  -3.541 | Function Loss:  -3.8691\n",
      "Total loss:  -2.7854 | PDE Loss:  -3.5424 | Function Loss:  -3.869\n",
      "Total loss:  -2.7855 | PDE Loss:  -3.5433 | Function Loss:  -3.8689\n",
      "Total loss:  -2.7856 | PDE Loss:  -3.5441 | Function Loss:  -3.8689\n",
      "Total loss:  -2.7857 | PDE Loss:  -3.5449 | Function Loss:  -3.8688\n",
      "Total loss:  -2.7859 | PDE Loss:  -3.545 | Function Loss:  -3.869\n",
      "Total loss:  -2.786 | PDE Loss:  -3.545 | Function Loss:  -3.8691\n",
      "Total loss:  -2.7861 | PDE Loss:  -3.5442 | Function Loss:  -3.8694\n",
      "Total loss:  -2.7862 | PDE Loss:  -3.5436 | Function Loss:  -3.8696\n",
      "Total loss:  -2.7863 | PDE Loss:  -3.543 | Function Loss:  -3.8699\n",
      "Total loss:  -2.7864 | PDE Loss:  -3.5425 | Function Loss:  -3.8701\n",
      "Total loss:  -2.7866 | PDE Loss:  -3.5414 | Function Loss:  -3.8705\n",
      "Total loss:  -2.7867 | PDE Loss:  -3.541 | Function Loss:  -3.8708\n",
      "Total loss:  -2.7868 | PDE Loss:  -3.5391 | Function Loss:  -3.8714\n",
      "Total loss:  -2.787 | PDE Loss:  -3.5394 | Function Loss:  -3.8715\n",
      "Total loss:  -2.7872 | PDE Loss:  -3.5396 | Function Loss:  -3.8717\n",
      "Total loss:  -2.7874 | PDE Loss:  -3.5398 | Function Loss:  -3.8719\n",
      "Total loss:  -2.7875 | PDE Loss:  -3.5397 | Function Loss:  -3.8721\n",
      "Total loss:  -2.7877 | PDE Loss:  -3.5397 | Function Loss:  -3.8723\n",
      "Total loss:  -2.7879 | PDE Loss:  -3.5378 | Function Loss:  -3.873\n",
      "Total loss:  -2.7881 | PDE Loss:  -3.5376 | Function Loss:  -3.8732\n",
      "Total loss:  -2.7883 | PDE Loss:  -3.5367 | Function Loss:  -3.8737\n",
      "Total loss:  -2.7886 | PDE Loss:  -3.536 | Function Loss:  -3.8742\n",
      "Total loss:  -2.7888 | PDE Loss:  -3.5349 | Function Loss:  -3.8747\n",
      "Total loss:  -2.7889 | PDE Loss:  -3.5345 | Function Loss:  -3.8749\n",
      "Total loss:  -2.789 | PDE Loss:  -3.5343 | Function Loss:  -3.8751\n",
      "Total loss:  -2.7892 | PDE Loss:  -3.5345 | Function Loss:  -3.8752\n",
      "Total loss:  -2.7893 | PDE Loss:  -3.535 | Function Loss:  -3.8752\n",
      "Total loss:  -2.7894 | PDE Loss:  -3.5355 | Function Loss:  -3.8753\n",
      "Total loss:  -2.7895 | PDE Loss:  -3.5364 | Function Loss:  -3.8752\n",
      "Total loss:  -2.7896 | PDE Loss:  -3.5367 | Function Loss:  -3.8752\n",
      "Total loss:  -2.7896 | PDE Loss:  -3.5373 | Function Loss:  -3.8752\n",
      "Total loss:  -2.7897 | PDE Loss:  -3.5377 | Function Loss:  -3.8752\n",
      "Total loss:  -2.7898 | PDE Loss:  -3.5379 | Function Loss:  -3.8752\n",
      "Total loss:  -2.7899 | PDE Loss:  -3.5381 | Function Loss:  -3.8753\n",
      "Total loss:  -2.7899 | PDE Loss:  -3.5382 | Function Loss:  -3.8753\n",
      "Total loss:  -2.79 | PDE Loss:  -3.5384 | Function Loss:  -3.8754\n",
      "Total loss:  -2.7901 | PDE Loss:  -3.5385 | Function Loss:  -3.8755\n",
      "Total loss:  -2.7901 | PDE Loss:  -3.5399 | Function Loss:  -3.8752\n",
      "Total loss:  -2.79 | PDE Loss:  -3.5371 | Function Loss:  -3.8757\n",
      "Total loss:  -2.7902 | PDE Loss:  -3.5392 | Function Loss:  -3.8755\n",
      "Total loss:  -2.7902 | PDE Loss:  -3.5393 | Function Loss:  -3.8755\n",
      "Total loss:  -2.7903 | PDE Loss:  -3.5401 | Function Loss:  -3.8754\n",
      "Total loss:  -2.7904 | PDE Loss:  -3.5413 | Function Loss:  -3.8753\n",
      "Total loss:  -2.7905 | PDE Loss:  -3.5424 | Function Loss:  -3.8751\n",
      "Total loss:  -2.7906 | PDE Loss:  -3.5436 | Function Loss:  -3.875\n",
      "Total loss:  -2.7907 | PDE Loss:  -3.5448 | Function Loss:  -3.8748\n",
      "Total loss:  -2.7907 | PDE Loss:  -3.5469 | Function Loss:  -3.8744\n",
      "Total loss:  -2.7907 | PDE Loss:  -3.5462 | Function Loss:  -3.8746\n",
      "Total loss:  -2.7908 | PDE Loss:  -3.5469 | Function Loss:  -3.8746\n",
      "Total loss:  -2.7909 | PDE Loss:  -3.5478 | Function Loss:  -3.8745\n",
      "Total loss:  -2.7912 | PDE Loss:  -3.5493 | Function Loss:  -3.8744\n",
      "Total loss:  -2.7913 | PDE Loss:  -3.5507 | Function Loss:  -3.8744\n",
      "Total loss:  -2.7915 | PDE Loss:  -3.5512 | Function Loss:  -3.8744\n",
      "Total loss:  -2.7916 | PDE Loss:  -3.5515 | Function Loss:  -3.8745\n",
      "Total loss:  -2.7917 | PDE Loss:  -3.5518 | Function Loss:  -3.8746\n",
      "Total loss:  -2.7919 | PDE Loss:  -3.5532 | Function Loss:  -3.8745\n",
      "Total loss:  -2.7921 | PDE Loss:  -3.5542 | Function Loss:  -3.8745\n",
      "Total loss:  -2.7922 | PDE Loss:  -3.5545 | Function Loss:  -3.8746\n",
      "Total loss:  -2.7923 | PDE Loss:  -3.5546 | Function Loss:  -3.8747\n",
      "Total loss:  -2.7923 | PDE Loss:  -3.5542 | Function Loss:  -3.8748\n",
      "Total loss:  -2.7923 | PDE Loss:  -3.5531 | Function Loss:  -3.8751\n",
      "Total loss:  -2.7924 | PDE Loss:  -3.5538 | Function Loss:  -3.875\n",
      "Total loss:  -2.7924 | PDE Loss:  -3.5537 | Function Loss:  -3.8751\n",
      "Total loss:  -2.7925 | PDE Loss:  -3.5532 | Function Loss:  -3.8752\n",
      "Total loss:  -2.7926 | PDE Loss:  -3.5529 | Function Loss:  -3.8754\n",
      "Total loss:  -2.7926 | PDE Loss:  -3.5523 | Function Loss:  -3.8755\n",
      "Total loss:  -2.7926 | PDE Loss:  -3.5522 | Function Loss:  -3.8756\n",
      "Total loss:  -2.7927 | PDE Loss:  -3.5517 | Function Loss:  -3.8758\n",
      "Total loss:  -2.7927 | PDE Loss:  -3.5515 | Function Loss:  -3.8759\n",
      "Total loss:  -2.7927 | PDE Loss:  -3.5513 | Function Loss:  -3.876\n",
      "Total loss:  -2.7928 | PDE Loss:  -3.551 | Function Loss:  -3.8761\n",
      "Total loss:  -2.7928 | PDE Loss:  -3.5507 | Function Loss:  -3.8762\n",
      "Total loss:  -2.7929 | PDE Loss:  -3.5503 | Function Loss:  -3.8763\n",
      "Total loss:  -2.7929 | PDE Loss:  -3.55 | Function Loss:  -3.8764\n",
      "Total loss:  -2.793 | PDE Loss:  -3.5495 | Function Loss:  -3.8766\n",
      "Total loss:  -2.793 | PDE Loss:  -3.5493 | Function Loss:  -3.8767\n",
      "Total loss:  -2.793 | PDE Loss:  -3.549 | Function Loss:  -3.8768\n",
      "Total loss:  -2.793 | PDE Loss:  -3.5487 | Function Loss:  -3.8769\n",
      "Total loss:  -2.7931 | PDE Loss:  -3.5484 | Function Loss:  -3.877\n",
      "Total loss:  -2.7931 | PDE Loss:  -3.5482 | Function Loss:  -3.877\n",
      "Total loss:  -2.7931 | PDE Loss:  -3.548 | Function Loss:  -3.8771\n",
      "Total loss:  -2.7931 | PDE Loss:  -3.5478 | Function Loss:  -3.8772\n",
      "Total loss:  -2.7932 | PDE Loss:  -3.5477 | Function Loss:  -3.8772\n",
      "Total loss:  -2.7932 | PDE Loss:  -3.5479 | Function Loss:  -3.8773\n",
      "Total loss:  -2.7933 | PDE Loss:  -3.5479 | Function Loss:  -3.8773\n",
      "Total loss:  -2.7934 | PDE Loss:  -3.5482 | Function Loss:  -3.8773\n",
      "Total loss:  -2.7934 | PDE Loss:  -3.5486 | Function Loss:  -3.8773\n",
      "Total loss:  -2.7935 | PDE Loss:  -3.5484 | Function Loss:  -3.8775\n",
      "Total loss:  -2.7935 | PDE Loss:  -3.5491 | Function Loss:  -3.8774\n",
      "Total loss:  -2.7936 | PDE Loss:  -3.5498 | Function Loss:  -3.8773\n",
      "Total loss:  -2.7936 | PDE Loss:  -3.5503 | Function Loss:  -3.8772\n",
      "Total loss:  -2.7936 | PDE Loss:  -3.5508 | Function Loss:  -3.8771\n",
      "Total loss:  -2.7937 | PDE Loss:  -3.5511 | Function Loss:  -3.8771\n",
      "Total loss:  -2.7937 | PDE Loss:  -3.5514 | Function Loss:  -3.8771\n",
      "Total loss:  -2.7937 | PDE Loss:  -3.5516 | Function Loss:  -3.8771\n",
      "Total loss:  -2.7937 | PDE Loss:  -3.5517 | Function Loss:  -3.8771\n",
      "Total loss:  -2.7938 | PDE Loss:  -3.5518 | Function Loss:  -3.8771\n",
      "Total loss:  -2.7938 | PDE Loss:  -3.5518 | Function Loss:  -3.8772\n",
      "Total loss:  -2.7938 | PDE Loss:  -3.5518 | Function Loss:  -3.8772\n",
      "Total loss:  -2.7939 | PDE Loss:  -3.5518 | Function Loss:  -3.8772\n",
      "Total loss:  -2.7939 | PDE Loss:  -3.5518 | Function Loss:  -3.8773\n",
      "Total loss:  -2.794 | PDE Loss:  -3.5519 | Function Loss:  -3.8773\n",
      "Total loss:  -2.794 | PDE Loss:  -3.5518 | Function Loss:  -3.8773\n",
      "Total loss:  -2.794 | PDE Loss:  -3.5519 | Function Loss:  -3.8774\n",
      "Total loss:  -2.794 | PDE Loss:  -3.5517 | Function Loss:  -3.8774\n",
      "Total loss:  -2.7941 | PDE Loss:  -3.5516 | Function Loss:  -3.8775\n",
      "Total loss:  -2.7942 | PDE Loss:  -3.5514 | Function Loss:  -3.8776\n",
      "Total loss:  -2.7942 | PDE Loss:  -3.5511 | Function Loss:  -3.8778\n",
      "Total loss:  -2.7943 | PDE Loss:  -3.5503 | Function Loss:  -3.878\n",
      "Total loss:  -2.7943 | PDE Loss:  -3.5501 | Function Loss:  -3.8782\n",
      "Total loss:  -2.7944 | PDE Loss:  -3.5496 | Function Loss:  -3.8783\n",
      "Total loss:  -2.7945 | PDE Loss:  -3.5493 | Function Loss:  -3.8785\n",
      "Total loss:  -2.7945 | PDE Loss:  -3.5491 | Function Loss:  -3.8786\n",
      "Total loss:  -2.7946 | PDE Loss:  -3.5489 | Function Loss:  -3.8787\n",
      "Total loss:  -2.7947 | PDE Loss:  -3.5489 | Function Loss:  -3.8788\n",
      "Total loss:  -2.7947 | PDE Loss:  -3.549 | Function Loss:  -3.8789\n",
      "Total loss:  -2.7948 | PDE Loss:  -3.5493 | Function Loss:  -3.8789\n",
      "Total loss:  -2.795 | PDE Loss:  -3.5499 | Function Loss:  -3.8789\n",
      "Total loss:  -2.7951 | PDE Loss:  -3.5503 | Function Loss:  -3.879\n",
      "Total loss:  -2.7952 | PDE Loss:  -3.5515 | Function Loss:  -3.8789\n",
      "Total loss:  -2.7955 | PDE Loss:  -3.5526 | Function Loss:  -3.8789\n",
      "Total loss:  -2.7957 | PDE Loss:  -3.5543 | Function Loss:  -3.8789\n",
      "Total loss:  -2.7959 | PDE Loss:  -3.5553 | Function Loss:  -3.8789\n",
      "Total loss:  -2.796 | PDE Loss:  -3.5561 | Function Loss:  -3.8789\n",
      "Total loss:  -2.7961 | PDE Loss:  -3.5567 | Function Loss:  -3.8789\n",
      "Total loss:  -2.7962 | PDE Loss:  -3.5569 | Function Loss:  -3.879\n",
      "Total loss:  -2.7963 | PDE Loss:  -3.557 | Function Loss:  -3.8791\n",
      "Total loss:  -2.7965 | PDE Loss:  -3.5572 | Function Loss:  -3.8792\n",
      "Total loss:  -2.7966 | PDE Loss:  -3.5565 | Function Loss:  -3.8795\n",
      "Total loss:  -2.7967 | PDE Loss:  -3.5571 | Function Loss:  -3.8796\n",
      "Total loss:  -2.7969 | PDE Loss:  -3.5575 | Function Loss:  -3.8797\n",
      "Total loss:  -2.7971 | PDE Loss:  -3.5581 | Function Loss:  -3.8797\n",
      "Total loss:  -2.7973 | PDE Loss:  -3.559 | Function Loss:  -3.8798\n",
      "Total loss:  -2.7974 | PDE Loss:  -3.5598 | Function Loss:  -3.8798\n",
      "Total loss:  -2.7975 | PDE Loss:  -3.5604 | Function Loss:  -3.8798\n",
      "Total loss:  -2.7977 | PDE Loss:  -3.561 | Function Loss:  -3.8799\n",
      "Total loss:  -2.7979 | PDE Loss:  -3.5616 | Function Loss:  -3.88\n",
      "Total loss:  -2.7981 | PDE Loss:  -3.5623 | Function Loss:  -3.8801\n",
      "Total loss:  -2.7982 | PDE Loss:  -3.5624 | Function Loss:  -3.8803\n",
      "Total loss:  -2.7984 | PDE Loss:  -3.563 | Function Loss:  -3.8804\n",
      "Total loss:  -2.7987 | PDE Loss:  -3.564 | Function Loss:  -3.8805\n",
      "Total loss:  -2.799 | PDE Loss:  -3.5643 | Function Loss:  -3.8808\n",
      "Total loss:  -2.7991 | PDE Loss:  -3.5643 | Function Loss:  -3.881\n",
      "Total loss:  -2.7993 | PDE Loss:  -3.5643 | Function Loss:  -3.8811\n",
      "Total loss:  -2.7994 | PDE Loss:  -3.5624 | Function Loss:  -3.8816\n",
      "Total loss:  -2.7995 | PDE Loss:  -3.5629 | Function Loss:  -3.8817\n",
      "Total loss:  -2.7996 | PDE Loss:  -3.5632 | Function Loss:  -3.8818\n",
      "Total loss:  -2.7998 | PDE Loss:  -3.5634 | Function Loss:  -3.8819\n",
      "Total loss:  -2.7999 | PDE Loss:  -3.5632 | Function Loss:  -3.8821\n",
      "Total loss:  -2.8 | PDE Loss:  -3.563 | Function Loss:  -3.8823\n",
      "Total loss:  -2.8002 | PDE Loss:  -3.5637 | Function Loss:  -3.8823\n",
      "Total loss:  -2.8002 | PDE Loss:  -3.5602 | Function Loss:  -3.8831\n",
      "Total loss:  -2.8003 | PDE Loss:  -3.562 | Function Loss:  -3.8829\n",
      "Total loss:  -2.8005 | PDE Loss:  -3.5638 | Function Loss:  -3.8827\n",
      "Total loss:  -2.8007 | PDE Loss:  -3.5653 | Function Loss:  -3.8826\n",
      "Total loss:  -2.8008 | PDE Loss:  -3.5666 | Function Loss:  -3.8825\n",
      "Total loss:  -2.801 | PDE Loss:  -3.567 | Function Loss:  -3.8827\n",
      "Total loss:  -2.8012 | PDE Loss:  -3.5671 | Function Loss:  -3.8828\n",
      "Total loss:  -2.8014 | PDE Loss:  -3.5669 | Function Loss:  -3.8831\n",
      "Total loss:  -2.8016 | PDE Loss:  -3.5665 | Function Loss:  -3.8834\n",
      "Total loss:  -2.8018 | PDE Loss:  -3.5658 | Function Loss:  -3.8838\n",
      "Total loss:  -2.8019 | PDE Loss:  -3.5652 | Function Loss:  -3.8841\n",
      "Total loss:  -2.802 | PDE Loss:  -3.565 | Function Loss:  -3.8843\n",
      "Total loss:  -2.8022 | PDE Loss:  -3.565 | Function Loss:  -3.8845\n",
      "Total loss:  -2.8024 | PDE Loss:  -3.5651 | Function Loss:  -3.8847\n",
      "Total loss:  -2.8026 | PDE Loss:  -3.5655 | Function Loss:  -3.8848\n",
      "Total loss:  -2.8027 | PDE Loss:  -3.5662 | Function Loss:  -3.8849\n",
      "Total loss:  -2.8029 | PDE Loss:  -3.5673 | Function Loss:  -3.8849\n",
      "Total loss:  -2.8031 | PDE Loss:  -3.5679 | Function Loss:  -3.885\n",
      "Total loss:  -2.8032 | PDE Loss:  -3.569 | Function Loss:  -3.8849\n",
      "Total loss:  -2.8033 | PDE Loss:  -3.5697 | Function Loss:  -3.8849\n",
      "Total loss:  -2.8034 | PDE Loss:  -3.5704 | Function Loss:  -3.8849\n",
      "Total loss:  -2.8035 | PDE Loss:  -3.5706 | Function Loss:  -3.8849\n",
      "Total loss:  -2.8036 | PDE Loss:  -3.5705 | Function Loss:  -3.8851\n",
      "Total loss:  -2.8037 | PDE Loss:  -3.5704 | Function Loss:  -3.8852\n",
      "Total loss:  -2.8037 | PDE Loss:  -3.5698 | Function Loss:  -3.8854\n",
      "Total loss:  -2.8038 | PDE Loss:  -3.5695 | Function Loss:  -3.8856\n",
      "Total loss:  -2.804 | PDE Loss:  -3.5681 | Function Loss:  -3.886\n",
      "Total loss:  -2.8041 | PDE Loss:  -3.5677 | Function Loss:  -3.8862\n",
      "Total loss:  -2.8042 | PDE Loss:  -3.5669 | Function Loss:  -3.8865\n",
      "Total loss:  -2.8043 | PDE Loss:  -3.5671 | Function Loss:  -3.8867\n",
      "Total loss:  -2.8044 | PDE Loss:  -3.5672 | Function Loss:  -3.8868\n",
      "Total loss:  -2.8045 | PDE Loss:  -3.5672 | Function Loss:  -3.8868\n",
      "Total loss:  -2.8046 | PDE Loss:  -3.5674 | Function Loss:  -3.8869\n",
      "Total loss:  -2.8046 | PDE Loss:  -3.5674 | Function Loss:  -3.887\n",
      "Total loss:  -2.8047 | PDE Loss:  -3.5678 | Function Loss:  -3.8869\n",
      "Total loss:  -2.8047 | PDE Loss:  -3.5678 | Function Loss:  -3.887\n",
      "Total loss:  -2.8048 | PDE Loss:  -3.5682 | Function Loss:  -3.887\n",
      "Total loss:  -2.8048 | PDE Loss:  -3.5665 | Function Loss:  -3.8874\n",
      "Total loss:  -2.8049 | PDE Loss:  -3.5674 | Function Loss:  -3.8873\n",
      "Total loss:  -2.805 | PDE Loss:  -3.568 | Function Loss:  -3.8873\n",
      "Total loss:  -2.8051 | PDE Loss:  -3.5685 | Function Loss:  -3.8873\n",
      "Total loss:  -2.8052 | PDE Loss:  -3.5686 | Function Loss:  -3.8874\n",
      "Total loss:  -2.8052 | PDE Loss:  -3.5688 | Function Loss:  -3.8874\n",
      "Total loss:  -2.8053 | PDE Loss:  -3.5688 | Function Loss:  -3.8875\n",
      "Total loss:  -2.8054 | PDE Loss:  -3.569 | Function Loss:  -3.8875\n",
      "Total loss:  -2.8055 | PDE Loss:  -3.5689 | Function Loss:  -3.8877\n",
      "Total loss:  -2.8056 | PDE Loss:  -3.569 | Function Loss:  -3.8878\n",
      "Total loss:  -2.8057 | PDE Loss:  -3.5692 | Function Loss:  -3.8879\n",
      "Total loss:  -2.8058 | PDE Loss:  -3.5696 | Function Loss:  -3.8879\n",
      "Total loss:  -2.8059 | PDE Loss:  -3.57 | Function Loss:  -3.888\n",
      "Total loss:  -2.806 | PDE Loss:  -3.5705 | Function Loss:  -3.888\n",
      "Total loss:  -2.8061 | PDE Loss:  -3.571 | Function Loss:  -3.888\n",
      "Total loss:  -2.8062 | PDE Loss:  -3.5715 | Function Loss:  -3.888\n",
      "Total loss:  -2.8063 | PDE Loss:  -3.5718 | Function Loss:  -3.888\n",
      "Total loss:  -2.8063 | PDE Loss:  -3.573 | Function Loss:  -3.8878\n",
      "Total loss:  -2.8065 | PDE Loss:  -3.5731 | Function Loss:  -3.888\n",
      "Total loss:  -2.8066 | PDE Loss:  -3.573 | Function Loss:  -3.8881\n",
      "Total loss:  -2.8067 | PDE Loss:  -3.5729 | Function Loss:  -3.8883\n",
      "Total loss:  -2.8068 | PDE Loss:  -3.5728 | Function Loss:  -3.8885\n",
      "Total loss:  -2.8069 | PDE Loss:  -3.5731 | Function Loss:  -3.8885\n",
      "Total loss:  -2.807 | PDE Loss:  -3.5733 | Function Loss:  -3.8886\n",
      "Total loss:  -2.8071 | PDE Loss:  -3.5738 | Function Loss:  -3.8886\n",
      "Total loss:  -2.8071 | PDE Loss:  -3.5742 | Function Loss:  -3.8886\n",
      "Total loss:  -2.8072 | PDE Loss:  -3.5749 | Function Loss:  -3.8885\n",
      "Total loss:  -2.8072 | PDE Loss:  -3.5755 | Function Loss:  -3.8884\n",
      "Total loss:  -2.8073 | PDE Loss:  -3.5763 | Function Loss:  -3.8883\n",
      "Total loss:  -2.8073 | PDE Loss:  -3.5768 | Function Loss:  -3.8883\n",
      "Total loss:  -2.8074 | PDE Loss:  -3.5773 | Function Loss:  -3.8882\n",
      "Total loss:  -2.8074 | PDE Loss:  -3.5775 | Function Loss:  -3.8882\n",
      "Total loss:  -2.8075 | PDE Loss:  -3.5775 | Function Loss:  -3.8883\n",
      "Total loss:  -2.8075 | PDE Loss:  -3.5774 | Function Loss:  -3.8884\n",
      "Total loss:  -2.8076 | PDE Loss:  -3.5771 | Function Loss:  -3.8885\n",
      "Total loss:  -2.8076 | PDE Loss:  -3.5769 | Function Loss:  -3.8886\n",
      "Total loss:  -2.8077 | PDE Loss:  -3.5766 | Function Loss:  -3.8887\n",
      "Total loss:  -2.8077 | PDE Loss:  -3.5766 | Function Loss:  -3.8888\n",
      "Total loss:  -2.8078 | PDE Loss:  -3.5766 | Function Loss:  -3.8888\n",
      "Total loss:  -2.8078 | PDE Loss:  -3.5768 | Function Loss:  -3.8889\n",
      "Total loss:  -2.8079 | PDE Loss:  -3.5772 | Function Loss:  -3.8889\n",
      "Total loss:  -2.808 | PDE Loss:  -3.578 | Function Loss:  -3.8888\n",
      "Total loss:  -2.8081 | PDE Loss:  -3.5788 | Function Loss:  -3.8887\n",
      "Total loss:  -2.8082 | PDE Loss:  -3.58 | Function Loss:  -3.8886\n",
      "Total loss:  -2.8083 | PDE Loss:  -3.5811 | Function Loss:  -3.8885\n",
      "Total loss:  -2.8084 | PDE Loss:  -3.5818 | Function Loss:  -3.8885\n",
      "Total loss:  -2.8084 | PDE Loss:  -3.582 | Function Loss:  -3.8885\n",
      "Total loss:  -2.8085 | PDE Loss:  -3.5821 | Function Loss:  -3.8886\n",
      "Total loss:  -2.8085 | PDE Loss:  -3.5821 | Function Loss:  -3.8886\n",
      "Total loss:  -2.8085 | PDE Loss:  -3.5819 | Function Loss:  -3.8887\n",
      "Total loss:  -2.8086 | PDE Loss:  -3.5819 | Function Loss:  -3.8888\n",
      "Total loss:  -2.8086 | PDE Loss:  -3.5818 | Function Loss:  -3.8888\n",
      "Total loss:  -2.8086 | PDE Loss:  -3.5815 | Function Loss:  -3.8889\n",
      "Total loss:  -2.8087 | PDE Loss:  -3.5815 | Function Loss:  -3.8889\n",
      "Total loss:  -2.8087 | PDE Loss:  -3.5817 | Function Loss:  -3.8889\n",
      "Total loss:  -2.8087 | PDE Loss:  -3.5819 | Function Loss:  -3.8889\n",
      "Total loss:  -2.8088 | PDE Loss:  -3.5821 | Function Loss:  -3.8889\n",
      "Total loss:  -2.8088 | PDE Loss:  -3.5824 | Function Loss:  -3.8889\n",
      "Total loss:  -2.8089 | PDE Loss:  -3.5826 | Function Loss:  -3.8889\n",
      "Total loss:  -2.8089 | PDE Loss:  -3.5828 | Function Loss:  -3.889\n",
      "Total loss:  -2.8089 | PDE Loss:  -3.5839 | Function Loss:  -3.8888\n",
      "Total loss:  -2.809 | PDE Loss:  -3.5836 | Function Loss:  -3.8889\n",
      "Total loss:  -2.8091 | PDE Loss:  -3.5835 | Function Loss:  -3.889\n",
      "Total loss:  -2.8092 | PDE Loss:  -3.5836 | Function Loss:  -3.8891\n",
      "Total loss:  -2.8093 | PDE Loss:  -3.5838 | Function Loss:  -3.8892\n",
      "Total loss:  -2.8094 | PDE Loss:  -3.5844 | Function Loss:  -3.8892\n",
      "Total loss:  -2.8095 | PDE Loss:  -3.5848 | Function Loss:  -3.8892\n",
      "Total loss:  -2.8095 | PDE Loss:  -3.5856 | Function Loss:  -3.8891\n",
      "Total loss:  -2.8096 | PDE Loss:  -3.586 | Function Loss:  -3.8892\n",
      "Total loss:  -2.8097 | PDE Loss:  -3.5863 | Function Loss:  -3.8891\n",
      "Total loss:  -2.8097 | PDE Loss:  -3.5865 | Function Loss:  -3.8892\n",
      "Total loss:  -2.8098 | PDE Loss:  -3.5868 | Function Loss:  -3.8892\n",
      "Total loss:  -2.8098 | PDE Loss:  -3.5871 | Function Loss:  -3.8892\n",
      "Total loss:  -2.8099 | PDE Loss:  -3.5873 | Function Loss:  -3.8892\n",
      "Total loss:  -2.8099 | PDE Loss:  -3.5876 | Function Loss:  -3.8892\n",
      "Total loss:  -2.8099 | PDE Loss:  -3.5881 | Function Loss:  -3.8891\n",
      "Total loss:  -2.81 | PDE Loss:  -3.5886 | Function Loss:  -3.889\n",
      "Total loss:  -2.81 | PDE Loss:  -3.589 | Function Loss:  -3.889\n",
      "Total loss:  -2.81 | PDE Loss:  -3.5896 | Function Loss:  -3.8889\n",
      "Total loss:  -2.81 | PDE Loss:  -3.59 | Function Loss:  -3.8888\n",
      "Total loss:  -2.81 | PDE Loss:  -3.5905 | Function Loss:  -3.8888\n",
      "Total loss:  -2.8101 | PDE Loss:  -3.5909 | Function Loss:  -3.8887\n",
      "Total loss:  -2.8101 | PDE Loss:  -3.5914 | Function Loss:  -3.8886\n",
      "Total loss:  -2.8101 | PDE Loss:  -3.5917 | Function Loss:  -3.8886\n",
      "Total loss:  -2.8101 | PDE Loss:  -3.5921 | Function Loss:  -3.8886\n",
      "Total loss:  -2.8102 | PDE Loss:  -3.5926 | Function Loss:  -3.8885\n",
      "Total loss:  -2.8102 | PDE Loss:  -3.5927 | Function Loss:  -3.8885\n",
      "Total loss:  -2.8103 | PDE Loss:  -3.593 | Function Loss:  -3.8886\n",
      "Total loss:  -2.8103 | PDE Loss:  -3.593 | Function Loss:  -3.8886\n",
      "Total loss:  -2.8104 | PDE Loss:  -3.5928 | Function Loss:  -3.8887\n",
      "Total loss:  -2.8104 | PDE Loss:  -3.5927 | Function Loss:  -3.8888\n",
      "Total loss:  -2.8105 | PDE Loss:  -3.5928 | Function Loss:  -3.8889\n",
      "Total loss:  -2.8106 | PDE Loss:  -3.5931 | Function Loss:  -3.8889\n",
      "Total loss:  -2.8106 | PDE Loss:  -3.5932 | Function Loss:  -3.8889\n",
      "Total loss:  -2.8106 | PDE Loss:  -3.5936 | Function Loss:  -3.8889\n",
      "Total loss:  -2.8107 | PDE Loss:  -3.594 | Function Loss:  -3.8888\n",
      "Total loss:  -2.8107 | PDE Loss:  -3.5946 | Function Loss:  -3.8888\n",
      "Total loss:  -2.8108 | PDE Loss:  -3.5953 | Function Loss:  -3.8887\n",
      "Total loss:  -2.8108 | PDE Loss:  -3.5958 | Function Loss:  -3.8887\n",
      "Total loss:  -2.8109 | PDE Loss:  -3.5965 | Function Loss:  -3.8886\n",
      "Total loss:  -2.811 | PDE Loss:  -3.5963 | Function Loss:  -3.8888\n",
      "Total loss:  -2.8111 | PDE Loss:  -3.5965 | Function Loss:  -3.8888\n",
      "Total loss:  -2.8111 | PDE Loss:  -3.5962 | Function Loss:  -3.8889\n",
      "Total loss:  -2.8112 | PDE Loss:  -3.5958 | Function Loss:  -3.8891\n",
      "Total loss:  -2.8113 | PDE Loss:  -3.5953 | Function Loss:  -3.8893\n",
      "Total loss:  -2.8113 | PDE Loss:  -3.5948 | Function Loss:  -3.8894\n",
      "Total loss:  -2.8113 | PDE Loss:  -3.5945 | Function Loss:  -3.8895\n",
      "Total loss:  -2.8114 | PDE Loss:  -3.5946 | Function Loss:  -3.8896\n",
      "Total loss:  -2.8115 | PDE Loss:  -3.5946 | Function Loss:  -3.8896\n",
      "Total loss:  -2.8115 | PDE Loss:  -3.595 | Function Loss:  -3.8897\n",
      "Total loss:  -2.8116 | PDE Loss:  -3.5952 | Function Loss:  -3.8897\n",
      "Total loss:  -2.8116 | PDE Loss:  -3.5956 | Function Loss:  -3.8897\n",
      "Total loss:  -2.8117 | PDE Loss:  -3.5959 | Function Loss:  -3.8897\n",
      "Total loss:  -2.8118 | PDE Loss:  -3.5962 | Function Loss:  -3.8898\n",
      "Total loss:  -2.8119 | PDE Loss:  -3.5963 | Function Loss:  -3.8899\n",
      "Total loss:  -2.812 | PDE Loss:  -3.5961 | Function Loss:  -3.8901\n",
      "Total loss:  -2.8122 | PDE Loss:  -3.596 | Function Loss:  -3.8902\n",
      "Total loss:  -2.8123 | PDE Loss:  -3.5958 | Function Loss:  -3.8904\n",
      "Total loss:  -2.8125 | PDE Loss:  -3.5955 | Function Loss:  -3.8907\n",
      "Total loss:  -2.8126 | PDE Loss:  -3.5952 | Function Loss:  -3.8909\n",
      "Total loss:  -2.8127 | PDE Loss:  -3.5947 | Function Loss:  -3.8911\n",
      "Total loss:  -2.8127 | PDE Loss:  -3.5946 | Function Loss:  -3.8912\n",
      "Total loss:  -2.8128 | PDE Loss:  -3.5945 | Function Loss:  -3.8912\n",
      "Total loss:  -2.8128 | PDE Loss:  -3.5947 | Function Loss:  -3.8913\n",
      "Total loss:  -2.8129 | PDE Loss:  -3.595 | Function Loss:  -3.8913\n",
      "Total loss:  -2.8129 | PDE Loss:  -3.5954 | Function Loss:  -3.8912\n",
      "Total loss:  -2.8129 | PDE Loss:  -3.5959 | Function Loss:  -3.8912\n",
      "Total loss:  -2.813 | PDE Loss:  -3.5967 | Function Loss:  -3.8911\n",
      "Total loss:  -2.813 | PDE Loss:  -3.5974 | Function Loss:  -3.891\n",
      "Total loss:  -2.8131 | PDE Loss:  -3.599 | Function Loss:  -3.8908\n",
      "Total loss:  -2.8132 | PDE Loss:  -3.5996 | Function Loss:  -3.8907\n",
      "Total loss:  -2.8132 | PDE Loss:  -3.5997 | Function Loss:  -3.8908\n",
      "Total loss:  -2.8133 | PDE Loss:  -3.5999 | Function Loss:  -3.8908\n",
      "Total loss:  -2.8134 | PDE Loss:  -3.5999 | Function Loss:  -3.8909\n",
      "Total loss:  -2.8134 | PDE Loss:  -3.5999 | Function Loss:  -3.891\n",
      "Total loss:  -2.8135 | PDE Loss:  -3.6 | Function Loss:  -3.891\n",
      "Total loss:  -2.8135 | PDE Loss:  -3.5999 | Function Loss:  -3.8911\n",
      "Total loss:  -2.8136 | PDE Loss:  -3.5999 | Function Loss:  -3.8912\n",
      "Total loss:  -2.8136 | PDE Loss:  -3.6001 | Function Loss:  -3.8912\n",
      "Total loss:  -2.8138 | PDE Loss:  -3.6003 | Function Loss:  -3.8913\n",
      "Total loss:  -2.8139 | PDE Loss:  -3.6005 | Function Loss:  -3.8914\n",
      "Total loss:  -2.814 | PDE Loss:  -3.6009 | Function Loss:  -3.8914\n",
      "Total loss:  -2.8141 | PDE Loss:  -3.6014 | Function Loss:  -3.8915\n",
      "Total loss:  -2.8142 | PDE Loss:  -3.602 | Function Loss:  -3.8915\n",
      "Total loss:  -2.8143 | PDE Loss:  -3.6025 | Function Loss:  -3.8915\n",
      "Total loss:  -2.8144 | PDE Loss:  -3.6029 | Function Loss:  -3.8916\n",
      "Total loss:  -2.8145 | PDE Loss:  -3.6032 | Function Loss:  -3.8916\n",
      "Total loss:  -2.8146 | PDE Loss:  -3.6035 | Function Loss:  -3.8917\n",
      "Total loss:  -2.8147 | PDE Loss:  -3.603 | Function Loss:  -3.8919\n",
      "Total loss:  -2.8148 | PDE Loss:  -3.6033 | Function Loss:  -3.8919\n",
      "Total loss:  -2.8149 | PDE Loss:  -3.6038 | Function Loss:  -3.892\n",
      "Total loss:  -2.815 | PDE Loss:  -3.6044 | Function Loss:  -3.892\n",
      "Total loss:  -2.8152 | PDE Loss:  -3.6052 | Function Loss:  -3.892\n",
      "Total loss:  -2.8153 | PDE Loss:  -3.6062 | Function Loss:  -3.892\n",
      "Total loss:  -2.8154 | PDE Loss:  -3.6073 | Function Loss:  -3.8919\n",
      "Total loss:  -2.8156 | PDE Loss:  -3.6088 | Function Loss:  -3.8918\n",
      "Total loss:  -2.8157 | PDE Loss:  -3.6106 | Function Loss:  -3.8916\n",
      "Total loss:  -2.816 | PDE Loss:  -3.613 | Function Loss:  -3.8914\n",
      "Total loss:  -2.8161 | PDE Loss:  -3.6152 | Function Loss:  -3.8913\n",
      "Total loss:  -2.8163 | PDE Loss:  -3.6165 | Function Loss:  -3.8912\n",
      "Total loss:  -2.8165 | PDE Loss:  -3.6184 | Function Loss:  -3.8911\n",
      "Total loss:  -2.8168 | PDE Loss:  -3.6198 | Function Loss:  -3.8911\n",
      "Total loss:  -2.817 | PDE Loss:  -3.6206 | Function Loss:  -3.8913\n",
      "Total loss:  -2.8172 | PDE Loss:  -3.621 | Function Loss:  -3.8914\n",
      "Total loss:  -2.8174 | PDE Loss:  -3.6208 | Function Loss:  -3.8917\n",
      "Total loss:  -2.8175 | PDE Loss:  -3.6204 | Function Loss:  -3.892\n",
      "Total loss:  -2.8177 | PDE Loss:  -3.6194 | Function Loss:  -3.8923\n",
      "Total loss:  -2.8179 | PDE Loss:  -3.6184 | Function Loss:  -3.8927\n",
      "Total loss:  -2.8181 | PDE Loss:  -3.6178 | Function Loss:  -3.8931\n",
      "Total loss:  -2.8183 | PDE Loss:  -3.617 | Function Loss:  -3.8935\n",
      "Total loss:  -2.8185 | PDE Loss:  -3.6166 | Function Loss:  -3.8938\n",
      "Total loss:  -2.8186 | PDE Loss:  -3.6164 | Function Loss:  -3.8939\n",
      "Total loss:  -2.8187 | PDE Loss:  -3.6165 | Function Loss:  -3.894\n",
      "Total loss:  -2.8188 | PDE Loss:  -3.6168 | Function Loss:  -3.8941\n",
      "Total loss:  -2.8189 | PDE Loss:  -3.6172 | Function Loss:  -3.8942\n",
      "Total loss:  -2.8191 | PDE Loss:  -3.6177 | Function Loss:  -3.8943\n",
      "Total loss:  -2.8192 | PDE Loss:  -3.618 | Function Loss:  -3.8943\n",
      "Total loss:  -2.8193 | PDE Loss:  -3.6181 | Function Loss:  -3.8944\n",
      "Total loss:  -2.8194 | PDE Loss:  -3.6181 | Function Loss:  -3.8946\n",
      "Total loss:  -2.8195 | PDE Loss:  -3.618 | Function Loss:  -3.8947\n",
      "Total loss:  -2.8196 | PDE Loss:  -3.6178 | Function Loss:  -3.8948\n",
      "Total loss:  -2.8197 | PDE Loss:  -3.6176 | Function Loss:  -3.895\n",
      "Total loss:  -2.8198 | PDE Loss:  -3.6174 | Function Loss:  -3.8951\n",
      "Total loss:  -2.8199 | PDE Loss:  -3.6173 | Function Loss:  -3.8953\n",
      "Total loss:  -2.8199 | PDE Loss:  -3.6173 | Function Loss:  -3.8953\n",
      "Total loss:  -2.82 | PDE Loss:  -3.6175 | Function Loss:  -3.8954\n",
      "Total loss:  -2.8201 | PDE Loss:  -3.6179 | Function Loss:  -3.8955\n",
      "Total loss:  -2.8202 | PDE Loss:  -3.6182 | Function Loss:  -3.8955\n",
      "Total loss:  -2.8203 | PDE Loss:  -3.6186 | Function Loss:  -3.8956\n",
      "Total loss:  -2.8204 | PDE Loss:  -3.619 | Function Loss:  -3.8956\n",
      "Total loss:  -2.8205 | PDE Loss:  -3.6195 | Function Loss:  -3.8957\n",
      "Total loss:  -2.8206 | PDE Loss:  -3.62 | Function Loss:  -3.8957\n",
      "Total loss:  -2.8207 | PDE Loss:  -3.6205 | Function Loss:  -3.8957\n",
      "Total loss:  -2.8208 | PDE Loss:  -3.621 | Function Loss:  -3.8957\n",
      "Total loss:  -2.8208 | PDE Loss:  -3.6213 | Function Loss:  -3.8957\n",
      "Total loss:  -2.8209 | PDE Loss:  -3.622 | Function Loss:  -3.8956\n",
      "Total loss:  -2.821 | PDE Loss:  -3.6225 | Function Loss:  -3.8957\n",
      "Total loss:  -2.8211 | PDE Loss:  -3.6225 | Function Loss:  -3.8958\n",
      "Total loss:  -2.8212 | PDE Loss:  -3.6225 | Function Loss:  -3.8958\n",
      "Total loss:  -2.8212 | PDE Loss:  -3.6223 | Function Loss:  -3.896\n",
      "Total loss:  -2.8212 | PDE Loss:  -3.6203 | Function Loss:  -3.8963\n",
      "Total loss:  -2.8213 | PDE Loss:  -3.6216 | Function Loss:  -3.8962\n",
      "Total loss:  -2.8214 | PDE Loss:  -3.6215 | Function Loss:  -3.8963\n",
      "Total loss:  -2.8214 | PDE Loss:  -3.6213 | Function Loss:  -3.8964\n",
      "Total loss:  -2.8215 | PDE Loss:  -3.6213 | Function Loss:  -3.8964\n",
      "Total loss:  -2.8215 | PDE Loss:  -3.6212 | Function Loss:  -3.8965\n",
      "Total loss:  -2.8216 | PDE Loss:  -3.6214 | Function Loss:  -3.8966\n",
      "Total loss:  -2.8217 | PDE Loss:  -3.6216 | Function Loss:  -3.8966\n",
      "Total loss:  -2.8217 | PDE Loss:  -3.622 | Function Loss:  -3.8966\n",
      "Total loss:  -2.8218 | PDE Loss:  -3.6226 | Function Loss:  -3.8966\n",
      "Total loss:  -2.8219 | PDE Loss:  -3.6229 | Function Loss:  -3.8966\n",
      "Total loss:  -2.8219 | PDE Loss:  -3.6234 | Function Loss:  -3.8966\n",
      "Total loss:  -2.822 | PDE Loss:  -3.6239 | Function Loss:  -3.8965\n",
      "Total loss:  -2.822 | PDE Loss:  -3.6242 | Function Loss:  -3.8965\n",
      "Total loss:  -2.822 | PDE Loss:  -3.6244 | Function Loss:  -3.8965\n",
      "Total loss:  -2.8221 | PDE Loss:  -3.6245 | Function Loss:  -3.8966\n",
      "Total loss:  -2.8221 | PDE Loss:  -3.6244 | Function Loss:  -3.8966\n",
      "Total loss:  -2.8222 | PDE Loss:  -3.6243 | Function Loss:  -3.8968\n",
      "Total loss:  -2.8223 | PDE Loss:  -3.6242 | Function Loss:  -3.8968\n",
      "Total loss:  -2.8223 | PDE Loss:  -3.624 | Function Loss:  -3.8969\n",
      "Total loss:  -2.8224 | PDE Loss:  -3.624 | Function Loss:  -3.897\n",
      "Total loss:  -2.8224 | PDE Loss:  -3.6237 | Function Loss:  -3.8971\n",
      "Total loss:  -2.8224 | PDE Loss:  -3.6236 | Function Loss:  -3.8972\n",
      "Total loss:  -2.8225 | PDE Loss:  -3.6234 | Function Loss:  -3.8973\n",
      "Total loss:  -2.8225 | PDE Loss:  -3.6233 | Function Loss:  -3.8973\n",
      "Total loss:  -2.8226 | PDE Loss:  -3.6233 | Function Loss:  -3.8974\n",
      "Total loss:  -2.8226 | PDE Loss:  -3.6233 | Function Loss:  -3.8974\n",
      "Total loss:  -2.8227 | PDE Loss:  -3.6242 | Function Loss:  -3.8973\n",
      "Total loss:  -2.8227 | PDE Loss:  -3.6241 | Function Loss:  -3.8974\n",
      "Total loss:  -2.8227 | PDE Loss:  -3.6241 | Function Loss:  -3.8974\n",
      "Total loss:  -2.8228 | PDE Loss:  -3.6242 | Function Loss:  -3.8975\n",
      "Total loss:  -2.8228 | PDE Loss:  -3.6243 | Function Loss:  -3.8975\n",
      "Total loss:  -2.8229 | PDE Loss:  -3.6249 | Function Loss:  -3.8975\n",
      "Total loss:  -2.823 | PDE Loss:  -3.6237 | Function Loss:  -3.8978\n",
      "Total loss:  -2.8231 | PDE Loss:  -3.6243 | Function Loss:  -3.8978\n",
      "Total loss:  -2.8231 | PDE Loss:  -3.6246 | Function Loss:  -3.8978\n",
      "Total loss:  -2.8232 | PDE Loss:  -3.6248 | Function Loss:  -3.8978\n",
      "Total loss:  -2.8233 | PDE Loss:  -3.6248 | Function Loss:  -3.898\n",
      "Total loss:  -2.8234 | PDE Loss:  -3.6234 | Function Loss:  -3.8984\n",
      "Total loss:  -2.8236 | PDE Loss:  -3.6224 | Function Loss:  -3.8987\n",
      "Total loss:  -2.8236 | PDE Loss:  -3.6226 | Function Loss:  -3.8988\n",
      "Total loss:  -2.8237 | PDE Loss:  -3.6225 | Function Loss:  -3.8989\n",
      "Total loss:  -2.8238 | PDE Loss:  -3.6226 | Function Loss:  -3.899\n",
      "Total loss:  -2.8238 | PDE Loss:  -3.6223 | Function Loss:  -3.8991\n",
      "Total loss:  -2.8239 | PDE Loss:  -3.6222 | Function Loss:  -3.8991\n",
      "Total loss:  -2.8239 | PDE Loss:  -3.6219 | Function Loss:  -3.8992\n",
      "Total loss:  -2.824 | PDE Loss:  -3.6217 | Function Loss:  -3.8994\n",
      "Total loss:  -2.8241 | PDE Loss:  -3.6216 | Function Loss:  -3.8995\n",
      "Total loss:  -2.8242 | PDE Loss:  -3.6215 | Function Loss:  -3.8996\n",
      "Total loss:  -2.8243 | PDE Loss:  -3.6217 | Function Loss:  -3.8997\n",
      "Total loss:  -2.8244 | PDE Loss:  -3.6218 | Function Loss:  -3.8998\n",
      "Final Loss:  -2.8243534564971924\n"
     ]
    }
   ],
   "source": [
    "pinn = Pinns(n_int, n_sb, n_tb, 0, 1, **kwargs)\n",
    "hist = pinn.fit(num_epochs=1, max_iter=5000, verbose=True)\n",
    "\n",
    "pins_phases.append(pinn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "torch.save(pinn.approximate_solution.state_dict(), 'saved_models/pinn_0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idle\n",
      "##############################  Phase 1  ##############################\n",
      "################################  0  ################################\n",
      "Total loss:  1.8798 | PDE Loss:  -0.0106 | Function Loss:  0.8742\n",
      "Total loss:  1.866 | PDE Loss:  0.1218 | Function Loss:  0.8581\n",
      "Total loss:  1.7591 | PDE Loss:  0.841 | Function Loss:  0.7033\n",
      "Total loss:  1.6443 | PDE Loss:  1.3874 | Function Loss:  0.294\n",
      "Total loss:  1.5557 | PDE Loss:  1.2068 | Function Loss:  0.2977\n",
      "Total loss:  1.3997 | PDE Loss:  0.4823 | Function Loss:  0.3438\n",
      "Total loss:  1.2674 | PDE Loss:  -0.8335 | Function Loss:  0.2639\n",
      "Total loss:  1.2506 | PDE Loss:  -0.2359 | Function Loss:  0.2362\n",
      "Total loss:  1.2076 | PDE Loss:  -1.274 | Function Loss:  0.2062\n",
      "Total loss:  1.2058 | PDE Loss:  -1.8312 | Function Loss:  0.2054\n",
      "Total loss:  1.2045 | PDE Loss:  -1.9935 | Function Loss:  0.2043\n",
      "Total loss:  1.2018 | PDE Loss:  -1.6248 | Function Loss:  0.2012\n",
      "Total loss:  1.1965 | PDE Loss:  -1.0648 | Function Loss:  0.1942\n",
      "Total loss:  1.1883 | PDE Loss:  -0.6293 | Function Loss:  0.1817\n",
      "Total loss:  1.1788 | PDE Loss:  -0.3579 | Function Loss:  0.166\n",
      "Total loss:  1.1695 | PDE Loss:  -0.2871 | Function Loss:  0.1541\n",
      "Total loss:  1.157 | PDE Loss:  -0.456 | Function Loss:  0.1462\n",
      "Total loss:  1.1495 | PDE Loss:  -0.4559 | Function Loss:  0.1386\n",
      "Total loss:  1.1464 | PDE Loss:  -0.434 | Function Loss:  0.1348\n",
      "Total loss:  1.1433 | PDE Loss:  -0.4005 | Function Loss:  0.1307\n",
      "Total loss:  1.1373 | PDE Loss:  -0.3243 | Function Loss:  0.122\n",
      "Total loss:  1.1297 | PDE Loss:  -0.171 | Function Loss:  0.1074\n",
      "Total loss:  1.1243 | PDE Loss:  -0.1085 | Function Loss:  0.0982\n",
      "Total loss:  1.1191 | PDE Loss:  -0.0309 | Function Loss:  0.0872\n",
      "Total loss:  1.1111 | PDE Loss:  0.0348 | Function Loss:  0.0731\n",
      "Total loss:  1.1061 | PDE Loss:  0.0477 | Function Loss:  0.0664\n",
      "Total loss:  1.1001 | PDE Loss:  0.047 | Function Loss:  0.0599\n",
      "Total loss:  1.0892 | PDE Loss:  -0.0134 | Function Loss:  0.0535\n",
      "Total loss:  1.0813 | PDE Loss:  -0.2177 | Function Loss:  0.0589\n",
      "Total loss:  1.0706 | PDE Loss:  -0.2725 | Function Loss:  0.0505\n",
      "Total loss:  1.0606 | PDE Loss:  -0.3039 | Function Loss:  0.0414\n",
      "Total loss:  1.0497 | PDE Loss:  -0.4703 | Function Loss:  0.0364\n",
      "Total loss:  1.0446 | PDE Loss:  -0.5886 | Function Loss:  0.0343\n",
      "Total loss:  1.0373 | PDE Loss:  -0.6479 | Function Loss:  0.0283\n",
      "Total loss:  1.0314 | PDE Loss:  -0.6249 | Function Loss:  0.0217\n",
      "Total loss:  1.0237 | PDE Loss:  -0.5493 | Function Loss:  0.0119\n",
      "Total loss:  0.9979 | PDE Loss:  -0.3279 | Function Loss:  -0.0231\n",
      "Total loss:  0.9806 | PDE Loss:  -0.0912 | Function Loss:  -0.0579\n",
      "Total loss:  0.9729 | PDE Loss:  -0.1531 | Function Loss:  -0.0609\n",
      "Total loss:  0.9625 | PDE Loss:  -0.2186 | Function Loss:  -0.0671\n",
      "Total loss:  0.9341 | PDE Loss:  -0.4137 | Function Loss:  -0.0859\n",
      "Total loss:  0.9099 | PDE Loss:  -0.6307 | Function Loss:  -0.1028\n",
      "Total loss:  0.8849 | PDE Loss:  -0.8754 | Function Loss:  -0.1227\n",
      "Total loss:  0.8469 | PDE Loss:  -1.0356 | Function Loss:  -0.1588\n",
      "Total loss:  0.8062 | PDE Loss:  -0.9557 | Function Loss:  -0.2013\n",
      "Total loss:  0.7861 | PDE Loss:  -0.9488 | Function Loss:  -0.222\n",
      "Total loss:  0.7225 | PDE Loss:  -0.5318 | Function Loss:  -0.3024\n",
      "Total loss:  0.6539 | PDE Loss:  -0.2915 | Function Loss:  -0.3983\n",
      "Total loss:  0.6628 | PDE Loss:  -0.1159 | Function Loss:  -0.4163\n",
      "Total loss:  0.6247 | PDE Loss:  -0.2197 | Function Loss:  -0.4423\n",
      "Total loss:  0.6078 | PDE Loss:  -0.4287 | Function Loss:  -0.4341\n",
      "Total loss:  0.6032 | PDE Loss:  -0.3531 | Function Loss:  -0.4477\n",
      "Total loss:  0.5999 | PDE Loss:  -0.3409 | Function Loss:  -0.453\n",
      "Total loss:  0.5959 | PDE Loss:  -0.287 | Function Loss:  -0.4651\n",
      "Total loss:  0.593 | PDE Loss:  -0.248 | Function Loss:  -0.4747\n",
      "Total loss:  0.5913 | PDE Loss:  -0.2136 | Function Loss:  -0.4828\n",
      "Total loss:  0.5888 | PDE Loss:  -0.209 | Function Loss:  -0.4865\n",
      "Total loss:  0.5786 | PDE Loss:  -0.2162 | Function Loss:  -0.4973\n",
      "Total loss:  0.5581 | PDE Loss:  -0.2665 | Function Loss:  -0.5124\n",
      "Total loss:  0.5196 | PDE Loss:  -0.3985 | Function Loss:  -0.5363\n",
      "Total loss:  0.4878 | PDE Loss:  -0.4524 | Function Loss:  -0.5652\n",
      "Total loss:  0.4806 | PDE Loss:  -0.4549 | Function Loss:  -0.5729\n",
      "Total loss:  0.461 | PDE Loss:  -0.7331 | Function Loss:  -0.5677\n",
      "Total loss:  0.4504 | PDE Loss:  -0.8543 | Function Loss:  -0.5717\n",
      "Total loss:  0.4447 | PDE Loss:  -0.9319 | Function Loss:  -0.574\n",
      "Total loss:  0.4372 | PDE Loss:  -1.0247 | Function Loss:  -0.578\n",
      "Total loss:  0.4276 | PDE Loss:  -1.0528 | Function Loss:  -0.587\n",
      "Total loss:  0.4092 | PDE Loss:  -0.9944 | Function Loss:  -0.6083\n",
      "Total loss:  0.368 | PDE Loss:  -0.7923 | Function Loss:  -0.6631\n",
      "Total loss:  0.3492 | PDE Loss:  -0.4713 | Function Loss:  -0.722\n",
      "Total loss:  0.3391 | PDE Loss:  -0.6473 | Function Loss:  -0.7082\n",
      "Total loss:  0.3252 | PDE Loss:  -0.7738 | Function Loss:  -0.7108\n",
      "Total loss:  0.2935 | PDE Loss:  -0.8282 | Function Loss:  -0.7406\n",
      "Total loss:  0.308 | PDE Loss:  -0.633 | Function Loss:  -0.7448\n",
      "Total loss:  0.2608 | PDE Loss:  -0.8507 | Function Loss:  -0.7741\n",
      "Total loss:  0.2454 | PDE Loss:  -0.9557 | Function Loss:  -0.7828\n",
      "Total loss:  0.2388 | PDE Loss:  -0.9343 | Function Loss:  -0.7914\n",
      "Total loss:  0.2287 | PDE Loss:  -0.9099 | Function Loss:  -0.804\n",
      "Total loss:  0.2229 | PDE Loss:  -0.8419 | Function Loss:  -0.8162\n",
      "Total loss:  0.2029 | PDE Loss:  -0.8129 | Function Loss:  -0.8412\n",
      "Total loss:  0.2046 | PDE Loss:  -0.4648 | Function Loss:  -0.9\n",
      "Total loss:  0.1875 | PDE Loss:  -0.6772 | Function Loss:  -0.8762\n",
      "Total loss:  0.1751 | PDE Loss:  -0.6593 | Function Loss:  -0.8937\n",
      "Total loss:  0.1331 | PDE Loss:  -0.6775 | Function Loss:  -0.9399\n",
      "Total loss:  0.1013 | PDE Loss:  -0.6996 | Function Loss:  -0.9735\n",
      "Total loss:  0.0751 | PDE Loss:  -0.6739 | Function Loss:  -1.0102\n",
      "Total loss:  0.0616 | PDE Loss:  -0.6388 | Function Loss:  -1.0349\n",
      "Total loss:  0.0455 | PDE Loss:  -0.6161 | Function Loss:  -1.0613\n",
      "Total loss:  0.0378 | PDE Loss:  -0.6183 | Function Loss:  -1.0706\n",
      "Total loss:  0.0325 | PDE Loss:  -0.6387 | Function Loss:  -1.0717\n",
      "Total loss:  0.0296 | PDE Loss:  -0.648 | Function Loss:  -1.0729\n",
      "Total loss:  0.028 | PDE Loss:  -0.6485 | Function Loss:  -1.0747\n",
      "Total loss:  0.026 | PDE Loss:  -0.6581 | Function Loss:  -1.0747\n",
      "Total loss:  0.0235 | PDE Loss:  -0.6738 | Function Loss:  -1.0739\n",
      "Total loss:  0.0214 | PDE Loss:  -0.6884 | Function Loss:  -1.0728\n",
      "Total loss:  0.0192 | PDE Loss:  -0.7051 | Function Loss:  -1.0716\n",
      "Total loss:  0.0173 | PDE Loss:  -0.717 | Function Loss:  -1.0712\n",
      "Total loss:  0.0155 | PDE Loss:  -0.7294 | Function Loss:  -1.0706\n",
      "Total loss:  0.0133 | PDE Loss:  -0.7424 | Function Loss:  -1.0705\n",
      "Total loss:  0.0103 | PDE Loss:  -0.761 | Function Loss:  -1.0702\n",
      "Total loss:  0.0065 | PDE Loss:  -0.7832 | Function Loss:  -1.0705\n",
      "Total loss:  0.0032 | PDE Loss:  -0.806 | Function Loss:  -1.0701\n",
      "Total loss:  0.0007 | PDE Loss:  -0.8226 | Function Loss:  -1.07\n",
      "Total loss:  -0.0015 | PDE Loss:  -0.8365 | Function Loss:  -1.0702\n",
      "Total loss:  -0.0038 | PDE Loss:  -0.8477 | Function Loss:  -1.0709\n",
      "Total loss:  -0.0062 | PDE Loss:  -0.8583 | Function Loss:  -1.072\n",
      "Total loss:  -0.0089 | PDE Loss:  -0.8646 | Function Loss:  -1.0741\n",
      "Total loss:  -0.012 | PDE Loss:  -0.8717 | Function Loss:  -1.0766\n",
      "Total loss:  -0.0151 | PDE Loss:  -0.8722 | Function Loss:  -1.0801\n",
      "Total loss:  -0.018 | PDE Loss:  -0.8793 | Function Loss:  -1.0824\n",
      "Total loss:  -0.0214 | PDE Loss:  -0.8817 | Function Loss:  -1.0859\n",
      "Total loss:  -0.0228 | PDE Loss:  -0.8872 | Function Loss:  -1.0866\n",
      "Total loss:  -0.0234 | PDE Loss:  -0.8895 | Function Loss:  -1.087\n",
      "Total loss:  -0.0237 | PDE Loss:  -0.8915 | Function Loss:  -1.0869\n",
      "Total loss:  -0.0241 | PDE Loss:  -0.8929 | Function Loss:  -1.0872\n",
      "Total loss:  -0.0249 | PDE Loss:  -0.8936 | Function Loss:  -1.088\n",
      "Total loss:  -0.026 | PDE Loss:  -0.8929 | Function Loss:  -1.0895\n",
      "Total loss:  -0.0272 | PDE Loss:  -0.8907 | Function Loss:  -1.0911\n",
      "Total loss:  -0.0284 | PDE Loss:  -0.8884 | Function Loss:  -1.093\n",
      "Total loss:  -0.0307 | PDE Loss:  -0.8868 | Function Loss:  -1.0958\n",
      "Total loss:  -0.0345 | PDE Loss:  -0.8889 | Function Loss:  -1.0999\n",
      "Total loss:  -0.0382 | PDE Loss:  -0.8899 | Function Loss:  -1.104\n",
      "Total loss:  -0.0416 | PDE Loss:  -0.8937 | Function Loss:  -1.1074\n",
      "Total loss:  -0.0448 | PDE Loss:  -0.8854 | Function Loss:  -1.1125\n",
      "Total loss:  -0.0461 | PDE Loss:  -0.8841 | Function Loss:  -1.1142\n",
      "Total loss:  -0.047 | PDE Loss:  -0.8799 | Function Loss:  -1.116\n",
      "Total loss:  -0.0478 | PDE Loss:  -0.8728 | Function Loss:  -1.1182\n",
      "Total loss:  -0.0485 | PDE Loss:  -0.8695 | Function Loss:  -1.1197\n",
      "Total loss:  -0.0492 | PDE Loss:  -0.869 | Function Loss:  -1.1206\n",
      "Total loss:  -0.05 | PDE Loss:  -0.8686 | Function Loss:  -1.1215\n",
      "Total loss:  -0.0506 | PDE Loss:  -0.8696 | Function Loss:  -1.122\n",
      "Total loss:  -0.0511 | PDE Loss:  -0.8691 | Function Loss:  -1.1228\n",
      "Total loss:  -0.0518 | PDE Loss:  -0.8683 | Function Loss:  -1.1237\n",
      "Total loss:  -0.0526 | PDE Loss:  -0.8655 | Function Loss:  -1.1251\n",
      "Total loss:  -0.0536 | PDE Loss:  -0.862 | Function Loss:  -1.127\n",
      "Total loss:  -0.0548 | PDE Loss:  -0.8558 | Function Loss:  -1.1295\n",
      "Total loss:  -0.0564 | PDE Loss:  -0.8495 | Function Loss:  -1.1326\n",
      "Total loss:  -0.0583 | PDE Loss:  -0.8422 | Function Loss:  -1.1363\n",
      "Total loss:  -0.061 | PDE Loss:  -0.8326 | Function Loss:  -1.1415\n",
      "Total loss:  -0.0636 | PDE Loss:  -0.8189 | Function Loss:  -1.1475\n",
      "Total loss:  -0.0658 | PDE Loss:  -0.8059 | Function Loss:  -1.153\n",
      "Total loss:  -0.0665 | PDE Loss:  -0.7988 | Function Loss:  -1.1554\n",
      "Total loss:  -0.0667 | PDE Loss:  -0.796 | Function Loss:  -1.1563\n",
      "Total loss:  -0.0669 | PDE Loss:  -0.7949 | Function Loss:  -1.1569\n",
      "Total loss:  -0.0673 | PDE Loss:  -0.7938 | Function Loss:  -1.1576\n",
      "Total loss:  -0.068 | PDE Loss:  -0.7967 | Function Loss:  -1.1577\n",
      "Total loss:  -0.0692 | PDE Loss:  -0.802 | Function Loss:  -1.1581\n",
      "Total loss:  -0.0707 | PDE Loss:  -0.8125 | Function Loss:  -1.1576\n",
      "Total loss:  -0.0726 | PDE Loss:  -0.8256 | Function Loss:  -1.157\n",
      "Total loss:  -0.0742 | PDE Loss:  -0.8368 | Function Loss:  -1.1566\n",
      "Total loss:  -0.0761 | PDE Loss:  -0.8537 | Function Loss:  -1.1554\n",
      "Total loss:  -0.0775 | PDE Loss:  -0.8556 | Function Loss:  -1.1567\n",
      "Total loss:  -0.0794 | PDE Loss:  -0.8611 | Function Loss:  -1.1579\n",
      "Total loss:  -0.0822 | PDE Loss:  -0.8696 | Function Loss:  -1.1595\n",
      "Total loss:  -0.0836 | PDE Loss:  -0.8683 | Function Loss:  -1.1615\n",
      "Total loss:  -0.0848 | PDE Loss:  -0.8734 | Function Loss:  -1.1619\n",
      "Total loss:  -0.0871 | PDE Loss:  -0.8739 | Function Loss:  -1.1646\n",
      "Total loss:  -0.0897 | PDE Loss:  -0.8803 | Function Loss:  -1.1665\n",
      "Total loss:  -0.0919 | PDE Loss:  -0.8895 | Function Loss:  -1.1673\n",
      "Total loss:  -0.0941 | PDE Loss:  -0.8974 | Function Loss:  -1.1685\n",
      "Total loss:  -0.0968 | PDE Loss:  -0.9241 | Function Loss:  -1.1668\n",
      "Total loss:  -0.0988 | PDE Loss:  -0.943 | Function Loss:  -1.1659\n",
      "Total loss:  -0.0999 | PDE Loss:  -0.9544 | Function Loss:  -1.1653\n",
      "Total loss:  -0.1008 | PDE Loss:  -0.9878 | Function Loss:  -1.1612\n",
      "Total loss:  -0.1029 | PDE Loss:  -0.9987 | Function Loss:  -1.162\n",
      "Total loss:  -0.1046 | PDE Loss:  -0.9915 | Function Loss:  -1.165\n",
      "Total loss:  -0.1059 | PDE Loss:  -1.0083 | Function Loss:  -1.1639\n",
      "Total loss:  -0.1078 | PDE Loss:  -1.0403 | Function Loss:  -1.1617\n",
      "Total loss:  -0.1101 | PDE Loss:  -1.0753 | Function Loss:  -1.1599\n",
      "Total loss:  -0.1129 | PDE Loss:  -1.1155 | Function Loss:  -1.1584\n",
      "Total loss:  -0.1142 | PDE Loss:  -1.14 | Function Loss:  -1.1572\n",
      "Total loss:  -0.1171 | PDE Loss:  -1.1514 | Function Loss:  -1.1592\n",
      "Total loss:  -0.1195 | PDE Loss:  -1.1545 | Function Loss:  -1.1616\n",
      "Total loss:  -0.1224 | PDE Loss:  -1.1509 | Function Loss:  -1.1651\n",
      "Total loss:  -0.1238 | PDE Loss:  -1.1404 | Function Loss:  -1.1677\n",
      "Total loss:  -0.1245 | PDE Loss:  -1.1349 | Function Loss:  -1.1692\n",
      "Total loss:  -0.1249 | PDE Loss:  -1.1354 | Function Loss:  -1.1696\n",
      "Total loss:  -0.1256 | PDE Loss:  -1.1354 | Function Loss:  -1.1703\n",
      "Total loss:  -0.1262 | PDE Loss:  -1.1333 | Function Loss:  -1.1712\n",
      "Total loss:  -0.1269 | PDE Loss:  -1.1357 | Function Loss:  -1.1717\n",
      "Total loss:  -0.1277 | PDE Loss:  -1.1321 | Function Loss:  -1.173\n",
      "Total loss:  -0.1289 | PDE Loss:  -1.1361 | Function Loss:  -1.1739\n",
      "Total loss:  -0.1308 | PDE Loss:  -1.1384 | Function Loss:  -1.1757\n",
      "Total loss:  -0.1329 | PDE Loss:  -1.1425 | Function Loss:  -1.1776\n",
      "Total loss:  -0.1345 | PDE Loss:  -1.16 | Function Loss:  -1.1776\n",
      "Total loss:  -0.1357 | PDE Loss:  -1.1618 | Function Loss:  -1.1786\n",
      "Total loss:  -0.137 | PDE Loss:  -1.1706 | Function Loss:  -1.1792\n",
      "Total loss:  -0.1403 | PDE Loss:  -1.205 | Function Loss:  -1.1795\n",
      "Total loss:  -0.1452 | PDE Loss:  -1.257 | Function Loss:  -1.1801\n",
      "Total loss:  -0.1501 | PDE Loss:  -1.3297 | Function Loss:  -1.1798\n",
      "Total loss:  -0.1559 | PDE Loss:  -1.4018 | Function Loss:  -1.1813\n",
      "Total loss:  -0.1631 | PDE Loss:  -1.5182 | Function Loss:  -1.1827\n",
      "Total loss:  -0.1676 | PDE Loss:  -1.5641 | Function Loss:  -1.1854\n",
      "Total loss:  -0.1707 | PDE Loss:  -1.5837 | Function Loss:  -1.1879\n",
      "Total loss:  -0.1735 | PDE Loss:  -1.6144 | Function Loss:  -1.1895\n",
      "Total loss:  -0.1757 | PDE Loss:  -1.6093 | Function Loss:  -1.192\n",
      "Total loss:  -0.1771 | PDE Loss:  -1.6319 | Function Loss:  -1.1926\n",
      "Total loss:  -0.1788 | PDE Loss:  -1.65 | Function Loss:  -1.1937\n",
      "Total loss:  -0.1805 | PDE Loss:  -1.6908 | Function Loss:  -1.1941\n",
      "Total loss:  -0.1817 | PDE Loss:  -1.7153 | Function Loss:  -1.1946\n",
      "Total loss:  -0.1824 | PDE Loss:  -1.737 | Function Loss:  -1.1947\n",
      "Total loss:  -0.1831 | PDE Loss:  -1.758 | Function Loss:  -1.1948\n",
      "Total loss:  -0.1838 | PDE Loss:  -1.767 | Function Loss:  -1.1953\n",
      "Total loss:  -0.1846 | PDE Loss:  -1.7861 | Function Loss:  -1.1956\n",
      "Total loss:  -0.1854 | PDE Loss:  -1.7882 | Function Loss:  -1.1964\n",
      "Total loss:  -0.1866 | PDE Loss:  -1.7954 | Function Loss:  -1.1974\n",
      "Total loss:  -0.1887 | PDE Loss:  -1.7998 | Function Loss:  -1.1995\n",
      "Total loss:  -0.1918 | PDE Loss:  -1.7906 | Function Loss:  -1.2029\n",
      "Total loss:  -0.1956 | PDE Loss:  -1.7859 | Function Loss:  -1.2069\n",
      "Total loss:  -0.1983 | PDE Loss:  -1.7791 | Function Loss:  -1.2099\n",
      "Total loss:  -0.2029 | PDE Loss:  -1.8084 | Function Loss:  -1.2138\n",
      "Total loss:  -0.2067 | PDE Loss:  -1.8 | Function Loss:  -1.218\n",
      "Total loss:  -0.2016 | PDE Loss:  -1.6163 | Function Loss:  -1.2186\n",
      "Total loss:  -0.2095 | PDE Loss:  -1.8043 | Function Loss:  -1.2207\n",
      "Total loss:  -0.2127 | PDE Loss:  -1.8283 | Function Loss:  -1.2234\n",
      "Total loss:  -0.2154 | PDE Loss:  -1.8191 | Function Loss:  -1.2263\n",
      "Total loss:  -0.2176 | PDE Loss:  -1.8039 | Function Loss:  -1.229\n",
      "Total loss:  -0.2198 | PDE Loss:  -1.7711 | Function Loss:  -1.2322\n",
      "Total loss:  -0.2224 | PDE Loss:  -1.7408 | Function Loss:  -1.2357\n",
      "Total loss:  -0.2243 | PDE Loss:  -1.7077 | Function Loss:  -1.2388\n",
      "Total loss:  -0.2263 | PDE Loss:  -1.6726 | Function Loss:  -1.2421\n",
      "Total loss:  -0.2288 | PDE Loss:  -1.6466 | Function Loss:  -1.2457\n",
      "Total loss:  -0.2304 | PDE Loss:  -1.5685 | Function Loss:  -1.2509\n",
      "Total loss:  -0.2353 | PDE Loss:  -1.5626 | Function Loss:  -1.2562\n",
      "Total loss:  -0.2398 | PDE Loss:  -1.5578 | Function Loss:  -1.2612\n",
      "Total loss:  -0.2438 | PDE Loss:  -1.5405 | Function Loss:  -1.2663\n",
      "Total loss:  -0.2469 | PDE Loss:  -1.4852 | Function Loss:  -1.2727\n",
      "Total loss:  -0.2461 | PDE Loss:  -1.4625 | Function Loss:  -1.2734\n",
      "Total loss:  -0.2483 | PDE Loss:  -1.4856 | Function Loss:  -1.2742\n",
      "Total loss:  -0.25 | PDE Loss:  -1.4434 | Function Loss:  -1.2787\n",
      "Total loss:  -0.251 | PDE Loss:  -1.4314 | Function Loss:  -1.2807\n",
      "Total loss:  -0.2523 | PDE Loss:  -1.4068 | Function Loss:  -1.2839\n",
      "Total loss:  -0.2547 | PDE Loss:  -1.3681 | Function Loss:  -1.2895\n",
      "Total loss:  -0.2561 | PDE Loss:  -1.3352 | Function Loss:  -1.2939\n",
      "Total loss:  -0.2568 | PDE Loss:  -1.2998 | Function Loss:  -1.2981\n",
      "Total loss:  -0.2579 | PDE Loss:  -1.2702 | Function Loss:  -1.3023\n",
      "Total loss:  -0.2587 | PDE Loss:  -1.2391 | Function Loss:  -1.3067\n",
      "Total loss:  -0.2597 | PDE Loss:  -1.225 | Function Loss:  -1.3095\n",
      "Total loss:  -0.2625 | PDE Loss:  -1.1902 | Function Loss:  -1.3171\n",
      "Total loss:  -0.2651 | PDE Loss:  -1.1427 | Function Loss:  -1.3269\n",
      "Total loss:  -0.2684 | PDE Loss:  -1.1663 | Function Loss:  -1.3271\n",
      "Total loss:  -0.2723 | PDE Loss:  -1.137 | Function Loss:  -1.336\n",
      "Total loss:  -0.2774 | PDE Loss:  -1.141 | Function Loss:  -1.3413\n",
      "Total loss:  -0.2826 | PDE Loss:  -1.1551 | Function Loss:  -1.3452\n",
      "Total loss:  -0.2865 | PDE Loss:  -1.1539 | Function Loss:  -1.3499\n",
      "Total loss:  -0.2899 | PDE Loss:  -1.1604 | Function Loss:  -1.3528\n",
      "Total loss:  -0.2906 | PDE Loss:  -1.1057 | Function Loss:  -1.3628\n",
      "Total loss:  -0.2919 | PDE Loss:  -1.1316 | Function Loss:  -1.3598\n",
      "Total loss:  -0.2936 | PDE Loss:  -1.1304 | Function Loss:  -1.362\n",
      "Total loss:  -0.2957 | PDE Loss:  -1.1246 | Function Loss:  -1.3654\n",
      "Total loss:  -0.2989 | PDE Loss:  -1.1204 | Function Loss:  -1.3699\n",
      "Total loss:  -0.3019 | PDE Loss:  -1.1176 | Function Loss:  -1.374\n",
      "Total loss:  -0.304 | PDE Loss:  -1.1115 | Function Loss:  -1.3775\n",
      "Total loss:  -0.3061 | PDE Loss:  -1.1051 | Function Loss:  -1.3813\n",
      "Total loss:  -0.3095 | PDE Loss:  -1.095 | Function Loss:  -1.3872\n",
      "Total loss:  -0.313 | PDE Loss:  -1.0963 | Function Loss:  -1.3911\n",
      "Total loss:  -0.313 | PDE Loss:  -1.0745 | Function Loss:  -1.3956\n",
      "Total loss:  -0.3145 | PDE Loss:  -1.0879 | Function Loss:  -1.3947\n",
      "Total loss:  -0.3182 | PDE Loss:  -1.1129 | Function Loss:  -1.3941\n",
      "Total loss:  -0.3206 | PDE Loss:  -1.1356 | Function Loss:  -1.3927\n",
      "Total loss:  -0.3231 | PDE Loss:  -1.165 | Function Loss:  -1.3906\n",
      "Total loss:  -0.325 | PDE Loss:  -1.1906 | Function Loss:  -1.3886\n",
      "Total loss:  -0.3265 | PDE Loss:  -1.2083 | Function Loss:  -1.3877\n",
      "Total loss:  -0.3281 | PDE Loss:  -1.2265 | Function Loss:  -1.3868\n",
      "Total loss:  -0.3303 | PDE Loss:  -1.2427 | Function Loss:  -1.3869\n",
      "Total loss:  -0.3345 | PDE Loss:  -1.2684 | Function Loss:  -1.3882\n",
      "Total loss:  -0.3405 | PDE Loss:  -1.294 | Function Loss:  -1.3918\n",
      "Total loss:  -0.3484 | PDE Loss:  -1.3151 | Function Loss:  -1.398\n",
      "Total loss:  -0.3553 | PDE Loss:  -1.3189 | Function Loss:  -1.4053\n",
      "Total loss:  -0.36 | PDE Loss:  -1.2876 | Function Loss:  -1.4146\n",
      "Total loss:  -0.3655 | PDE Loss:  -1.2953 | Function Loss:  -1.4198\n",
      "Total loss:  -0.3705 | PDE Loss:  -1.302 | Function Loss:  -1.4246\n",
      "Total loss:  -0.3767 | PDE Loss:  -1.3098 | Function Loss:  -1.4305\n",
      "Total loss:  -0.3816 | PDE Loss:  -1.2875 | Function Loss:  -1.4391\n",
      "Total loss:  -0.3867 | PDE Loss:  -1.2797 | Function Loss:  -1.4462\n",
      "Total loss:  -0.3916 | PDE Loss:  -1.2716 | Function Loss:  -1.453\n",
      "Total loss:  -0.3951 | PDE Loss:  -1.2699 | Function Loss:  -1.4573\n",
      "Total loss:  -0.3981 | PDE Loss:  -1.2572 | Function Loss:  -1.4627\n",
      "Total loss:  -0.3996 | PDE Loss:  -1.2441 | Function Loss:  -1.4667\n",
      "Total loss:  -0.4009 | PDE Loss:  -1.2412 | Function Loss:  -1.4687\n",
      "Total loss:  -0.4022 | PDE Loss:  -1.241 | Function Loss:  -1.4702\n",
      "Total loss:  -0.4036 | PDE Loss:  -1.2441 | Function Loss:  -1.4713\n",
      "Total loss:  -0.4048 | PDE Loss:  -1.2487 | Function Loss:  -1.472\n",
      "Total loss:  -0.406 | PDE Loss:  -1.2583 | Function Loss:  -1.4717\n",
      "Total loss:  -0.4064 | PDE Loss:  -1.2561 | Function Loss:  -1.4726\n",
      "Total loss:  -0.4076 | PDE Loss:  -1.2455 | Function Loss:  -1.4757\n",
      "Total loss:  -0.4087 | PDE Loss:  -1.2325 | Function Loss:  -1.4793\n",
      "Total loss:  -0.41 | PDE Loss:  -1.2133 | Function Loss:  -1.4843\n",
      "Total loss:  -0.4116 | PDE Loss:  -1.1925 | Function Loss:  -1.4903\n",
      "Total loss:  -0.4147 | PDE Loss:  -1.1616 | Function Loss:  -1.5004\n",
      "Total loss:  -0.4185 | PDE Loss:  -1.1258 | Function Loss:  -1.5133\n",
      "Total loss:  -0.4217 | PDE Loss:  -1.1138 | Function Loss:  -1.5204\n",
      "Total loss:  -0.4249 | PDE Loss:  -1.1016 | Function Loss:  -1.5275\n",
      "Total loss:  -0.4274 | PDE Loss:  -1.1052 | Function Loss:  -1.5297\n",
      "Total loss:  -0.4298 | PDE Loss:  -1.102 | Function Loss:  -1.5337\n",
      "Total loss:  -0.4336 | PDE Loss:  -1.1087 | Function Loss:  -1.5367\n",
      "Total loss:  -0.4419 | PDE Loss:  -1.1316 | Function Loss:  -1.5411\n",
      "Total loss:  -0.4467 | PDE Loss:  -1.1507 | Function Loss:  -1.5424\n",
      "Total loss:  -0.4474 | PDE Loss:  -1.1573 | Function Loss:  -1.5416\n",
      "Total loss:  -0.4508 | PDE Loss:  -1.1613 | Function Loss:  -1.5448\n",
      "Total loss:  -0.4569 | PDE Loss:  -1.204 | Function Loss:  -1.5426\n",
      "Total loss:  -0.4636 | PDE Loss:  -1.2179 | Function Loss:  -1.5477\n",
      "Total loss:  -0.4709 | PDE Loss:  -1.2418 | Function Loss:  -1.5515\n",
      "Total loss:  -0.4763 | PDE Loss:  -1.2688 | Function Loss:  -1.5526\n",
      "Total loss:  -0.4791 | PDE Loss:  -1.2695 | Function Loss:  -1.5558\n",
      "Total loss:  -0.4831 | PDE Loss:  -1.2754 | Function Loss:  -1.5596\n",
      "Total loss:  -0.4901 | PDE Loss:  -1.3194 | Function Loss:  -1.5598\n",
      "Total loss:  -0.4923 | PDE Loss:  -1.3274 | Function Loss:  -1.5609\n",
      "Total loss:  -0.4992 | PDE Loss:  -1.3405 | Function Loss:  -1.5667\n",
      "Total loss:  -0.5019 | PDE Loss:  -1.3377 | Function Loss:  -1.5704\n",
      "Total loss:  -0.5036 | PDE Loss:  -1.3222 | Function Loss:  -1.5751\n",
      "Total loss:  -0.506 | PDE Loss:  -1.3099 | Function Loss:  -1.5803\n",
      "Total loss:  -0.5083 | PDE Loss:  -1.2951 | Function Loss:  -1.5858\n",
      "Total loss:  -0.5119 | PDE Loss:  -1.2992 | Function Loss:  -1.5893\n",
      "Total loss:  -0.5201 | PDE Loss:  -1.3093 | Function Loss:  -1.5971\n",
      "Total loss:  -0.5272 | PDE Loss:  -1.3338 | Function Loss:  -1.6009\n",
      "Total loss:  -0.5344 | PDE Loss:  -1.3733 | Function Loss:  -1.6024\n",
      "Total loss:  -0.537 | PDE Loss:  -1.3635 | Function Loss:  -1.6071\n",
      "Total loss:  -0.5392 | PDE Loss:  -1.3623 | Function Loss:  -1.6099\n",
      "Total loss:  -0.5417 | PDE Loss:  -1.3838 | Function Loss:  -1.6091\n",
      "Total loss:  -0.5433 | PDE Loss:  -1.3912 | Function Loss:  -1.6098\n",
      "Total loss:  -0.545 | PDE Loss:  -1.4056 | Function Loss:  -1.6094\n",
      "Total loss:  -0.5467 | PDE Loss:  -1.4103 | Function Loss:  -1.6107\n",
      "Total loss:  -0.5492 | PDE Loss:  -1.4177 | Function Loss:  -1.6123\n",
      "Total loss:  -0.5507 | PDE Loss:  -1.4228 | Function Loss:  -1.6133\n",
      "Total loss:  -0.5515 | PDE Loss:  -1.4257 | Function Loss:  -1.6138\n",
      "Total loss:  -0.552 | PDE Loss:  -1.4304 | Function Loss:  -1.6136\n",
      "Total loss:  -0.5525 | PDE Loss:  -1.432 | Function Loss:  -1.614\n",
      "Total loss:  -0.5531 | PDE Loss:  -1.4402 | Function Loss:  -1.6135\n",
      "Total loss:  -0.5539 | PDE Loss:  -1.4462 | Function Loss:  -1.6135\n",
      "Total loss:  -0.5553 | PDE Loss:  -1.4642 | Function Loss:  -1.6124\n",
      "Total loss:  -0.5572 | PDE Loss:  -1.4823 | Function Loss:  -1.6121\n",
      "Total loss:  -0.5592 | PDE Loss:  -1.5067 | Function Loss:  -1.6112\n",
      "Total loss:  -0.5606 | PDE Loss:  -1.5223 | Function Loss:  -1.6109\n",
      "Total loss:  -0.5617 | PDE Loss:  -1.5286 | Function Loss:  -1.6113\n",
      "Total loss:  -0.5625 | PDE Loss:  -1.5326 | Function Loss:  -1.6117\n",
      "Total loss:  -0.5635 | PDE Loss:  -1.5314 | Function Loss:  -1.613\n",
      "Total loss:  -0.5649 | PDE Loss:  -1.5323 | Function Loss:  -1.6144\n",
      "Total loss:  -0.5667 | PDE Loss:  -1.5243 | Function Loss:  -1.6174\n",
      "Total loss:  -0.5688 | PDE Loss:  -1.5161 | Function Loss:  -1.6208\n",
      "Total loss:  -0.5709 | PDE Loss:  -1.5055 | Function Loss:  -1.6246\n",
      "Total loss:  -0.5731 | PDE Loss:  -1.482 | Function Loss:  -1.6302\n",
      "Total loss:  -0.5747 | PDE Loss:  -1.4741 | Function Loss:  -1.6332\n",
      "Total loss:  -0.5769 | PDE Loss:  -1.4612 | Function Loss:  -1.6377\n",
      "Total loss:  -0.5798 | PDE Loss:  -1.4447 | Function Loss:  -1.6436\n",
      "Total loss:  -0.5825 | PDE Loss:  -1.429 | Function Loss:  -1.6493\n",
      "Total loss:  -0.5848 | PDE Loss:  -1.414 | Function Loss:  -1.6545\n",
      "Total loss:  -0.5865 | PDE Loss:  -1.406 | Function Loss:  -1.6579\n",
      "Total loss:  -0.5876 | PDE Loss:  -1.3975 | Function Loss:  -1.6607\n",
      "Total loss:  -0.5882 | PDE Loss:  -1.3952 | Function Loss:  -1.6618\n",
      "Total loss:  -0.5886 | PDE Loss:  -1.392 | Function Loss:  -1.6629\n",
      "Total loss:  -0.589 | PDE Loss:  -1.3872 | Function Loss:  -1.6642\n",
      "Total loss:  -0.5893 | PDE Loss:  -1.3856 | Function Loss:  -1.6649\n",
      "Total loss:  -0.5897 | PDE Loss:  -1.3791 | Function Loss:  -1.6667\n",
      "Total loss:  -0.5902 | PDE Loss:  -1.375 | Function Loss:  -1.668\n",
      "Total loss:  -0.5908 | PDE Loss:  -1.3693 | Function Loss:  -1.6699\n",
      "Total loss:  -0.5918 | PDE Loss:  -1.3621 | Function Loss:  -1.6726\n",
      "Total loss:  -0.5939 | PDE Loss:  -1.3549 | Function Loss:  -1.6766\n",
      "Total loss:  -0.5961 | PDE Loss:  -1.3553 | Function Loss:  -1.6792\n",
      "Total loss:  -0.5976 | PDE Loss:  -1.3518 | Function Loss:  -1.6817\n",
      "Total loss:  -0.6005 | PDE Loss:  -1.3624 | Function Loss:  -1.683\n",
      "Total loss:  -0.6036 | PDE Loss:  -1.3628 | Function Loss:  -1.6867\n",
      "Total loss:  -0.6051 | PDE Loss:  -1.3718 | Function Loss:  -1.6866\n",
      "Total loss:  -0.607 | PDE Loss:  -1.3771 | Function Loss:  -1.6878\n",
      "Total loss:  -0.6078 | PDE Loss:  -1.3772 | Function Loss:  -1.6887\n",
      "Total loss:  -0.6099 | PDE Loss:  -1.3749 | Function Loss:  -1.6917\n",
      "Total loss:  -0.6106 | PDE Loss:  -1.3755 | Function Loss:  -1.6925\n",
      "Total loss:  -0.6115 | PDE Loss:  -1.3782 | Function Loss:  -1.6929\n",
      "Total loss:  -0.6124 | PDE Loss:  -1.3809 | Function Loss:  -1.6936\n",
      "Total loss:  -0.6134 | PDE Loss:  -1.3811 | Function Loss:  -1.6947\n",
      "Total loss:  -0.6143 | PDE Loss:  -1.3816 | Function Loss:  -1.6957\n",
      "Total loss:  -0.6156 | PDE Loss:  -1.3799 | Function Loss:  -1.6977\n",
      "Total loss:  -0.6176 | PDE Loss:  -1.3773 | Function Loss:  -1.7005\n",
      "Total loss:  -0.6193 | PDE Loss:  -1.3724 | Function Loss:  -1.7037\n",
      "Total loss:  -0.6226 | PDE Loss:  -1.3678 | Function Loss:  -1.7086\n",
      "Total loss:  -0.6255 | PDE Loss:  -1.3663 | Function Loss:  -1.7125\n",
      "Total loss:  -0.6302 | PDE Loss:  -1.3699 | Function Loss:  -1.7175\n",
      "Total loss:  -0.6083 | PDE Loss:  -1.3436 | Function Loss:  -1.6966\n",
      "Total loss:  -0.6319 | PDE Loss:  -1.3676 | Function Loss:  -1.7201\n",
      "Total loss:  -0.6352 | PDE Loss:  -1.3652 | Function Loss:  -1.7247\n",
      "Total loss:  -0.6375 | PDE Loss:  -1.3589 | Function Loss:  -1.7289\n",
      "Total loss:  -0.642 | PDE Loss:  -1.3769 | Function Loss:  -1.7304\n",
      "Total loss:  -0.6444 | PDE Loss:  -1.3732 | Function Loss:  -1.7342\n",
      "Total loss:  -0.647 | PDE Loss:  -1.3598 | Function Loss:  -1.7405\n",
      "Total loss:  -0.6491 | PDE Loss:  -1.3557 | Function Loss:  -1.7441\n",
      "Total loss:  -0.6517 | PDE Loss:  -1.3489 | Function Loss:  -1.7491\n",
      "Total loss:  -0.6527 | PDE Loss:  -1.3395 | Function Loss:  -1.7528\n",
      "Total loss:  -0.6535 | PDE Loss:  -1.3363 | Function Loss:  -1.7546\n",
      "Total loss:  -0.6545 | PDE Loss:  -1.3272 | Function Loss:  -1.7582\n",
      "Total loss:  -0.6557 | PDE Loss:  -1.3179 | Function Loss:  -1.7622\n",
      "Total loss:  -0.6569 | PDE Loss:  -1.304 | Function Loss:  -1.7678\n",
      "Total loss:  -0.658 | PDE Loss:  -1.2939 | Function Loss:  -1.7722\n",
      "Total loss:  -0.6585 | PDE Loss:  -1.2766 | Function Loss:  -1.7782\n",
      "Total loss:  -0.6592 | PDE Loss:  -1.2736 | Function Loss:  -1.7801\n",
      "Total loss:  -0.66 | PDE Loss:  -1.269 | Function Loss:  -1.7827\n",
      "Total loss:  -0.661 | PDE Loss:  -1.2644 | Function Loss:  -1.7855\n",
      "Total loss:  -0.6622 | PDE Loss:  -1.2601 | Function Loss:  -1.7886\n",
      "Total loss:  -0.6638 | PDE Loss:  -1.2597 | Function Loss:  -1.7909\n",
      "Total loss:  -0.6649 | PDE Loss:  -1.2579 | Function Loss:  -1.793\n",
      "Total loss:  -0.6663 | PDE Loss:  -1.2637 | Function Loss:  -1.7927\n",
      "Total loss:  -0.6684 | PDE Loss:  -1.2747 | Function Loss:  -1.7919\n",
      "Total loss:  -0.6709 | PDE Loss:  -1.2811 | Function Loss:  -1.7931\n",
      "Total loss:  -0.6723 | PDE Loss:  -1.2885 | Function Loss:  -1.7927\n",
      "Total loss:  -0.6738 | PDE Loss:  -1.2981 | Function Loss:  -1.7916\n",
      "Total loss:  -0.6751 | PDE Loss:  -1.2998 | Function Loss:  -1.7927\n",
      "Total loss:  -0.6763 | PDE Loss:  -1.3067 | Function Loss:  -1.7922\n",
      "Total loss:  -0.679 | PDE Loss:  -1.3151 | Function Loss:  -1.7931\n",
      "Total loss:  -0.6816 | PDE Loss:  -1.3241 | Function Loss:  -1.7938\n",
      "Total loss:  -0.6843 | PDE Loss:  -1.3322 | Function Loss:  -1.7949\n",
      "Total loss:  -0.6859 | PDE Loss:  -1.3417 | Function Loss:  -1.7943\n",
      "Total loss:  -0.6882 | PDE Loss:  -1.3491 | Function Loss:  -1.7952\n",
      "Total loss:  -0.6922 | PDE Loss:  -1.3588 | Function Loss:  -1.7977\n",
      "Total loss:  -0.6958 | PDE Loss:  -1.3694 | Function Loss:  -1.7993\n",
      "Total loss:  -0.6974 | PDE Loss:  -1.3827 | Function Loss:  -1.7977\n",
      "Total loss:  -0.6993 | PDE Loss:  -1.4002 | Function Loss:  -1.7958\n",
      "Total loss:  -0.7001 | PDE Loss:  -1.4024 | Function Loss:  -1.7962\n",
      "Total loss:  -0.7008 | PDE Loss:  -1.4082 | Function Loss:  -1.7957\n",
      "Total loss:  -0.7016 | PDE Loss:  -1.4183 | Function Loss:  -1.7942\n",
      "Total loss:  -0.7024 | PDE Loss:  -1.4279 | Function Loss:  -1.7929\n",
      "Total loss:  -0.7032 | PDE Loss:  -1.44 | Function Loss:  -1.7912\n",
      "Total loss:  -0.7039 | PDE Loss:  -1.4479 | Function Loss:  -1.7903\n",
      "Total loss:  -0.7047 | PDE Loss:  -1.4582 | Function Loss:  -1.789\n",
      "Total loss:  -0.7056 | PDE Loss:  -1.4604 | Function Loss:  -1.7896\n",
      "Total loss:  -0.7072 | PDE Loss:  -1.4632 | Function Loss:  -1.791\n",
      "Total loss:  -0.7086 | PDE Loss:  -1.4652 | Function Loss:  -1.7923\n",
      "Total loss:  -0.7095 | PDE Loss:  -1.4706 | Function Loss:  -1.7922\n",
      "Total loss:  -0.7103 | PDE Loss:  -1.4759 | Function Loss:  -1.792\n",
      "Total loss:  -0.7109 | PDE Loss:  -1.4867 | Function Loss:  -1.7905\n",
      "Total loss:  -0.7114 | PDE Loss:  -1.4982 | Function Loss:  -1.7889\n",
      "Total loss:  -0.712 | PDE Loss:  -1.5095 | Function Loss:  -1.7874\n",
      "Total loss:  -0.7124 | PDE Loss:  -1.5211 | Function Loss:  -1.7857\n",
      "Total loss:  -0.7126 | PDE Loss:  -1.5262 | Function Loss:  -1.785\n",
      "Total loss:  -0.7127 | PDE Loss:  -1.5289 | Function Loss:  -1.7847\n",
      "Total loss:  -0.7128 | PDE Loss:  -1.5293 | Function Loss:  -1.7847\n",
      "Total loss:  -0.7128 | PDE Loss:  -1.5284 | Function Loss:  -1.7849\n",
      "Total loss:  -0.7129 | PDE Loss:  -1.5262 | Function Loss:  -1.7854\n",
      "Total loss:  -0.7131 | PDE Loss:  -1.5227 | Function Loss:  -1.7863\n",
      "Total loss:  -0.7134 | PDE Loss:  -1.5173 | Function Loss:  -1.7876\n",
      "Total loss:  -0.7139 | PDE Loss:  -1.5113 | Function Loss:  -1.7893\n",
      "Total loss:  -0.7145 | PDE Loss:  -1.5046 | Function Loss:  -1.7913\n",
      "Total loss:  -0.7155 | PDE Loss:  -1.4996 | Function Loss:  -1.7935\n",
      "Total loss:  -0.7169 | PDE Loss:  -1.498 | Function Loss:  -1.7955\n",
      "Total loss:  -0.719 | PDE Loss:  -1.5027 | Function Loss:  -1.7971\n",
      "Total loss:  -0.7217 | PDE Loss:  -1.5138 | Function Loss:  -1.7982\n",
      "Total loss:  -0.7249 | PDE Loss:  -1.5325 | Function Loss:  -1.7985\n",
      "Total loss:  -0.7269 | PDE Loss:  -1.5503 | Function Loss:  -1.7976\n",
      "Total loss:  -0.7295 | PDE Loss:  -1.5715 | Function Loss:  -1.797\n",
      "Total loss:  -0.7303 | PDE Loss:  -1.5688 | Function Loss:  -1.7984\n",
      "Total loss:  -0.7317 | PDE Loss:  -1.5683 | Function Loss:  -1.8001\n",
      "Total loss:  -0.733 | PDE Loss:  -1.5641 | Function Loss:  -1.8023\n",
      "Total loss:  -0.7344 | PDE Loss:  -1.569 | Function Loss:  -1.8031\n",
      "Total loss:  -0.7361 | PDE Loss:  -1.5717 | Function Loss:  -1.8046\n",
      "Total loss:  -0.7383 | PDE Loss:  -1.583 | Function Loss:  -1.8053\n",
      "Total loss:  -0.7414 | PDE Loss:  -1.6002 | Function Loss:  -1.8061\n",
      "Total loss:  -0.7443 | PDE Loss:  -1.6195 | Function Loss:  -1.8065\n",
      "Total loss:  -0.7473 | PDE Loss:  -1.6348 | Function Loss:  -1.8076\n",
      "Total loss:  -0.7487 | PDE Loss:  -1.6381 | Function Loss:  -1.8087\n",
      "Total loss:  -0.7491 | PDE Loss:  -1.6335 | Function Loss:  -1.8099\n",
      "Total loss:  -0.7501 | PDE Loss:  -1.6282 | Function Loss:  -1.8118\n",
      "Total loss:  -0.7509 | PDE Loss:  -1.6177 | Function Loss:  -1.8143\n",
      "Total loss:  -0.7516 | PDE Loss:  -1.6113 | Function Loss:  -1.8162\n",
      "Total loss:  -0.7535 | PDE Loss:  -1.5819 | Function Loss:  -1.8233\n",
      "Total loss:  -0.7549 | PDE Loss:  -1.5697 | Function Loss:  -1.8272\n",
      "Total loss:  -0.7559 | PDE Loss:  -1.5596 | Function Loss:  -1.8302\n",
      "Total loss:  -0.7568 | PDE Loss:  -1.5459 | Function Loss:  -1.8338\n",
      "Total loss:  -0.7578 | PDE Loss:  -1.5416 | Function Loss:  -1.8359\n",
      "Total loss:  -0.7585 | PDE Loss:  -1.5387 | Function Loss:  -1.8373\n",
      "Total loss:  -0.7594 | PDE Loss:  -1.5309 | Function Loss:  -1.8399\n",
      "Total loss:  -0.7603 | PDE Loss:  -1.5322 | Function Loss:  -1.8407\n",
      "Total loss:  -0.7609 | PDE Loss:  -1.527 | Function Loss:  -1.8426\n",
      "Total loss:  -0.7617 | PDE Loss:  -1.5258 | Function Loss:  -1.8437\n",
      "Total loss:  -0.7621 | PDE Loss:  -1.5228 | Function Loss:  -1.8448\n",
      "Total loss:  -0.7625 | PDE Loss:  -1.5239 | Function Loss:  -1.8451\n",
      "Total loss:  -0.763 | PDE Loss:  -1.5231 | Function Loss:  -1.8458\n",
      "Total loss:  -0.7638 | PDE Loss:  -1.5187 | Function Loss:  -1.8478\n",
      "Total loss:  -0.7648 | PDE Loss:  -1.5166 | Function Loss:  -1.8495\n",
      "Total loss:  -0.7655 | PDE Loss:  -1.5155 | Function Loss:  -1.8506\n",
      "Total loss:  -0.7665 | PDE Loss:  -1.5216 | Function Loss:  -1.8505\n",
      "Total loss:  -0.7676 | PDE Loss:  -1.5273 | Function Loss:  -1.8506\n",
      "Total loss:  -0.7687 | PDE Loss:  -1.5348 | Function Loss:  -1.8504\n",
      "Total loss:  -0.7698 | PDE Loss:  -1.5455 | Function Loss:  -1.8494\n",
      "Total loss:  -0.7709 | PDE Loss:  -1.5572 | Function Loss:  -1.8484\n",
      "Total loss:  -0.7722 | PDE Loss:  -1.5719 | Function Loss:  -1.8472\n",
      "Total loss:  -0.7735 | PDE Loss:  -1.585 | Function Loss:  -1.8463\n",
      "Total loss:  -0.7747 | PDE Loss:  -1.5927 | Function Loss:  -1.8463\n",
      "Total loss:  -0.7756 | PDE Loss:  -1.6104 | Function Loss:  -1.8443\n",
      "Total loss:  -0.7765 | PDE Loss:  -1.6123 | Function Loss:  -1.8451\n",
      "Total loss:  -0.7772 | PDE Loss:  -1.6119 | Function Loss:  -1.8459\n",
      "Total loss:  -0.7777 | PDE Loss:  -1.613 | Function Loss:  -1.8463\n",
      "Total loss:  -0.7782 | PDE Loss:  -1.6163 | Function Loss:  -1.8464\n",
      "Total loss:  -0.7788 | PDE Loss:  -1.617 | Function Loss:  -1.8469\n",
      "Total loss:  -0.7795 | PDE Loss:  -1.6166 | Function Loss:  -1.8477\n",
      "Total loss:  -0.7801 | PDE Loss:  -1.6151 | Function Loss:  -1.8487\n",
      "Total loss:  -0.7806 | PDE Loss:  -1.6101 | Function Loss:  -1.8502\n",
      "Total loss:  -0.781 | PDE Loss:  -1.6071 | Function Loss:  -1.8511\n",
      "Total loss:  -0.7812 | PDE Loss:  -1.6005 | Function Loss:  -1.8526\n",
      "Total loss:  -0.7813 | PDE Loss:  -1.599 | Function Loss:  -1.853\n",
      "Total loss:  -0.7814 | PDE Loss:  -1.5972 | Function Loss:  -1.8535\n",
      "Total loss:  -0.7815 | PDE Loss:  -1.595 | Function Loss:  -1.854\n",
      "Total loss:  -0.7817 | PDE Loss:  -1.5923 | Function Loss:  -1.8546\n",
      "Total loss:  -0.7819 | PDE Loss:  -1.5887 | Function Loss:  -1.8555\n",
      "Total loss:  -0.7821 | PDE Loss:  -1.5838 | Function Loss:  -1.8568\n",
      "Total loss:  -0.7826 | PDE Loss:  -1.5765 | Function Loss:  -1.8587\n",
      "Total loss:  -0.7832 | PDE Loss:  -1.5667 | Function Loss:  -1.8614\n",
      "Total loss:  -0.7842 | PDE Loss:  -1.552 | Function Loss:  -1.8655\n",
      "Total loss:  -0.7854 | PDE Loss:  -1.5363 | Function Loss:  -1.8703\n",
      "Total loss:  -0.7865 | PDE Loss:  -1.5222 | Function Loss:  -1.8747\n",
      "Total loss:  -0.7873 | PDE Loss:  -1.5163 | Function Loss:  -1.877\n",
      "Total loss:  -0.7879 | PDE Loss:  -1.5056 | Function Loss:  -1.8803\n",
      "Total loss:  -0.7884 | PDE Loss:  -1.5099 | Function Loss:  -1.8799\n",
      "Total loss:  -0.7886 | PDE Loss:  -1.511 | Function Loss:  -1.8799\n",
      "Total loss:  -0.7889 | PDE Loss:  -1.5143 | Function Loss:  -1.8794\n",
      "Total loss:  -0.7894 | PDE Loss:  -1.5211 | Function Loss:  -1.8785\n",
      "Total loss:  -0.7902 | PDE Loss:  -1.5323 | Function Loss:  -1.8769\n",
      "Total loss:  -0.7909 | PDE Loss:  -1.5424 | Function Loss:  -1.8756\n",
      "Total loss:  -0.792 | PDE Loss:  -1.5581 | Function Loss:  -1.8736\n",
      "Total loss:  -0.793 | PDE Loss:  -1.5698 | Function Loss:  -1.8725\n",
      "Total loss:  -0.7935 | PDE Loss:  -1.5751 | Function Loss:  -1.8719\n",
      "Total loss:  -0.7938 | PDE Loss:  -1.5755 | Function Loss:  -1.8723\n",
      "Total loss:  -0.7942 | PDE Loss:  -1.5747 | Function Loss:  -1.8729\n",
      "Total loss:  -0.7945 | PDE Loss:  -1.5727 | Function Loss:  -1.8736\n",
      "Total loss:  -0.7947 | PDE Loss:  -1.5691 | Function Loss:  -1.8747\n",
      "Total loss:  -0.7949 | PDE Loss:  -1.5671 | Function Loss:  -1.8753\n",
      "Total loss:  -0.795 | PDE Loss:  -1.5656 | Function Loss:  -1.8758\n",
      "Total loss:  -0.7951 | PDE Loss:  -1.5644 | Function Loss:  -1.8761\n",
      "Total loss:  -0.7952 | PDE Loss:  -1.5631 | Function Loss:  -1.8765\n",
      "Total loss:  -0.7953 | PDE Loss:  -1.5623 | Function Loss:  -1.8768\n",
      "Total loss:  -0.7954 | PDE Loss:  -1.5609 | Function Loss:  -1.8772\n",
      "Total loss:  -0.7955 | PDE Loss:  -1.5597 | Function Loss:  -1.8776\n",
      "Total loss:  -0.7957 | PDE Loss:  -1.5576 | Function Loss:  -1.8782\n",
      "Total loss:  -0.7959 | PDE Loss:  -1.556 | Function Loss:  -1.8788\n",
      "Total loss:  -0.7963 | PDE Loss:  -1.5539 | Function Loss:  -1.8797\n",
      "Total loss:  -0.7969 | PDE Loss:  -1.5535 | Function Loss:  -1.8805\n",
      "Total loss:  -0.7978 | PDE Loss:  -1.5534 | Function Loss:  -1.8816\n",
      "Total loss:  -0.7992 | PDE Loss:  -1.5549 | Function Loss:  -1.883\n",
      "Total loss:  -0.8002 | PDE Loss:  -1.5552 | Function Loss:  -1.8842\n",
      "Total loss:  -0.8024 | PDE Loss:  -1.5587 | Function Loss:  -1.8861\n",
      "Total loss:  -0.8067 | PDE Loss:  -1.5605 | Function Loss:  -1.891\n",
      "Total loss:  -0.806 | PDE Loss:  -1.5747 | Function Loss:  -1.8871\n",
      "Total loss:  -0.8099 | PDE Loss:  -1.5702 | Function Loss:  -1.8927\n",
      "Total loss:  -0.8144 | PDE Loss:  -1.5609 | Function Loss:  -1.9002\n",
      "Total loss:  -0.8038 | PDE Loss:  -1.5522 | Function Loss:  -1.8891\n",
      "Total loss:  -0.8166 | PDE Loss:  -1.5606 | Function Loss:  -1.903\n",
      "Total loss:  -0.8188 | PDE Loss:  -1.586 | Function Loss:  -1.9002\n",
      "Total loss:  -0.8218 | PDE Loss:  -1.6008 | Function Loss:  -1.9008\n",
      "Total loss:  -0.8247 | PDE Loss:  -1.6063 | Function Loss:  -1.9032\n",
      "Total loss:  -0.8275 | PDE Loss:  -1.6148 | Function Loss:  -1.9048\n",
      "Total loss:  -0.8312 | PDE Loss:  -1.6221 | Function Loss:  -1.9079\n",
      "Total loss:  -0.8352 | PDE Loss:  -1.6381 | Function Loss:  -1.9096\n",
      "Total loss:  -0.8383 | PDE Loss:  -1.6414 | Function Loss:  -1.9126\n",
      "Total loss:  -0.8398 | PDE Loss:  -1.6454 | Function Loss:  -1.9137\n",
      "Total loss:  -0.8409 | PDE Loss:  -1.6461 | Function Loss:  -1.9149\n",
      "Total loss:  -0.8424 | PDE Loss:  -1.647 | Function Loss:  -1.9165\n",
      "Total loss:  -0.8431 | PDE Loss:  -1.6449 | Function Loss:  -1.9177\n",
      "Total loss:  -0.8442 | PDE Loss:  -1.6457 | Function Loss:  -1.9189\n",
      "Total loss:  -0.8455 | PDE Loss:  -1.6517 | Function Loss:  -1.9193\n",
      "Total loss:  -0.8464 | PDE Loss:  -1.653 | Function Loss:  -1.9202\n",
      "Total loss:  -0.8469 | PDE Loss:  -1.6552 | Function Loss:  -1.9204\n",
      "Total loss:  -0.8474 | PDE Loss:  -1.6575 | Function Loss:  -1.9205\n",
      "Total loss:  -0.8478 | PDE Loss:  -1.6569 | Function Loss:  -1.921\n",
      "Total loss:  -0.8481 | PDE Loss:  -1.6568 | Function Loss:  -1.9214\n",
      "Total loss:  -0.8486 | PDE Loss:  -1.6557 | Function Loss:  -1.9222\n",
      "Total loss:  -0.8491 | PDE Loss:  -1.6554 | Function Loss:  -1.9228\n",
      "Total loss:  -0.8497 | PDE Loss:  -1.6548 | Function Loss:  -1.9237\n",
      "Total loss:  -0.8505 | PDE Loss:  -1.6573 | Function Loss:  -1.9242\n",
      "Total loss:  -0.8516 | PDE Loss:  -1.6609 | Function Loss:  -1.9248\n",
      "Total loss:  -0.8524 | PDE Loss:  -1.6668 | Function Loss:  -1.9247\n",
      "Total loss:  -0.8533 | PDE Loss:  -1.6748 | Function Loss:  -1.9243\n",
      "Total loss:  -0.8538 | PDE Loss:  -1.6816 | Function Loss:  -1.9236\n",
      "Total loss:  -0.854 | PDE Loss:  -1.6862 | Function Loss:  -1.9231\n",
      "Total loss:  -0.8541 | PDE Loss:  -1.6894 | Function Loss:  -1.9227\n",
      "Total loss:  -0.8541 | PDE Loss:  -1.6905 | Function Loss:  -1.9226\n",
      "Total loss:  -0.8542 | PDE Loss:  -1.6916 | Function Loss:  -1.9224\n",
      "Total loss:  -0.8542 | PDE Loss:  -1.6921 | Function Loss:  -1.9224\n",
      "Total loss:  -0.8543 | PDE Loss:  -1.6925 | Function Loss:  -1.9224\n",
      "Total loss:  -0.8544 | PDE Loss:  -1.6921 | Function Loss:  -1.9225\n",
      "Total loss:  -0.8545 | PDE Loss:  -1.6916 | Function Loss:  -1.9228\n",
      "Total loss:  -0.8547 | PDE Loss:  -1.6895 | Function Loss:  -1.9233\n",
      "Total loss:  -0.8545 | PDE Loss:  -1.6883 | Function Loss:  -1.9234\n",
      "Total loss:  -0.8548 | PDE Loss:  -1.6896 | Function Loss:  -1.9235\n",
      "Total loss:  -0.855 | PDE Loss:  -1.6872 | Function Loss:  -1.9242\n",
      "Total loss:  -0.8553 | PDE Loss:  -1.6835 | Function Loss:  -1.9252\n",
      "Total loss:  -0.8556 | PDE Loss:  -1.6805 | Function Loss:  -1.926\n",
      "Total loss:  -0.8559 | PDE Loss:  -1.6779 | Function Loss:  -1.9268\n",
      "Total loss:  -0.856 | PDE Loss:  -1.6768 | Function Loss:  -1.9272\n",
      "Total loss:  -0.8562 | PDE Loss:  -1.6759 | Function Loss:  -1.9275\n",
      "Total loss:  -0.8564 | PDE Loss:  -1.6761 | Function Loss:  -1.9277\n",
      "Total loss:  -0.8566 | PDE Loss:  -1.6767 | Function Loss:  -1.9278\n",
      "Total loss:  -0.857 | PDE Loss:  -1.6785 | Function Loss:  -1.928\n",
      "Total loss:  -0.8575 | PDE Loss:  -1.6814 | Function Loss:  -1.9281\n",
      "Total loss:  -0.8583 | PDE Loss:  -1.686 | Function Loss:  -1.9282\n",
      "Total loss:  -0.8594 | PDE Loss:  -1.6919 | Function Loss:  -1.9285\n",
      "Total loss:  -0.8607 | PDE Loss:  -1.6995 | Function Loss:  -1.9287\n",
      "Total loss:  -0.862 | PDE Loss:  -1.7059 | Function Loss:  -1.9291\n",
      "Total loss:  -0.8633 | PDE Loss:  -1.7125 | Function Loss:  -1.9296\n",
      "Total loss:  -0.8645 | PDE Loss:  -1.7167 | Function Loss:  -1.9303\n",
      "Total loss:  -0.8659 | PDE Loss:  -1.7218 | Function Loss:  -1.9311\n",
      "Total loss:  -0.8671 | PDE Loss:  -1.7245 | Function Loss:  -1.932\n",
      "Total loss:  -0.869 | PDE Loss:  -1.7282 | Function Loss:  -1.9337\n",
      "Total loss:  -0.8705 | PDE Loss:  -1.7313 | Function Loss:  -1.9348\n",
      "Total loss:  -0.8718 | PDE Loss:  -1.7296 | Function Loss:  -1.9367\n",
      "Total loss:  -0.8726 | PDE Loss:  -1.7291 | Function Loss:  -1.9376\n",
      "Total loss:  -0.8732 | PDE Loss:  -1.7245 | Function Loss:  -1.9392\n",
      "Total loss:  -0.8738 | PDE Loss:  -1.7231 | Function Loss:  -1.9401\n",
      "Total loss:  -0.8743 | PDE Loss:  -1.7201 | Function Loss:  -1.9411\n",
      "Total loss:  -0.8746 | PDE Loss:  -1.7192 | Function Loss:  -1.9416\n",
      "Total loss:  -0.8748 | PDE Loss:  -1.719 | Function Loss:  -1.9419\n",
      "Total loss:  -0.875 | PDE Loss:  -1.7188 | Function Loss:  -1.9422\n",
      "Total loss:  -0.8753 | PDE Loss:  -1.7203 | Function Loss:  -1.9422\n",
      "Total loss:  -0.8755 | PDE Loss:  -1.7209 | Function Loss:  -1.9424\n",
      "Total loss:  -0.876 | PDE Loss:  -1.7233 | Function Loss:  -1.9426\n",
      "Total loss:  -0.8766 | PDE Loss:  -1.7241 | Function Loss:  -1.9431\n",
      "Total loss:  -0.8773 | PDE Loss:  -1.7249 | Function Loss:  -1.9438\n",
      "Total loss:  -0.8779 | PDE Loss:  -1.7222 | Function Loss:  -1.945\n",
      "Total loss:  -0.8785 | PDE Loss:  -1.7179 | Function Loss:  -1.9465\n",
      "Total loss:  -0.8791 | PDE Loss:  -1.7104 | Function Loss:  -1.9484\n",
      "Total loss:  -0.8795 | PDE Loss:  -1.7029 | Function Loss:  -1.9502\n",
      "Total loss:  -0.8798 | PDE Loss:  -1.6965 | Function Loss:  -1.9517\n",
      "Total loss:  -0.88 | PDE Loss:  -1.6927 | Function Loss:  -1.9526\n",
      "Total loss:  -0.8801 | PDE Loss:  -1.6858 | Function Loss:  -1.954\n",
      "Total loss:  -0.8802 | PDE Loss:  -1.6843 | Function Loss:  -1.9544\n",
      "Total loss:  -0.8803 | PDE Loss:  -1.6831 | Function Loss:  -1.9547\n",
      "Total loss:  -0.8804 | PDE Loss:  -1.6819 | Function Loss:  -1.9551\n",
      "Total loss:  -0.8805 | PDE Loss:  -1.6807 | Function Loss:  -1.9554\n",
      "Total loss:  -0.8806 | PDE Loss:  -1.6796 | Function Loss:  -1.9557\n",
      "Total loss:  -0.8808 | PDE Loss:  -1.6777 | Function Loss:  -1.9563\n",
      "Total loss:  -0.881 | PDE Loss:  -1.6757 | Function Loss:  -1.957\n",
      "Total loss:  -0.8814 | PDE Loss:  -1.6715 | Function Loss:  -1.9582\n",
      "Total loss:  -0.8817 | PDE Loss:  -1.6676 | Function Loss:  -1.9594\n",
      "Total loss:  -0.8822 | PDE Loss:  -1.6624 | Function Loss:  -1.961\n",
      "Total loss:  -0.8827 | PDE Loss:  -1.658 | Function Loss:  -1.9625\n",
      "Total loss:  -0.8831 | PDE Loss:  -1.6554 | Function Loss:  -1.9635\n",
      "Total loss:  -0.8834 | PDE Loss:  -1.6542 | Function Loss:  -1.964\n",
      "Total loss:  -0.8836 | PDE Loss:  -1.6544 | Function Loss:  -1.9642\n",
      "Total loss:  -0.8838 | PDE Loss:  -1.6542 | Function Loss:  -1.9646\n",
      "Total loss:  -0.8841 | PDE Loss:  -1.6576 | Function Loss:  -1.9642\n",
      "Total loss:  -0.8844 | PDE Loss:  -1.659 | Function Loss:  -1.9643\n",
      "Total loss:  -0.8848 | PDE Loss:  -1.662 | Function Loss:  -1.9642\n",
      "Total loss:  -0.8854 | PDE Loss:  -1.6652 | Function Loss:  -1.9642\n",
      "Total loss:  -0.886 | PDE Loss:  -1.6675 | Function Loss:  -1.9646\n",
      "Total loss:  -0.8868 | PDE Loss:  -1.6693 | Function Loss:  -1.9651\n",
      "Total loss:  -0.8875 | PDE Loss:  -1.6688 | Function Loss:  -1.9661\n",
      "Total loss:  -0.8885 | PDE Loss:  -1.6676 | Function Loss:  -1.9675\n",
      "Total loss:  -0.8895 | PDE Loss:  -1.6632 | Function Loss:  -1.9696\n",
      "Total loss:  -0.8905 | PDE Loss:  -1.6596 | Function Loss:  -1.9716\n",
      "Total loss:  -0.8913 | PDE Loss:  -1.6547 | Function Loss:  -1.9735\n",
      "Total loss:  -0.892 | PDE Loss:  -1.6545 | Function Loss:  -1.9744\n",
      "Total loss:  -0.893 | PDE Loss:  -1.6472 | Function Loss:  -1.9771\n",
      "Total loss:  -0.8937 | PDE Loss:  -1.6463 | Function Loss:  -1.9781\n",
      "Total loss:  -0.8956 | PDE Loss:  -1.6468 | Function Loss:  -1.9803\n",
      "Total loss:  -0.8979 | PDE Loss:  -1.653 | Function Loss:  -1.9819\n",
      "Total loss:  -0.8997 | PDE Loss:  -1.6571 | Function Loss:  -1.9831\n",
      "Total loss:  -0.9012 | PDE Loss:  -1.6551 | Function Loss:  -1.9854\n",
      "Total loss:  -0.9023 | PDE Loss:  -1.6525 | Function Loss:  -1.9872\n",
      "Total loss:  -0.9039 | PDE Loss:  -1.6452 | Function Loss:  -1.9908\n",
      "Total loss:  -0.9047 | PDE Loss:  -1.6425 | Function Loss:  -1.9924\n",
      "Total loss:  -0.9052 | PDE Loss:  -1.6408 | Function Loss:  -1.9934\n",
      "Total loss:  -0.9056 | PDE Loss:  -1.6386 | Function Loss:  -1.9944\n",
      "Total loss:  -0.906 | PDE Loss:  -1.6377 | Function Loss:  -1.9951\n",
      "Total loss:  -0.9063 | PDE Loss:  -1.6377 | Function Loss:  -1.9954\n",
      "Total loss:  -0.9065 | PDE Loss:  -1.6382 | Function Loss:  -1.9956\n",
      "Total loss:  -0.9068 | PDE Loss:  -1.6384 | Function Loss:  -1.9959\n",
      "Total loss:  -0.9071 | PDE Loss:  -1.6401 | Function Loss:  -1.9959\n",
      "Total loss:  -0.9073 | PDE Loss:  -1.6387 | Function Loss:  -1.9964\n",
      "Total loss:  -0.9076 | PDE Loss:  -1.6371 | Function Loss:  -1.9971\n",
      "Total loss:  -0.908 | PDE Loss:  -1.6346 | Function Loss:  -1.9983\n",
      "Total loss:  -0.9085 | PDE Loss:  -1.6347 | Function Loss:  -1.9989\n",
      "Total loss:  -0.9091 | PDE Loss:  -1.6332 | Function Loss:  -1.9999\n",
      "Total loss:  -0.9098 | PDE Loss:  -1.6357 | Function Loss:  -2.0002\n",
      "Total loss:  -0.9106 | PDE Loss:  -1.638 | Function Loss:  -2.0007\n",
      "Total loss:  -0.9112 | PDE Loss:  -1.6393 | Function Loss:  -2.0011\n",
      "Total loss:  -0.912 | PDE Loss:  -1.6472 | Function Loss:  -2.0003\n",
      "Total loss:  -0.9126 | PDE Loss:  -1.6506 | Function Loss:  -2.0003\n",
      "Total loss:  -0.9132 | PDE Loss:  -1.6534 | Function Loss:  -2.0003\n",
      "Total loss:  -0.9138 | PDE Loss:  -1.6552 | Function Loss:  -2.0007\n",
      "Total loss:  -0.9145 | PDE Loss:  -1.6555 | Function Loss:  -2.0015\n",
      "Total loss:  -0.9152 | PDE Loss:  -1.6542 | Function Loss:  -2.0026\n",
      "Total loss:  -0.9159 | PDE Loss:  -1.6547 | Function Loss:  -2.0034\n",
      "Total loss:  -0.9169 | PDE Loss:  -1.654 | Function Loss:  -2.0048\n",
      "Total loss:  -0.9184 | PDE Loss:  -1.6529 | Function Loss:  -2.0069\n",
      "Total loss:  -0.9197 | PDE Loss:  -1.6523 | Function Loss:  -2.0085\n",
      "Total loss:  -0.9207 | PDE Loss:  -1.6487 | Function Loss:  -2.0107\n",
      "Total loss:  -0.9218 | PDE Loss:  -1.6428 | Function Loss:  -2.0134\n",
      "Total loss:  -0.9233 | PDE Loss:  -1.6425 | Function Loss:  -2.0153\n",
      "Total loss:  -0.9253 | PDE Loss:  -1.6369 | Function Loss:  -2.0191\n",
      "Total loss:  -0.9266 | PDE Loss:  -1.6355 | Function Loss:  -2.021\n",
      "Total loss:  -0.926 | PDE Loss:  -1.626 | Function Loss:  -2.0227\n",
      "Total loss:  -0.9274 | PDE Loss:  -1.632 | Function Loss:  -2.0229\n",
      "Total loss:  -0.9282 | PDE Loss:  -1.6306 | Function Loss:  -2.0242\n",
      "Total loss:  -0.9293 | PDE Loss:  -1.6292 | Function Loss:  -2.0259\n",
      "Total loss:  -0.9306 | PDE Loss:  -1.6306 | Function Loss:  -2.0272\n",
      "Total loss:  -0.9318 | PDE Loss:  -1.6327 | Function Loss:  -2.0283\n",
      "Total loss:  -0.9336 | PDE Loss:  -1.6374 | Function Loss:  -2.0293\n",
      "Total loss:  -0.9352 | PDE Loss:  -1.6441 | Function Loss:  -2.0297\n",
      "Total loss:  -0.938 | PDE Loss:  -1.6609 | Function Loss:  -2.0291\n",
      "Total loss:  -0.9394 | PDE Loss:  -1.6623 | Function Loss:  -2.0305\n",
      "Total loss:  -0.9412 | PDE Loss:  -1.6671 | Function Loss:  -2.0316\n",
      "Total loss:  -0.9431 | PDE Loss:  -1.6755 | Function Loss:  -2.0321\n",
      "Total loss:  -0.9448 | PDE Loss:  -1.6823 | Function Loss:  -2.0326\n",
      "Total loss:  -0.946 | PDE Loss:  -1.6893 | Function Loss:  -2.0325\n",
      "Total loss:  -0.947 | PDE Loss:  -1.6923 | Function Loss:  -2.0331\n",
      "Total loss:  -0.9477 | PDE Loss:  -1.6896 | Function Loss:  -2.0346\n",
      "Total loss:  -0.9484 | PDE Loss:  -1.6879 | Function Loss:  -2.0358\n",
      "Total loss:  -0.9492 | PDE Loss:  -1.6839 | Function Loss:  -2.0376\n",
      "Total loss:  -0.9501 | PDE Loss:  -1.6746 | Function Loss:  -2.0409\n",
      "Total loss:  -0.9511 | PDE Loss:  -1.6684 | Function Loss:  -2.0436\n",
      "Total loss:  -0.9522 | PDE Loss:  -1.6583 | Function Loss:  -2.0474\n",
      "Total loss:  -0.9533 | PDE Loss:  -1.6496 | Function Loss:  -2.0509\n",
      "Total loss:  -0.9545 | PDE Loss:  -1.6425 | Function Loss:  -2.0542\n",
      "Total loss:  -0.9556 | PDE Loss:  -1.6372 | Function Loss:  -2.057\n",
      "Total loss:  -0.9563 | PDE Loss:  -1.6366 | Function Loss:  -2.058\n",
      "Total loss:  -0.9566 | PDE Loss:  -1.6376 | Function Loss:  -2.0582\n",
      "Total loss:  -0.9571 | PDE Loss:  -1.639 | Function Loss:  -2.0584\n",
      "Total loss:  -0.9578 | PDE Loss:  -1.6445 | Function Loss:  -2.0578\n",
      "Total loss:  -0.9583 | PDE Loss:  -1.6478 | Function Loss:  -2.0576\n",
      "Total loss:  -0.9588 | PDE Loss:  -1.6504 | Function Loss:  -2.0576\n",
      "Total loss:  -0.9592 | PDE Loss:  -1.6536 | Function Loss:  -2.0573\n",
      "Total loss:  -0.9595 | PDE Loss:  -1.6543 | Function Loss:  -2.0575\n",
      "Total loss:  -0.9599 | PDE Loss:  -1.6547 | Function Loss:  -2.0578\n",
      "Total loss:  -0.9603 | PDE Loss:  -1.6537 | Function Loss:  -2.0586\n",
      "Total loss:  -0.9609 | PDE Loss:  -1.6535 | Function Loss:  -2.0594\n",
      "Total loss:  -0.9617 | PDE Loss:  -1.6518 | Function Loss:  -2.0608\n",
      "Total loss:  -0.9628 | PDE Loss:  -1.6509 | Function Loss:  -2.0625\n",
      "Total loss:  -0.9637 | PDE Loss:  -1.6464 | Function Loss:  -2.0648\n",
      "Total loss:  -0.9644 | PDE Loss:  -1.6483 | Function Loss:  -2.0652\n",
      "Total loss:  -0.9649 | PDE Loss:  -1.6492 | Function Loss:  -2.0655\n",
      "Total loss:  -0.9654 | PDE Loss:  -1.6502 | Function Loss:  -2.0659\n",
      "Total loss:  -0.9656 | PDE Loss:  -1.6509 | Function Loss:  -2.066\n",
      "Total loss:  -0.9664 | PDE Loss:  -1.6558 | Function Loss:  -2.0657\n",
      "Total loss:  -0.967 | PDE Loss:  -1.6576 | Function Loss:  -2.066\n",
      "Total loss:  -0.9677 | PDE Loss:  -1.6606 | Function Loss:  -2.0661\n",
      "Total loss:  -0.9682 | PDE Loss:  -1.6649 | Function Loss:  -2.0657\n",
      "Total loss:  -0.9686 | PDE Loss:  -1.6675 | Function Loss:  -2.0655\n",
      "Total loss:  -0.9689 | PDE Loss:  -1.67 | Function Loss:  -2.0653\n",
      "Total loss:  -0.9693 | PDE Loss:  -1.6737 | Function Loss:  -2.0649\n",
      "Total loss:  -0.9698 | PDE Loss:  -1.6763 | Function Loss:  -2.0648\n",
      "Total loss:  -0.9701 | PDE Loss:  -1.6811 | Function Loss:  -2.064\n",
      "Total loss:  -0.9704 | PDE Loss:  -1.6859 | Function Loss:  -2.0633\n",
      "Total loss:  -0.9706 | PDE Loss:  -1.6868 | Function Loss:  -2.0633\n",
      "Total loss:  -0.9709 | PDE Loss:  -1.6879 | Function Loss:  -2.0634\n",
      "Total loss:  -0.9713 | PDE Loss:  -1.6878 | Function Loss:  -2.0639\n",
      "Total loss:  -0.9718 | PDE Loss:  -1.6859 | Function Loss:  -2.065\n",
      "Total loss:  -0.9728 | PDE Loss:  -1.6815 | Function Loss:  -2.0673\n",
      "Total loss:  -0.974 | PDE Loss:  -1.6734 | Function Loss:  -2.0708\n",
      "Total loss:  -0.9757 | PDE Loss:  -1.6649 | Function Loss:  -2.0751\n",
      "Total loss:  -0.9777 | PDE Loss:  -1.6541 | Function Loss:  -2.0804\n",
      "Total loss:  -0.9801 | PDE Loss:  -1.6382 | Function Loss:  -2.0879\n",
      "Total loss:  -0.9817 | PDE Loss:  -1.6259 | Function Loss:  -2.0935\n",
      "Total loss:  -0.9828 | PDE Loss:  -1.62 | Function Loss:  -2.0966\n",
      "Total loss:  -0.9845 | PDE Loss:  -1.622 | Function Loss:  -2.0983\n",
      "Total loss:  -0.9856 | PDE Loss:  -1.6174 | Function Loss:  -2.101\n",
      "Total loss:  -0.9865 | PDE Loss:  -1.6163 | Function Loss:  -2.1026\n",
      "Total loss:  -0.9872 | PDE Loss:  -1.6184 | Function Loss:  -2.1029\n",
      "Total loss:  -0.988 | PDE Loss:  -1.6181 | Function Loss:  -2.104\n",
      "Total loss:  -0.9887 | PDE Loss:  -1.6185 | Function Loss:  -2.1047\n",
      "Total loss:  -0.9892 | PDE Loss:  -1.6161 | Function Loss:  -2.1061\n",
      "Total loss:  -0.9896 | PDE Loss:  -1.6151 | Function Loss:  -2.107\n",
      "Total loss:  -0.99 | PDE Loss:  -1.6125 | Function Loss:  -2.1083\n",
      "Total loss:  -0.9903 | PDE Loss:  -1.6117 | Function Loss:  -2.109\n",
      "Total loss:  -0.9906 | PDE Loss:  -1.6103 | Function Loss:  -2.1098\n",
      "Total loss:  -0.9909 | PDE Loss:  -1.6096 | Function Loss:  -2.1105\n",
      "Total loss:  -0.9913 | PDE Loss:  -1.6095 | Function Loss:  -2.111\n",
      "Total loss:  -0.9917 | PDE Loss:  -1.6085 | Function Loss:  -2.1118\n",
      "Total loss:  -0.9923 | PDE Loss:  -1.6103 | Function Loss:  -2.1121\n",
      "Total loss:  -0.9931 | PDE Loss:  -1.6124 | Function Loss:  -2.1124\n",
      "Total loss:  -0.9941 | PDE Loss:  -1.6154 | Function Loss:  -2.1128\n",
      "Total loss:  -0.9948 | PDE Loss:  -1.6179 | Function Loss:  -2.113\n",
      "Total loss:  -0.9956 | PDE Loss:  -1.6209 | Function Loss:  -2.1131\n",
      "Total loss:  -0.9966 | PDE Loss:  -1.6201 | Function Loss:  -2.1146\n",
      "Total loss:  -0.9972 | PDE Loss:  -1.6204 | Function Loss:  -2.1153\n",
      "Total loss:  -0.9976 | PDE Loss:  -1.6199 | Function Loss:  -2.116\n",
      "Total loss:  -0.9979 | PDE Loss:  -1.6184 | Function Loss:  -2.1169\n",
      "Total loss:  -0.9982 | PDE Loss:  -1.6185 | Function Loss:  -2.1172\n",
      "Total loss:  -0.9983 | PDE Loss:  -1.617 | Function Loss:  -2.1178\n",
      "Total loss:  -0.9984 | PDE Loss:  -1.6163 | Function Loss:  -2.1182\n",
      "Total loss:  -0.9986 | PDE Loss:  -1.6147 | Function Loss:  -2.1189\n",
      "Total loss:  -0.9987 | PDE Loss:  -1.615 | Function Loss:  -2.119\n",
      "Total loss:  -0.9989 | PDE Loss:  -1.617 | Function Loss:  -2.1187\n",
      "Total loss:  -0.9992 | PDE Loss:  -1.6192 | Function Loss:  -2.1183\n",
      "Total loss:  -0.9994 | PDE Loss:  -1.6224 | Function Loss:  -2.1175\n",
      "Total loss:  -0.9996 | PDE Loss:  -1.6252 | Function Loss:  -2.1169\n",
      "Total loss:  -0.9998 | PDE Loss:  -1.6283 | Function Loss:  -2.1162\n",
      "Total loss:  -1.0 | PDE Loss:  -1.6304 | Function Loss:  -2.1159\n",
      "Total loss:  -1.0002 | PDE Loss:  -1.632 | Function Loss:  -2.1156\n",
      "Total loss:  -1.0004 | PDE Loss:  -1.6325 | Function Loss:  -2.1157\n",
      "Total loss:  -1.0006 | PDE Loss:  -1.6323 | Function Loss:  -2.1161\n",
      "Total loss:  -1.0008 | PDE Loss:  -1.631 | Function Loss:  -2.1168\n",
      "Total loss:  -1.001 | PDE Loss:  -1.6291 | Function Loss:  -2.1177\n",
      "Total loss:  -1.0013 | PDE Loss:  -1.6267 | Function Loss:  -2.1187\n",
      "Total loss:  -1.0015 | PDE Loss:  -1.6244 | Function Loss:  -2.1197\n",
      "Total loss:  -1.0019 | PDE Loss:  -1.6215 | Function Loss:  -2.1211\n",
      "Total loss:  -1.0022 | PDE Loss:  -1.6191 | Function Loss:  -2.1223\n",
      "Total loss:  -1.0026 | PDE Loss:  -1.6174 | Function Loss:  -2.1234\n",
      "Total loss:  -1.0031 | PDE Loss:  -1.6166 | Function Loss:  -2.1242\n",
      "Total loss:  -1.0036 | PDE Loss:  -1.6171 | Function Loss:  -2.1248\n",
      "Total loss:  -1.004 | PDE Loss:  -1.6183 | Function Loss:  -2.125\n",
      "Total loss:  -1.0045 | PDE Loss:  -1.6207 | Function Loss:  -2.1248\n",
      "Total loss:  -1.0049 | PDE Loss:  -1.6239 | Function Loss:  -2.1243\n",
      "Total loss:  -1.0053 | PDE Loss:  -1.6278 | Function Loss:  -2.1237\n",
      "Total loss:  -1.0057 | PDE Loss:  -1.6328 | Function Loss:  -2.1227\n",
      "Total loss:  -1.0061 | PDE Loss:  -1.6371 | Function Loss:  -2.1218\n",
      "Total loss:  -1.0063 | PDE Loss:  -1.6414 | Function Loss:  -2.1207\n",
      "Total loss:  -1.0066 | PDE Loss:  -1.6448 | Function Loss:  -2.1201\n",
      "Total loss:  -1.0068 | PDE Loss:  -1.6476 | Function Loss:  -2.1196\n",
      "Total loss:  -1.0071 | PDE Loss:  -1.6504 | Function Loss:  -2.1191\n",
      "Total loss:  -1.0073 | PDE Loss:  -1.6538 | Function Loss:  -2.1184\n",
      "Total loss:  -1.0075 | PDE Loss:  -1.6562 | Function Loss:  -2.1179\n",
      "Total loss:  -1.0076 | PDE Loss:  -1.6582 | Function Loss:  -2.1175\n",
      "Total loss:  -1.0077 | PDE Loss:  -1.6599 | Function Loss:  -2.1172\n",
      "Total loss:  -1.0079 | PDE Loss:  -1.6603 | Function Loss:  -2.1172\n",
      "Total loss:  -1.008 | PDE Loss:  -1.6614 | Function Loss:  -2.1171\n",
      "Total loss:  -1.0081 | PDE Loss:  -1.6617 | Function Loss:  -2.1171\n",
      "Total loss:  -1.0082 | PDE Loss:  -1.6623 | Function Loss:  -2.1171\n",
      "Total loss:  -1.0083 | PDE Loss:  -1.6639 | Function Loss:  -2.1167\n",
      "Total loss:  -1.0084 | PDE Loss:  -1.6639 | Function Loss:  -2.1169\n",
      "Total loss:  -1.0085 | PDE Loss:  -1.664 | Function Loss:  -2.117\n",
      "Total loss:  -1.0086 | PDE Loss:  -1.6636 | Function Loss:  -2.1172\n",
      "Total loss:  -1.0087 | PDE Loss:  -1.663 | Function Loss:  -2.1175\n",
      "Total loss:  -1.0088 | PDE Loss:  -1.6623 | Function Loss:  -2.1178\n",
      "Total loss:  -1.0088 | PDE Loss:  -1.6613 | Function Loss:  -2.1182\n",
      "Total loss:  -1.009 | PDE Loss:  -1.6604 | Function Loss:  -2.1186\n",
      "Total loss:  -1.0091 | PDE Loss:  -1.6568 | Function Loss:  -2.1199\n",
      "Total loss:  -1.0092 | PDE Loss:  -1.6563 | Function Loss:  -2.1201\n",
      "Total loss:  -1.0096 | PDE Loss:  -1.655 | Function Loss:  -2.121\n",
      "Total loss:  -1.0101 | PDE Loss:  -1.6543 | Function Loss:  -2.1218\n",
      "Total loss:  -1.0107 | PDE Loss:  -1.6532 | Function Loss:  -2.123\n",
      "Total loss:  -1.0116 | PDE Loss:  -1.6547 | Function Loss:  -2.1236\n",
      "Total loss:  -1.0126 | PDE Loss:  -1.6558 | Function Loss:  -2.1246\n",
      "Total loss:  -1.0136 | PDE Loss:  -1.6609 | Function Loss:  -2.1244\n",
      "Total loss:  -1.0146 | PDE Loss:  -1.6647 | Function Loss:  -2.1247\n",
      "Total loss:  -1.0155 | PDE Loss:  -1.6658 | Function Loss:  -2.1254\n",
      "Total loss:  -1.0163 | PDE Loss:  -1.6684 | Function Loss:  -2.1258\n",
      "Total loss:  -1.0171 | PDE Loss:  -1.6679 | Function Loss:  -2.1269\n",
      "Total loss:  -1.0176 | PDE Loss:  -1.6648 | Function Loss:  -2.1285\n",
      "Total loss:  -1.0183 | PDE Loss:  -1.663 | Function Loss:  -2.13\n",
      "Total loss:  -1.0192 | PDE Loss:  -1.6605 | Function Loss:  -2.1319\n",
      "Total loss:  -1.0202 | PDE Loss:  -1.656 | Function Loss:  -2.1344\n",
      "Total loss:  -1.0212 | PDE Loss:  -1.6507 | Function Loss:  -2.1373\n",
      "Total loss:  -1.0218 | PDE Loss:  -1.6432 | Function Loss:  -2.1404\n",
      "Total loss:  -1.0226 | PDE Loss:  -1.6391 | Function Loss:  -2.1429\n",
      "Total loss:  -1.0237 | PDE Loss:  -1.6355 | Function Loss:  -2.1454\n",
      "Total loss:  -1.025 | PDE Loss:  -1.6254 | Function Loss:  -2.1505\n",
      "Total loss:  -1.0262 | PDE Loss:  -1.6188 | Function Loss:  -2.1544\n",
      "Total loss:  -1.0271 | PDE Loss:  -1.6103 | Function Loss:  -2.1585\n",
      "Total loss:  -1.0272 | PDE Loss:  -1.6105 | Function Loss:  -2.1586\n",
      "Total loss:  -1.028 | PDE Loss:  -1.6101 | Function Loss:  -2.1598\n",
      "Total loss:  -1.0283 | PDE Loss:  -1.6103 | Function Loss:  -2.1602\n",
      "Total loss:  -1.0287 | PDE Loss:  -1.6115 | Function Loss:  -2.1603\n",
      "Total loss:  -1.0292 | PDE Loss:  -1.6134 | Function Loss:  -2.1603\n",
      "Total loss:  -1.0299 | PDE Loss:  -1.6181 | Function Loss:  -2.1596\n",
      "Total loss:  -1.0306 | PDE Loss:  -1.6165 | Function Loss:  -2.161\n",
      "Total loss:  -1.0311 | PDE Loss:  -1.6158 | Function Loss:  -2.162\n",
      "Total loss:  -1.0315 | PDE Loss:  -1.6146 | Function Loss:  -2.163\n",
      "Total loss:  -1.0319 | PDE Loss:  -1.6125 | Function Loss:  -2.1643\n",
      "Total loss:  -1.0322 | PDE Loss:  -1.6124 | Function Loss:  -2.1646\n",
      "Total loss:  -1.0324 | PDE Loss:  -1.611 | Function Loss:  -2.1655\n",
      "Total loss:  -1.0326 | PDE Loss:  -1.6111 | Function Loss:  -2.1657\n",
      "Total loss:  -1.0328 | PDE Loss:  -1.6108 | Function Loss:  -2.166\n",
      "Total loss:  -1.033 | PDE Loss:  -1.6116 | Function Loss:  -2.166\n",
      "Total loss:  -1.0332 | PDE Loss:  -1.6121 | Function Loss:  -2.1661\n",
      "Total loss:  -1.0334 | PDE Loss:  -1.6118 | Function Loss:  -2.1666\n",
      "Total loss:  -1.0337 | PDE Loss:  -1.6112 | Function Loss:  -2.1671\n",
      "Total loss:  -1.0339 | PDE Loss:  -1.6092 | Function Loss:  -2.1682\n",
      "Total loss:  -1.0342 | PDE Loss:  -1.6064 | Function Loss:  -2.1695\n",
      "Total loss:  -1.0347 | PDE Loss:  -1.6013 | Function Loss:  -2.1721\n",
      "Total loss:  -1.0352 | PDE Loss:  -1.5929 | Function Loss:  -2.1759\n",
      "Total loss:  -1.0358 | PDE Loss:  -1.5831 | Function Loss:  -2.1806\n",
      "Total loss:  -1.0361 | PDE Loss:  -1.5813 | Function Loss:  -2.1818\n",
      "Total loss:  -1.0365 | PDE Loss:  -1.5801 | Function Loss:  -2.1828\n",
      "Total loss:  -1.0368 | PDE Loss:  -1.5803 | Function Loss:  -2.1832\n",
      "Total loss:  -1.0369 | PDE Loss:  -1.5778 | Function Loss:  -2.1844\n",
      "Total loss:  -1.037 | PDE Loss:  -1.5786 | Function Loss:  -2.1841\n",
      "Total loss:  -1.037 | PDE Loss:  -1.5792 | Function Loss:  -2.1839\n",
      "Total loss:  -1.0371 | PDE Loss:  -1.5794 | Function Loss:  -2.1839\n",
      "Total loss:  -1.0371 | PDE Loss:  -1.5801 | Function Loss:  -2.1837\n",
      "Total loss:  -1.0371 | PDE Loss:  -1.5801 | Function Loss:  -2.1837\n",
      "Total loss:  -1.0371 | PDE Loss:  -1.5801 | Function Loss:  -2.1837\n",
      "Total loss:  -1.0372 | PDE Loss:  -1.5801 | Function Loss:  -2.1838\n",
      "Total loss:  -1.0373 | PDE Loss:  -1.5799 | Function Loss:  -2.1839\n",
      "Total loss:  -1.0373 | PDE Loss:  -1.5798 | Function Loss:  -2.1841\n",
      "Total loss:  -1.0374 | PDE Loss:  -1.5795 | Function Loss:  -2.1843\n",
      "Total loss:  -1.0375 | PDE Loss:  -1.5794 | Function Loss:  -2.1845\n",
      "Total loss:  -1.0376 | PDE Loss:  -1.5793 | Function Loss:  -2.1847\n",
      "Total loss:  -1.0377 | PDE Loss:  -1.5797 | Function Loss:  -2.1846\n",
      "Total loss:  -1.0377 | PDE Loss:  -1.5801 | Function Loss:  -2.1846\n",
      "Total loss:  -1.0378 | PDE Loss:  -1.5808 | Function Loss:  -2.1844\n",
      "Total loss:  -1.0379 | PDE Loss:  -1.5817 | Function Loss:  -2.1841\n",
      "Total loss:  -1.038 | PDE Loss:  -1.5832 | Function Loss:  -2.1837\n",
      "Total loss:  -1.0381 | PDE Loss:  -1.5849 | Function Loss:  -2.1831\n",
      "Total loss:  -1.0383 | PDE Loss:  -1.5875 | Function Loss:  -2.1823\n",
      "Total loss:  -1.0384 | PDE Loss:  -1.5897 | Function Loss:  -2.1817\n",
      "Total loss:  -1.0386 | PDE Loss:  -1.5919 | Function Loss:  -2.1811\n",
      "Total loss:  -1.0389 | PDE Loss:  -1.593 | Function Loss:  -2.181\n",
      "Total loss:  -1.0391 | PDE Loss:  -1.5946 | Function Loss:  -2.1807\n",
      "Total loss:  -1.0394 | PDE Loss:  -1.5951 | Function Loss:  -2.1809\n",
      "Total loss:  -1.0396 | PDE Loss:  -1.5969 | Function Loss:  -2.1805\n",
      "Total loss:  -1.0399 | PDE Loss:  -1.5977 | Function Loss:  -2.1806\n",
      "Total loss:  -1.0402 | PDE Loss:  -1.5994 | Function Loss:  -2.1803\n",
      "Total loss:  -1.0405 | PDE Loss:  -1.6005 | Function Loss:  -2.1805\n",
      "Total loss:  -1.0409 | PDE Loss:  -1.6028 | Function Loss:  -2.1801\n",
      "Total loss:  -1.0412 | PDE Loss:  -1.6042 | Function Loss:  -2.1799\n",
      "Total loss:  -1.0414 | PDE Loss:  -1.6064 | Function Loss:  -2.1794\n",
      "Total loss:  -1.0415 | PDE Loss:  -1.6083 | Function Loss:  -2.1789\n",
      "Total loss:  -1.0417 | PDE Loss:  -1.6095 | Function Loss:  -2.1786\n",
      "Total loss:  -1.0418 | PDE Loss:  -1.6107 | Function Loss:  -2.1784\n",
      "Total loss:  -1.0419 | PDE Loss:  -1.6111 | Function Loss:  -2.1784\n",
      "Total loss:  -1.0421 | PDE Loss:  -1.6114 | Function Loss:  -2.1785\n",
      "Total loss:  -1.0422 | PDE Loss:  -1.6105 | Function Loss:  -2.179\n",
      "Total loss:  -1.0423 | PDE Loss:  -1.6098 | Function Loss:  -2.1794\n",
      "Total loss:  -1.0424 | PDE Loss:  -1.6087 | Function Loss:  -2.18\n",
      "Total loss:  -1.0425 | PDE Loss:  -1.6078 | Function Loss:  -2.1804\n",
      "Total loss:  -1.0426 | PDE Loss:  -1.6071 | Function Loss:  -2.1808\n",
      "Total loss:  -1.0426 | PDE Loss:  -1.6068 | Function Loss:  -2.181\n",
      "Total loss:  -1.0427 | PDE Loss:  -1.6068 | Function Loss:  -2.1811\n",
      "Total loss:  -1.0428 | PDE Loss:  -1.6071 | Function Loss:  -2.1811\n",
      "Total loss:  -1.0429 | PDE Loss:  -1.608 | Function Loss:  -2.1809\n",
      "Total loss:  -1.043 | PDE Loss:  -1.6089 | Function Loss:  -2.1807\n",
      "Total loss:  -1.0431 | PDE Loss:  -1.6102 | Function Loss:  -2.1804\n",
      "Total loss:  -1.0433 | PDE Loss:  -1.6116 | Function Loss:  -2.1801\n",
      "Total loss:  -1.0434 | PDE Loss:  -1.6126 | Function Loss:  -2.1799\n",
      "Total loss:  -1.0435 | PDE Loss:  -1.6129 | Function Loss:  -2.1799\n",
      "Total loss:  -1.0435 | PDE Loss:  -1.6125 | Function Loss:  -2.1801\n",
      "Total loss:  -1.0436 | PDE Loss:  -1.6117 | Function Loss:  -2.1804\n",
      "Total loss:  -1.0436 | PDE Loss:  -1.6106 | Function Loss:  -2.1809\n",
      "Total loss:  -1.0437 | PDE Loss:  -1.6091 | Function Loss:  -2.1815\n",
      "Total loss:  -1.0437 | PDE Loss:  -1.6073 | Function Loss:  -2.1823\n",
      "Total loss:  -1.0438 | PDE Loss:  -1.6052 | Function Loss:  -2.1832\n",
      "Total loss:  -1.0439 | PDE Loss:  -1.6033 | Function Loss:  -2.184\n",
      "Total loss:  -1.044 | PDE Loss:  -1.6013 | Function Loss:  -2.1849\n",
      "Total loss:  -1.044 | PDE Loss:  -1.6003 | Function Loss:  -2.1854\n",
      "Total loss:  -1.0441 | PDE Loss:  -1.5995 | Function Loss:  -2.1857\n",
      "Total loss:  -1.0442 | PDE Loss:  -1.5996 | Function Loss:  -2.1858\n",
      "Total loss:  -1.0442 | PDE Loss:  -1.5998 | Function Loss:  -2.1858\n",
      "Total loss:  -1.0443 | PDE Loss:  -1.6006 | Function Loss:  -2.1857\n",
      "Total loss:  -1.0444 | PDE Loss:  -1.6024 | Function Loss:  -2.1851\n",
      "Total loss:  -1.0445 | PDE Loss:  -1.6032 | Function Loss:  -2.1848\n",
      "Total loss:  -1.0445 | PDE Loss:  -1.6049 | Function Loss:  -2.1843\n",
      "Total loss:  -1.0446 | PDE Loss:  -1.6074 | Function Loss:  -2.1835\n",
      "Total loss:  -1.0448 | PDE Loss:  -1.6089 | Function Loss:  -2.1831\n",
      "Total loss:  -1.0449 | PDE Loss:  -1.6112 | Function Loss:  -2.1824\n",
      "Total loss:  -1.0451 | PDE Loss:  -1.614 | Function Loss:  -2.1816\n",
      "Total loss:  -1.0452 | PDE Loss:  -1.6151 | Function Loss:  -2.1814\n",
      "Total loss:  -1.0453 | PDE Loss:  -1.6166 | Function Loss:  -2.181\n",
      "Total loss:  -1.0457 | PDE Loss:  -1.6186 | Function Loss:  -2.1808\n",
      "Total loss:  -1.0459 | PDE Loss:  -1.6218 | Function Loss:  -2.18\n",
      "Total loss:  -1.0463 | PDE Loss:  -1.6244 | Function Loss:  -2.1795\n",
      "Total loss:  -1.0464 | PDE Loss:  -1.6263 | Function Loss:  -2.179\n",
      "Total loss:  -1.0466 | PDE Loss:  -1.6277 | Function Loss:  -2.1788\n",
      "Total loss:  -1.0468 | PDE Loss:  -1.6308 | Function Loss:  -2.1779\n",
      "Total loss:  -1.0471 | PDE Loss:  -1.6327 | Function Loss:  -2.1777\n",
      "Total loss:  -1.0474 | PDE Loss:  -1.635 | Function Loss:  -2.1772\n",
      "Total loss:  -1.048 | PDE Loss:  -1.6409 | Function Loss:  -2.176\n",
      "Total loss:  -1.0486 | PDE Loss:  -1.6454 | Function Loss:  -2.1753\n",
      "Total loss:  -1.0492 | PDE Loss:  -1.6501 | Function Loss:  -2.1746\n",
      "Total loss:  -1.0499 | PDE Loss:  -1.6589 | Function Loss:  -2.1725\n",
      "Total loss:  -1.0508 | PDE Loss:  -1.6634 | Function Loss:  -2.1723\n",
      "Total loss:  -1.0518 | PDE Loss:  -1.6682 | Function Loss:  -2.1721\n",
      "Total loss:  -1.0531 | PDE Loss:  -1.6685 | Function Loss:  -2.1736\n",
      "Total loss:  -1.0542 | PDE Loss:  -1.6694 | Function Loss:  -2.1748\n",
      "Total loss:  -1.0557 | PDE Loss:  -1.6643 | Function Loss:  -2.1784\n",
      "Total loss:  -1.0567 | PDE Loss:  -1.661 | Function Loss:  -2.1809\n",
      "Total loss:  -1.0587 | PDE Loss:  -1.6603 | Function Loss:  -2.1838\n",
      "Total loss:  -1.0607 | PDE Loss:  -1.6586 | Function Loss:  -2.187\n",
      "Total loss:  -1.0615 | PDE Loss:  -1.659 | Function Loss:  -2.1879\n",
      "Total loss:  -1.0623 | PDE Loss:  -1.6645 | Function Loss:  -2.1872\n",
      "Total loss:  -1.0629 | PDE Loss:  -1.6671 | Function Loss:  -2.1871\n",
      "Total loss:  -1.0633 | PDE Loss:  -1.6696 | Function Loss:  -2.1868\n",
      "Total loss:  -1.0639 | PDE Loss:  -1.6734 | Function Loss:  -2.1864\n",
      "Total loss:  -1.0644 | PDE Loss:  -1.6773 | Function Loss:  -2.1858\n",
      "Total loss:  -1.0648 | PDE Loss:  -1.6799 | Function Loss:  -2.1855\n",
      "Total loss:  -1.0652 | PDE Loss:  -1.6827 | Function Loss:  -2.1852\n",
      "Total loss:  -1.0656 | PDE Loss:  -1.6845 | Function Loss:  -2.1851\n",
      "Total loss:  -1.0659 | PDE Loss:  -1.6854 | Function Loss:  -2.1852\n",
      "Total loss:  -1.066 | PDE Loss:  -1.6857 | Function Loss:  -2.1853\n",
      "Total loss:  -1.0661 | PDE Loss:  -1.6856 | Function Loss:  -2.1854\n",
      "Total loss:  -1.0663 | PDE Loss:  -1.6856 | Function Loss:  -2.1856\n",
      "Total loss:  -1.0664 | PDE Loss:  -1.6856 | Function Loss:  -2.1857\n",
      "Total loss:  -1.0665 | PDE Loss:  -1.6858 | Function Loss:  -2.1858\n",
      "Total loss:  -1.0666 | PDE Loss:  -1.686 | Function Loss:  -2.1859\n",
      "Total loss:  -1.0668 | PDE Loss:  -1.6862 | Function Loss:  -2.1861\n",
      "Total loss:  -1.067 | PDE Loss:  -1.6862 | Function Loss:  -2.1863\n",
      "Total loss:  -1.0672 | PDE Loss:  -1.6872 | Function Loss:  -2.1863\n",
      "Total loss:  -1.0674 | PDE Loss:  -1.688 | Function Loss:  -2.1863\n",
      "Total loss:  -1.0676 | PDE Loss:  -1.6901 | Function Loss:  -2.186\n",
      "Total loss:  -1.0679 | PDE Loss:  -1.6919 | Function Loss:  -2.1857\n",
      "Total loss:  -1.0682 | PDE Loss:  -1.6944 | Function Loss:  -2.1853\n",
      "Total loss:  -1.0684 | PDE Loss:  -1.6964 | Function Loss:  -2.185\n",
      "Total loss:  -1.0686 | PDE Loss:  -1.6986 | Function Loss:  -2.1847\n",
      "Total loss:  -1.0688 | PDE Loss:  -1.7018 | Function Loss:  -2.1839\n",
      "Total loss:  -1.069 | PDE Loss:  -1.7027 | Function Loss:  -2.1839\n",
      "Total loss:  -1.0692 | PDE Loss:  -1.7053 | Function Loss:  -2.1834\n",
      "Total loss:  -1.0694 | PDE Loss:  -1.7069 | Function Loss:  -2.1831\n",
      "Total loss:  -1.0696 | PDE Loss:  -1.7085 | Function Loss:  -2.183\n",
      "Total loss:  -1.0698 | PDE Loss:  -1.7107 | Function Loss:  -2.1826\n",
      "Total loss:  -1.07 | PDE Loss:  -1.7125 | Function Loss:  -2.1823\n",
      "Total loss:  -1.0702 | PDE Loss:  -1.7144 | Function Loss:  -2.182\n",
      "Total loss:  -1.0703 | PDE Loss:  -1.7154 | Function Loss:  -2.1818\n",
      "Total loss:  -1.0706 | PDE Loss:  -1.7168 | Function Loss:  -2.1817\n",
      "Total loss:  -1.0707 | PDE Loss:  -1.7173 | Function Loss:  -2.1818\n",
      "Total loss:  -1.0709 | PDE Loss:  -1.7175 | Function Loss:  -2.1819\n",
      "Total loss:  -1.0709 | PDE Loss:  -1.7176 | Function Loss:  -2.182\n",
      "Total loss:  -1.071 | PDE Loss:  -1.7168 | Function Loss:  -2.1823\n",
      "Total loss:  -1.0711 | PDE Loss:  -1.7169 | Function Loss:  -2.1823\n",
      "Total loss:  -1.0711 | PDE Loss:  -1.7165 | Function Loss:  -2.1825\n",
      "Total loss:  -1.0712 | PDE Loss:  -1.7172 | Function Loss:  -2.1825\n",
      "Total loss:  -1.0713 | PDE Loss:  -1.7168 | Function Loss:  -2.1827\n",
      "Total loss:  -1.0715 | PDE Loss:  -1.7166 | Function Loss:  -2.1829\n",
      "Total loss:  -1.0716 | PDE Loss:  -1.7178 | Function Loss:  -2.1828\n",
      "Total loss:  -1.0717 | PDE Loss:  -1.7181 | Function Loss:  -2.1829\n",
      "Total loss:  -1.0719 | PDE Loss:  -1.7183 | Function Loss:  -2.183\n",
      "Total loss:  -1.0722 | PDE Loss:  -1.7165 | Function Loss:  -2.1839\n",
      "Total loss:  -1.0725 | PDE Loss:  -1.7161 | Function Loss:  -2.1844\n",
      "Total loss:  -1.0729 | PDE Loss:  -1.715 | Function Loss:  -2.1853\n",
      "Total loss:  -1.0735 | PDE Loss:  -1.7141 | Function Loss:  -2.1863\n",
      "Total loss:  -1.074 | PDE Loss:  -1.7102 | Function Loss:  -2.1881\n",
      "Total loss:  -1.0744 | PDE Loss:  -1.7086 | Function Loss:  -2.1892\n",
      "Total loss:  -1.0747 | PDE Loss:  -1.7093 | Function Loss:  -2.1893\n",
      "Total loss:  -1.0751 | PDE Loss:  -1.7071 | Function Loss:  -2.1905\n",
      "Total loss:  -1.0755 | PDE Loss:  -1.7037 | Function Loss:  -2.1921\n",
      "Total loss:  -1.0757 | PDE Loss:  -1.7019 | Function Loss:  -2.1929\n",
      "Total loss:  -1.076 | PDE Loss:  -1.7027 | Function Loss:  -2.193\n",
      "Total loss:  -1.0763 | PDE Loss:  -1.7042 | Function Loss:  -2.1929\n",
      "Total loss:  -1.0769 | PDE Loss:  -1.7094 | Function Loss:  -2.1921\n",
      "Total loss:  -1.0774 | PDE Loss:  -1.7158 | Function Loss:  -2.1909\n",
      "Total loss:  -1.0779 | PDE Loss:  -1.7237 | Function Loss:  -2.1892\n",
      "Total loss:  -1.0782 | PDE Loss:  -1.7284 | Function Loss:  -2.1881\n",
      "Total loss:  -1.0783 | PDE Loss:  -1.732 | Function Loss:  -2.1874\n",
      "Total loss:  -1.0784 | PDE Loss:  -1.736 | Function Loss:  -2.1863\n",
      "Total loss:  -1.0786 | PDE Loss:  -1.7373 | Function Loss:  -2.1862\n",
      "Total loss:  -1.0788 | PDE Loss:  -1.7386 | Function Loss:  -2.1861\n",
      "Total loss:  -1.079 | PDE Loss:  -1.7393 | Function Loss:  -2.1861\n",
      "Total loss:  -1.0792 | PDE Loss:  -1.7397 | Function Loss:  -2.1862\n",
      "Total loss:  -1.0793 | PDE Loss:  -1.7412 | Function Loss:  -2.186\n",
      "Total loss:  -1.0794 | PDE Loss:  -1.7417 | Function Loss:  -2.186\n",
      "Total loss:  -1.0796 | PDE Loss:  -1.7448 | Function Loss:  -2.1853\n",
      "Total loss:  -1.0797 | PDE Loss:  -1.7477 | Function Loss:  -2.1848\n",
      "Total loss:  -1.08 | PDE Loss:  -1.7513 | Function Loss:  -2.1841\n",
      "Total loss:  -1.0802 | PDE Loss:  -1.755 | Function Loss:  -2.1834\n",
      "Total loss:  -1.0805 | PDE Loss:  -1.7585 | Function Loss:  -2.1828\n",
      "Total loss:  -1.0808 | PDE Loss:  -1.7601 | Function Loss:  -2.1828\n",
      "Total loss:  -1.0808 | PDE Loss:  -1.7653 | Function Loss:  -2.1814\n",
      "Total loss:  -1.081 | PDE Loss:  -1.7633 | Function Loss:  -2.1822\n",
      "Total loss:  -1.0811 | PDE Loss:  -1.7645 | Function Loss:  -2.1821\n",
      "Total loss:  -1.0815 | PDE Loss:  -1.7632 | Function Loss:  -2.1828\n",
      "Total loss:  -1.0818 | PDE Loss:  -1.7619 | Function Loss:  -2.1836\n",
      "Total loss:  -1.082 | PDE Loss:  -1.7605 | Function Loss:  -2.1842\n",
      "Total loss:  -1.0822 | PDE Loss:  -1.7598 | Function Loss:  -2.1846\n",
      "Total loss:  -1.0824 | PDE Loss:  -1.7587 | Function Loss:  -2.1851\n",
      "Total loss:  -1.0827 | PDE Loss:  -1.7601 | Function Loss:  -2.1851\n",
      "Total loss:  -1.0831 | PDE Loss:  -1.7617 | Function Loss:  -2.1853\n",
      "Total loss:  -1.0835 | PDE Loss:  -1.7656 | Function Loss:  -2.1848\n",
      "Total loss:  -1.084 | PDE Loss:  -1.7688 | Function Loss:  -2.1845\n",
      "Total loss:  -1.0843 | PDE Loss:  -1.7718 | Function Loss:  -2.1841\n",
      "Total loss:  -1.0847 | PDE Loss:  -1.7735 | Function Loss:  -2.1841\n",
      "Total loss:  -1.0849 | PDE Loss:  -1.7757 | Function Loss:  -2.1839\n",
      "Total loss:  -1.0851 | PDE Loss:  -1.7746 | Function Loss:  -2.1845\n",
      "Total loss:  -1.0853 | PDE Loss:  -1.7727 | Function Loss:  -2.1851\n",
      "Total loss:  -1.0854 | PDE Loss:  -1.7718 | Function Loss:  -2.1855\n",
      "Total loss:  -1.0855 | PDE Loss:  -1.771 | Function Loss:  -2.1859\n",
      "Total loss:  -1.0856 | PDE Loss:  -1.7708 | Function Loss:  -2.1861\n",
      "Total loss:  -1.0857 | PDE Loss:  -1.7708 | Function Loss:  -2.1862\n",
      "Total loss:  -1.0858 | PDE Loss:  -1.7718 | Function Loss:  -2.1861\n",
      "Total loss:  -1.086 | PDE Loss:  -1.7729 | Function Loss:  -2.186\n",
      "Total loss:  -1.0862 | PDE Loss:  -1.7745 | Function Loss:  -2.1858\n",
      "Total loss:  -1.0865 | PDE Loss:  -1.7768 | Function Loss:  -2.1856\n",
      "Total loss:  -1.0868 | PDE Loss:  -1.7796 | Function Loss:  -2.1853\n",
      "Total loss:  -1.0873 | PDE Loss:  -1.782 | Function Loss:  -2.1853\n",
      "Total loss:  -1.088 | PDE Loss:  -1.7834 | Function Loss:  -2.1858\n",
      "Total loss:  -1.0884 | PDE Loss:  -1.7828 | Function Loss:  -2.1865\n",
      "Total loss:  -1.0891 | PDE Loss:  -1.7806 | Function Loss:  -2.1879\n",
      "Total loss:  -1.0897 | PDE Loss:  -1.7782 | Function Loss:  -2.1892\n",
      "Total loss:  -1.0905 | PDE Loss:  -1.7729 | Function Loss:  -2.1916\n",
      "Total loss:  -1.0912 | PDE Loss:  -1.7688 | Function Loss:  -2.1936\n",
      "Total loss:  -1.0918 | PDE Loss:  -1.7639 | Function Loss:  -2.1957\n",
      "Total loss:  -1.0926 | PDE Loss:  -1.7572 | Function Loss:  -2.1986\n",
      "Total loss:  -1.0932 | PDE Loss:  -1.7572 | Function Loss:  -2.1993\n",
      "Total loss:  -1.0941 | PDE Loss:  -1.759 | Function Loss:  -2.2\n",
      "Total loss:  -1.095 | PDE Loss:  -1.7626 | Function Loss:  -2.2001\n",
      "Total loss:  -1.0957 | PDE Loss:  -1.7651 | Function Loss:  -2.2003\n",
      "Total loss:  -1.0962 | PDE Loss:  -1.7689 | Function Loss:  -2.2\n",
      "Total loss:  -1.0967 | PDE Loss:  -1.7734 | Function Loss:  -2.1994\n",
      "Total loss:  -1.0975 | PDE Loss:  -1.775 | Function Loss:  -2.1999\n",
      "Total loss:  -1.0984 | PDE Loss:  -1.7784 | Function Loss:  -2.2002\n",
      "Total loss:  -1.1 | PDE Loss:  -1.789 | Function Loss:  -2.1994\n",
      "Total loss:  -1.1014 | PDE Loss:  -1.8006 | Function Loss:  -2.1982\n",
      "Total loss:  -1.1018 | PDE Loss:  -1.8165 | Function Loss:  -2.1949\n",
      "Total loss:  -1.1021 | PDE Loss:  -1.8115 | Function Loss:  -2.1965\n",
      "Total loss:  -1.1028 | PDE Loss:  -1.8207 | Function Loss:  -2.1952\n",
      "Total loss:  -1.1034 | PDE Loss:  -1.8285 | Function Loss:  -2.194\n",
      "Total loss:  -1.1036 | PDE Loss:  -1.8302 | Function Loss:  -2.1939\n",
      "Total loss:  -1.1037 | PDE Loss:  -1.8317 | Function Loss:  -2.1937\n",
      "Total loss:  -1.1038 | PDE Loss:  -1.8309 | Function Loss:  -2.194\n",
      "Total loss:  -1.1039 | PDE Loss:  -1.8303 | Function Loss:  -2.1942\n",
      "Total loss:  -1.104 | PDE Loss:  -1.8297 | Function Loss:  -2.1944\n",
      "Total loss:  -1.104 | PDE Loss:  -1.829 | Function Loss:  -2.1947\n",
      "Total loss:  -1.1041 | PDE Loss:  -1.8283 | Function Loss:  -2.1949\n",
      "Total loss:  -1.1041 | PDE Loss:  -1.8276 | Function Loss:  -2.1951\n",
      "Total loss:  -1.1042 | PDE Loss:  -1.8272 | Function Loss:  -2.1953\n",
      "Total loss:  -1.1042 | PDE Loss:  -1.8261 | Function Loss:  -2.1956\n",
      "Total loss:  -1.1043 | PDE Loss:  -1.8258 | Function Loss:  -2.1958\n",
      "Total loss:  -1.1044 | PDE Loss:  -1.8248 | Function Loss:  -2.1961\n",
      "Total loss:  -1.1045 | PDE Loss:  -1.8243 | Function Loss:  -2.1964\n",
      "Total loss:  -1.1047 | PDE Loss:  -1.8229 | Function Loss:  -2.1969\n",
      "Total loss:  -1.1049 | PDE Loss:  -1.8215 | Function Loss:  -2.1975\n",
      "Total loss:  -1.1051 | PDE Loss:  -1.8211 | Function Loss:  -2.1979\n",
      "Total loss:  -1.1055 | PDE Loss:  -1.8199 | Function Loss:  -2.1986\n",
      "Total loss:  -1.1058 | PDE Loss:  -1.8204 | Function Loss:  -2.1989\n",
      "Total loss:  -1.1061 | PDE Loss:  -1.8192 | Function Loss:  -2.1996\n",
      "Total loss:  -1.1064 | PDE Loss:  -1.8199 | Function Loss:  -2.1997\n",
      "Total loss:  -1.1066 | PDE Loss:  -1.8183 | Function Loss:  -2.2003\n",
      "Total loss:  -1.1068 | PDE Loss:  -1.8189 | Function Loss:  -2.2005\n",
      "Total loss:  -1.1071 | PDE Loss:  -1.8205 | Function Loss:  -2.2005\n",
      "Total loss:  -1.1074 | PDE Loss:  -1.8221 | Function Loss:  -2.2005\n",
      "Total loss:  -1.1078 | PDE Loss:  -1.825 | Function Loss:  -2.2002\n",
      "Total loss:  -1.1081 | PDE Loss:  -1.8278 | Function Loss:  -2.2\n",
      "Total loss:  -1.1084 | PDE Loss:  -1.833 | Function Loss:  -2.1991\n",
      "Total loss:  -1.1087 | PDE Loss:  -1.8357 | Function Loss:  -2.1988\n",
      "Total loss:  -1.1089 | PDE Loss:  -1.8389 | Function Loss:  -2.1984\n",
      "Total loss:  -1.1092 | PDE Loss:  -1.8439 | Function Loss:  -2.1976\n",
      "Total loss:  -1.1094 | PDE Loss:  -1.8456 | Function Loss:  -2.1975\n",
      "Total loss:  -1.1096 | PDE Loss:  -1.8459 | Function Loss:  -2.1976\n",
      "Total loss:  -1.1098 | PDE Loss:  -1.8459 | Function Loss:  -2.1979\n",
      "Total loss:  -1.1101 | PDE Loss:  -1.8448 | Function Loss:  -2.1985\n",
      "Total loss:  -1.1104 | PDE Loss:  -1.8419 | Function Loss:  -2.1996\n",
      "Total loss:  -1.1106 | PDE Loss:  -1.8399 | Function Loss:  -2.2003\n",
      "Total loss:  -1.1109 | PDE Loss:  -1.8353 | Function Loss:  -2.2017\n",
      "Total loss:  -1.111 | PDE Loss:  -1.8346 | Function Loss:  -2.2019\n",
      "Total loss:  -1.1111 | PDE Loss:  -1.8352 | Function Loss:  -2.2019\n",
      "Total loss:  -1.1112 | PDE Loss:  -1.8357 | Function Loss:  -2.202\n",
      "Total loss:  -1.1113 | PDE Loss:  -1.8377 | Function Loss:  -2.2016\n",
      "Total loss:  -1.1114 | PDE Loss:  -1.8399 | Function Loss:  -2.2012\n",
      "Total loss:  -1.1115 | PDE Loss:  -1.8429 | Function Loss:  -2.2007\n",
      "Total loss:  -1.1116 | PDE Loss:  -1.8469 | Function Loss:  -2.1999\n",
      "Total loss:  -1.1117 | PDE Loss:  -1.8501 | Function Loss:  -2.1993\n",
      "Total loss:  -1.1119 | PDE Loss:  -1.8547 | Function Loss:  -2.1985\n",
      "Total loss:  -1.1121 | PDE Loss:  -1.8586 | Function Loss:  -2.1979\n",
      "Total loss:  -1.1122 | PDE Loss:  -1.8622 | Function Loss:  -2.1973\n",
      "Total loss:  -1.1123 | PDE Loss:  -1.864 | Function Loss:  -2.197\n",
      "Total loss:  -1.1124 | PDE Loss:  -1.8653 | Function Loss:  -2.1969\n",
      "Total loss:  -1.1125 | PDE Loss:  -1.8653 | Function Loss:  -2.1969\n",
      "Total loss:  -1.1126 | PDE Loss:  -1.8648 | Function Loss:  -2.1972\n",
      "Total loss:  -1.1128 | PDE Loss:  -1.8645 | Function Loss:  -2.1975\n",
      "Total loss:  -1.113 | PDE Loss:  -1.8647 | Function Loss:  -2.1977\n",
      "Total loss:  -1.1133 | PDE Loss:  -1.8656 | Function Loss:  -2.1978\n",
      "Total loss:  -1.1136 | PDE Loss:  -1.8674 | Function Loss:  -2.1978\n",
      "Total loss:  -1.1139 | PDE Loss:  -1.87 | Function Loss:  -2.1976\n",
      "Total loss:  -1.1141 | PDE Loss:  -1.8735 | Function Loss:  -2.1972\n",
      "Total loss:  -1.1144 | PDE Loss:  -1.8767 | Function Loss:  -2.1968\n",
      "Total loss:  -1.1146 | PDE Loss:  -1.8838 | Function Loss:  -2.1956\n",
      "Total loss:  -1.1147 | PDE Loss:  -1.8838 | Function Loss:  -2.1958\n",
      "Total loss:  -1.1149 | PDE Loss:  -1.8859 | Function Loss:  -2.1955\n",
      "Total loss:  -1.115 | PDE Loss:  -1.8852 | Function Loss:  -2.1957\n",
      "Total loss:  -1.1151 | PDE Loss:  -1.8844 | Function Loss:  -2.1961\n",
      "Total loss:  -1.1152 | PDE Loss:  -1.8828 | Function Loss:  -2.1966\n",
      "Total loss:  -1.1154 | PDE Loss:  -1.8804 | Function Loss:  -2.1972\n",
      "Total loss:  -1.1155 | PDE Loss:  -1.8775 | Function Loss:  -2.198\n",
      "Total loss:  -1.1157 | PDE Loss:  -1.8747 | Function Loss:  -2.1988\n",
      "Total loss:  -1.1159 | PDE Loss:  -1.8709 | Function Loss:  -2.1999\n",
      "Total loss:  -1.1161 | PDE Loss:  -1.8685 | Function Loss:  -2.2007\n",
      "Total loss:  -1.1164 | PDE Loss:  -1.8663 | Function Loss:  -2.2014\n",
      "Total loss:  -1.1168 | PDE Loss:  -1.8641 | Function Loss:  -2.2024\n",
      "Total loss:  -1.1172 | PDE Loss:  -1.8614 | Function Loss:  -2.2036\n",
      "Total loss:  -1.1175 | PDE Loss:  -1.8606 | Function Loss:  -2.2041\n",
      "Total loss:  -1.1178 | PDE Loss:  -1.8593 | Function Loss:  -2.2047\n",
      "Total loss:  -1.1181 | PDE Loss:  -1.8587 | Function Loss:  -2.2051\n",
      "Total loss:  -1.1183 | PDE Loss:  -1.8583 | Function Loss:  -2.2055\n",
      "Total loss:  -1.1185 | PDE Loss:  -1.8552 | Function Loss:  -2.2064\n",
      "Total loss:  -1.1186 | PDE Loss:  -1.8549 | Function Loss:  -2.2067\n",
      "Total loss:  -1.1187 | PDE Loss:  -1.8542 | Function Loss:  -2.207\n",
      "Total loss:  -1.119 | PDE Loss:  -1.8528 | Function Loss:  -2.2076\n",
      "Total loss:  -1.1194 | PDE Loss:  -1.8521 | Function Loss:  -2.2083\n",
      "Total loss:  -1.1198 | PDE Loss:  -1.8514 | Function Loss:  -2.209\n",
      "Total loss:  -1.1203 | PDE Loss:  -1.8518 | Function Loss:  -2.2095\n",
      "Total loss:  -1.1207 | PDE Loss:  -1.8536 | Function Loss:  -2.2096\n",
      "Total loss:  -1.1211 | PDE Loss:  -1.8562 | Function Loss:  -2.2094\n",
      "Total loss:  -1.1214 | PDE Loss:  -1.8598 | Function Loss:  -2.209\n",
      "Total loss:  -1.1219 | PDE Loss:  -1.8639 | Function Loss:  -2.2087\n",
      "Total loss:  -1.1224 | PDE Loss:  -1.8702 | Function Loss:  -2.2079\n",
      "Total loss:  -1.1227 | PDE Loss:  -1.8731 | Function Loss:  -2.2077\n",
      "Total loss:  -1.1231 | PDE Loss:  -1.8776 | Function Loss:  -2.2071\n",
      "Total loss:  -1.1234 | PDE Loss:  -1.8793 | Function Loss:  -2.2072\n",
      "Total loss:  -1.1237 | PDE Loss:  -1.8803 | Function Loss:  -2.2074\n",
      "Total loss:  -1.1242 | PDE Loss:  -1.8791 | Function Loss:  -2.2082\n",
      "Total loss:  -1.1245 | PDE Loss:  -1.8782 | Function Loss:  -2.2088\n",
      "Total loss:  -1.1247 | PDE Loss:  -1.8774 | Function Loss:  -2.2092\n",
      "Total loss:  -1.125 | PDE Loss:  -1.8768 | Function Loss:  -2.2097\n",
      "Total loss:  -1.1254 | PDE Loss:  -1.8782 | Function Loss:  -2.2099\n",
      "Total loss:  -1.1259 | PDE Loss:  -1.8815 | Function Loss:  -2.2097\n",
      "Total loss:  -1.1262 | PDE Loss:  -1.883 | Function Loss:  -2.2098\n",
      "Total loss:  -1.1266 | PDE Loss:  -1.8875 | Function Loss:  -2.2094\n",
      "Total loss:  -1.127 | PDE Loss:  -1.8899 | Function Loss:  -2.2093\n",
      "Total loss:  -1.1273 | PDE Loss:  -1.8918 | Function Loss:  -2.2093\n",
      "Total loss:  -1.1276 | PDE Loss:  -1.8947 | Function Loss:  -2.209\n",
      "Total loss:  -1.1279 | PDE Loss:  -1.8954 | Function Loss:  -2.2093\n",
      "Total loss:  -1.1283 | PDE Loss:  -1.8962 | Function Loss:  -2.2095\n",
      "Total loss:  -1.1288 | PDE Loss:  -1.8951 | Function Loss:  -2.2104\n",
      "Total loss:  -1.1291 | PDE Loss:  -1.8951 | Function Loss:  -2.2108\n",
      "Total loss:  -1.1297 | PDE Loss:  -1.8944 | Function Loss:  -2.2116\n",
      "Total loss:  -1.1301 | PDE Loss:  -1.8926 | Function Loss:  -2.2125\n",
      "Total loss:  -1.1308 | PDE Loss:  -1.8919 | Function Loss:  -2.2134\n",
      "Total loss:  -1.1316 | PDE Loss:  -1.8916 | Function Loss:  -2.2145\n",
      "Total loss:  -1.1327 | PDE Loss:  -1.8908 | Function Loss:  -2.2159\n",
      "Total loss:  -1.1321 | PDE Loss:  -1.8899 | Function Loss:  -2.2155\n",
      "Total loss:  -1.1332 | PDE Loss:  -1.8909 | Function Loss:  -2.2166\n",
      "Total loss:  -1.1341 | PDE Loss:  -1.8931 | Function Loss:  -2.2172\n",
      "Total loss:  -1.1352 | PDE Loss:  -1.8919 | Function Loss:  -2.2188\n",
      "Total loss:  -1.1367 | PDE Loss:  -1.8863 | Function Loss:  -2.2218\n",
      "Total loss:  -1.1379 | PDE Loss:  -1.8855 | Function Loss:  -2.2235\n",
      "Total loss:  -1.1378 | PDE Loss:  -1.8822 | Function Loss:  -2.2241\n",
      "Total loss:  -1.1388 | PDE Loss:  -1.884 | Function Loss:  -2.2249\n",
      "Total loss:  -1.1398 | PDE Loss:  -1.8832 | Function Loss:  -2.2263\n",
      "Total loss:  -1.1407 | PDE Loss:  -1.8796 | Function Loss:  -2.2282\n",
      "Total loss:  -1.1415 | PDE Loss:  -1.8761 | Function Loss:  -2.2299\n",
      "Total loss:  -1.142 | PDE Loss:  -1.8716 | Function Loss:  -2.2316\n",
      "Total loss:  -1.1424 | PDE Loss:  -1.8709 | Function Loss:  -2.2323\n",
      "Total loss:  -1.1427 | PDE Loss:  -1.8702 | Function Loss:  -2.2328\n",
      "Total loss:  -1.1432 | PDE Loss:  -1.8708 | Function Loss:  -2.2332\n",
      "Total loss:  -1.1436 | PDE Loss:  -1.8693 | Function Loss:  -2.234\n",
      "Total loss:  -1.144 | PDE Loss:  -1.8702 | Function Loss:  -2.2343\n",
      "Total loss:  -1.1444 | PDE Loss:  -1.8711 | Function Loss:  -2.2346\n",
      "Total loss:  -1.145 | PDE Loss:  -1.8724 | Function Loss:  -2.235\n",
      "Total loss:  -1.1456 | PDE Loss:  -1.8738 | Function Loss:  -2.2355\n",
      "Total loss:  -1.1464 | PDE Loss:  -1.8754 | Function Loss:  -2.2361\n",
      "Total loss:  -1.1475 | PDE Loss:  -1.8784 | Function Loss:  -2.2367\n",
      "Total loss:  -1.1485 | PDE Loss:  -1.8802 | Function Loss:  -2.2376\n",
      "Total loss:  -1.1497 | PDE Loss:  -1.8866 | Function Loss:  -2.2376\n",
      "Total loss:  -1.1506 | PDE Loss:  -1.8876 | Function Loss:  -2.2385\n",
      "Total loss:  -1.1518 | PDE Loss:  -1.8881 | Function Loss:  -2.2399\n",
      "Total loss:  -1.1528 | PDE Loss:  -1.8878 | Function Loss:  -2.2412\n",
      "Total loss:  -1.1539 | PDE Loss:  -1.8869 | Function Loss:  -2.2427\n",
      "Total loss:  -1.1549 | PDE Loss:  -1.8884 | Function Loss:  -2.2436\n",
      "Total loss:  -1.1559 | PDE Loss:  -1.8891 | Function Loss:  -2.2446\n",
      "Total loss:  -1.1567 | PDE Loss:  -1.8875 | Function Loss:  -2.246\n",
      "Total loss:  -1.1573 | PDE Loss:  -1.8911 | Function Loss:  -2.2459\n",
      "Total loss:  -1.1582 | PDE Loss:  -1.8937 | Function Loss:  -2.2464\n",
      "Total loss:  -1.159 | PDE Loss:  -1.8967 | Function Loss:  -2.2468\n",
      "Total loss:  -1.1599 | PDE Loss:  -1.8968 | Function Loss:  -2.2478\n",
      "Total loss:  -1.1607 | PDE Loss:  -1.8979 | Function Loss:  -2.2485\n",
      "Total loss:  -1.1612 | PDE Loss:  -1.8982 | Function Loss:  -2.2491\n",
      "Total loss:  -1.162 | PDE Loss:  -1.8972 | Function Loss:  -2.2502\n",
      "Total loss:  -1.1624 | PDE Loss:  -1.8961 | Function Loss:  -2.2511\n",
      "Total loss:  -1.1628 | PDE Loss:  -1.8968 | Function Loss:  -2.2514\n",
      "Total loss:  -1.1632 | PDE Loss:  -1.898 | Function Loss:  -2.2517\n",
      "Total loss:  -1.1637 | PDE Loss:  -1.8978 | Function Loss:  -2.2522\n",
      "Total loss:  -1.164 | PDE Loss:  -1.8981 | Function Loss:  -2.2525\n",
      "Total loss:  -1.1644 | PDE Loss:  -1.8983 | Function Loss:  -2.253\n",
      "Total loss:  -1.1649 | PDE Loss:  -1.9004 | Function Loss:  -2.2532\n",
      "Total loss:  -1.1655 | PDE Loss:  -1.903 | Function Loss:  -2.2532\n",
      "Total loss:  -1.1661 | PDE Loss:  -1.9078 | Function Loss:  -2.2529\n",
      "Total loss:  -1.1666 | PDE Loss:  -1.9123 | Function Loss:  -2.2525\n",
      "Total loss:  -1.167 | PDE Loss:  -1.9181 | Function Loss:  -2.2518\n",
      "Total loss:  -1.1675 | PDE Loss:  -1.924 | Function Loss:  -2.2511\n",
      "Total loss:  -1.1678 | PDE Loss:  -1.9273 | Function Loss:  -2.2508\n",
      "Total loss:  -1.1685 | PDE Loss:  -1.9337 | Function Loss:  -2.2504\n",
      "Total loss:  -1.1695 | PDE Loss:  -1.9407 | Function Loss:  -2.25\n",
      "Total loss:  -1.1703 | PDE Loss:  -1.9465 | Function Loss:  -2.2499\n",
      "Total loss:  -1.1711 | PDE Loss:  -1.9516 | Function Loss:  -2.2498\n",
      "Total loss:  -1.1718 | PDE Loss:  -1.9563 | Function Loss:  -2.2498\n",
      "Total loss:  -1.1727 | PDE Loss:  -1.9618 | Function Loss:  -2.2498\n",
      "Total loss:  -1.1736 | PDE Loss:  -1.9663 | Function Loss:  -2.2499\n",
      "Total loss:  -1.1743 | PDE Loss:  -1.9696 | Function Loss:  -2.2501\n",
      "Total loss:  -1.1748 | PDE Loss:  -1.971 | Function Loss:  -2.2505\n",
      "Total loss:  -1.1753 | PDE Loss:  -1.9712 | Function Loss:  -2.251\n",
      "Total loss:  -1.1756 | PDE Loss:  -1.9712 | Function Loss:  -2.2513\n",
      "Total loss:  -1.1759 | PDE Loss:  -1.9713 | Function Loss:  -2.2517\n",
      "Total loss:  -1.1763 | PDE Loss:  -1.9715 | Function Loss:  -2.2521\n",
      "Total loss:  -1.1767 | PDE Loss:  -1.9722 | Function Loss:  -2.2525\n",
      "Total loss:  -1.1771 | PDE Loss:  -1.9725 | Function Loss:  -2.2529\n",
      "Total loss:  -1.1777 | PDE Loss:  -1.9724 | Function Loss:  -2.2536\n",
      "Total loss:  -1.1781 | PDE Loss:  -1.9734 | Function Loss:  -2.254\n",
      "Total loss:  -1.1787 | PDE Loss:  -1.9723 | Function Loss:  -2.2549\n",
      "Total loss:  -1.1791 | PDE Loss:  -1.9727 | Function Loss:  -2.2552\n",
      "Total loss:  -1.1795 | PDE Loss:  -1.9736 | Function Loss:  -2.2556\n",
      "Total loss:  -1.1798 | PDE Loss:  -1.9737 | Function Loss:  -2.2559\n",
      "Total loss:  -1.1801 | PDE Loss:  -1.9748 | Function Loss:  -2.256\n",
      "Total loss:  -1.1803 | PDE Loss:  -1.9759 | Function Loss:  -2.2561\n",
      "Total loss:  -1.1805 | PDE Loss:  -1.9773 | Function Loss:  -2.2561\n",
      "Total loss:  -1.1808 | PDE Loss:  -1.9788 | Function Loss:  -2.2561\n",
      "Total loss:  -1.1809 | PDE Loss:  -1.9807 | Function Loss:  -2.2559\n",
      "Total loss:  -1.1811 | PDE Loss:  -1.981 | Function Loss:  -2.256\n",
      "Total loss:  -1.1812 | PDE Loss:  -1.9823 | Function Loss:  -2.2559\n",
      "Total loss:  -1.1813 | PDE Loss:  -1.9824 | Function Loss:  -2.256\n",
      "Total loss:  -1.1814 | PDE Loss:  -1.9829 | Function Loss:  -2.256\n",
      "Total loss:  -1.1814 | PDE Loss:  -1.9834 | Function Loss:  -2.256\n",
      "Total loss:  -1.1815 | PDE Loss:  -1.9839 | Function Loss:  -2.256\n",
      "Total loss:  -1.1816 | PDE Loss:  -1.985 | Function Loss:  -2.2559\n",
      "Total loss:  -1.1818 | PDE Loss:  -1.9862 | Function Loss:  -2.2559\n",
      "Total loss:  -1.1819 | PDE Loss:  -1.9879 | Function Loss:  -2.2557\n",
      "Total loss:  -1.1821 | PDE Loss:  -1.9898 | Function Loss:  -2.2556\n",
      "Total loss:  -1.1823 | PDE Loss:  -1.9912 | Function Loss:  -2.2556\n",
      "Total loss:  -1.1826 | PDE Loss:  -1.9923 | Function Loss:  -2.2557\n",
      "Total loss:  -1.1827 | PDE Loss:  -1.9923 | Function Loss:  -2.2559\n",
      "Total loss:  -1.1829 | PDE Loss:  -1.9918 | Function Loss:  -2.2562\n",
      "Total loss:  -1.183 | PDE Loss:  -1.9907 | Function Loss:  -2.2566\n",
      "Total loss:  -1.1832 | PDE Loss:  -1.9894 | Function Loss:  -2.2569\n",
      "Total loss:  -1.1833 | PDE Loss:  -1.9882 | Function Loss:  -2.2573\n",
      "Total loss:  -1.1834 | PDE Loss:  -1.9872 | Function Loss:  -2.2576\n",
      "Total loss:  -1.1835 | PDE Loss:  -1.9864 | Function Loss:  -2.2579\n",
      "Total loss:  -1.1837 | PDE Loss:  -1.9856 | Function Loss:  -2.2582\n",
      "Total loss:  -1.1838 | PDE Loss:  -1.9856 | Function Loss:  -2.2584\n",
      "Total loss:  -1.1839 | PDE Loss:  -1.9858 | Function Loss:  -2.2585\n",
      "Total loss:  -1.1841 | PDE Loss:  -1.9866 | Function Loss:  -2.2586\n",
      "Total loss:  -1.1843 | PDE Loss:  -1.9886 | Function Loss:  -2.2584\n",
      "Total loss:  -1.1844 | PDE Loss:  -1.9914 | Function Loss:  -2.2581\n",
      "Total loss:  -1.1846 | PDE Loss:  -1.9943 | Function Loss:  -2.2577\n",
      "Total loss:  -1.1848 | PDE Loss:  -1.9995 | Function Loss:  -2.257\n",
      "Total loss:  -1.1849 | PDE Loss:  -2.0012 | Function Loss:  -2.2568\n",
      "Total loss:  -1.1851 | PDE Loss:  -2.0034 | Function Loss:  -2.2567\n",
      "Total loss:  -1.1853 | PDE Loss:  -2.0044 | Function Loss:  -2.2568\n",
      "Total loss:  -1.1855 | PDE Loss:  -2.0045 | Function Loss:  -2.2569\n",
      "Total loss:  -1.1857 | PDE Loss:  -2.0045 | Function Loss:  -2.2571\n",
      "Total loss:  -1.1858 | PDE Loss:  -2.0037 | Function Loss:  -2.2575\n",
      "Total loss:  -1.1861 | PDE Loss:  -2.0025 | Function Loss:  -2.258\n",
      "Total loss:  -1.1864 | PDE Loss:  -2.001 | Function Loss:  -2.2586\n",
      "Total loss:  -1.1869 | PDE Loss:  -1.9986 | Function Loss:  -2.2597\n",
      "Total loss:  -1.1875 | PDE Loss:  -1.9975 | Function Loss:  -2.2606\n",
      "Total loss:  -1.1885 | PDE Loss:  -1.9961 | Function Loss:  -2.262\n",
      "Total loss:  -1.1895 | PDE Loss:  -1.9969 | Function Loss:  -2.263\n",
      "Total loss:  -1.188 | PDE Loss:  -1.9873 | Function Loss:  -2.2631\n",
      "Total loss:  -1.19 | PDE Loss:  -1.9963 | Function Loss:  -2.2637\n",
      "Total loss:  -1.1902 | PDE Loss:  -1.9979 | Function Loss:  -2.2638\n",
      "Total loss:  -1.1906 | PDE Loss:  -2.0013 | Function Loss:  -2.2636\n",
      "Total loss:  -1.1909 | PDE Loss:  -2.0052 | Function Loss:  -2.2632\n",
      "Total loss:  -1.1911 | PDE Loss:  -2.0066 | Function Loss:  -2.2632\n",
      "Total loss:  -1.1914 | PDE Loss:  -2.0065 | Function Loss:  -2.2635\n",
      "Total loss:  -1.1918 | PDE Loss:  -2.0061 | Function Loss:  -2.2641\n",
      "Total loss:  -1.1921 | PDE Loss:  -2.0049 | Function Loss:  -2.2646\n",
      "Total loss:  -1.1924 | PDE Loss:  -2.0035 | Function Loss:  -2.2653\n",
      "Total loss:  -1.1928 | PDE Loss:  -2.0026 | Function Loss:  -2.2659\n",
      "Total loss:  -1.1931 | PDE Loss:  -2.0013 | Function Loss:  -2.2665\n",
      "Total loss:  -1.1933 | PDE Loss:  -2.0011 | Function Loss:  -2.2668\n",
      "Total loss:  -1.1935 | PDE Loss:  -2.0008 | Function Loss:  -2.2671\n",
      "Total loss:  -1.1937 | PDE Loss:  -2.002 | Function Loss:  -2.2671\n",
      "Total loss:  -1.1938 | PDE Loss:  -2.0028 | Function Loss:  -2.2671\n",
      "Total loss:  -1.194 | PDE Loss:  -2.0038 | Function Loss:  -2.2671\n",
      "Total loss:  -1.194 | PDE Loss:  -2.0044 | Function Loss:  -2.2671\n",
      "Total loss:  -1.1941 | PDE Loss:  -2.0046 | Function Loss:  -2.2671\n",
      "Total loss:  -1.1942 | PDE Loss:  -2.0042 | Function Loss:  -2.2673\n",
      "Total loss:  -1.1943 | PDE Loss:  -2.0037 | Function Loss:  -2.2675\n",
      "Total loss:  -1.1944 | PDE Loss:  -2.0026 | Function Loss:  -2.2678\n",
      "Total loss:  -1.1945 | PDE Loss:  -2.0013 | Function Loss:  -2.2681\n",
      "Total loss:  -1.1946 | PDE Loss:  -1.9996 | Function Loss:  -2.2686\n",
      "Total loss:  -1.1948 | PDE Loss:  -1.9972 | Function Loss:  -2.2692\n",
      "Total loss:  -1.1949 | PDE Loss:  -1.9947 | Function Loss:  -2.2699\n",
      "Total loss:  -1.1951 | PDE Loss:  -1.9937 | Function Loss:  -2.2702\n",
      "Total loss:  -1.1952 | PDE Loss:  -1.9929 | Function Loss:  -2.2706\n",
      "Total loss:  -1.1953 | PDE Loss:  -1.992 | Function Loss:  -2.2709\n",
      "Total loss:  -1.1955 | PDE Loss:  -1.9918 | Function Loss:  -2.2711\n",
      "Total loss:  -1.1956 | PDE Loss:  -1.9908 | Function Loss:  -2.2714\n",
      "Total loss:  -1.1957 | PDE Loss:  -1.9909 | Function Loss:  -2.2715\n",
      "Total loss:  -1.1957 | PDE Loss:  -1.9904 | Function Loss:  -2.2717\n",
      "Total loss:  -1.1959 | PDE Loss:  -1.9897 | Function Loss:  -2.272\n",
      "Total loss:  -1.196 | PDE Loss:  -1.9888 | Function Loss:  -2.2724\n",
      "Total loss:  -1.1962 | PDE Loss:  -1.9875 | Function Loss:  -2.2728\n",
      "Total loss:  -1.1963 | PDE Loss:  -1.9862 | Function Loss:  -2.2732\n",
      "Total loss:  -1.1963 | PDE Loss:  -1.9814 | Function Loss:  -2.2741\n",
      "Total loss:  -1.1964 | PDE Loss:  -1.984 | Function Loss:  -2.2737\n",
      "Total loss:  -1.1966 | PDE Loss:  -1.9828 | Function Loss:  -2.2741\n",
      "Total loss:  -1.1968 | PDE Loss:  -1.9808 | Function Loss:  -2.2748\n",
      "Total loss:  -1.197 | PDE Loss:  -1.9758 | Function Loss:  -2.2761\n",
      "Total loss:  -1.1974 | PDE Loss:  -1.9747 | Function Loss:  -2.2768\n",
      "Total loss:  -1.1976 | PDE Loss:  -1.9726 | Function Loss:  -2.2774\n",
      "Total loss:  -1.1978 | PDE Loss:  -1.9733 | Function Loss:  -2.2775\n",
      "Total loss:  -1.198 | PDE Loss:  -1.9737 | Function Loss:  -2.2777\n",
      "Total loss:  -1.1983 | PDE Loss:  -1.9747 | Function Loss:  -2.2778\n",
      "Total loss:  -1.1986 | PDE Loss:  -1.9746 | Function Loss:  -2.2783\n",
      "Total loss:  -1.1991 | PDE Loss:  -1.9762 | Function Loss:  -2.2785\n",
      "Total loss:  -1.1993 | PDE Loss:  -1.9753 | Function Loss:  -2.279\n",
      "Total loss:  -1.1997 | PDE Loss:  -1.9749 | Function Loss:  -2.2795\n",
      "Total loss:  -1.2 | PDE Loss:  -1.9725 | Function Loss:  -2.2803\n",
      "Total loss:  -1.2002 | PDE Loss:  -1.9703 | Function Loss:  -2.281\n",
      "Total loss:  -1.2004 | PDE Loss:  -1.9667 | Function Loss:  -2.2819\n",
      "Total loss:  -1.2005 | PDE Loss:  -1.9637 | Function Loss:  -2.2827\n",
      "Total loss:  -1.2006 | PDE Loss:  -1.9625 | Function Loss:  -2.2831\n",
      "Total loss:  -1.2007 | PDE Loss:  -1.961 | Function Loss:  -2.2835\n",
      "Total loss:  -1.2008 | PDE Loss:  -1.9602 | Function Loss:  -2.2838\n",
      "Total loss:  -1.2009 | PDE Loss:  -1.9602 | Function Loss:  -2.2839\n",
      "Total loss:  -1.201 | PDE Loss:  -1.9602 | Function Loss:  -2.284\n",
      "Total loss:  -1.2011 | PDE Loss:  -1.9589 | Function Loss:  -2.2844\n",
      "Total loss:  -1.2012 | PDE Loss:  -1.9593 | Function Loss:  -2.2845\n",
      "Total loss:  -1.2013 | PDE Loss:  -1.9591 | Function Loss:  -2.2847\n",
      "Total loss:  -1.2014 | PDE Loss:  -1.9602 | Function Loss:  -2.2846\n",
      "Total loss:  -1.2015 | PDE Loss:  -1.9601 | Function Loss:  -2.2847\n",
      "Total loss:  -1.2016 | PDE Loss:  -1.9598 | Function Loss:  -2.2849\n",
      "Total loss:  -1.2016 | PDE Loss:  -1.96 | Function Loss:  -2.2849\n",
      "Total loss:  -1.2017 | PDE Loss:  -1.9596 | Function Loss:  -2.2851\n",
      "Total loss:  -1.2019 | PDE Loss:  -1.9604 | Function Loss:  -2.2851\n",
      "Total loss:  -1.2021 | PDE Loss:  -1.9601 | Function Loss:  -2.2854\n",
      "Total loss:  -1.2023 | PDE Loss:  -1.9609 | Function Loss:  -2.2855\n",
      "Total loss:  -1.2026 | PDE Loss:  -1.9624 | Function Loss:  -2.2856\n",
      "Total loss:  -1.203 | PDE Loss:  -1.9646 | Function Loss:  -2.2856\n",
      "Total loss:  -1.2034 | PDE Loss:  -1.9675 | Function Loss:  -2.2854\n",
      "Total loss:  -1.2038 | PDE Loss:  -1.9703 | Function Loss:  -2.2853\n",
      "Total loss:  -1.2042 | PDE Loss:  -1.9726 | Function Loss:  -2.2854\n",
      "Total loss:  -1.2049 | PDE Loss:  -1.976 | Function Loss:  -2.2855\n",
      "Total loss:  -1.2054 | PDE Loss:  -1.9779 | Function Loss:  -2.2857\n",
      "Total loss:  -1.2058 | PDE Loss:  -1.9786 | Function Loss:  -2.286\n",
      "Total loss:  -1.2065 | PDE Loss:  -1.98 | Function Loss:  -2.2866\n",
      "Total loss:  -1.2072 | PDE Loss:  -1.9813 | Function Loss:  -2.2871\n",
      "Total loss:  -1.2078 | PDE Loss:  -1.9829 | Function Loss:  -2.2875\n",
      "Total loss:  -1.2084 | PDE Loss:  -1.9864 | Function Loss:  -2.2876\n",
      "Total loss:  -1.2088 | PDE Loss:  -1.9888 | Function Loss:  -2.2877\n",
      "Total loss:  -1.2095 | PDE Loss:  -1.9915 | Function Loss:  -2.2879\n",
      "Total loss:  -1.2105 | PDE Loss:  -1.9998 | Function Loss:  -2.2875\n",
      "Total loss:  -1.2114 | PDE Loss:  -2.0061 | Function Loss:  -2.2874\n",
      "Total loss:  -1.2123 | PDE Loss:  -2.0136 | Function Loss:  -2.287\n",
      "Total loss:  -1.213 | PDE Loss:  -2.018 | Function Loss:  -2.287\n",
      "Total loss:  -1.2134 | PDE Loss:  -2.0217 | Function Loss:  -2.2868\n",
      "Total loss:  -1.2138 | PDE Loss:  -2.0221 | Function Loss:  -2.2872\n",
      "Total loss:  -1.2142 | PDE Loss:  -2.0204 | Function Loss:  -2.288\n",
      "Total loss:  -1.2147 | PDE Loss:  -2.0205 | Function Loss:  -2.2886\n",
      "Total loss:  -1.2151 | PDE Loss:  -2.0198 | Function Loss:  -2.2891\n",
      "Total loss:  -1.2155 | PDE Loss:  -2.0187 | Function Loss:  -2.2899\n",
      "Total loss:  -1.2161 | PDE Loss:  -2.018 | Function Loss:  -2.2906\n",
      "Total loss:  -1.2156 | PDE Loss:  -2.0229 | Function Loss:  -2.2892\n",
      "Total loss:  -1.2164 | PDE Loss:  -2.0218 | Function Loss:  -2.2904\n",
      "Total loss:  -1.217 | PDE Loss:  -2.0215 | Function Loss:  -2.2911\n",
      "Total loss:  -1.218 | PDE Loss:  -2.0247 | Function Loss:  -2.2916\n",
      "Total loss:  -1.2186 | PDE Loss:  -2.0245 | Function Loss:  -2.2925\n",
      "Total loss:  -1.2194 | PDE Loss:  -2.0269 | Function Loss:  -2.2929\n",
      "Total loss:  -1.2196 | PDE Loss:  -2.0294 | Function Loss:  -2.2928\n",
      "Total loss:  -1.22 | PDE Loss:  -2.0323 | Function Loss:  -2.2927\n",
      "Total loss:  -1.2203 | PDE Loss:  -2.0347 | Function Loss:  -2.2926\n",
      "Total loss:  -1.2206 | PDE Loss:  -2.036 | Function Loss:  -2.2928\n",
      "Total loss:  -1.2208 | PDE Loss:  -2.0374 | Function Loss:  -2.2927\n",
      "Total loss:  -1.221 | PDE Loss:  -2.0386 | Function Loss:  -2.2927\n",
      "Total loss:  -1.2212 | PDE Loss:  -2.0402 | Function Loss:  -2.2926\n",
      "Total loss:  -1.2213 | PDE Loss:  -2.0416 | Function Loss:  -2.2925\n",
      "Total loss:  -1.2214 | PDE Loss:  -2.0428 | Function Loss:  -2.2924\n",
      "Total loss:  -1.2214 | PDE Loss:  -2.044 | Function Loss:  -2.2923\n",
      "Total loss:  -1.2215 | PDE Loss:  -2.0453 | Function Loss:  -2.2922\n",
      "Total loss:  -1.2217 | PDE Loss:  -2.0469 | Function Loss:  -2.292\n",
      "Total loss:  -1.2219 | PDE Loss:  -2.0485 | Function Loss:  -2.292\n",
      "Total loss:  -1.2221 | PDE Loss:  -2.05 | Function Loss:  -2.2919\n",
      "Total loss:  -1.2223 | PDE Loss:  -2.0517 | Function Loss:  -2.2919\n",
      "Total loss:  -1.2227 | PDE Loss:  -2.0533 | Function Loss:  -2.2921\n",
      "Total loss:  -1.2233 | PDE Loss:  -2.0559 | Function Loss:  -2.2924\n",
      "Total loss:  -1.2242 | PDE Loss:  -2.0584 | Function Loss:  -2.293\n",
      "Total loss:  -1.2254 | PDE Loss:  -2.063 | Function Loss:  -2.2936\n",
      "Total loss:  -1.2271 | PDE Loss:  -2.0685 | Function Loss:  -2.2946\n",
      "Total loss:  -1.2297 | PDE Loss:  -2.0796 | Function Loss:  -2.2959\n",
      "Total loss:  -1.2321 | PDE Loss:  -2.0859 | Function Loss:  -2.2976\n",
      "Total loss:  -1.2349 | PDE Loss:  -2.0924 | Function Loss:  -2.2998\n",
      "Total loss:  -1.2363 | PDE Loss:  -2.0944 | Function Loss:  -2.3011\n",
      "Total loss:  -1.2343 | PDE Loss:  -2.0872 | Function Loss:  -2.2999\n",
      "Total loss:  -1.2373 | PDE Loss:  -2.0939 | Function Loss:  -2.3024\n",
      "Total loss:  -1.2382 | PDE Loss:  -2.0962 | Function Loss:  -2.3031\n",
      "Total loss:  -1.2394 | PDE Loss:  -2.0981 | Function Loss:  -2.3041\n",
      "Total loss:  -1.2405 | PDE Loss:  -2.1004 | Function Loss:  -2.305\n",
      "Total loss:  -1.2413 | PDE Loss:  -2.1009 | Function Loss:  -2.3059\n",
      "Total loss:  -1.2421 | PDE Loss:  -2.1033 | Function Loss:  -2.3064\n",
      "Total loss:  -1.2433 | PDE Loss:  -2.1088 | Function Loss:  -2.307\n",
      "Total loss:  -1.245 | PDE Loss:  -2.117 | Function Loss:  -2.3076\n",
      "Total loss:  -1.2468 | PDE Loss:  -2.1308 | Function Loss:  -2.3076\n",
      "Total loss:  -1.2486 | PDE Loss:  -2.1387 | Function Loss:  -2.3085\n",
      "Total loss:  -1.2508 | PDE Loss:  -2.154 | Function Loss:  -2.3087\n",
      "Total loss:  -1.252 | PDE Loss:  -2.1688 | Function Loss:  -2.3081\n",
      "Total loss:  -1.2532 | PDE Loss:  -2.1783 | Function Loss:  -2.3082\n",
      "Total loss:  -1.254 | PDE Loss:  -2.1793 | Function Loss:  -2.3089\n",
      "Total loss:  -1.2561 | PDE Loss:  -2.1804 | Function Loss:  -2.3112\n",
      "Total loss:  -1.2574 | PDE Loss:  -2.183 | Function Loss:  -2.3123\n",
      "Total loss:  -1.259 | PDE Loss:  -2.1876 | Function Loss:  -2.3135\n",
      "Total loss:  -1.2607 | PDE Loss:  -2.1894 | Function Loss:  -2.3152\n",
      "Total loss:  -1.2622 | PDE Loss:  -2.1921 | Function Loss:  -2.3165\n",
      "Total loss:  -1.2635 | PDE Loss:  -2.1901 | Function Loss:  -2.3182\n",
      "Total loss:  -1.2647 | PDE Loss:  -2.1903 | Function Loss:  -2.3195\n",
      "Total loss:  -1.266 | PDE Loss:  -2.189 | Function Loss:  -2.3212\n",
      "Total loss:  -1.2669 | PDE Loss:  -2.184 | Function Loss:  -2.323\n",
      "Total loss:  -1.268 | PDE Loss:  -2.1849 | Function Loss:  -2.3241\n",
      "Total loss:  -1.2689 | PDE Loss:  -2.1896 | Function Loss:  -2.3244\n",
      "Total loss:  -1.2696 | PDE Loss:  -2.1874 | Function Loss:  -2.3255\n",
      "Total loss:  -1.2703 | PDE Loss:  -2.1895 | Function Loss:  -2.3261\n",
      "Total loss:  -1.2711 | PDE Loss:  -2.1936 | Function Loss:  -2.3264\n",
      "Total loss:  -1.2718 | PDE Loss:  -2.1977 | Function Loss:  -2.3266\n",
      "Total loss:  -1.2723 | PDE Loss:  -2.2002 | Function Loss:  -2.3269\n",
      "Total loss:  -1.2729 | PDE Loss:  -2.2027 | Function Loss:  -2.3272\n",
      "Total loss:  -1.2737 | PDE Loss:  -2.2038 | Function Loss:  -2.3279\n",
      "Total loss:  -1.2742 | PDE Loss:  -2.2045 | Function Loss:  -2.3285\n",
      "Total loss:  -1.2747 | PDE Loss:  -2.2036 | Function Loss:  -2.3292\n",
      "Total loss:  -1.2753 | PDE Loss:  -2.2033 | Function Loss:  -2.3298\n",
      "Total loss:  -1.2758 | PDE Loss:  -2.2014 | Function Loss:  -2.3307\n",
      "Total loss:  -1.2763 | PDE Loss:  -2.2003 | Function Loss:  -2.3314\n",
      "Total loss:  -1.2769 | PDE Loss:  -2.2 | Function Loss:  -2.3321\n",
      "Total loss:  -1.2774 | PDE Loss:  -2.199 | Function Loss:  -2.3328\n",
      "Total loss:  -1.2778 | PDE Loss:  -2.2 | Function Loss:  -2.3331\n",
      "Total loss:  -1.2783 | PDE Loss:  -2.2021 | Function Loss:  -2.3334\n",
      "Total loss:  -1.2788 | PDE Loss:  -2.2054 | Function Loss:  -2.3336\n",
      "Total loss:  -1.2795 | PDE Loss:  -2.2112 | Function Loss:  -2.3335\n",
      "Total loss:  -1.28 | PDE Loss:  -2.2142 | Function Loss:  -2.3337\n",
      "Total loss:  -1.2807 | PDE Loss:  -2.2187 | Function Loss:  -2.3339\n",
      "Total loss:  -1.2812 | PDE Loss:  -2.2217 | Function Loss:  -2.3341\n",
      "Total loss:  -1.2817 | PDE Loss:  -2.2241 | Function Loss:  -2.3343\n",
      "Total loss:  -1.282 | PDE Loss:  -2.2261 | Function Loss:  -2.3345\n",
      "Total loss:  -1.2825 | PDE Loss:  -2.2287 | Function Loss:  -2.3346\n",
      "Total loss:  -1.2829 | PDE Loss:  -2.2293 | Function Loss:  -2.335\n",
      "Total loss:  -1.2833 | PDE Loss:  -2.23 | Function Loss:  -2.3354\n",
      "Total loss:  -1.2837 | PDE Loss:  -2.2297 | Function Loss:  -2.3359\n",
      "Total loss:  -1.284 | PDE Loss:  -2.2292 | Function Loss:  -2.3363\n",
      "Total loss:  -1.2843 | PDE Loss:  -2.2283 | Function Loss:  -2.3367\n",
      "Total loss:  -1.2844 | PDE Loss:  -2.2275 | Function Loss:  -2.337\n",
      "Total loss:  -1.2845 | PDE Loss:  -2.2268 | Function Loss:  -2.3372\n",
      "Total loss:  -1.2847 | PDE Loss:  -2.2264 | Function Loss:  -2.3374\n",
      "Total loss:  -1.2848 | PDE Loss:  -2.2256 | Function Loss:  -2.3376\n",
      "Total loss:  -1.285 | PDE Loss:  -2.223 | Function Loss:  -2.3382\n",
      "Total loss:  -1.2853 | PDE Loss:  -2.2206 | Function Loss:  -2.3389\n",
      "Total loss:  -1.2856 | PDE Loss:  -2.216 | Function Loss:  -2.3398\n",
      "Total loss:  -1.2859 | PDE Loss:  -2.2131 | Function Loss:  -2.3405\n",
      "Total loss:  -1.2863 | PDE Loss:  -2.2099 | Function Loss:  -2.3414\n",
      "Total loss:  -1.2865 | PDE Loss:  -2.2085 | Function Loss:  -2.3419\n",
      "Total loss:  -1.2867 | PDE Loss:  -2.2084 | Function Loss:  -2.3421\n",
      "Total loss:  -1.2869 | PDE Loss:  -2.2093 | Function Loss:  -2.3422\n",
      "Total loss:  -1.2871 | PDE Loss:  -2.211 | Function Loss:  -2.3422\n",
      "Total loss:  -1.2872 | PDE Loss:  -2.2124 | Function Loss:  -2.3421\n",
      "Total loss:  -1.2874 | PDE Loss:  -2.2142 | Function Loss:  -2.3421\n",
      "Total loss:  -1.2877 | PDE Loss:  -2.2171 | Function Loss:  -2.342\n",
      "Total loss:  -1.2879 | PDE Loss:  -2.2195 | Function Loss:  -2.342\n",
      "Total loss:  -1.2882 | PDE Loss:  -2.2195 | Function Loss:  -2.3423\n",
      "Total loss:  -1.2885 | PDE Loss:  -2.2216 | Function Loss:  -2.3423\n",
      "Total loss:  -1.2888 | PDE Loss:  -2.2217 | Function Loss:  -2.3426\n",
      "Total loss:  -1.289 | PDE Loss:  -2.2192 | Function Loss:  -2.3433\n",
      "Total loss:  -1.2894 | PDE Loss:  -2.2158 | Function Loss:  -2.3441\n",
      "Total loss:  -1.2897 | PDE Loss:  -2.2109 | Function Loss:  -2.3451\n",
      "Total loss:  -1.29 | PDE Loss:  -2.2054 | Function Loss:  -2.3463\n",
      "Total loss:  -1.2904 | PDE Loss:  -2.2001 | Function Loss:  -2.3475\n",
      "Total loss:  -1.2909 | PDE Loss:  -2.1933 | Function Loss:  -2.349\n",
      "Total loss:  -1.2912 | PDE Loss:  -2.1882 | Function Loss:  -2.3501\n",
      "Total loss:  -1.2915 | PDE Loss:  -2.1853 | Function Loss:  -2.3508\n",
      "Total loss:  -1.2917 | PDE Loss:  -2.181 | Function Loss:  -2.3517\n",
      "Total loss:  -1.2918 | PDE Loss:  -2.1799 | Function Loss:  -2.352\n",
      "Total loss:  -1.2919 | PDE Loss:  -2.1796 | Function Loss:  -2.3522\n",
      "Total loss:  -1.292 | PDE Loss:  -2.1788 | Function Loss:  -2.3524\n",
      "Total loss:  -1.2921 | PDE Loss:  -2.179 | Function Loss:  -2.3524\n",
      "Total loss:  -1.2921 | PDE Loss:  -2.1782 | Function Loss:  -2.3526\n",
      "Total loss:  -1.2922 | PDE Loss:  -2.1776 | Function Loss:  -2.3527\n",
      "Total loss:  -1.2922 | PDE Loss:  -2.1756 | Function Loss:  -2.3531\n",
      "Total loss:  -1.2924 | PDE Loss:  -2.174 | Function Loss:  -2.3535\n",
      "Total loss:  -1.2925 | PDE Loss:  -2.1711 | Function Loss:  -2.3541\n",
      "Total loss:  -1.2927 | PDE Loss:  -2.1683 | Function Loss:  -2.3548\n",
      "Total loss:  -1.2929 | PDE Loss:  -2.1652 | Function Loss:  -2.3555\n",
      "Total loss:  -1.2933 | PDE Loss:  -2.1628 | Function Loss:  -2.3563\n",
      "Total loss:  -1.2936 | PDE Loss:  -2.1605 | Function Loss:  -2.357\n",
      "Total loss:  -1.294 | PDE Loss:  -2.1596 | Function Loss:  -2.3576\n",
      "Total loss:  -1.2943 | PDE Loss:  -2.1564 | Function Loss:  -2.3585\n",
      "Total loss:  -1.2946 | PDE Loss:  -2.156 | Function Loss:  -2.3589\n",
      "Total loss:  -1.2948 | PDE Loss:  -2.1545 | Function Loss:  -2.3594\n",
      "Total loss:  -1.2951 | PDE Loss:  -2.1508 | Function Loss:  -2.3603\n",
      "Total loss:  -1.2954 | PDE Loss:  -2.148 | Function Loss:  -2.3611\n",
      "Total loss:  -1.2955 | PDE Loss:  -2.1448 | Function Loss:  -2.3618\n",
      "Total loss:  -1.2958 | PDE Loss:  -2.1425 | Function Loss:  -2.3625\n",
      "Total loss:  -1.296 | PDE Loss:  -2.1399 | Function Loss:  -2.3631\n",
      "Total loss:  -1.2962 | PDE Loss:  -2.1395 | Function Loss:  -2.3635\n",
      "Total loss:  -1.2964 | PDE Loss:  -2.1395 | Function Loss:  -2.3637\n",
      "Total loss:  -1.2966 | PDE Loss:  -2.1412 | Function Loss:  -2.3637\n",
      "Total loss:  -1.2969 | PDE Loss:  -2.1425 | Function Loss:  -2.3637\n",
      "Total loss:  -1.2971 | PDE Loss:  -2.1458 | Function Loss:  -2.3634\n",
      "Total loss:  -1.2972 | PDE Loss:  -2.1462 | Function Loss:  -2.3635\n",
      "Total loss:  -1.2973 | PDE Loss:  -2.1469 | Function Loss:  -2.3635\n",
      "Total loss:  -1.2974 | PDE Loss:  -2.1473 | Function Loss:  -2.3636\n",
      "Total loss:  -1.2976 | PDE Loss:  -2.1469 | Function Loss:  -2.3638\n",
      "Total loss:  -1.2977 | PDE Loss:  -2.1461 | Function Loss:  -2.3641\n",
      "Total loss:  -1.2979 | PDE Loss:  -2.1452 | Function Loss:  -2.3645\n",
      "Total loss:  -1.2981 | PDE Loss:  -2.1437 | Function Loss:  -2.3649\n",
      "Total loss:  -1.2983 | PDE Loss:  -2.1423 | Function Loss:  -2.3654\n",
      "Total loss:  -1.2985 | PDE Loss:  -2.1405 | Function Loss:  -2.3659\n",
      "Total loss:  -1.2987 | PDE Loss:  -2.1379 | Function Loss:  -2.3666\n",
      "Total loss:  -1.2989 | PDE Loss:  -2.1367 | Function Loss:  -2.367\n",
      "Total loss:  -1.299 | PDE Loss:  -2.134 | Function Loss:  -2.3677\n",
      "Total loss:  -1.2991 | PDE Loss:  -2.1326 | Function Loss:  -2.368\n",
      "Total loss:  -1.2992 | PDE Loss:  -2.1312 | Function Loss:  -2.3684\n",
      "Total loss:  -1.2994 | PDE Loss:  -2.1305 | Function Loss:  -2.3687\n",
      "Total loss:  -1.2995 | PDE Loss:  -2.1302 | Function Loss:  -2.3688\n",
      "Total loss:  -1.2996 | PDE Loss:  -2.1306 | Function Loss:  -2.3689\n",
      "Total loss:  -1.2997 | PDE Loss:  -2.1311 | Function Loss:  -2.369\n",
      "Total loss:  -1.2999 | PDE Loss:  -2.1327 | Function Loss:  -2.369\n",
      "Total loss:  -1.3002 | PDE Loss:  -2.1348 | Function Loss:  -2.3689\n",
      "Total loss:  -1.3007 | PDE Loss:  -2.1387 | Function Loss:  -2.3688\n",
      "Total loss:  -1.3012 | PDE Loss:  -2.143 | Function Loss:  -2.3687\n",
      "Total loss:  -1.3017 | PDE Loss:  -2.1464 | Function Loss:  -2.3687\n",
      "Total loss:  -1.3025 | PDE Loss:  -2.1483 | Function Loss:  -2.3694\n",
      "Total loss:  -1.3035 | PDE Loss:  -2.1528 | Function Loss:  -2.3698\n",
      "Total loss:  -1.3045 | PDE Loss:  -2.1558 | Function Loss:  -2.3704\n",
      "Total loss:  -1.3049 | PDE Loss:  -2.1588 | Function Loss:  -2.3704\n",
      "Total loss:  -1.3054 | PDE Loss:  -2.1648 | Function Loss:  -2.37\n",
      "Total loss:  -1.3054 | PDE Loss:  -2.1667 | Function Loss:  -2.3697\n",
      "Total loss:  -1.3056 | PDE Loss:  -2.166 | Function Loss:  -2.37\n",
      "Total loss:  -1.3058 | PDE Loss:  -2.1685 | Function Loss:  -2.3699\n",
      "Total loss:  -1.3061 | PDE Loss:  -2.1708 | Function Loss:  -2.3698\n",
      "Total loss:  -1.3065 | PDE Loss:  -2.1733 | Function Loss:  -2.3699\n",
      "Total loss:  -1.307 | PDE Loss:  -2.1747 | Function Loss:  -2.3703\n",
      "Total loss:  -1.3074 | PDE Loss:  -2.175 | Function Loss:  -2.3707\n",
      "Total loss:  -1.3077 | PDE Loss:  -2.1738 | Function Loss:  -2.3712\n",
      "Total loss:  -1.3079 | PDE Loss:  -2.1723 | Function Loss:  -2.3718\n",
      "Total loss:  -1.3081 | PDE Loss:  -2.1715 | Function Loss:  -2.3721\n",
      "Total loss:  -1.3083 | PDE Loss:  -2.1704 | Function Loss:  -2.3725\n",
      "Total loss:  -1.3085 | PDE Loss:  -2.171 | Function Loss:  -2.3726\n",
      "Total loss:  -1.3087 | PDE Loss:  -2.1714 | Function Loss:  -2.3728\n",
      "Total loss:  -1.3089 | PDE Loss:  -2.1733 | Function Loss:  -2.3727\n",
      "Total loss:  -1.3092 | PDE Loss:  -2.1756 | Function Loss:  -2.3727\n",
      "Total loss:  -1.3095 | PDE Loss:  -2.1789 | Function Loss:  -2.3726\n",
      "Total loss:  -1.3099 | PDE Loss:  -2.1838 | Function Loss:  -2.3722\n",
      "Total loss:  -1.3104 | PDE Loss:  -2.1891 | Function Loss:  -2.372\n",
      "Total loss:  -1.3108 | PDE Loss:  -2.1949 | Function Loss:  -2.3716\n",
      "Total loss:  -1.3113 | PDE Loss:  -2.1993 | Function Loss:  -2.3715\n",
      "Total loss:  -1.3119 | PDE Loss:  -2.2041 | Function Loss:  -2.3714\n",
      "Total loss:  -1.3126 | PDE Loss:  -2.208 | Function Loss:  -2.3717\n",
      "Total loss:  -1.3129 | PDE Loss:  -2.2102 | Function Loss:  -2.3718\n",
      "Total loss:  -1.3134 | PDE Loss:  -2.2126 | Function Loss:  -2.372\n",
      "Total loss:  -1.3138 | PDE Loss:  -2.2141 | Function Loss:  -2.3722\n",
      "Total loss:  -1.3142 | PDE Loss:  -2.2152 | Function Loss:  -2.3725\n",
      "Total loss:  -1.3146 | PDE Loss:  -2.215 | Function Loss:  -2.3729\n",
      "Total loss:  -1.3152 | PDE Loss:  -2.2153 | Function Loss:  -2.3736\n",
      "Total loss:  -1.3159 | PDE Loss:  -2.2137 | Function Loss:  -2.3747\n",
      "Total loss:  -1.3164 | PDE Loss:  -2.2135 | Function Loss:  -2.3753\n",
      "Total loss:  -1.3169 | PDE Loss:  -2.214 | Function Loss:  -2.3757\n",
      "Total loss:  -1.3173 | PDE Loss:  -2.2136 | Function Loss:  -2.3763\n",
      "Total loss:  -1.3178 | PDE Loss:  -2.2131 | Function Loss:  -2.3769\n",
      "Total loss:  -1.3183 | PDE Loss:  -2.2102 | Function Loss:  -2.378\n",
      "Total loss:  -1.3189 | PDE Loss:  -2.2075 | Function Loss:  -2.379\n",
      "Total loss:  -1.3193 | PDE Loss:  -2.2039 | Function Loss:  -2.38\n",
      "Total loss:  -1.3198 | PDE Loss:  -2.1963 | Function Loss:  -2.3817\n",
      "Total loss:  -1.3202 | PDE Loss:  -2.1905 | Function Loss:  -2.3831\n",
      "Total loss:  -1.3204 | PDE Loss:  -2.1892 | Function Loss:  -2.3835\n",
      "Total loss:  -1.3211 | PDE Loss:  -2.1838 | Function Loss:  -2.3852\n",
      "Total loss:  -1.3217 | PDE Loss:  -2.1781 | Function Loss:  -2.3868\n",
      "Total loss:  -1.3224 | PDE Loss:  -2.1719 | Function Loss:  -2.3886\n",
      "Total loss:  -1.3229 | PDE Loss:  -2.1629 | Function Loss:  -2.3907\n",
      "Total loss:  -1.3235 | PDE Loss:  -2.1622 | Function Loss:  -2.3915\n",
      "Total loss:  -1.3241 | PDE Loss:  -2.1626 | Function Loss:  -2.3922\n",
      "Total loss:  -1.3248 | PDE Loss:  -2.1632 | Function Loss:  -2.3929\n",
      "Total loss:  -1.3257 | PDE Loss:  -2.1615 | Function Loss:  -2.3942\n",
      "Total loss:  -1.3262 | PDE Loss:  -2.1652 | Function Loss:  -2.3942\n",
      "Total loss:  -1.3265 | PDE Loss:  -2.1638 | Function Loss:  -2.3948\n",
      "Total loss:  -1.3268 | PDE Loss:  -2.1634 | Function Loss:  -2.3952\n",
      "Total loss:  -1.327 | PDE Loss:  -2.1635 | Function Loss:  -2.3954\n",
      "Total loss:  -1.3272 | PDE Loss:  -2.1643 | Function Loss:  -2.3955\n",
      "Total loss:  -1.3275 | PDE Loss:  -2.1656 | Function Loss:  -2.3956\n",
      "Total loss:  -1.3275 | PDE Loss:  -2.1632 | Function Loss:  -2.3961\n",
      "Total loss:  -1.3278 | PDE Loss:  -2.1647 | Function Loss:  -2.3961\n",
      "Total loss:  -1.328 | PDE Loss:  -2.1658 | Function Loss:  -2.3962\n",
      "Total loss:  -1.3282 | PDE Loss:  -2.1665 | Function Loss:  -2.3963\n",
      "Total loss:  -1.3283 | PDE Loss:  -2.166 | Function Loss:  -2.3965\n",
      "Total loss:  -1.3285 | PDE Loss:  -2.1667 | Function Loss:  -2.3966\n",
      "Total loss:  -1.3286 | PDE Loss:  -2.1658 | Function Loss:  -2.3969\n",
      "Total loss:  -1.3287 | PDE Loss:  -2.1652 | Function Loss:  -2.3971\n",
      "Total loss:  -1.3289 | PDE Loss:  -2.1644 | Function Loss:  -2.3975\n",
      "Total loss:  -1.3291 | PDE Loss:  -2.1643 | Function Loss:  -2.3977\n",
      "Total loss:  -1.3293 | PDE Loss:  -2.1649 | Function Loss:  -2.3979\n",
      "Total loss:  -1.3296 | PDE Loss:  -2.1666 | Function Loss:  -2.3979\n",
      "Total loss:  -1.3299 | PDE Loss:  -2.1683 | Function Loss:  -2.3979\n",
      "Total loss:  -1.3302 | PDE Loss:  -2.1717 | Function Loss:  -2.3977\n",
      "Total loss:  -1.3304 | PDE Loss:  -2.1735 | Function Loss:  -2.3977\n",
      "Total loss:  -1.3307 | PDE Loss:  -2.1758 | Function Loss:  -2.3976\n",
      "Total loss:  -1.3312 | PDE Loss:  -2.179 | Function Loss:  -2.3977\n",
      "Total loss:  -1.3319 | PDE Loss:  -2.1832 | Function Loss:  -2.3978\n",
      "Total loss:  -1.3325 | PDE Loss:  -2.1861 | Function Loss:  -2.3981\n",
      "Total loss:  -1.333 | PDE Loss:  -2.1866 | Function Loss:  -2.3986\n",
      "Total loss:  -1.3335 | PDE Loss:  -2.1872 | Function Loss:  -2.3991\n",
      "Total loss:  -1.334 | PDE Loss:  -2.1863 | Function Loss:  -2.3997\n",
      "Total loss:  -1.3344 | PDE Loss:  -2.1844 | Function Loss:  -2.4005\n",
      "Total loss:  -1.3347 | PDE Loss:  -2.1849 | Function Loss:  -2.4008\n",
      "Total loss:  -1.3352 | PDE Loss:  -2.1857 | Function Loss:  -2.4012\n",
      "Total loss:  -1.3355 | PDE Loss:  -2.1872 | Function Loss:  -2.4014\n",
      "Total loss:  -1.3359 | PDE Loss:  -2.1886 | Function Loss:  -2.4016\n",
      "Total loss:  -1.336 | PDE Loss:  -2.1897 | Function Loss:  -2.4016\n",
      "Total loss:  -1.3364 | PDE Loss:  -2.1937 | Function Loss:  -2.4013\n",
      "Total loss:  -1.3367 | PDE Loss:  -2.1977 | Function Loss:  -2.4011\n",
      "Total loss:  -1.337 | PDE Loss:  -2.2016 | Function Loss:  -2.4008\n",
      "Total loss:  -1.3373 | PDE Loss:  -2.2059 | Function Loss:  -2.4004\n",
      "Total loss:  -1.3374 | PDE Loss:  -2.2083 | Function Loss:  -2.4002\n",
      "Total loss:  -1.3375 | PDE Loss:  -2.2095 | Function Loss:  -2.4002\n",
      "Total loss:  -1.3376 | PDE Loss:  -2.2101 | Function Loss:  -2.4002\n",
      "Total loss:  -1.3377 | PDE Loss:  -2.2108 | Function Loss:  -2.4002\n",
      "Total loss:  -1.3378 | PDE Loss:  -2.2105 | Function Loss:  -2.4003\n",
      "Total loss:  -1.3378 | PDE Loss:  -2.2109 | Function Loss:  -2.4002\n",
      "Total loss:  -1.3378 | PDE Loss:  -2.2106 | Function Loss:  -2.4003\n",
      "Total loss:  -1.3379 | PDE Loss:  -2.2104 | Function Loss:  -2.4004\n",
      "Total loss:  -1.3379 | PDE Loss:  -2.2098 | Function Loss:  -2.4005\n",
      "Total loss:  -1.3379 | PDE Loss:  -2.2091 | Function Loss:  -2.4007\n",
      "Total loss:  -1.338 | PDE Loss:  -2.208 | Function Loss:  -2.4009\n",
      "Total loss:  -1.3381 | PDE Loss:  -2.2065 | Function Loss:  -2.4012\n",
      "Total loss:  -1.3381 | PDE Loss:  -2.2046 | Function Loss:  -2.4016\n",
      "Total loss:  -1.3382 | PDE Loss:  -2.2029 | Function Loss:  -2.402\n",
      "Total loss:  -1.3383 | PDE Loss:  -2.2007 | Function Loss:  -2.4024\n",
      "Total loss:  -1.3384 | PDE Loss:  -2.1993 | Function Loss:  -2.4028\n",
      "Total loss:  -1.3385 | PDE Loss:  -2.1978 | Function Loss:  -2.4031\n",
      "Total loss:  -1.3386 | PDE Loss:  -2.1972 | Function Loss:  -2.4033\n",
      "Total loss:  -1.3387 | PDE Loss:  -2.1964 | Function Loss:  -2.4035\n",
      "Total loss:  -1.3388 | PDE Loss:  -2.1958 | Function Loss:  -2.4038\n",
      "Total loss:  -1.3389 | PDE Loss:  -2.1952 | Function Loss:  -2.404\n",
      "Total loss:  -1.339 | PDE Loss:  -2.1945 | Function Loss:  -2.4043\n",
      "Total loss:  -1.3391 | PDE Loss:  -2.194 | Function Loss:  -2.4045\n",
      "Total loss:  -1.3392 | PDE Loss:  -2.1928 | Function Loss:  -2.4048\n",
      "Total loss:  -1.3393 | PDE Loss:  -2.1925 | Function Loss:  -2.4049\n",
      "Total loss:  -1.3393 | PDE Loss:  -2.1916 | Function Loss:  -2.4051\n",
      "Total loss:  -1.3393 | PDE Loss:  -2.1915 | Function Loss:  -2.4051\n",
      "Total loss:  -1.3394 | PDE Loss:  -2.1913 | Function Loss:  -2.4052\n",
      "Total loss:  -1.3394 | PDE Loss:  -2.1915 | Function Loss:  -2.4052\n",
      "Total loss:  -1.3394 | PDE Loss:  -2.1921 | Function Loss:  -2.4051\n",
      "Total loss:  -1.3395 | PDE Loss:  -2.1929 | Function Loss:  -2.4051\n",
      "Total loss:  -1.3395 | PDE Loss:  -2.1938 | Function Loss:  -2.405\n",
      "Total loss:  -1.3396 | PDE Loss:  -2.1944 | Function Loss:  -2.4049\n",
      "Total loss:  -1.3396 | PDE Loss:  -2.1951 | Function Loss:  -2.4048\n",
      "Total loss:  -1.3396 | PDE Loss:  -2.1957 | Function Loss:  -2.4047\n",
      "Total loss:  -1.3396 | PDE Loss:  -2.1955 | Function Loss:  -2.4048\n",
      "Total loss:  -1.3396 | PDE Loss:  -2.1953 | Function Loss:  -2.4048\n",
      "Total loss:  -1.3397 | PDE Loss:  -2.1947 | Function Loss:  -2.405\n",
      "Total loss:  -1.3397 | PDE Loss:  -2.1935 | Function Loss:  -2.4053\n",
      "Total loss:  -1.3398 | PDE Loss:  -2.1925 | Function Loss:  -2.4055\n",
      "Total loss:  -1.3398 | PDE Loss:  -2.1913 | Function Loss:  -2.4057\n",
      "Total loss:  -1.3399 | PDE Loss:  -2.1902 | Function Loss:  -2.406\n",
      "Total loss:  -1.3399 | PDE Loss:  -2.1895 | Function Loss:  -2.4062\n",
      "Total loss:  -1.34 | PDE Loss:  -2.1889 | Function Loss:  -2.4063\n",
      "Total loss:  -1.3401 | PDE Loss:  -2.1893 | Function Loss:  -2.4064\n",
      "Total loss:  -1.3402 | PDE Loss:  -2.19 | Function Loss:  -2.4063\n",
      "Total loss:  -1.3402 | PDE Loss:  -2.1912 | Function Loss:  -2.4062\n",
      "Total loss:  -1.3403 | PDE Loss:  -2.1928 | Function Loss:  -2.406\n",
      "Total loss:  -1.3403 | PDE Loss:  -2.1937 | Function Loss:  -2.4059\n",
      "Total loss:  -1.3404 | PDE Loss:  -2.1949 | Function Loss:  -2.4058\n",
      "Total loss:  -1.3405 | PDE Loss:  -2.1956 | Function Loss:  -2.4058\n",
      "Total loss:  -1.3406 | PDE Loss:  -2.1964 | Function Loss:  -2.4058\n",
      "Total loss:  -1.3407 | PDE Loss:  -2.1966 | Function Loss:  -2.4058\n",
      "Total loss:  -1.3408 | PDE Loss:  -2.1964 | Function Loss:  -2.406\n",
      "Total loss:  -1.3409 | PDE Loss:  -2.1966 | Function Loss:  -2.4061\n",
      "Total loss:  -1.341 | PDE Loss:  -2.1964 | Function Loss:  -2.4063\n",
      "Total loss:  -1.3413 | PDE Loss:  -2.1966 | Function Loss:  -2.4066\n",
      "Total loss:  -1.3416 | PDE Loss:  -2.1969 | Function Loss:  -2.4069\n",
      "Total loss:  -1.3421 | PDE Loss:  -2.1976 | Function Loss:  -2.4073\n",
      "Total loss:  -1.3425 | PDE Loss:  -2.1997 | Function Loss:  -2.4075\n",
      "Total loss:  -1.3434 | PDE Loss:  -2.2037 | Function Loss:  -2.4078\n",
      "Total loss:  -1.3444 | PDE Loss:  -2.2089 | Function Loss:  -2.4082\n",
      "Total loss:  -1.3456 | PDE Loss:  -2.2187 | Function Loss:  -2.4081\n",
      "Total loss:  -1.3466 | PDE Loss:  -2.2296 | Function Loss:  -2.4075\n",
      "Total loss:  -1.3477 | PDE Loss:  -2.2372 | Function Loss:  -2.4077\n",
      "Total loss:  -1.3483 | PDE Loss:  -2.2405 | Function Loss:  -2.4079\n",
      "Total loss:  -1.3494 | PDE Loss:  -2.2439 | Function Loss:  -2.4086\n",
      "Total loss:  -1.35 | PDE Loss:  -2.2462 | Function Loss:  -2.409\n",
      "Total loss:  -1.3504 | PDE Loss:  -2.2473 | Function Loss:  -2.4093\n",
      "Total loss:  -1.3506 | PDE Loss:  -2.2471 | Function Loss:  -2.4095\n",
      "Total loss:  -1.3508 | PDE Loss:  -2.2469 | Function Loss:  -2.4098\n",
      "Total loss:  -1.3509 | PDE Loss:  -2.2469 | Function Loss:  -2.41\n",
      "Total loss:  -1.3511 | PDE Loss:  -2.2468 | Function Loss:  -2.4101\n",
      "Total loss:  -1.3512 | PDE Loss:  -2.2471 | Function Loss:  -2.4102\n",
      "Total loss:  -1.3514 | PDE Loss:  -2.2469 | Function Loss:  -2.4104\n",
      "Total loss:  -1.3515 | PDE Loss:  -2.2458 | Function Loss:  -2.4108\n",
      "Total loss:  -1.3517 | PDE Loss:  -2.2464 | Function Loss:  -2.4109\n",
      "Total loss:  -1.3518 | PDE Loss:  -2.2466 | Function Loss:  -2.411\n",
      "Total loss:  -1.352 | PDE Loss:  -2.2471 | Function Loss:  -2.4112\n",
      "Total loss:  -1.3522 | PDE Loss:  -2.2481 | Function Loss:  -2.4113\n",
      "Total loss:  -1.3524 | PDE Loss:  -2.2486 | Function Loss:  -2.4113\n",
      "Total loss:  -1.3526 | PDE Loss:  -2.2496 | Function Loss:  -2.4115\n",
      "Total loss:  -1.3529 | PDE Loss:  -2.2503 | Function Loss:  -2.4117\n",
      "Total loss:  -1.3532 | PDE Loss:  -2.2507 | Function Loss:  -2.412\n",
      "Total loss:  -1.3535 | PDE Loss:  -2.2503 | Function Loss:  -2.4124\n",
      "Total loss:  -1.3537 | PDE Loss:  -2.2492 | Function Loss:  -2.4128\n",
      "Total loss:  -1.3538 | PDE Loss:  -2.2484 | Function Loss:  -2.413\n",
      "Total loss:  -1.354 | PDE Loss:  -2.2468 | Function Loss:  -2.4135\n",
      "Total loss:  -1.3541 | PDE Loss:  -2.2455 | Function Loss:  -2.4138\n",
      "Total loss:  -1.3542 | PDE Loss:  -2.2436 | Function Loss:  -2.4142\n",
      "Total loss:  -1.3543 | PDE Loss:  -2.2424 | Function Loss:  -2.4145\n",
      "Total loss:  -1.3543 | PDE Loss:  -2.2421 | Function Loss:  -2.4146\n",
      "Total loss:  -1.3544 | PDE Loss:  -2.2422 | Function Loss:  -2.4147\n",
      "Total loss:  -1.3546 | PDE Loss:  -2.2427 | Function Loss:  -2.4147\n",
      "Total loss:  -1.3547 | PDE Loss:  -2.2434 | Function Loss:  -2.4148\n",
      "Total loss:  -1.3548 | PDE Loss:  -2.2439 | Function Loss:  -2.4148\n",
      "Total loss:  -1.3549 | PDE Loss:  -2.2445 | Function Loss:  -2.4149\n",
      "Total loss:  -1.3551 | PDE Loss:  -2.2451 | Function Loss:  -2.415\n",
      "Total loss:  -1.3554 | PDE Loss:  -2.2456 | Function Loss:  -2.4153\n",
      "Total loss:  -1.3557 | PDE Loss:  -2.2461 | Function Loss:  -2.4155\n",
      "Total loss:  -1.3561 | PDE Loss:  -2.2458 | Function Loss:  -2.416\n",
      "Total loss:  -1.3564 | PDE Loss:  -2.2466 | Function Loss:  -2.4162\n",
      "Total loss:  -1.3567 | PDE Loss:  -2.245 | Function Loss:  -2.4169\n",
      "Total loss:  -1.357 | PDE Loss:  -2.2437 | Function Loss:  -2.4174\n",
      "Total loss:  -1.3572 | PDE Loss:  -2.2432 | Function Loss:  -2.4177\n",
      "Total loss:  -1.3572 | PDE Loss:  -2.2394 | Function Loss:  -2.4182\n",
      "Total loss:  -1.3573 | PDE Loss:  -2.2417 | Function Loss:  -2.4181\n",
      "Total loss:  -1.3575 | PDE Loss:  -2.2415 | Function Loss:  -2.4182\n",
      "Total loss:  -1.3575 | PDE Loss:  -2.2419 | Function Loss:  -2.4183\n",
      "Total loss:  -1.3576 | PDE Loss:  -2.2419 | Function Loss:  -2.4183\n",
      "Total loss:  -1.3576 | PDE Loss:  -2.2417 | Function Loss:  -2.4184\n",
      "Total loss:  -1.3577 | PDE Loss:  -2.2409 | Function Loss:  -2.4186\n",
      "Total loss:  -1.3578 | PDE Loss:  -2.2392 | Function Loss:  -2.419\n",
      "Total loss:  -1.3579 | PDE Loss:  -2.2365 | Function Loss:  -2.4195\n",
      "Total loss:  -1.358 | PDE Loss:  -2.2333 | Function Loss:  -2.4201\n",
      "Total loss:  -1.3581 | PDE Loss:  -2.2297 | Function Loss:  -2.4208\n",
      "Total loss:  -1.3581 | PDE Loss:  -2.225 | Function Loss:  -2.4215\n",
      "Total loss:  -1.3581 | PDE Loss:  -2.2253 | Function Loss:  -2.4215\n",
      "Total loss:  -1.3582 | PDE Loss:  -2.2259 | Function Loss:  -2.4215\n",
      "Total loss:  -1.3582 | PDE Loss:  -2.2264 | Function Loss:  -2.4214\n",
      "Total loss:  -1.3582 | PDE Loss:  -2.227 | Function Loss:  -2.4213\n",
      "Total loss:  -1.3582 | PDE Loss:  -2.2273 | Function Loss:  -2.4213\n",
      "Total loss:  -1.3583 | PDE Loss:  -2.2277 | Function Loss:  -2.4213\n",
      "Total loss:  -1.3583 | PDE Loss:  -2.2279 | Function Loss:  -2.4213\n",
      "Total loss:  -1.3583 | PDE Loss:  -2.2281 | Function Loss:  -2.4213\n",
      "Total loss:  -1.3584 | PDE Loss:  -2.2281 | Function Loss:  -2.4214\n",
      "Total loss:  -1.3584 | PDE Loss:  -2.2279 | Function Loss:  -2.4215\n",
      "Total loss:  -1.3585 | PDE Loss:  -2.2275 | Function Loss:  -2.4216\n",
      "Total loss:  -1.3586 | PDE Loss:  -2.2267 | Function Loss:  -2.4218\n",
      "Total loss:  -1.3587 | PDE Loss:  -2.2257 | Function Loss:  -2.4221\n",
      "Total loss:  -1.3588 | PDE Loss:  -2.2246 | Function Loss:  -2.4223\n",
      "Total loss:  -1.3589 | PDE Loss:  -2.2236 | Function Loss:  -2.4227\n",
      "Total loss:  -1.359 | PDE Loss:  -2.2223 | Function Loss:  -2.423\n",
      "Total loss:  -1.3591 | PDE Loss:  -2.2225 | Function Loss:  -2.4231\n",
      "Total loss:  -1.3592 | PDE Loss:  -2.2216 | Function Loss:  -2.4233\n",
      "Total loss:  -1.3592 | PDE Loss:  -2.2227 | Function Loss:  -2.4232\n",
      "Total loss:  -1.3593 | PDE Loss:  -2.2236 | Function Loss:  -2.4231\n",
      "Total loss:  -1.3594 | PDE Loss:  -2.2251 | Function Loss:  -2.423\n",
      "Total loss:  -1.3594 | PDE Loss:  -2.2256 | Function Loss:  -2.4229\n",
      "Total loss:  -1.3594 | PDE Loss:  -2.2255 | Function Loss:  -2.423\n",
      "Total loss:  -1.3595 | PDE Loss:  -2.2254 | Function Loss:  -2.4231\n",
      "Total loss:  -1.3596 | PDE Loss:  -2.225 | Function Loss:  -2.4232\n",
      "Total loss:  -1.3597 | PDE Loss:  -2.2249 | Function Loss:  -2.4234\n",
      "Total loss:  -1.3598 | PDE Loss:  -2.2245 | Function Loss:  -2.4235\n",
      "Total loss:  -1.3599 | PDE Loss:  -2.2241 | Function Loss:  -2.4237\n",
      "Total loss:  -1.36 | PDE Loss:  -2.2239 | Function Loss:  -2.4239\n",
      "Total loss:  -1.3602 | PDE Loss:  -2.2234 | Function Loss:  -2.4241\n",
      "Total loss:  -1.3603 | PDE Loss:  -2.2223 | Function Loss:  -2.4244\n",
      "Total loss:  -1.3604 | PDE Loss:  -2.2223 | Function Loss:  -2.4246\n",
      "Total loss:  -1.3605 | PDE Loss:  -2.22 | Function Loss:  -2.4251\n",
      "Total loss:  -1.3605 | PDE Loss:  -2.2188 | Function Loss:  -2.4253\n",
      "Total loss:  -1.3606 | PDE Loss:  -2.2171 | Function Loss:  -2.4257\n",
      "Total loss:  -1.3606 | PDE Loss:  -2.2155 | Function Loss:  -2.426\n",
      "Total loss:  -1.3607 | PDE Loss:  -2.2135 | Function Loss:  -2.4264\n",
      "Total loss:  -1.3608 | PDE Loss:  -2.2114 | Function Loss:  -2.4268\n",
      "Total loss:  -1.3609 | PDE Loss:  -2.2095 | Function Loss:  -2.4273\n",
      "Total loss:  -1.3611 | PDE Loss:  -2.2076 | Function Loss:  -2.4278\n",
      "Total loss:  -1.3608 | PDE Loss:  -2.2075 | Function Loss:  -2.4275\n",
      "Total loss:  -1.3611 | PDE Loss:  -2.208 | Function Loss:  -2.4278\n",
      "Total loss:  -1.3613 | PDE Loss:  -2.207 | Function Loss:  -2.4282\n",
      "Total loss:  -1.3617 | PDE Loss:  -2.2061 | Function Loss:  -2.4287\n",
      "Total loss:  -1.362 | PDE Loss:  -2.2081 | Function Loss:  -2.4288\n",
      "Total loss:  -1.3624 | PDE Loss:  -2.2093 | Function Loss:  -2.4291\n",
      "Total loss:  -1.3626 | PDE Loss:  -2.2125 | Function Loss:  -2.4288\n",
      "Total loss:  -1.3629 | PDE Loss:  -2.2136 | Function Loss:  -2.4289\n",
      "Total loss:  -1.3631 | PDE Loss:  -2.215 | Function Loss:  -2.4289\n",
      "Total loss:  -1.3633 | PDE Loss:  -2.2159 | Function Loss:  -2.429\n",
      "Total loss:  -1.3635 | PDE Loss:  -2.2165 | Function Loss:  -2.4292\n",
      "Total loss:  -1.3638 | PDE Loss:  -2.2157 | Function Loss:  -2.4296\n",
      "Total loss:  -1.364 | PDE Loss:  -2.2154 | Function Loss:  -2.4299\n",
      "Total loss:  -1.3643 | PDE Loss:  -2.2137 | Function Loss:  -2.4305\n",
      "Total loss:  -1.3646 | PDE Loss:  -2.2124 | Function Loss:  -2.4311\n",
      "Total loss:  -1.365 | PDE Loss:  -2.2091 | Function Loss:  -2.4321\n",
      "Total loss:  -1.3653 | PDE Loss:  -2.208 | Function Loss:  -2.4327\n",
      "Total loss:  -1.3659 | PDE Loss:  -2.2071 | Function Loss:  -2.4334\n",
      "Total loss:  -1.3668 | PDE Loss:  -2.2072 | Function Loss:  -2.4346\n",
      "Total loss:  -1.367 | PDE Loss:  -2.2014 | Function Loss:  -2.4358\n",
      "Total loss:  -1.3676 | PDE Loss:  -2.2054 | Function Loss:  -2.4357\n",
      "Total loss:  -1.3688 | PDE Loss:  -2.208 | Function Loss:  -2.4367\n",
      "Total loss:  -1.3698 | PDE Loss:  -2.2074 | Function Loss:  -2.438\n",
      "Total loss:  -1.3709 | PDE Loss:  -2.2043 | Function Loss:  -2.4398\n",
      "Total loss:  -1.3718 | PDE Loss:  -2.2006 | Function Loss:  -2.4415\n",
      "Total loss:  -1.3727 | PDE Loss:  -2.1943 | Function Loss:  -2.4437\n",
      "Total loss:  -1.3733 | PDE Loss:  -2.1884 | Function Loss:  -2.4454\n",
      "Total loss:  -1.3741 | PDE Loss:  -2.1854 | Function Loss:  -2.4469\n",
      "Total loss:  -1.3751 | PDE Loss:  -2.1825 | Function Loss:  -2.4486\n",
      "Total loss:  -1.376 | PDE Loss:  -2.1818 | Function Loss:  -2.4499\n",
      "Total loss:  -1.377 | PDE Loss:  -2.1733 | Function Loss:  -2.4526\n",
      "Total loss:  -1.378 | PDE Loss:  -2.1713 | Function Loss:  -2.4542\n",
      "Total loss:  -1.379 | PDE Loss:  -2.1684 | Function Loss:  -2.4559\n",
      "Total loss:  -1.3798 | PDE Loss:  -2.1673 | Function Loss:  -2.4572\n",
      "Total loss:  -1.3805 | PDE Loss:  -2.1629 | Function Loss:  -2.4589\n",
      "Total loss:  -1.3813 | PDE Loss:  -2.1597 | Function Loss:  -2.4605\n",
      "Total loss:  -1.3817 | PDE Loss:  -2.1587 | Function Loss:  -2.4611\n",
      "Total loss:  -1.3822 | PDE Loss:  -2.1556 | Function Loss:  -2.4623\n",
      "Total loss:  -1.3826 | PDE Loss:  -2.1555 | Function Loss:  -2.4629\n",
      "Total loss:  -1.383 | PDE Loss:  -2.1537 | Function Loss:  -2.4636\n",
      "Total loss:  -1.3833 | PDE Loss:  -2.1522 | Function Loss:  -2.4643\n",
      "Total loss:  -1.3835 | PDE Loss:  -2.1519 | Function Loss:  -2.4647\n",
      "Total loss:  -1.3841 | PDE Loss:  -2.1508 | Function Loss:  -2.4656\n",
      "Total loss:  -1.3849 | PDE Loss:  -2.1485 | Function Loss:  -2.467\n",
      "Total loss:  -1.3857 | PDE Loss:  -2.1483 | Function Loss:  -2.468\n",
      "Total loss:  -1.3866 | PDE Loss:  -2.1427 | Function Loss:  -2.4704\n",
      "Total loss:  -1.3873 | PDE Loss:  -2.1423 | Function Loss:  -2.4713\n",
      "Total loss:  -1.3883 | PDE Loss:  -2.1424 | Function Loss:  -2.4725\n",
      "Total loss:  -1.3903 | PDE Loss:  -2.1455 | Function Loss:  -2.4742\n",
      "Total loss:  -1.3916 | PDE Loss:  -2.1486 | Function Loss:  -2.4751\n",
      "Total loss:  -1.3923 | PDE Loss:  -2.1502 | Function Loss:  -2.4757\n",
      "Total loss:  -1.3915 | PDE Loss:  -2.1594 | Function Loss:  -2.4728\n",
      "Total loss:  -1.3928 | PDE Loss:  -2.1551 | Function Loss:  -2.4753\n",
      "Total loss:  -1.3933 | PDE Loss:  -2.1572 | Function Loss:  -2.4753\n",
      "Total loss:  -1.394 | PDE Loss:  -2.1618 | Function Loss:  -2.4752\n",
      "Total loss:  -1.3947 | PDE Loss:  -2.1643 | Function Loss:  -2.4756\n",
      "Total loss:  -1.3952 | PDE Loss:  -2.1656 | Function Loss:  -2.4759\n",
      "Total loss:  -1.3959 | PDE Loss:  -2.1672 | Function Loss:  -2.4764\n",
      "Total loss:  -1.3966 | PDE Loss:  -2.1678 | Function Loss:  -2.4772\n",
      "Total loss:  -1.3978 | PDE Loss:  -2.1691 | Function Loss:  -2.4784\n",
      "Total loss:  -1.3989 | PDE Loss:  -2.1736 | Function Loss:  -2.4788\n",
      "Total loss:  -1.4 | PDE Loss:  -2.1741 | Function Loss:  -2.48\n",
      "Total loss:  -1.4013 | PDE Loss:  -2.1716 | Function Loss:  -2.482\n",
      "Total loss:  -1.4015 | PDE Loss:  -2.1691 | Function Loss:  -2.4829\n",
      "Total loss:  -1.4022 | PDE Loss:  -2.1711 | Function Loss:  -2.4833\n",
      "Total loss:  -1.4032 | PDE Loss:  -2.1665 | Function Loss:  -2.4854\n",
      "Total loss:  -1.404 | PDE Loss:  -2.1617 | Function Loss:  -2.4874\n",
      "Total loss:  -1.4051 | PDE Loss:  -2.1642 | Function Loss:  -2.4882\n",
      "Total loss:  -1.4062 | PDE Loss:  -2.1643 | Function Loss:  -2.4895\n",
      "Total loss:  -1.407 | PDE Loss:  -2.1637 | Function Loss:  -2.4906\n",
      "Total loss:  -1.4077 | PDE Loss:  -2.1608 | Function Loss:  -2.4921\n",
      "Total loss:  -1.4082 | PDE Loss:  -2.1587 | Function Loss:  -2.4931\n",
      "Total loss:  -1.4089 | PDE Loss:  -2.1546 | Function Loss:  -2.4948\n",
      "Total loss:  -1.4094 | PDE Loss:  -2.1525 | Function Loss:  -2.4959\n",
      "Total loss:  -1.4097 | PDE Loss:  -2.1512 | Function Loss:  -2.4966\n",
      "Total loss:  -1.4099 | PDE Loss:  -2.1502 | Function Loss:  -2.4971\n",
      "Total loss:  -1.4101 | PDE Loss:  -2.1498 | Function Loss:  -2.4975\n",
      "Total loss:  -1.4103 | PDE Loss:  -2.1496 | Function Loss:  -2.4977\n",
      "Total loss:  -1.4105 | PDE Loss:  -2.1496 | Function Loss:  -2.4979\n",
      "Total loss:  -1.4108 | PDE Loss:  -2.1496 | Function Loss:  -2.4983\n",
      "Total loss:  -1.4111 | PDE Loss:  -2.1494 | Function Loss:  -2.4988\n",
      "Total loss:  -1.4115 | PDE Loss:  -2.149 | Function Loss:  -2.4993\n",
      "Total loss:  -1.4118 | PDE Loss:  -2.1489 | Function Loss:  -2.4997\n",
      "Total loss:  -1.412 | PDE Loss:  -2.1483 | Function Loss:  -2.5001\n",
      "Total loss:  -1.4123 | PDE Loss:  -2.1479 | Function Loss:  -2.5005\n",
      "Total loss:  -1.4125 | PDE Loss:  -2.146 | Function Loss:  -2.5012\n",
      "Total loss:  -1.4128 | PDE Loss:  -2.144 | Function Loss:  -2.502\n",
      "Total loss:  -1.4131 | PDE Loss:  -2.1409 | Function Loss:  -2.5031\n",
      "Total loss:  -1.4134 | PDE Loss:  -2.1361 | Function Loss:  -2.5046\n",
      "Total loss:  -1.4136 | PDE Loss:  -2.1355 | Function Loss:  -2.505\n",
      "Total loss:  -1.4139 | PDE Loss:  -2.1345 | Function Loss:  -2.5055\n",
      "Total loss:  -1.4142 | PDE Loss:  -2.1339 | Function Loss:  -2.5061\n",
      "Total loss:  -1.4144 | PDE Loss:  -2.1336 | Function Loss:  -2.5064\n",
      "Total loss:  -1.4145 | PDE Loss:  -2.1329 | Function Loss:  -2.5067\n",
      "Total loss:  -1.4147 | PDE Loss:  -2.1325 | Function Loss:  -2.507\n",
      "Total loss:  -1.4148 | PDE Loss:  -2.1314 | Function Loss:  -2.5074\n",
      "Total loss:  -1.4149 | PDE Loss:  -2.1303 | Function Loss:  -2.5078\n",
      "Total loss:  -1.415 | PDE Loss:  -2.1287 | Function Loss:  -2.5083\n",
      "Total loss:  -1.4152 | PDE Loss:  -2.1262 | Function Loss:  -2.5091\n",
      "Total loss:  -1.4153 | PDE Loss:  -2.1253 | Function Loss:  -2.5096\n",
      "Total loss:  -1.4155 | PDE Loss:  -2.1236 | Function Loss:  -2.5101\n",
      "Total loss:  -1.4157 | PDE Loss:  -2.1231 | Function Loss:  -2.5105\n",
      "Total loss:  -1.4158 | PDE Loss:  -2.1228 | Function Loss:  -2.5107\n",
      "Total loss:  -1.4159 | PDE Loss:  -2.1229 | Function Loss:  -2.5109\n",
      "Total loss:  -1.416 | PDE Loss:  -2.1234 | Function Loss:  -2.5109\n",
      "Total loss:  -1.4162 | PDE Loss:  -2.1239 | Function Loss:  -2.511\n",
      "Total loss:  -1.4164 | PDE Loss:  -2.1244 | Function Loss:  -2.5111\n",
      "Total loss:  -1.4166 | PDE Loss:  -2.1254 | Function Loss:  -2.5111\n",
      "Total loss:  -1.4168 | PDE Loss:  -2.1232 | Function Loss:  -2.5118\n",
      "Total loss:  -1.4171 | PDE Loss:  -2.1242 | Function Loss:  -2.512\n",
      "Total loss:  -1.4175 | PDE Loss:  -2.1251 | Function Loss:  -2.5122\n",
      "Total loss:  -1.4178 | PDE Loss:  -2.1263 | Function Loss:  -2.5124\n",
      "Total loss:  -1.4181 | PDE Loss:  -2.1253 | Function Loss:  -2.513\n",
      "Total loss:  -1.4183 | PDE Loss:  -2.1261 | Function Loss:  -2.513\n",
      "Total loss:  -1.4184 | PDE Loss:  -2.1265 | Function Loss:  -2.5131\n",
      "Total loss:  -1.4186 | PDE Loss:  -2.1274 | Function Loss:  -2.5131\n",
      "Total loss:  -1.4188 | PDE Loss:  -2.1283 | Function Loss:  -2.5131\n",
      "Total loss:  -1.419 | PDE Loss:  -2.1291 | Function Loss:  -2.5131\n",
      "Total loss:  -1.4193 | PDE Loss:  -2.1307 | Function Loss:  -2.5131\n",
      "Total loss:  -1.4196 | PDE Loss:  -2.1322 | Function Loss:  -2.5132\n",
      "Total loss:  -1.42 | PDE Loss:  -2.1346 | Function Loss:  -2.5131\n",
      "Total loss:  -1.4196 | PDE Loss:  -2.1347 | Function Loss:  -2.5126\n",
      "Total loss:  -1.4203 | PDE Loss:  -2.1353 | Function Loss:  -2.5133\n",
      "Total loss:  -1.4207 | PDE Loss:  -2.1367 | Function Loss:  -2.5134\n",
      "Total loss:  -1.4212 | PDE Loss:  -2.1379 | Function Loss:  -2.5138\n",
      "Total loss:  -1.4216 | PDE Loss:  -2.1415 | Function Loss:  -2.5134\n",
      "Total loss:  -1.422 | PDE Loss:  -2.1416 | Function Loss:  -2.5139\n",
      "Total loss:  -1.4223 | PDE Loss:  -2.142 | Function Loss:  -2.5142\n",
      "Total loss:  -1.4225 | PDE Loss:  -2.1428 | Function Loss:  -2.5142\n",
      "Total loss:  -1.4227 | PDE Loss:  -2.1442 | Function Loss:  -2.5141\n",
      "Total loss:  -1.4227 | PDE Loss:  -2.1447 | Function Loss:  -2.5141\n",
      "Total loss:  -1.4228 | PDE Loss:  -2.1456 | Function Loss:  -2.514\n",
      "Total loss:  -1.4229 | PDE Loss:  -2.1461 | Function Loss:  -2.514\n",
      "Total loss:  -1.423 | PDE Loss:  -2.1464 | Function Loss:  -2.514\n",
      "Total loss:  -1.4231 | PDE Loss:  -2.1469 | Function Loss:  -2.514\n",
      "Total loss:  -1.4231 | PDE Loss:  -2.144 | Function Loss:  -2.5147\n",
      "Total loss:  -1.4232 | PDE Loss:  -2.1456 | Function Loss:  -2.5145\n",
      "Total loss:  -1.4234 | PDE Loss:  -2.147 | Function Loss:  -2.5143\n",
      "Total loss:  -1.4235 | PDE Loss:  -2.1485 | Function Loss:  -2.5142\n",
      "Total loss:  -1.4237 | PDE Loss:  -2.1501 | Function Loss:  -2.5141\n",
      "Total loss:  -1.424 | PDE Loss:  -2.1518 | Function Loss:  -2.514\n",
      "Total loss:  -1.4243 | PDE Loss:  -2.1539 | Function Loss:  -2.5139\n",
      "Total loss:  -1.4246 | PDE Loss:  -2.1555 | Function Loss:  -2.5139\n",
      "Total loss:  -1.4249 | PDE Loss:  -2.1571 | Function Loss:  -2.5139\n",
      "Total loss:  -1.4252 | PDE Loss:  -2.1581 | Function Loss:  -2.5141\n",
      "Total loss:  -1.4254 | PDE Loss:  -2.1588 | Function Loss:  -2.5142\n",
      "Total loss:  -1.4256 | PDE Loss:  -2.1595 | Function Loss:  -2.5143\n",
      "Total loss:  -1.4258 | PDE Loss:  -2.1598 | Function Loss:  -2.5144\n",
      "Total loss:  -1.4261 | PDE Loss:  -2.1603 | Function Loss:  -2.5146\n",
      "Total loss:  -1.4263 | PDE Loss:  -2.1604 | Function Loss:  -2.5149\n",
      "Total loss:  -1.4265 | PDE Loss:  -2.1604 | Function Loss:  -2.5151\n",
      "Total loss:  -1.4269 | PDE Loss:  -2.1602 | Function Loss:  -2.5156\n",
      "Total loss:  -1.4272 | PDE Loss:  -2.16 | Function Loss:  -2.5161\n",
      "Total loss:  -1.4275 | PDE Loss:  -2.1603 | Function Loss:  -2.5164\n",
      "Total loss:  -1.4278 | PDE Loss:  -2.1606 | Function Loss:  -2.5167\n",
      "Total loss:  -1.4281 | PDE Loss:  -2.1619 | Function Loss:  -2.5167\n",
      "Total loss:  -1.4283 | PDE Loss:  -2.1622 | Function Loss:  -2.5169\n",
      "Total loss:  -1.4287 | PDE Loss:  -2.1632 | Function Loss:  -2.5171\n",
      "Total loss:  -1.4289 | PDE Loss:  -2.1633 | Function Loss:  -2.5174\n",
      "Total loss:  -1.4291 | PDE Loss:  -2.1633 | Function Loss:  -2.5176\n",
      "Total loss:  -1.4292 | PDE Loss:  -2.1627 | Function Loss:  -2.5179\n",
      "Total loss:  -1.4293 | PDE Loss:  -2.1621 | Function Loss:  -2.5181\n",
      "Total loss:  -1.4294 | PDE Loss:  -2.1615 | Function Loss:  -2.5184\n",
      "Total loss:  -1.4294 | PDE Loss:  -2.1605 | Function Loss:  -2.5187\n",
      "Total loss:  -1.4295 | PDE Loss:  -2.1603 | Function Loss:  -2.5188\n",
      "Total loss:  -1.4295 | PDE Loss:  -2.1602 | Function Loss:  -2.5189\n",
      "Total loss:  -1.4296 | PDE Loss:  -2.1603 | Function Loss:  -2.5189\n",
      "Total loss:  -1.4296 | PDE Loss:  -2.1604 | Function Loss:  -2.5189\n",
      "Total loss:  -1.4297 | PDE Loss:  -2.1607 | Function Loss:  -2.5189\n",
      "Total loss:  -1.4298 | PDE Loss:  -2.161 | Function Loss:  -2.519\n",
      "Total loss:  -1.4299 | PDE Loss:  -2.1611 | Function Loss:  -2.5191\n",
      "Total loss:  -1.4301 | PDE Loss:  -2.1612 | Function Loss:  -2.5193\n",
      "Total loss:  -1.4302 | PDE Loss:  -2.1616 | Function Loss:  -2.5194\n",
      "Total loss:  -1.4305 | PDE Loss:  -2.1627 | Function Loss:  -2.5194\n",
      "Total loss:  -1.4309 | PDE Loss:  -2.166 | Function Loss:  -2.5192\n",
      "Total loss:  -1.4315 | PDE Loss:  -2.1697 | Function Loss:  -2.5191\n",
      "Total loss:  -1.4321 | PDE Loss:  -2.1753 | Function Loss:  -2.5187\n",
      "Total loss:  -1.4329 | PDE Loss:  -2.1827 | Function Loss:  -2.5179\n",
      "Total loss:  -1.4336 | PDE Loss:  -2.189 | Function Loss:  -2.5174\n",
      "Total loss:  -1.434 | PDE Loss:  -2.1932 | Function Loss:  -2.5171\n",
      "Total loss:  -1.4344 | PDE Loss:  -2.1971 | Function Loss:  -2.5167\n",
      "Total loss:  -1.4347 | PDE Loss:  -2.1981 | Function Loss:  -2.5169\n",
      "Total loss:  -1.435 | PDE Loss:  -2.1956 | Function Loss:  -2.5177\n",
      "Total loss:  -1.4352 | PDE Loss:  -2.1959 | Function Loss:  -2.518\n",
      "Total loss:  -1.4354 | PDE Loss:  -2.1962 | Function Loss:  -2.5182\n",
      "Total loss:  -1.4356 | PDE Loss:  -2.1961 | Function Loss:  -2.5185\n",
      "Total loss:  -1.4359 | PDE Loss:  -2.1962 | Function Loss:  -2.5188\n",
      "Total loss:  -1.4362 | PDE Loss:  -2.1963 | Function Loss:  -2.5191\n",
      "Total loss:  -1.4364 | PDE Loss:  -2.1975 | Function Loss:  -2.5191\n",
      "Total loss:  -1.4367 | PDE Loss:  -2.1978 | Function Loss:  -2.5193\n",
      "Total loss:  -1.437 | PDE Loss:  -2.2003 | Function Loss:  -2.5192\n",
      "Total loss:  -1.4374 | PDE Loss:  -2.2036 | Function Loss:  -2.519\n",
      "Total loss:  -1.4377 | PDE Loss:  -2.2077 | Function Loss:  -2.5185\n",
      "Total loss:  -1.438 | PDE Loss:  -2.211 | Function Loss:  -2.5182\n",
      "Total loss:  -1.4385 | PDE Loss:  -2.2171 | Function Loss:  -2.5177\n",
      "Total loss:  -1.4393 | PDE Loss:  -2.2222 | Function Loss:  -2.5175\n",
      "Total loss:  -1.4405 | PDE Loss:  -2.2305 | Function Loss:  -2.5174\n",
      "Total loss:  -1.3818 | PDE Loss:  -2.043 | Function Loss:  -2.4886\n",
      "Total loss:  -1.441 | PDE Loss:  -2.2348 | Function Loss:  -2.5171\n",
      "Total loss:  -1.4421 | PDE Loss:  -2.2371 | Function Loss:  -2.518\n",
      "Total loss:  -1.4443 | PDE Loss:  -2.2388 | Function Loss:  -2.5202\n",
      "Total loss:  -1.4449 | PDE Loss:  -2.2363 | Function Loss:  -2.5215\n",
      "Total loss:  -1.4454 | PDE Loss:  -2.239 | Function Loss:  -2.5216\n",
      "Total loss:  -1.4464 | PDE Loss:  -2.2383 | Function Loss:  -2.5228\n",
      "Total loss:  -1.4472 | PDE Loss:  -2.2355 | Function Loss:  -2.5244\n",
      "Total loss:  -1.4476 | PDE Loss:  -2.2352 | Function Loss:  -2.5249\n",
      "Total loss:  -1.4481 | PDE Loss:  -2.2373 | Function Loss:  -2.5251\n",
      "Total loss:  -1.4488 | PDE Loss:  -2.2386 | Function Loss:  -2.5257\n",
      "Total loss:  -1.4494 | PDE Loss:  -2.2396 | Function Loss:  -2.5262\n",
      "Total loss:  -1.45 | PDE Loss:  -2.2394 | Function Loss:  -2.5269\n",
      "Total loss:  -1.4504 | PDE Loss:  -2.2392 | Function Loss:  -2.5274\n",
      "Total loss:  -1.4509 | PDE Loss:  -2.2395 | Function Loss:  -2.528\n",
      "Total loss:  -1.4513 | PDE Loss:  -2.2396 | Function Loss:  -2.5285\n",
      "Total loss:  -1.4516 | PDE Loss:  -2.2403 | Function Loss:  -2.5287\n",
      "Total loss:  -1.4518 | PDE Loss:  -2.2405 | Function Loss:  -2.5289\n",
      "Total loss:  -1.452 | PDE Loss:  -2.2414 | Function Loss:  -2.529\n",
      "Total loss:  -1.4522 | PDE Loss:  -2.2416 | Function Loss:  -2.5292\n",
      "Total loss:  -1.4524 | PDE Loss:  -2.2421 | Function Loss:  -2.5293\n",
      "Total loss:  -1.4526 | PDE Loss:  -2.2413 | Function Loss:  -2.5297\n",
      "Total loss:  -1.4528 | PDE Loss:  -2.2412 | Function Loss:  -2.53\n",
      "Total loss:  -1.4531 | PDE Loss:  -2.2395 | Function Loss:  -2.5307\n",
      "Total loss:  -1.4534 | PDE Loss:  -2.2383 | Function Loss:  -2.5312\n",
      "Total loss:  -1.4536 | PDE Loss:  -2.2369 | Function Loss:  -2.5318\n",
      "Total loss:  -1.4538 | PDE Loss:  -2.2357 | Function Loss:  -2.5323\n",
      "Total loss:  -1.4541 | PDE Loss:  -2.2345 | Function Loss:  -2.5328\n",
      "Total loss:  -1.4543 | PDE Loss:  -2.2335 | Function Loss:  -2.5333\n",
      "Total loss:  -1.4544 | PDE Loss:  -2.2307 | Function Loss:  -2.534\n",
      "Total loss:  -1.4546 | PDE Loss:  -2.231 | Function Loss:  -2.5342\n",
      "Total loss:  -1.4548 | PDE Loss:  -2.2314 | Function Loss:  -2.5343\n",
      "Total loss:  -1.455 | PDE Loss:  -2.2319 | Function Loss:  -2.5344\n",
      "Total loss:  -1.4551 | PDE Loss:  -2.2321 | Function Loss:  -2.5345\n",
      "Total loss:  -1.4553 | PDE Loss:  -2.2322 | Function Loss:  -2.5347\n",
      "Total loss:  -1.4554 | PDE Loss:  -2.2323 | Function Loss:  -2.5349\n",
      "Total loss:  -1.4556 | PDE Loss:  -2.2318 | Function Loss:  -2.5351\n",
      "Total loss:  -1.4558 | PDE Loss:  -2.2314 | Function Loss:  -2.5355\n",
      "Total loss:  -1.456 | PDE Loss:  -2.23 | Function Loss:  -2.536\n",
      "Total loss:  -1.4562 | PDE Loss:  -2.229 | Function Loss:  -2.5365\n",
      "Total loss:  -1.4565 | PDE Loss:  -2.2283 | Function Loss:  -2.5369\n",
      "Total loss:  -1.4567 | PDE Loss:  -2.227 | Function Loss:  -2.5375\n",
      "Total loss:  -1.4569 | PDE Loss:  -2.227 | Function Loss:  -2.5377\n",
      "Total loss:  -1.4571 | PDE Loss:  -2.2272 | Function Loss:  -2.5378\n",
      "Total loss:  -1.4573 | PDE Loss:  -2.2282 | Function Loss:  -2.5379\n",
      "Total loss:  -1.4574 | PDE Loss:  -2.2295 | Function Loss:  -2.5378\n",
      "Total loss:  -1.4576 | PDE Loss:  -2.2309 | Function Loss:  -2.5378\n",
      "Total loss:  -1.4578 | PDE Loss:  -2.2319 | Function Loss:  -2.5378\n",
      "Total loss:  -1.458 | PDE Loss:  -2.233 | Function Loss:  -2.5378\n",
      "Total loss:  -1.4583 | PDE Loss:  -2.2346 | Function Loss:  -2.5379\n",
      "Total loss:  -1.4586 | PDE Loss:  -2.2355 | Function Loss:  -2.538\n",
      "Total loss:  -1.459 | PDE Loss:  -2.2378 | Function Loss:  -2.538\n",
      "Total loss:  -1.4594 | PDE Loss:  -2.2396 | Function Loss:  -2.5382\n",
      "Total loss:  -1.46 | PDE Loss:  -2.2425 | Function Loss:  -2.5384\n",
      "Total loss:  -1.4604 | PDE Loss:  -2.2439 | Function Loss:  -2.5385\n",
      "Total loss:  -1.4607 | PDE Loss:  -2.2443 | Function Loss:  -2.5388\n",
      "Total loss:  -1.4609 | PDE Loss:  -2.2453 | Function Loss:  -2.5388\n",
      "Total loss:  -1.4611 | PDE Loss:  -2.2469 | Function Loss:  -2.5388\n",
      "Total loss:  -1.4614 | PDE Loss:  -2.2495 | Function Loss:  -2.5386\n",
      "Total loss:  -1.4616 | PDE Loss:  -2.2526 | Function Loss:  -2.5383\n",
      "Total loss:  -1.4619 | PDE Loss:  -2.2558 | Function Loss:  -2.538\n",
      "Total loss:  -1.462 | PDE Loss:  -2.258 | Function Loss:  -2.5378\n",
      "Total loss:  -1.4622 | PDE Loss:  -2.2596 | Function Loss:  -2.5376\n",
      "Total loss:  -1.4624 | PDE Loss:  -2.2605 | Function Loss:  -2.5377\n",
      "Total loss:  -1.4625 | PDE Loss:  -2.2613 | Function Loss:  -2.5377\n",
      "Total loss:  -1.4627 | PDE Loss:  -2.2611 | Function Loss:  -2.5379\n",
      "Total loss:  -1.4628 | PDE Loss:  -2.2604 | Function Loss:  -2.5382\n",
      "Total loss:  -1.463 | PDE Loss:  -2.2605 | Function Loss:  -2.5383\n",
      "Total loss:  -1.4631 | PDE Loss:  -2.261 | Function Loss:  -2.5385\n",
      "Total loss:  -1.4633 | PDE Loss:  -2.2612 | Function Loss:  -2.5386\n",
      "Total loss:  -1.4634 | PDE Loss:  -2.2627 | Function Loss:  -2.5385\n",
      "Total loss:  -1.4634 | PDE Loss:  -2.2632 | Function Loss:  -2.5384\n",
      "Total loss:  -1.4635 | PDE Loss:  -2.2643 | Function Loss:  -2.5383\n",
      "Total loss:  -1.4636 | PDE Loss:  -2.2651 | Function Loss:  -2.5382\n",
      "Total loss:  -1.4636 | PDE Loss:  -2.2656 | Function Loss:  -2.5382\n",
      "Total loss:  -1.4637 | PDE Loss:  -2.2657 | Function Loss:  -2.5382\n",
      "Total loss:  -1.4637 | PDE Loss:  -2.2654 | Function Loss:  -2.5383\n",
      "Total loss:  -1.4637 | PDE Loss:  -2.2648 | Function Loss:  -2.5385\n",
      "Total loss:  -1.4637 | PDE Loss:  -2.2619 | Function Loss:  -2.539\n",
      "Total loss:  -1.4638 | PDE Loss:  -2.2634 | Function Loss:  -2.5388\n",
      "Total loss:  -1.4638 | PDE Loss:  -2.2629 | Function Loss:  -2.5389\n",
      "Total loss:  -1.4638 | PDE Loss:  -2.2624 | Function Loss:  -2.5391\n",
      "Total loss:  -1.4639 | PDE Loss:  -2.262 | Function Loss:  -2.5392\n",
      "Total loss:  -1.464 | PDE Loss:  -2.2619 | Function Loss:  -2.5393\n",
      "Total loss:  -1.464 | PDE Loss:  -2.2621 | Function Loss:  -2.5393\n",
      "Total loss:  -1.4641 | PDE Loss:  -2.2628 | Function Loss:  -2.5393\n",
      "Total loss:  -1.4642 | PDE Loss:  -2.263 | Function Loss:  -2.5393\n",
      "Total loss:  -1.4642 | PDE Loss:  -2.2644 | Function Loss:  -2.5391\n",
      "Total loss:  -1.4643 | PDE Loss:  -2.2658 | Function Loss:  -2.5389\n",
      "Total loss:  -1.4643 | PDE Loss:  -2.2673 | Function Loss:  -2.5387\n",
      "Total loss:  -1.4644 | PDE Loss:  -2.2685 | Function Loss:  -2.5386\n",
      "Total loss:  -1.4644 | PDE Loss:  -2.2694 | Function Loss:  -2.5384\n",
      "Total loss:  -1.4645 | PDE Loss:  -2.2698 | Function Loss:  -2.5384\n",
      "Total loss:  -1.4645 | PDE Loss:  -2.2699 | Function Loss:  -2.5384\n",
      "Total loss:  -1.4645 | PDE Loss:  -2.2698 | Function Loss:  -2.5385\n",
      "Total loss:  -1.4646 | PDE Loss:  -2.2697 | Function Loss:  -2.5386\n",
      "Total loss:  -1.4646 | PDE Loss:  -2.2695 | Function Loss:  -2.5387\n",
      "Total loss:  -1.4647 | PDE Loss:  -2.2696 | Function Loss:  -2.5387\n",
      "Total loss:  -1.4647 | PDE Loss:  -2.2698 | Function Loss:  -2.5387\n",
      "Total loss:  -1.4648 | PDE Loss:  -2.2701 | Function Loss:  -2.5387\n",
      "Total loss:  -1.4648 | PDE Loss:  -2.2709 | Function Loss:  -2.5386\n",
      "Total loss:  -1.4649 | PDE Loss:  -2.2714 | Function Loss:  -2.5386\n",
      "Total loss:  -1.4649 | PDE Loss:  -2.2721 | Function Loss:  -2.5385\n",
      "Total loss:  -1.4649 | PDE Loss:  -2.273 | Function Loss:  -2.5384\n",
      "Total loss:  -1.465 | PDE Loss:  -2.274 | Function Loss:  -2.5382\n",
      "Total loss:  -1.465 | PDE Loss:  -2.2752 | Function Loss:  -2.5381\n",
      "Total loss:  -1.4651 | PDE Loss:  -2.2762 | Function Loss:  -2.5379\n",
      "Total loss:  -1.4651 | PDE Loss:  -2.2771 | Function Loss:  -2.5378\n",
      "Total loss:  -1.4652 | PDE Loss:  -2.2779 | Function Loss:  -2.5378\n",
      "Total loss:  -1.4652 | PDE Loss:  -2.2783 | Function Loss:  -2.5377\n",
      "Total loss:  -1.4653 | PDE Loss:  -2.2785 | Function Loss:  -2.5377\n",
      "Total loss:  -1.4653 | PDE Loss:  -2.2784 | Function Loss:  -2.5378\n",
      "Total loss:  -1.4653 | PDE Loss:  -2.2784 | Function Loss:  -2.5378\n",
      "Total loss:  -1.4654 | PDE Loss:  -2.2782 | Function Loss:  -2.5379\n",
      "Total loss:  -1.4654 | PDE Loss:  -2.2781 | Function Loss:  -2.538\n",
      "Total loss:  -1.4654 | PDE Loss:  -2.2777 | Function Loss:  -2.5381\n",
      "Total loss:  -1.4655 | PDE Loss:  -2.2768 | Function Loss:  -2.5384\n",
      "Total loss:  -1.4656 | PDE Loss:  -2.2764 | Function Loss:  -2.5385\n",
      "Total loss:  -1.4657 | PDE Loss:  -2.2763 | Function Loss:  -2.5386\n",
      "Total loss:  -1.4658 | PDE Loss:  -2.2762 | Function Loss:  -2.5388\n",
      "Total loss:  -1.4659 | PDE Loss:  -2.2761 | Function Loss:  -2.5389\n",
      "Total loss:  -1.4659 | PDE Loss:  -2.2764 | Function Loss:  -2.5389\n",
      "Total loss:  -1.4661 | PDE Loss:  -2.2767 | Function Loss:  -2.539\n",
      "Total loss:  -1.4663 | PDE Loss:  -2.2772 | Function Loss:  -2.5392\n",
      "Total loss:  -1.4665 | PDE Loss:  -2.2783 | Function Loss:  -2.5393\n",
      "Total loss:  -1.4669 | PDE Loss:  -2.2799 | Function Loss:  -2.5395\n",
      "Total loss:  -1.4673 | PDE Loss:  -2.2809 | Function Loss:  -2.5397\n",
      "Total loss:  -1.4679 | PDE Loss:  -2.282 | Function Loss:  -2.5403\n",
      "Total loss:  -1.4685 | PDE Loss:  -2.2821 | Function Loss:  -2.5409\n",
      "Total loss:  -1.4693 | PDE Loss:  -2.2833 | Function Loss:  -2.5417\n",
      "Total loss:  -1.47 | PDE Loss:  -2.2818 | Function Loss:  -2.5427\n",
      "Total loss:  -1.4709 | PDE Loss:  -2.2825 | Function Loss:  -2.5437\n",
      "Total loss:  -1.4716 | PDE Loss:  -2.2838 | Function Loss:  -2.5443\n",
      "Total loss:  -1.4723 | PDE Loss:  -2.2844 | Function Loss:  -2.5451\n",
      "Total loss:  -1.4729 | PDE Loss:  -2.2866 | Function Loss:  -2.5453\n",
      "Total loss:  -1.472 | PDE Loss:  -2.282 | Function Loss:  -2.545\n",
      "Total loss:  -1.4732 | PDE Loss:  -2.2858 | Function Loss:  -2.5459\n",
      "Total loss:  -1.4738 | PDE Loss:  -2.2882 | Function Loss:  -2.546\n",
      "Total loss:  -1.4743 | PDE Loss:  -2.2906 | Function Loss:  -2.5462\n",
      "Total loss:  -1.4747 | PDE Loss:  -2.2936 | Function Loss:  -2.5462\n",
      "Total loss:  -1.4751 | PDE Loss:  -2.2958 | Function Loss:  -2.5463\n",
      "Total loss:  -1.4755 | PDE Loss:  -2.2957 | Function Loss:  -2.5468\n",
      "Total loss:  -1.4759 | PDE Loss:  -2.2953 | Function Loss:  -2.5472\n",
      "Total loss:  -1.4761 | PDE Loss:  -2.2944 | Function Loss:  -2.5477\n",
      "Total loss:  -1.4763 | PDE Loss:  -2.2928 | Function Loss:  -2.5482\n",
      "Total loss:  -1.4765 | PDE Loss:  -2.2918 | Function Loss:  -2.5487\n",
      "Total loss:  -1.4767 | PDE Loss:  -2.2904 | Function Loss:  -2.5491\n",
      "Total loss:  -1.4769 | PDE Loss:  -2.2896 | Function Loss:  -2.5495\n",
      "Total loss:  -1.477 | PDE Loss:  -2.2877 | Function Loss:  -2.55\n",
      "Total loss:  -1.4772 | PDE Loss:  -2.2876 | Function Loss:  -2.5502\n",
      "Total loss:  -1.4773 | PDE Loss:  -2.2835 | Function Loss:  -2.5511\n",
      "Total loss:  -1.4775 | PDE Loss:  -2.2843 | Function Loss:  -2.5511\n",
      "Total loss:  -1.4777 | PDE Loss:  -2.285 | Function Loss:  -2.5513\n",
      "Total loss:  -1.4779 | PDE Loss:  -2.2851 | Function Loss:  -2.5515\n",
      "Total loss:  -1.4781 | PDE Loss:  -2.2848 | Function Loss:  -2.5518\n",
      "Total loss:  -1.4783 | PDE Loss:  -2.2844 | Function Loss:  -2.5521\n",
      "Total loss:  -1.4787 | PDE Loss:  -2.2831 | Function Loss:  -2.5528\n",
      "Total loss:  -1.479 | PDE Loss:  -2.2825 | Function Loss:  -2.5533\n",
      "Total loss:  -1.4793 | PDE Loss:  -2.2806 | Function Loss:  -2.554\n",
      "Total loss:  -1.4796 | PDE Loss:  -2.2805 | Function Loss:  -2.5543\n",
      "Total loss:  -1.4798 | PDE Loss:  -2.2809 | Function Loss:  -2.5545\n",
      "Total loss:  -1.4801 | PDE Loss:  -2.2808 | Function Loss:  -2.5548\n",
      "Total loss:  -1.4803 | PDE Loss:  -2.2826 | Function Loss:  -2.5548\n",
      "Total loss:  -1.4805 | PDE Loss:  -2.2828 | Function Loss:  -2.555\n",
      "Total loss:  -1.4807 | PDE Loss:  -2.2838 | Function Loss:  -2.555\n",
      "Total loss:  -1.4809 | PDE Loss:  -2.2851 | Function Loss:  -2.555\n",
      "Total loss:  -1.4811 | PDE Loss:  -2.2864 | Function Loss:  -2.5551\n",
      "Total loss:  -1.4814 | PDE Loss:  -2.2867 | Function Loss:  -2.5553\n",
      "Total loss:  -1.4816 | PDE Loss:  -2.2878 | Function Loss:  -2.5554\n",
      "Total loss:  -1.4817 | PDE Loss:  -2.2874 | Function Loss:  -2.5556\n",
      "Total loss:  -1.4818 | PDE Loss:  -2.2865 | Function Loss:  -2.5559\n",
      "Total loss:  -1.4819 | PDE Loss:  -2.2853 | Function Loss:  -2.5562\n",
      "Total loss:  -1.482 | PDE Loss:  -2.2845 | Function Loss:  -2.5565\n",
      "Total loss:  -1.4821 | PDE Loss:  -2.2839 | Function Loss:  -2.5567\n",
      "Total loss:  -1.4822 | PDE Loss:  -2.2833 | Function Loss:  -2.5569\n",
      "Total loss:  -1.4822 | PDE Loss:  -2.2827 | Function Loss:  -2.5571\n",
      "Total loss:  -1.4824 | PDE Loss:  -2.2822 | Function Loss:  -2.5573\n",
      "Total loss:  -1.4825 | PDE Loss:  -2.2817 | Function Loss:  -2.5576\n",
      "Total loss:  -1.4827 | PDE Loss:  -2.2812 | Function Loss:  -2.5579\n",
      "Total loss:  -1.4829 | PDE Loss:  -2.2809 | Function Loss:  -2.5582\n",
      "Total loss:  -1.4831 | PDE Loss:  -2.2804 | Function Loss:  -2.5586\n",
      "Total loss:  -1.4834 | PDE Loss:  -2.28 | Function Loss:  -2.559\n",
      "Total loss:  -1.4839 | PDE Loss:  -2.2787 | Function Loss:  -2.5599\n",
      "Total loss:  -1.4846 | PDE Loss:  -2.2791 | Function Loss:  -2.5606\n",
      "Total loss:  -1.4849 | PDE Loss:  -2.2742 | Function Loss:  -2.5619\n",
      "Total loss:  -1.4857 | PDE Loss:  -2.2747 | Function Loss:  -2.5628\n",
      "Total loss:  -1.4863 | PDE Loss:  -2.2789 | Function Loss:  -2.5626\n",
      "Total loss:  -1.4871 | PDE Loss:  -2.2788 | Function Loss:  -2.5636\n",
      "Total loss:  -1.4881 | PDE Loss:  -2.2754 | Function Loss:  -2.5655\n",
      "Total loss:  -1.4886 | PDE Loss:  -2.2776 | Function Loss:  -2.5657\n",
      "Total loss:  -1.4892 | PDE Loss:  -2.2799 | Function Loss:  -2.566\n",
      "Total loss:  -1.4898 | PDE Loss:  -2.283 | Function Loss:  -2.5661\n",
      "Total loss:  -1.4904 | PDE Loss:  -2.2847 | Function Loss:  -2.5664\n",
      "Total loss:  -1.4911 | PDE Loss:  -2.2846 | Function Loss:  -2.5673\n",
      "Total loss:  -1.4921 | PDE Loss:  -2.2837 | Function Loss:  -2.5687\n",
      "Total loss:  -1.493 | PDE Loss:  -2.2788 | Function Loss:  -2.5706\n",
      "Total loss:  -1.4939 | PDE Loss:  -2.2758 | Function Loss:  -2.5723\n",
      "Total loss:  -1.4943 | PDE Loss:  -2.2743 | Function Loss:  -2.5731\n",
      "Total loss:  -1.4947 | PDE Loss:  -2.271 | Function Loss:  -2.5742\n",
      "Total loss:  -1.4948 | PDE Loss:  -2.2655 | Function Loss:  -2.5755\n",
      "Total loss:  -1.4953 | PDE Loss:  -2.2683 | Function Loss:  -2.5755\n",
      "Total loss:  -1.4955 | PDE Loss:  -2.2702 | Function Loss:  -2.5753\n",
      "Total loss:  -1.4957 | PDE Loss:  -2.2709 | Function Loss:  -2.5754\n",
      "Total loss:  -1.4959 | PDE Loss:  -2.2732 | Function Loss:  -2.5752\n",
      "Total loss:  -1.496 | PDE Loss:  -2.2741 | Function Loss:  -2.5753\n",
      "Total loss:  -1.4963 | PDE Loss:  -2.2749 | Function Loss:  -2.5753\n",
      "Total loss:  -1.4965 | PDE Loss:  -2.2764 | Function Loss:  -2.5754\n",
      "Total loss:  -1.4968 | PDE Loss:  -2.2768 | Function Loss:  -2.5756\n",
      "Total loss:  -1.4971 | PDE Loss:  -2.2783 | Function Loss:  -2.5756\n",
      "Total loss:  -1.4973 | PDE Loss:  -2.2783 | Function Loss:  -2.5759\n",
      "Total loss:  -1.4975 | PDE Loss:  -2.2794 | Function Loss:  -2.5759\n",
      "Total loss:  -1.4977 | PDE Loss:  -2.2799 | Function Loss:  -2.5761\n",
      "Total loss:  -1.4978 | PDE Loss:  -2.2809 | Function Loss:  -2.576\n",
      "Total loss:  -1.498 | PDE Loss:  -2.2819 | Function Loss:  -2.576\n",
      "Total loss:  -1.4981 | PDE Loss:  -2.2837 | Function Loss:  -2.5758\n",
      "Total loss:  -1.4983 | PDE Loss:  -2.2856 | Function Loss:  -2.5756\n",
      "Total loss:  -1.4983 | PDE Loss:  -2.2864 | Function Loss:  -2.5756\n",
      "Total loss:  -1.4984 | PDE Loss:  -2.2885 | Function Loss:  -2.5753\n",
      "Total loss:  -1.4985 | PDE Loss:  -2.2891 | Function Loss:  -2.5752\n",
      "Total loss:  -1.4986 | PDE Loss:  -2.2901 | Function Loss:  -2.5751\n",
      "Total loss:  -1.4986 | PDE Loss:  -2.2908 | Function Loss:  -2.5751\n",
      "Total loss:  -1.4987 | PDE Loss:  -2.2918 | Function Loss:  -2.575\n",
      "Total loss:  -1.4988 | PDE Loss:  -2.2922 | Function Loss:  -2.575\n",
      "Total loss:  -1.499 | PDE Loss:  -2.2922 | Function Loss:  -2.5752\n",
      "Total loss:  -1.4992 | PDE Loss:  -2.2917 | Function Loss:  -2.5755\n",
      "Total loss:  -1.4994 | PDE Loss:  -2.2904 | Function Loss:  -2.5761\n",
      "Total loss:  -1.4996 | PDE Loss:  -2.2888 | Function Loss:  -2.5767\n",
      "Total loss:  -1.4999 | PDE Loss:  -2.2868 | Function Loss:  -2.5773\n",
      "Total loss:  -1.5001 | PDE Loss:  -2.2857 | Function Loss:  -2.5779\n",
      "Total loss:  -1.5005 | PDE Loss:  -2.2849 | Function Loss:  -2.5784\n",
      "Total loss:  -1.5009 | PDE Loss:  -2.2861 | Function Loss:  -2.5788\n",
      "Total loss:  -1.5013 | PDE Loss:  -2.2885 | Function Loss:  -2.5788\n",
      "Total loss:  -1.5012 | PDE Loss:  -2.2932 | Function Loss:  -2.5777\n",
      "Total loss:  -1.5016 | PDE Loss:  -2.2911 | Function Loss:  -2.5785\n",
      "Total loss:  -1.5018 | PDE Loss:  -2.2926 | Function Loss:  -2.5785\n",
      "Total loss:  -1.5022 | PDE Loss:  -2.2981 | Function Loss:  -2.5779\n",
      "Total loss:  -1.5025 | PDE Loss:  -2.3008 | Function Loss:  -2.5778\n",
      "Total loss:  -1.5028 | PDE Loss:  -2.3044 | Function Loss:  -2.5774\n",
      "Total loss:  -1.5031 | PDE Loss:  -2.3076 | Function Loss:  -2.5772\n",
      "Total loss:  -1.5034 | PDE Loss:  -2.3103 | Function Loss:  -2.5771\n",
      "Total loss:  -1.5038 | PDE Loss:  -2.313 | Function Loss:  -2.577\n",
      "Total loss:  -1.5041 | PDE Loss:  -2.315 | Function Loss:  -2.577\n",
      "Total loss:  -1.5045 | PDE Loss:  -2.3168 | Function Loss:  -2.5772\n",
      "Total loss:  -1.5048 | PDE Loss:  -2.3188 | Function Loss:  -2.5772\n",
      "Total loss:  -1.5052 | PDE Loss:  -2.3195 | Function Loss:  -2.5775\n",
      "Total loss:  -1.5055 | PDE Loss:  -2.3216 | Function Loss:  -2.5774\n",
      "Total loss:  -1.5057 | PDE Loss:  -2.3218 | Function Loss:  -2.5777\n",
      "Total loss:  -1.5058 | PDE Loss:  -2.3224 | Function Loss:  -2.5777\n",
      "Total loss:  -1.5059 | PDE Loss:  -2.3233 | Function Loss:  -2.5777\n",
      "Total loss:  -1.506 | PDE Loss:  -2.3241 | Function Loss:  -2.5776\n",
      "Total loss:  -1.506 | PDE Loss:  -2.3242 | Function Loss:  -2.5777\n",
      "Total loss:  -1.5061 | PDE Loss:  -2.3247 | Function Loss:  -2.5776\n",
      "Total loss:  -1.5062 | PDE Loss:  -2.3253 | Function Loss:  -2.5776\n",
      "Total loss:  -1.5063 | PDE Loss:  -2.3255 | Function Loss:  -2.5777\n",
      "Total loss:  -1.5063 | PDE Loss:  -2.3259 | Function Loss:  -2.5777\n",
      "Total loss:  -1.5064 | PDE Loss:  -2.3258 | Function Loss:  -2.5778\n",
      "Total loss:  -1.5064 | PDE Loss:  -2.326 | Function Loss:  -2.5778\n",
      "Total loss:  -1.5065 | PDE Loss:  -2.3266 | Function Loss:  -2.5777\n",
      "Total loss:  -1.5065 | PDE Loss:  -2.3264 | Function Loss:  -2.5778\n",
      "Total loss:  -1.5066 | PDE Loss:  -2.3263 | Function Loss:  -2.5779\n",
      "Total loss:  -1.5066 | PDE Loss:  -2.3265 | Function Loss:  -2.5779\n",
      "Total loss:  -1.5066 | PDE Loss:  -2.3268 | Function Loss:  -2.5779\n",
      "Total loss:  -1.5066 | PDE Loss:  -2.3272 | Function Loss:  -2.5778\n",
      "Total loss:  -1.5067 | PDE Loss:  -2.3281 | Function Loss:  -2.5777\n",
      "Total loss:  -1.5067 | PDE Loss:  -2.329 | Function Loss:  -2.5776\n",
      "Total loss:  -1.5068 | PDE Loss:  -2.3308 | Function Loss:  -2.5774\n",
      "Total loss:  -1.5069 | PDE Loss:  -2.3321 | Function Loss:  -2.5772\n",
      "Total loss:  -1.5069 | PDE Loss:  -2.3336 | Function Loss:  -2.577\n",
      "Total loss:  -1.507 | PDE Loss:  -2.3353 | Function Loss:  -2.5768\n",
      "Total loss:  -1.507 | PDE Loss:  -2.3367 | Function Loss:  -2.5766\n",
      "Total loss:  -1.5071 | PDE Loss:  -2.338 | Function Loss:  -2.5764\n",
      "Total loss:  -1.5071 | PDE Loss:  -2.3385 | Function Loss:  -2.5764\n",
      "Total loss:  -1.5072 | PDE Loss:  -2.339 | Function Loss:  -2.5764\n",
      "Total loss:  -1.5072 | PDE Loss:  -2.3396 | Function Loss:  -2.5763\n",
      "Total loss:  -1.5073 | PDE Loss:  -2.3401 | Function Loss:  -2.5763\n",
      "Total loss:  -1.5073 | PDE Loss:  -2.341 | Function Loss:  -2.5762\n",
      "Total loss:  -1.5074 | PDE Loss:  -2.3419 | Function Loss:  -2.5761\n",
      "Total loss:  -1.5074 | PDE Loss:  -2.3435 | Function Loss:  -2.5759\n",
      "Total loss:  -1.5073 | PDE Loss:  -2.3451 | Function Loss:  -2.5755\n",
      "Total loss:  -1.5075 | PDE Loss:  -2.3441 | Function Loss:  -2.5758\n",
      "Total loss:  -1.5075 | PDE Loss:  -2.3449 | Function Loss:  -2.5757\n",
      "Total loss:  -1.5076 | PDE Loss:  -2.3471 | Function Loss:  -2.5755\n",
      "Total loss:  -1.5076 | PDE Loss:  -2.3485 | Function Loss:  -2.5753\n",
      "Total loss:  -1.5077 | PDE Loss:  -2.3501 | Function Loss:  -2.5751\n",
      "Total loss:  -1.5078 | PDE Loss:  -2.3512 | Function Loss:  -2.575\n",
      "Total loss:  -1.5078 | PDE Loss:  -2.3522 | Function Loss:  -2.5749\n",
      "Total loss:  -1.5079 | PDE Loss:  -2.3534 | Function Loss:  -2.5748\n",
      "Total loss:  -1.5079 | PDE Loss:  -2.3531 | Function Loss:  -2.5749\n",
      "Total loss:  -1.508 | PDE Loss:  -2.3531 | Function Loss:  -2.5749\n",
      "Total loss:  -1.508 | PDE Loss:  -2.3524 | Function Loss:  -2.5751\n",
      "Total loss:  -1.5081 | PDE Loss:  -2.3516 | Function Loss:  -2.5753\n",
      "Total loss:  -1.5081 | PDE Loss:  -2.3506 | Function Loss:  -2.5755\n",
      "Total loss:  -1.5082 | PDE Loss:  -2.3492 | Function Loss:  -2.5758\n",
      "Total loss:  -1.5082 | PDE Loss:  -2.3475 | Function Loss:  -2.5762\n",
      "Total loss:  -1.5083 | PDE Loss:  -2.3461 | Function Loss:  -2.5765\n",
      "Total loss:  -1.5084 | PDE Loss:  -2.3447 | Function Loss:  -2.5768\n",
      "Total loss:  -1.5085 | PDE Loss:  -2.3431 | Function Loss:  -2.5772\n",
      "Total loss:  -1.5086 | PDE Loss:  -2.3415 | Function Loss:  -2.5776\n",
      "Total loss:  -1.5087 | PDE Loss:  -2.3408 | Function Loss:  -2.5779\n",
      "Total loss:  -1.5088 | PDE Loss:  -2.3406 | Function Loss:  -2.578\n",
      "Total loss:  -1.5088 | PDE Loss:  -2.3403 | Function Loss:  -2.5781\n",
      "Total loss:  -1.5089 | PDE Loss:  -2.3398 | Function Loss:  -2.5783\n",
      "Total loss:  -1.509 | PDE Loss:  -2.3387 | Function Loss:  -2.5785\n",
      "Total loss:  -1.509 | PDE Loss:  -2.3377 | Function Loss:  -2.5788\n",
      "Total loss:  -1.5091 | PDE Loss:  -2.3354 | Function Loss:  -2.5793\n",
      "Total loss:  -1.5091 | PDE Loss:  -2.3334 | Function Loss:  -2.5797\n",
      "Total loss:  -1.5092 | PDE Loss:  -2.332 | Function Loss:  -2.58\n",
      "Total loss:  -1.5092 | PDE Loss:  -2.3297 | Function Loss:  -2.5804\n",
      "Total loss:  -1.5093 | PDE Loss:  -2.329 | Function Loss:  -2.5806\n",
      "Total loss:  -1.5093 | PDE Loss:  -2.3286 | Function Loss:  -2.5807\n",
      "Total loss:  -1.5094 | PDE Loss:  -2.3293 | Function Loss:  -2.5807\n",
      "Total loss:  -1.5095 | PDE Loss:  -2.3307 | Function Loss:  -2.5806\n",
      "Total loss:  -1.5096 | PDE Loss:  -2.3329 | Function Loss:  -2.5803\n",
      "Total loss:  -1.5097 | PDE Loss:  -2.336 | Function Loss:  -2.5799\n",
      "Total loss:  -1.5099 | PDE Loss:  -2.339 | Function Loss:  -2.5795\n",
      "Total loss:  -1.51 | PDE Loss:  -2.342 | Function Loss:  -2.5792\n",
      "Total loss:  -1.5101 | PDE Loss:  -2.345 | Function Loss:  -2.5788\n",
      "Total loss:  -1.5102 | PDE Loss:  -2.3453 | Function Loss:  -2.5789\n",
      "Total loss:  -1.5104 | PDE Loss:  -2.3447 | Function Loss:  -2.5792\n",
      "Total loss:  -1.5105 | PDE Loss:  -2.3432 | Function Loss:  -2.5796\n",
      "Total loss:  -1.5106 | PDE Loss:  -2.3417 | Function Loss:  -2.58\n",
      "Total loss:  -1.5107 | PDE Loss:  -2.3396 | Function Loss:  -2.5804\n",
      "Total loss:  -1.5107 | PDE Loss:  -2.3392 | Function Loss:  -2.5805\n",
      "Total loss:  -1.5108 | PDE Loss:  -2.3395 | Function Loss:  -2.5805\n",
      "Total loss:  -1.5108 | PDE Loss:  -2.3401 | Function Loss:  -2.5804\n",
      "Total loss:  -1.5108 | PDE Loss:  -2.3411 | Function Loss:  -2.5803\n",
      "Total loss:  -1.5109 | PDE Loss:  -2.3422 | Function Loss:  -2.5801\n",
      "Total loss:  -1.5109 | PDE Loss:  -2.3432 | Function Loss:  -2.58\n",
      "Total loss:  -1.5109 | PDE Loss:  -2.3443 | Function Loss:  -2.5799\n",
      "Total loss:  -1.511 | PDE Loss:  -2.3452 | Function Loss:  -2.5797\n",
      "Total loss:  -1.511 | PDE Loss:  -2.3459 | Function Loss:  -2.5797\n",
      "Total loss:  -1.5111 | PDE Loss:  -2.3462 | Function Loss:  -2.5797\n",
      "Total loss:  -1.5111 | PDE Loss:  -2.3463 | Function Loss:  -2.5797\n",
      "Total loss:  -1.5111 | PDE Loss:  -2.3459 | Function Loss:  -2.5798\n",
      "Total loss:  -1.5112 | PDE Loss:  -2.3454 | Function Loss:  -2.58\n",
      "Total loss:  -1.5113 | PDE Loss:  -2.345 | Function Loss:  -2.5801\n",
      "Total loss:  -1.5114 | PDE Loss:  -2.3443 | Function Loss:  -2.5804\n",
      "Total loss:  -1.5115 | PDE Loss:  -2.3434 | Function Loss:  -2.5807\n",
      "Total loss:  -1.5116 | PDE Loss:  -2.3429 | Function Loss:  -2.5809\n",
      "Total loss:  -1.5116 | PDE Loss:  -2.3425 | Function Loss:  -2.581\n",
      "Total loss:  -1.5117 | PDE Loss:  -2.3421 | Function Loss:  -2.5811\n",
      "Total loss:  -1.5118 | PDE Loss:  -2.3423 | Function Loss:  -2.5812\n",
      "Total loss:  -1.5119 | PDE Loss:  -2.3422 | Function Loss:  -2.5813\n",
      "Total loss:  -1.512 | PDE Loss:  -2.3438 | Function Loss:  -2.5812\n",
      "Total loss:  -1.5121 | PDE Loss:  -2.344 | Function Loss:  -2.5813\n",
      "Total loss:  -1.5123 | PDE Loss:  -2.3446 | Function Loss:  -2.5814\n",
      "Total loss:  -1.5125 | PDE Loss:  -2.3445 | Function Loss:  -2.5817\n",
      "Total loss:  -1.5128 | PDE Loss:  -2.3447 | Function Loss:  -2.582\n",
      "Total loss:  -1.513 | PDE Loss:  -2.3437 | Function Loss:  -2.5824\n",
      "Total loss:  -1.5131 | PDE Loss:  -2.3427 | Function Loss:  -2.5827\n",
      "Total loss:  -1.5134 | PDE Loss:  -2.3415 | Function Loss:  -2.5832\n",
      "Total loss:  -1.5136 | PDE Loss:  -2.3414 | Function Loss:  -2.5835\n",
      "Total loss:  -1.514 | PDE Loss:  -2.3402 | Function Loss:  -2.5841\n",
      "Total loss:  -1.5144 | PDE Loss:  -2.3412 | Function Loss:  -2.5845\n",
      "Total loss:  -1.515 | PDE Loss:  -2.3436 | Function Loss:  -2.5847\n",
      "Total loss:  -1.5154 | PDE Loss:  -2.3462 | Function Loss:  -2.5847\n",
      "Total loss:  -1.5155 | PDE Loss:  -2.3511 | Function Loss:  -2.5841\n",
      "Total loss:  -1.5159 | PDE Loss:  -2.3521 | Function Loss:  -2.5844\n",
      "Total loss:  -1.5162 | PDE Loss:  -2.352 | Function Loss:  -2.5847\n",
      "Total loss:  -1.5164 | PDE Loss:  -2.3517 | Function Loss:  -2.585\n",
      "Total loss:  -1.5168 | PDE Loss:  -2.3516 | Function Loss:  -2.5855\n",
      "Total loss:  -1.5172 | PDE Loss:  -2.3521 | Function Loss:  -2.5858\n",
      "Total loss:  -1.5175 | PDE Loss:  -2.352 | Function Loss:  -2.5863\n",
      "Total loss:  -1.5178 | PDE Loss:  -2.3518 | Function Loss:  -2.5867\n",
      "Total loss:  -1.5181 | PDE Loss:  -2.3508 | Function Loss:  -2.5871\n",
      "Total loss:  -1.5183 | PDE Loss:  -2.3488 | Function Loss:  -2.5878\n",
      "Total loss:  -1.5186 | PDE Loss:  -2.3486 | Function Loss:  -2.5881\n",
      "Total loss:  -1.5189 | PDE Loss:  -2.3481 | Function Loss:  -2.5885\n",
      "Total loss:  -1.5191 | PDE Loss:  -2.3463 | Function Loss:  -2.5891\n",
      "Total loss:  -1.5193 | PDE Loss:  -2.3471 | Function Loss:  -2.5892\n",
      "Total loss:  -1.5195 | PDE Loss:  -2.3474 | Function Loss:  -2.5894\n",
      "Total loss:  -1.5197 | PDE Loss:  -2.3489 | Function Loss:  -2.5894\n",
      "Total loss:  -1.5199 | PDE Loss:  -2.351 | Function Loss:  -2.5893\n",
      "Total loss:  -1.5201 | PDE Loss:  -2.3531 | Function Loss:  -2.5891\n",
      "Total loss:  -1.5203 | PDE Loss:  -2.3555 | Function Loss:  -2.5889\n",
      "Total loss:  -1.5204 | PDE Loss:  -2.3566 | Function Loss:  -2.5889\n",
      "Total loss:  -1.5206 | PDE Loss:  -2.3578 | Function Loss:  -2.5889\n",
      "Total loss:  -1.5208 | PDE Loss:  -2.3585 | Function Loss:  -2.589\n",
      "Total loss:  -1.5209 | PDE Loss:  -2.3599 | Function Loss:  -2.5888\n",
      "Total loss:  -1.5211 | PDE Loss:  -2.3602 | Function Loss:  -2.589\n",
      "Total loss:  -1.5212 | PDE Loss:  -2.3598 | Function Loss:  -2.5892\n",
      "Total loss:  -1.5213 | PDE Loss:  -2.3595 | Function Loss:  -2.5894\n",
      "Total loss:  -1.5213 | PDE Loss:  -2.359 | Function Loss:  -2.5896\n",
      "Total loss:  -1.5214 | PDE Loss:  -2.3584 | Function Loss:  -2.5898\n",
      "Total loss:  -1.5216 | PDE Loss:  -2.3581 | Function Loss:  -2.5899\n",
      "Total loss:  -1.5217 | PDE Loss:  -2.3576 | Function Loss:  -2.5902\n",
      "Total loss:  -1.5218 | PDE Loss:  -2.3576 | Function Loss:  -2.5903\n",
      "Total loss:  -1.5219 | PDE Loss:  -2.3577 | Function Loss:  -2.5905\n",
      "Total loss:  -1.5222 | PDE Loss:  -2.3577 | Function Loss:  -2.5907\n",
      "Total loss:  -1.5225 | PDE Loss:  -2.3576 | Function Loss:  -2.5911\n",
      "Total loss:  -1.5229 | PDE Loss:  -2.3568 | Function Loss:  -2.5917\n",
      "Total loss:  -1.5231 | PDE Loss:  -2.3568 | Function Loss:  -2.592\n",
      "Total loss:  -1.5234 | PDE Loss:  -2.3577 | Function Loss:  -2.5922\n",
      "Total loss:  -1.5237 | PDE Loss:  -2.3575 | Function Loss:  -2.5925\n",
      "Total loss:  -1.5238 | PDE Loss:  -2.3582 | Function Loss:  -2.5926\n",
      "Total loss:  -1.5239 | PDE Loss:  -2.3575 | Function Loss:  -2.5928\n",
      "Total loss:  -1.5241 | PDE Loss:  -2.3575 | Function Loss:  -2.593\n",
      "Total loss:  -1.5242 | PDE Loss:  -2.3566 | Function Loss:  -2.5932\n",
      "Total loss:  -1.5242 | PDE Loss:  -2.3554 | Function Loss:  -2.5936\n",
      "Total loss:  -1.5243 | PDE Loss:  -2.3545 | Function Loss:  -2.5938\n",
      "Total loss:  -1.5244 | PDE Loss:  -2.3534 | Function Loss:  -2.5941\n",
      "Total loss:  -1.5245 | PDE Loss:  -2.3528 | Function Loss:  -2.5943\n",
      "Total loss:  -1.5245 | PDE Loss:  -2.3527 | Function Loss:  -2.5944\n",
      "Total loss:  -1.5246 | PDE Loss:  -2.3525 | Function Loss:  -2.5945\n",
      "Total loss:  -1.5247 | PDE Loss:  -2.353 | Function Loss:  -2.5945\n",
      "Total loss:  -1.5248 | PDE Loss:  -2.3535 | Function Loss:  -2.5945\n",
      "Total loss:  -1.5249 | PDE Loss:  -2.3547 | Function Loss:  -2.5945\n",
      "Total loss:  -1.525 | PDE Loss:  -2.3563 | Function Loss:  -2.5943\n",
      "Total loss:  -1.5251 | PDE Loss:  -2.3587 | Function Loss:  -2.594\n",
      "Total loss:  -1.5252 | PDE Loss:  -2.3614 | Function Loss:  -2.5936\n",
      "Total loss:  -1.5253 | PDE Loss:  -2.3632 | Function Loss:  -2.5934\n",
      "Total loss:  -1.5253 | PDE Loss:  -2.365 | Function Loss:  -2.5932\n",
      "Total loss:  -1.5254 | PDE Loss:  -2.3662 | Function Loss:  -2.593\n",
      "Total loss:  -1.5254 | PDE Loss:  -2.367 | Function Loss:  -2.593\n",
      "Total loss:  -1.5255 | PDE Loss:  -2.3676 | Function Loss:  -2.5929\n",
      "Total loss:  -1.5255 | PDE Loss:  -2.3678 | Function Loss:  -2.5929\n",
      "Total loss:  -1.5255 | PDE Loss:  -2.3679 | Function Loss:  -2.5929\n",
      "Total loss:  -1.5256 | PDE Loss:  -2.3681 | Function Loss:  -2.593\n",
      "Total loss:  -1.5257 | PDE Loss:  -2.3681 | Function Loss:  -2.593\n",
      "Total loss:  -1.5257 | PDE Loss:  -2.3676 | Function Loss:  -2.5932\n",
      "Total loss:  -1.5258 | PDE Loss:  -2.3671 | Function Loss:  -2.5933\n",
      "Total loss:  -1.5258 | PDE Loss:  -2.3665 | Function Loss:  -2.5935\n",
      "Total loss:  -1.5259 | PDE Loss:  -2.3659 | Function Loss:  -2.5937\n",
      "Total loss:  -1.5259 | PDE Loss:  -2.3654 | Function Loss:  -2.5938\n",
      "Total loss:  -1.526 | PDE Loss:  -2.3647 | Function Loss:  -2.594\n",
      "Total loss:  -1.526 | PDE Loss:  -2.3646 | Function Loss:  -2.5941\n",
      "Total loss:  -1.5261 | PDE Loss:  -2.3647 | Function Loss:  -2.5941\n",
      "Total loss:  -1.5261 | PDE Loss:  -2.365 | Function Loss:  -2.5941\n",
      "Total loss:  -1.5261 | PDE Loss:  -2.3652 | Function Loss:  -2.5941\n",
      "Total loss:  -1.5262 | PDE Loss:  -2.3655 | Function Loss:  -2.5941\n",
      "Total loss:  -1.5262 | PDE Loss:  -2.3657 | Function Loss:  -2.5941\n",
      "Total loss:  -1.5262 | PDE Loss:  -2.3662 | Function Loss:  -2.594\n",
      "Total loss:  -1.5263 | PDE Loss:  -2.3664 | Function Loss:  -2.594\n",
      "Total loss:  -1.5263 | PDE Loss:  -2.3668 | Function Loss:  -2.594\n",
      "Total loss:  -1.5263 | PDE Loss:  -2.3678 | Function Loss:  -2.5939\n",
      "Total loss:  -1.5264 | PDE Loss:  -2.3679 | Function Loss:  -2.5939\n",
      "Total loss:  -1.5264 | PDE Loss:  -2.3678 | Function Loss:  -2.594\n",
      "Total loss:  -1.5264 | PDE Loss:  -2.3678 | Function Loss:  -2.594\n",
      "Total loss:  -1.5265 | PDE Loss:  -2.3675 | Function Loss:  -2.5941\n",
      "Total loss:  -1.5265 | PDE Loss:  -2.3678 | Function Loss:  -2.5941\n",
      "Total loss:  -1.5265 | PDE Loss:  -2.3675 | Function Loss:  -2.5942\n",
      "Total loss:  -1.5266 | PDE Loss:  -2.3674 | Function Loss:  -2.5942\n",
      "Total loss:  -1.5266 | PDE Loss:  -2.368 | Function Loss:  -2.5942\n",
      "Total loss:  -1.5266 | PDE Loss:  -2.3686 | Function Loss:  -2.5941\n",
      "Total loss:  -1.5267 | PDE Loss:  -2.3688 | Function Loss:  -2.5941\n",
      "Total loss:  -1.5267 | PDE Loss:  -2.3693 | Function Loss:  -2.5941\n",
      "Total loss:  -1.5268 | PDE Loss:  -2.3699 | Function Loss:  -2.594\n",
      "Total loss:  -1.5268 | PDE Loss:  -2.3702 | Function Loss:  -2.5941\n",
      "Total loss:  -1.5269 | PDE Loss:  -2.3709 | Function Loss:  -2.594\n",
      "Total loss:  -1.5269 | PDE Loss:  -2.371 | Function Loss:  -2.594\n",
      "Total loss:  -1.5269 | PDE Loss:  -2.3713 | Function Loss:  -2.594\n",
      "Total loss:  -1.527 | PDE Loss:  -2.3716 | Function Loss:  -2.594\n",
      "Total loss:  -1.527 | PDE Loss:  -2.3718 | Function Loss:  -2.594\n",
      "Total loss:  -1.527 | PDE Loss:  -2.3721 | Function Loss:  -2.5939\n",
      "Total loss:  -1.527 | PDE Loss:  -2.3725 | Function Loss:  -2.5939\n",
      "Total loss:  -1.527 | PDE Loss:  -2.3728 | Function Loss:  -2.5939\n",
      "Total loss:  -1.5269 | PDE Loss:  -2.3736 | Function Loss:  -2.5936\n",
      "Total loss:  -1.527 | PDE Loss:  -2.373 | Function Loss:  -2.5938\n",
      "Total loss:  -1.5271 | PDE Loss:  -2.3733 | Function Loss:  -2.5938\n",
      "Total loss:  -1.5271 | PDE Loss:  -2.3735 | Function Loss:  -2.5938\n",
      "Total loss:  -1.5271 | PDE Loss:  -2.374 | Function Loss:  -2.5938\n",
      "Total loss:  -1.5271 | PDE Loss:  -2.3736 | Function Loss:  -2.5939\n",
      "Total loss:  -1.5272 | PDE Loss:  -2.3741 | Function Loss:  -2.5938\n",
      "Total loss:  -1.5272 | PDE Loss:  -2.3748 | Function Loss:  -2.5938\n",
      "Total loss:  -1.5273 | PDE Loss:  -2.3752 | Function Loss:  -2.5938\n",
      "Total loss:  -1.5273 | PDE Loss:  -2.3754 | Function Loss:  -2.5938\n",
      "Total loss:  -1.5274 | PDE Loss:  -2.3755 | Function Loss:  -2.5938\n",
      "Total loss:  -1.5274 | PDE Loss:  -2.3754 | Function Loss:  -2.5938\n",
      "Total loss:  -1.5274 | PDE Loss:  -2.3754 | Function Loss:  -2.5939\n",
      "Total loss:  -1.5274 | PDE Loss:  -2.3754 | Function Loss:  -2.5939\n",
      "Total loss:  -1.5274 | PDE Loss:  -2.3754 | Function Loss:  -2.5939\n",
      "Total loss:  -1.5274 | PDE Loss:  -2.3754 | Function Loss:  -2.5939\n",
      "Total loss:  -1.5274 | PDE Loss:  -2.3754 | Function Loss:  -2.5939\n",
      "Total loss:  -1.5274 | PDE Loss:  -2.3754 | Function Loss:  -2.5939\n",
      "Total loss:  -1.5274 | PDE Loss:  -2.3754 | Function Loss:  -2.5939\n",
      "Total loss:  -1.5274 | PDE Loss:  -2.3754 | Function Loss:  -2.5939\n",
      "Total loss:  -1.5274 | PDE Loss:  -2.3753 | Function Loss:  -2.5939\n",
      "Total loss:  -1.5275 | PDE Loss:  -2.3753 | Function Loss:  -2.5939\n",
      "Total loss:  -1.5275 | PDE Loss:  -2.3755 | Function Loss:  -2.5939\n",
      "Total loss:  -1.5275 | PDE Loss:  -2.3758 | Function Loss:  -2.5939\n",
      "Total loss:  -1.5276 | PDE Loss:  -2.3763 | Function Loss:  -2.5939\n",
      "Total loss:  -1.5276 | PDE Loss:  -2.3771 | Function Loss:  -2.5939\n",
      "Total loss:  -1.5277 | PDE Loss:  -2.3784 | Function Loss:  -2.5938\n",
      "Total loss:  -1.5279 | PDE Loss:  -2.3799 | Function Loss:  -2.5937\n",
      "Total loss:  -1.528 | PDE Loss:  -2.3817 | Function Loss:  -2.5936\n",
      "Total loss:  -1.5282 | PDE Loss:  -2.3838 | Function Loss:  -2.5934\n",
      "Total loss:  -1.5283 | PDE Loss:  -2.3854 | Function Loss:  -2.5932\n",
      "Total loss:  -1.5284 | PDE Loss:  -2.3863 | Function Loss:  -2.5933\n",
      "Total loss:  -1.5285 | PDE Loss:  -2.3861 | Function Loss:  -2.5935\n",
      "Total loss:  -1.5286 | PDE Loss:  -2.3857 | Function Loss:  -2.5936\n",
      "Total loss:  -1.5287 | PDE Loss:  -2.3846 | Function Loss:  -2.5939\n",
      "Total loss:  -1.5288 | PDE Loss:  -2.3836 | Function Loss:  -2.5942\n",
      "Total loss:  -1.5289 | PDE Loss:  -2.3824 | Function Loss:  -2.5944\n",
      "Total loss:  -1.5289 | PDE Loss:  -2.3817 | Function Loss:  -2.5946\n",
      "Total loss:  -1.529 | PDE Loss:  -2.3812 | Function Loss:  -2.5948\n",
      "Total loss:  -1.529 | PDE Loss:  -2.3811 | Function Loss:  -2.5948\n",
      "Total loss:  -1.5291 | PDE Loss:  -2.3812 | Function Loss:  -2.5949\n",
      "Total loss:  -1.5291 | PDE Loss:  -2.3813 | Function Loss:  -2.5949\n",
      "Total loss:  -1.5291 | PDE Loss:  -2.3815 | Function Loss:  -2.5949\n",
      "Total loss:  -1.5291 | PDE Loss:  -2.3818 | Function Loss:  -2.5948\n",
      "Total loss:  -1.5292 | PDE Loss:  -2.3823 | Function Loss:  -2.5948\n",
      "Total loss:  -1.5292 | PDE Loss:  -2.383 | Function Loss:  -2.5947\n",
      "Total loss:  -1.5292 | PDE Loss:  -2.3844 | Function Loss:  -2.5945\n",
      "Total loss:  -1.5293 | PDE Loss:  -2.3856 | Function Loss:  -2.5944\n",
      "Total loss:  -1.5293 | PDE Loss:  -2.3866 | Function Loss:  -2.5943\n",
      "Total loss:  -1.5294 | PDE Loss:  -2.3878 | Function Loss:  -2.5941\n",
      "Total loss:  -1.5294 | PDE Loss:  -2.3886 | Function Loss:  -2.594\n",
      "Total loss:  -1.5294 | PDE Loss:  -2.3897 | Function Loss:  -2.5939\n",
      "Total loss:  -1.5294 | PDE Loss:  -2.39 | Function Loss:  -2.5938\n",
      "Total loss:  -1.5295 | PDE Loss:  -2.39 | Function Loss:  -2.5939\n",
      "Total loss:  -1.5295 | PDE Loss:  -2.39 | Function Loss:  -2.5939\n",
      "Total loss:  -1.5295 | PDE Loss:  -2.3896 | Function Loss:  -2.594\n",
      "Total loss:  -1.5295 | PDE Loss:  -2.3898 | Function Loss:  -2.594\n",
      "Total loss:  -1.5296 | PDE Loss:  -2.3892 | Function Loss:  -2.5942\n",
      "Total loss:  -1.5296 | PDE Loss:  -2.3891 | Function Loss:  -2.5942\n",
      "Total loss:  -1.5296 | PDE Loss:  -2.3889 | Function Loss:  -2.5943\n",
      "Total loss:  -1.5297 | PDE Loss:  -2.3894 | Function Loss:  -2.5942\n",
      "Total loss:  -1.5297 | PDE Loss:  -2.3899 | Function Loss:  -2.5942\n",
      "Total loss:  -1.5297 | PDE Loss:  -2.3906 | Function Loss:  -2.5941\n",
      "Total loss:  -1.5298 | PDE Loss:  -2.3915 | Function Loss:  -2.594\n",
      "Total loss:  -1.5298 | PDE Loss:  -2.3928 | Function Loss:  -2.5938\n",
      "Total loss:  -1.5298 | PDE Loss:  -2.3937 | Function Loss:  -2.5937\n",
      "Total loss:  -1.5299 | PDE Loss:  -2.3943 | Function Loss:  -2.5937\n",
      "Total loss:  -1.5299 | PDE Loss:  -2.3951 | Function Loss:  -2.5936\n",
      "Total loss:  -1.53 | PDE Loss:  -2.3953 | Function Loss:  -2.5936\n",
      "Total loss:  -1.53 | PDE Loss:  -2.3953 | Function Loss:  -2.5937\n",
      "Total loss:  -1.5301 | PDE Loss:  -2.3951 | Function Loss:  -2.5938\n",
      "Total loss:  -1.5301 | PDE Loss:  -2.3949 | Function Loss:  -2.5939\n",
      "Total loss:  -1.5302 | PDE Loss:  -2.3943 | Function Loss:  -2.5941\n",
      "Total loss:  -1.5303 | PDE Loss:  -2.3942 | Function Loss:  -2.5941\n",
      "Total loss:  -1.5303 | PDE Loss:  -2.3943 | Function Loss:  -2.5942\n",
      "Total loss:  -1.5304 | PDE Loss:  -2.3945 | Function Loss:  -2.5942\n",
      "Total loss:  -1.5304 | PDE Loss:  -2.3954 | Function Loss:  -2.5942\n",
      "Total loss:  -1.5305 | PDE Loss:  -2.3957 | Function Loss:  -2.5942\n",
      "Total loss:  -1.5305 | PDE Loss:  -2.3958 | Function Loss:  -2.5942\n",
      "Total loss:  -1.5305 | PDE Loss:  -2.3963 | Function Loss:  -2.5941\n",
      "Total loss:  -1.5306 | PDE Loss:  -2.3968 | Function Loss:  -2.5941\n",
      "Total loss:  -1.5307 | PDE Loss:  -2.3975 | Function Loss:  -2.5941\n",
      "Total loss:  -1.5307 | PDE Loss:  -2.3978 | Function Loss:  -2.5941\n",
      "Total loss:  -1.5308 | PDE Loss:  -2.3985 | Function Loss:  -2.5941\n",
      "Total loss:  -1.5309 | PDE Loss:  -2.3988 | Function Loss:  -2.5942\n",
      "Total loss:  -1.5311 | PDE Loss:  -2.4002 | Function Loss:  -2.5941\n",
      "Total loss:  -1.5312 | PDE Loss:  -2.4007 | Function Loss:  -2.5942\n",
      "Total loss:  -1.5313 | PDE Loss:  -2.4006 | Function Loss:  -2.5943\n",
      "Total loss:  -1.5314 | PDE Loss:  -2.401 | Function Loss:  -2.5944\n",
      "Total loss:  -1.5316 | PDE Loss:  -2.4002 | Function Loss:  -2.5947\n",
      "Total loss:  -1.5317 | PDE Loss:  -2.3994 | Function Loss:  -2.595\n",
      "Total loss:  -1.5317 | PDE Loss:  -2.3991 | Function Loss:  -2.5951\n",
      "Total loss:  -1.5319 | PDE Loss:  -2.3973 | Function Loss:  -2.5955\n",
      "Total loss:  -1.532 | PDE Loss:  -2.3953 | Function Loss:  -2.596\n",
      "Total loss:  -1.5321 | PDE Loss:  -2.3952 | Function Loss:  -2.5961\n",
      "Total loss:  -1.5322 | PDE Loss:  -2.3943 | Function Loss:  -2.5963\n",
      "Total loss:  -1.5322 | PDE Loss:  -2.3939 | Function Loss:  -2.5965\n",
      "Total loss:  -1.5323 | PDE Loss:  -2.3936 | Function Loss:  -2.5966\n",
      "Total loss:  -1.5324 | PDE Loss:  -2.3931 | Function Loss:  -2.5967\n",
      "Total loss:  -1.5324 | PDE Loss:  -2.3927 | Function Loss:  -2.5969\n",
      "Total loss:  -1.5324 | PDE Loss:  -2.393 | Function Loss:  -2.5968\n",
      "Total loss:  -1.5325 | PDE Loss:  -2.393 | Function Loss:  -2.5969\n",
      "Total loss:  -1.5325 | PDE Loss:  -2.3934 | Function Loss:  -2.5969\n",
      "Total loss:  -1.5325 | PDE Loss:  -2.3941 | Function Loss:  -2.5968\n",
      "Total loss:  -1.5326 | PDE Loss:  -2.3947 | Function Loss:  -2.5968\n",
      "Total loss:  -1.5326 | PDE Loss:  -2.3959 | Function Loss:  -2.5966\n",
      "Total loss:  -1.5327 | PDE Loss:  -2.3971 | Function Loss:  -2.5965\n",
      "Total loss:  -1.5327 | PDE Loss:  -2.3986 | Function Loss:  -2.5963\n",
      "Total loss:  -1.5328 | PDE Loss:  -2.4001 | Function Loss:  -2.5961\n",
      "Total loss:  -1.5328 | PDE Loss:  -2.4013 | Function Loss:  -2.596\n",
      "Total loss:  -1.5329 | PDE Loss:  -2.4018 | Function Loss:  -2.596\n",
      "Total loss:  -1.5329 | PDE Loss:  -2.4022 | Function Loss:  -2.596\n",
      "Total loss:  -1.533 | PDE Loss:  -2.4022 | Function Loss:  -2.596\n",
      "Total loss:  -1.5331 | PDE Loss:  -2.4019 | Function Loss:  -2.5962\n",
      "Total loss:  -1.5331 | PDE Loss:  -2.4012 | Function Loss:  -2.5964\n",
      "Total loss:  -1.5332 | PDE Loss:  -2.4004 | Function Loss:  -2.5966\n",
      "Total loss:  -1.5334 | PDE Loss:  -2.399 | Function Loss:  -2.597\n",
      "Total loss:  -1.5336 | PDE Loss:  -2.3971 | Function Loss:  -2.5976\n",
      "Total loss:  -1.5338 | PDE Loss:  -2.3948 | Function Loss:  -2.5982\n",
      "Total loss:  -1.5341 | PDE Loss:  -2.3923 | Function Loss:  -2.5988\n",
      "Total loss:  -1.5342 | PDE Loss:  -2.3905 | Function Loss:  -2.5993\n",
      "Total loss:  -1.5344 | PDE Loss:  -2.3904 | Function Loss:  -2.5995\n",
      "Total loss:  -1.5346 | PDE Loss:  -2.39 | Function Loss:  -2.5999\n",
      "Total loss:  -1.535 | PDE Loss:  -2.3918 | Function Loss:  -2.6\n",
      "Total loss:  -1.5352 | PDE Loss:  -2.3934 | Function Loss:  -2.6\n",
      "Total loss:  -1.5354 | PDE Loss:  -2.3947 | Function Loss:  -2.6001\n",
      "Total loss:  -1.5356 | PDE Loss:  -2.3941 | Function Loss:  -2.6003\n",
      "Total loss:  -1.5358 | PDE Loss:  -2.3952 | Function Loss:  -2.6004\n",
      "Total loss:  -1.536 | PDE Loss:  -2.3988 | Function Loss:  -2.6001\n",
      "Total loss:  -1.5362 | PDE Loss:  -2.3984 | Function Loss:  -2.6004\n",
      "Total loss:  -1.5364 | PDE Loss:  -2.3978 | Function Loss:  -2.6007\n",
      "Total loss:  -1.5365 | PDE Loss:  -2.3971 | Function Loss:  -2.601\n",
      "Total loss:  -1.5367 | PDE Loss:  -2.3966 | Function Loss:  -2.6012\n",
      "Total loss:  -1.5368 | PDE Loss:  -2.3968 | Function Loss:  -2.6013\n",
      "Total loss:  -1.537 | PDE Loss:  -2.3979 | Function Loss:  -2.6013\n",
      "Total loss:  -1.5371 | PDE Loss:  -2.3994 | Function Loss:  -2.6013\n",
      "Total loss:  -1.5373 | PDE Loss:  -2.4006 | Function Loss:  -2.6013\n",
      "Total loss:  -1.5374 | PDE Loss:  -2.4023 | Function Loss:  -2.6011\n",
      "Total loss:  -1.5376 | PDE Loss:  -2.4042 | Function Loss:  -2.601\n",
      "Total loss:  -1.5377 | PDE Loss:  -2.4055 | Function Loss:  -2.601\n",
      "Total loss:  -1.5378 | PDE Loss:  -2.4055 | Function Loss:  -2.6011\n",
      "Total loss:  -1.5379 | PDE Loss:  -2.4046 | Function Loss:  -2.6014\n",
      "Total loss:  -1.538 | PDE Loss:  -2.4044 | Function Loss:  -2.6015\n",
      "Total loss:  -1.5381 | PDE Loss:  -2.4044 | Function Loss:  -2.6016\n",
      "Total loss:  -1.5382 | PDE Loss:  -2.4046 | Function Loss:  -2.6016\n",
      "Total loss:  -1.5382 | PDE Loss:  -2.4054 | Function Loss:  -2.6016\n",
      "Total loss:  -1.5383 | PDE Loss:  -2.4072 | Function Loss:  -2.6013\n",
      "Total loss:  -1.5383 | PDE Loss:  -2.4065 | Function Loss:  -2.6015\n",
      "Total loss:  -1.5384 | PDE Loss:  -2.4075 | Function Loss:  -2.6014\n",
      "Total loss:  -1.5384 | PDE Loss:  -2.4081 | Function Loss:  -2.6014\n",
      "Total loss:  -1.5385 | PDE Loss:  -2.409 | Function Loss:  -2.6013\n",
      "Total loss:  -1.5385 | PDE Loss:  -2.4097 | Function Loss:  -2.6012\n",
      "Total loss:  -1.5385 | PDE Loss:  -2.4103 | Function Loss:  -2.6012\n",
      "Total loss:  -1.5385 | PDE Loss:  -2.4107 | Function Loss:  -2.6011\n",
      "Total loss:  -1.5386 | PDE Loss:  -2.4109 | Function Loss:  -2.6011\n",
      "Total loss:  -1.5386 | PDE Loss:  -2.4112 | Function Loss:  -2.6011\n",
      "Total loss:  -1.5386 | PDE Loss:  -2.4113 | Function Loss:  -2.6011\n",
      "Total loss:  -1.5386 | PDE Loss:  -2.4114 | Function Loss:  -2.6011\n",
      "Total loss:  -1.5386 | PDE Loss:  -2.4114 | Function Loss:  -2.6011\n",
      "Total loss:  -1.5387 | PDE Loss:  -2.4114 | Function Loss:  -2.6012\n",
      "Total loss:  -1.5387 | PDE Loss:  -2.4115 | Function Loss:  -2.6012\n",
      "Total loss:  -1.5387 | PDE Loss:  -2.4111 | Function Loss:  -2.6013\n",
      "Total loss:  -1.5387 | PDE Loss:  -2.4111 | Function Loss:  -2.6013\n",
      "Total loss:  -1.5388 | PDE Loss:  -2.4106 | Function Loss:  -2.6014\n",
      "Total loss:  -1.5388 | PDE Loss:  -2.4101 | Function Loss:  -2.6015\n",
      "Total loss:  -1.5388 | PDE Loss:  -2.4097 | Function Loss:  -2.6016\n",
      "Total loss:  -1.5389 | PDE Loss:  -2.4091 | Function Loss:  -2.6018\n",
      "Total loss:  -1.5389 | PDE Loss:  -2.4087 | Function Loss:  -2.6018\n",
      "Total loss:  -1.5389 | PDE Loss:  -2.4081 | Function Loss:  -2.602\n",
      "Total loss:  -1.5389 | PDE Loss:  -2.4078 | Function Loss:  -2.602\n",
      "Total loss:  -1.5389 | PDE Loss:  -2.4075 | Function Loss:  -2.6021\n",
      "Total loss:  -1.539 | PDE Loss:  -2.4072 | Function Loss:  -2.6022\n",
      "Total loss:  -1.539 | PDE Loss:  -2.4069 | Function Loss:  -2.6023\n",
      "Total loss:  -1.539 | PDE Loss:  -2.4062 | Function Loss:  -2.6024\n",
      "Total loss:  -1.539 | PDE Loss:  -2.406 | Function Loss:  -2.6025\n",
      "Total loss:  -1.5391 | PDE Loss:  -2.4056 | Function Loss:  -2.6026\n",
      "Total loss:  -1.5391 | PDE Loss:  -2.4051 | Function Loss:  -2.6027\n",
      "Total loss:  -1.5391 | PDE Loss:  -2.4047 | Function Loss:  -2.6028\n",
      "Total loss:  -1.5392 | PDE Loss:  -2.4042 | Function Loss:  -2.6029\n",
      "Total loss:  -1.5392 | PDE Loss:  -2.4038 | Function Loss:  -2.603\n",
      "Total loss:  -1.5392 | PDE Loss:  -2.4034 | Function Loss:  -2.6031\n",
      "Total loss:  -1.5393 | PDE Loss:  -2.4031 | Function Loss:  -2.6032\n",
      "Total loss:  -1.5393 | PDE Loss:  -2.403 | Function Loss:  -2.6032\n",
      "Total loss:  -1.5394 | PDE Loss:  -2.403 | Function Loss:  -2.6033\n",
      "Total loss:  -1.5394 | PDE Loss:  -2.4027 | Function Loss:  -2.6034\n",
      "Total loss:  -1.5395 | PDE Loss:  -2.4029 | Function Loss:  -2.6035\n",
      "Total loss:  -1.5396 | PDE Loss:  -2.4026 | Function Loss:  -2.6036\n",
      "Total loss:  -1.5396 | PDE Loss:  -2.4025 | Function Loss:  -2.6037\n",
      "Total loss:  -1.5397 | PDE Loss:  -2.4022 | Function Loss:  -2.6038\n",
      "Total loss:  -1.5397 | PDE Loss:  -2.4021 | Function Loss:  -2.6038\n",
      "Total loss:  -1.5398 | PDE Loss:  -2.402 | Function Loss:  -2.6039\n",
      "Total loss:  -1.5398 | PDE Loss:  -2.4019 | Function Loss:  -2.604\n",
      "Total loss:  -1.5398 | PDE Loss:  -2.402 | Function Loss:  -2.604\n",
      "Total loss:  -1.5399 | PDE Loss:  -2.4023 | Function Loss:  -2.604\n",
      "Total loss:  -1.5399 | PDE Loss:  -2.4026 | Function Loss:  -2.604\n",
      "Total loss:  -1.54 | PDE Loss:  -2.4034 | Function Loss:  -2.6039\n",
      "Total loss:  -1.54 | PDE Loss:  -2.4044 | Function Loss:  -2.6038\n",
      "Total loss:  -1.54 | PDE Loss:  -2.4052 | Function Loss:  -2.6037\n",
      "Total loss:  -1.54 | PDE Loss:  -2.4062 | Function Loss:  -2.6036\n",
      "Total loss:  -1.5401 | PDE Loss:  -2.4067 | Function Loss:  -2.6035\n",
      "Total loss:  -1.5401 | PDE Loss:  -2.4071 | Function Loss:  -2.6035\n",
      "Total loss:  -1.5401 | PDE Loss:  -2.4073 | Function Loss:  -2.6035\n",
      "Total loss:  -1.5401 | PDE Loss:  -2.4075 | Function Loss:  -2.6035\n",
      "Total loss:  -1.5402 | PDE Loss:  -2.4071 | Function Loss:  -2.6036\n",
      "Total loss:  -1.5402 | PDE Loss:  -2.4066 | Function Loss:  -2.6037\n",
      "Total loss:  -1.5402 | PDE Loss:  -2.4058 | Function Loss:  -2.6039\n",
      "Total loss:  -1.5403 | PDE Loss:  -2.4043 | Function Loss:  -2.6041\n",
      "Total loss:  -1.5403 | PDE Loss:  -2.4031 | Function Loss:  -2.6044\n",
      "Total loss:  -1.5404 | PDE Loss:  -2.4022 | Function Loss:  -2.6046\n",
      "Total loss:  -1.5404 | PDE Loss:  -2.4016 | Function Loss:  -2.6047\n",
      "Total loss:  -1.5405 | PDE Loss:  -2.4016 | Function Loss:  -2.6048\n",
      "Total loss:  -1.5405 | PDE Loss:  -2.4022 | Function Loss:  -2.6048\n",
      "Total loss:  -1.5406 | PDE Loss:  -2.4033 | Function Loss:  -2.6047\n",
      "Total loss:  -1.5406 | PDE Loss:  -2.4045 | Function Loss:  -2.6045\n",
      "Total loss:  -1.5407 | PDE Loss:  -2.4056 | Function Loss:  -2.6044\n",
      "Total loss:  -1.5407 | PDE Loss:  -2.4067 | Function Loss:  -2.6043\n",
      "Total loss:  -1.5408 | PDE Loss:  -2.4074 | Function Loss:  -2.6042\n",
      "Total loss:  -1.5408 | PDE Loss:  -2.4081 | Function Loss:  -2.6042\n",
      "Total loss:  -1.5409 | PDE Loss:  -2.4093 | Function Loss:  -2.6041\n",
      "Total loss:  -1.541 | PDE Loss:  -2.4085 | Function Loss:  -2.6043\n",
      "Total loss:  -1.5411 | PDE Loss:  -2.4083 | Function Loss:  -2.6044\n",
      "Total loss:  -1.5413 | PDE Loss:  -2.405 | Function Loss:  -2.6052\n",
      "Total loss:  -1.5416 | PDE Loss:  -2.401 | Function Loss:  -2.6062\n",
      "Total loss:  -1.5418 | PDE Loss:  -2.3983 | Function Loss:  -2.6068\n",
      "Total loss:  -1.542 | PDE Loss:  -2.3952 | Function Loss:  -2.6076\n",
      "Total loss:  -1.5422 | PDE Loss:  -2.3918 | Function Loss:  -2.6084\n",
      "Total loss:  -1.5425 | PDE Loss:  -2.3899 | Function Loss:  -2.6091\n",
      "Total loss:  -1.5427 | PDE Loss:  -2.3839 | Function Loss:  -2.6103\n",
      "Total loss:  -1.5429 | PDE Loss:  -2.3842 | Function Loss:  -2.6105\n",
      "Total loss:  -1.5432 | PDE Loss:  -2.3843 | Function Loss:  -2.6108\n",
      "Total loss:  -1.5434 | PDE Loss:  -2.3843 | Function Loss:  -2.6111\n",
      "Total loss:  -1.5438 | PDE Loss:  -2.3823 | Function Loss:  -2.6118\n",
      "Total loss:  -1.5441 | PDE Loss:  -2.3825 | Function Loss:  -2.6122\n",
      "Total loss:  -1.5445 | PDE Loss:  -2.3809 | Function Loss:  -2.6129\n",
      "Total loss:  -1.545 | PDE Loss:  -2.3816 | Function Loss:  -2.6134\n",
      "Total loss:  -1.5453 | PDE Loss:  -2.3778 | Function Loss:  -2.6143\n",
      "Total loss:  -1.5457 | PDE Loss:  -2.378 | Function Loss:  -2.6149\n",
      "Total loss:  -1.5462 | PDE Loss:  -2.3799 | Function Loss:  -2.615\n",
      "Total loss:  -1.5465 | PDE Loss:  -2.3794 | Function Loss:  -2.6155\n",
      "Total loss:  -1.5467 | PDE Loss:  -2.38 | Function Loss:  -2.6157\n",
      "Total loss:  -1.5469 | PDE Loss:  -2.3808 | Function Loss:  -2.6158\n",
      "Total loss:  -1.5471 | PDE Loss:  -2.3817 | Function Loss:  -2.6159\n",
      "Total loss:  -1.5474 | PDE Loss:  -2.3823 | Function Loss:  -2.6161\n",
      "Total loss:  -1.5478 | PDE Loss:  -2.3852 | Function Loss:  -2.616\n",
      "Total loss:  -1.5481 | PDE Loss:  -2.385 | Function Loss:  -2.6165\n",
      "Total loss:  -1.5487 | PDE Loss:  -2.3852 | Function Loss:  -2.617\n",
      "Total loss:  -1.5492 | PDE Loss:  -2.3874 | Function Loss:  -2.6173\n",
      "Total loss:  -1.5495 | PDE Loss:  -2.3878 | Function Loss:  -2.6177\n",
      "Total loss:  -1.5499 | PDE Loss:  -2.3874 | Function Loss:  -2.6182\n",
      "Total loss:  -1.5502 | PDE Loss:  -2.3879 | Function Loss:  -2.6184\n",
      "Total loss:  -1.5504 | PDE Loss:  -2.3885 | Function Loss:  -2.6185\n",
      "Total loss:  -1.5506 | PDE Loss:  -2.3903 | Function Loss:  -2.6184\n",
      "Total loss:  -1.5507 | PDE Loss:  -2.3915 | Function Loss:  -2.6184\n",
      "Total loss:  -1.5508 | PDE Loss:  -2.3932 | Function Loss:  -2.6182\n",
      "Total loss:  -1.5509 | PDE Loss:  -2.3937 | Function Loss:  -2.6182\n",
      "Total loss:  -1.5509 | PDE Loss:  -2.394 | Function Loss:  -2.6182\n",
      "Total loss:  -1.551 | PDE Loss:  -2.3942 | Function Loss:  -2.6182\n",
      "Total loss:  -1.551 | PDE Loss:  -2.3946 | Function Loss:  -2.6182\n",
      "Total loss:  -1.5511 | PDE Loss:  -2.3947 | Function Loss:  -2.6183\n",
      "Total loss:  -1.5511 | PDE Loss:  -2.395 | Function Loss:  -2.6183\n",
      "Total loss:  -1.5512 | PDE Loss:  -2.3952 | Function Loss:  -2.6183\n",
      "Total loss:  -1.5512 | PDE Loss:  -2.3954 | Function Loss:  -2.6183\n",
      "Total loss:  -1.5512 | PDE Loss:  -2.3958 | Function Loss:  -2.6183\n",
      "Total loss:  -1.5513 | PDE Loss:  -2.3967 | Function Loss:  -2.6182\n",
      "Total loss:  -1.5505 | PDE Loss:  -2.3954 | Function Loss:  -2.6175\n",
      "Total loss:  -1.5513 | PDE Loss:  -2.3967 | Function Loss:  -2.6182\n",
      "Total loss:  -1.5514 | PDE Loss:  -2.3974 | Function Loss:  -2.6182\n",
      "Total loss:  -1.5515 | PDE Loss:  -2.3986 | Function Loss:  -2.6181\n",
      "Total loss:  -1.5516 | PDE Loss:  -2.3996 | Function Loss:  -2.618\n",
      "Total loss:  -1.5517 | PDE Loss:  -2.4004 | Function Loss:  -2.618\n",
      "Total loss:  -1.5518 | PDE Loss:  -2.4006 | Function Loss:  -2.6181\n",
      "Total loss:  -1.5519 | PDE Loss:  -2.4003 | Function Loss:  -2.6183\n",
      "Total loss:  -1.5521 | PDE Loss:  -2.3994 | Function Loss:  -2.6187\n",
      "Total loss:  -1.5523 | PDE Loss:  -2.3974 | Function Loss:  -2.6193\n",
      "Total loss:  -1.5526 | PDE Loss:  -2.3934 | Function Loss:  -2.6203\n",
      "Total loss:  -1.5529 | PDE Loss:  -2.3903 | Function Loss:  -2.6211\n",
      "Total loss:  -1.5531 | PDE Loss:  -2.3874 | Function Loss:  -2.6219\n",
      "Total loss:  -1.5533 | PDE Loss:  -2.3868 | Function Loss:  -2.6222\n",
      "Total loss:  -1.5535 | PDE Loss:  -2.386 | Function Loss:  -2.6226\n",
      "Total loss:  -1.5536 | PDE Loss:  -2.3873 | Function Loss:  -2.6225\n",
      "Total loss:  -1.5537 | PDE Loss:  -2.3887 | Function Loss:  -2.6224\n",
      "Total loss:  -1.5538 | PDE Loss:  -2.3896 | Function Loss:  -2.6224\n",
      "Total loss:  -1.554 | PDE Loss:  -2.3906 | Function Loss:  -2.6224\n",
      "Total loss:  -1.5542 | PDE Loss:  -2.3902 | Function Loss:  -2.6226\n",
      "Total loss:  -1.5543 | PDE Loss:  -2.3895 | Function Loss:  -2.623\n",
      "Total loss:  -1.5545 | PDE Loss:  -2.3878 | Function Loss:  -2.6234\n",
      "Total loss:  -1.5546 | PDE Loss:  -2.3865 | Function Loss:  -2.6238\n",
      "Total loss:  -1.5547 | PDE Loss:  -2.3854 | Function Loss:  -2.6241\n",
      "Total loss:  -1.5549 | PDE Loss:  -2.3845 | Function Loss:  -2.6244\n",
      "Total loss:  -1.555 | PDE Loss:  -2.3846 | Function Loss:  -2.6246\n",
      "Total loss:  -1.5551 | PDE Loss:  -2.3851 | Function Loss:  -2.6246\n",
      "Total loss:  -1.5552 | PDE Loss:  -2.385 | Function Loss:  -2.6247\n",
      "Total loss:  -1.5552 | PDE Loss:  -2.3858 | Function Loss:  -2.6246\n",
      "Total loss:  -1.5553 | PDE Loss:  -2.3875 | Function Loss:  -2.6244\n",
      "Total loss:  -1.5553 | PDE Loss:  -2.3895 | Function Loss:  -2.6241\n",
      "Total loss:  -1.5554 | PDE Loss:  -2.3915 | Function Loss:  -2.6239\n",
      "Total loss:  -1.5554 | PDE Loss:  -2.3925 | Function Loss:  -2.6237\n",
      "Total loss:  -1.5555 | PDE Loss:  -2.3942 | Function Loss:  -2.6235\n",
      "Total loss:  -1.5556 | PDE Loss:  -2.395 | Function Loss:  -2.6235\n",
      "Total loss:  -1.5556 | PDE Loss:  -2.3954 | Function Loss:  -2.6235\n",
      "Total loss:  -1.5557 | PDE Loss:  -2.3954 | Function Loss:  -2.6235\n",
      "Total loss:  -1.5557 | PDE Loss:  -2.3948 | Function Loss:  -2.6237\n",
      "Total loss:  -1.5558 | PDE Loss:  -2.3945 | Function Loss:  -2.6238\n",
      "Total loss:  -1.5558 | PDE Loss:  -2.394 | Function Loss:  -2.6239\n",
      "Total loss:  -1.5558 | PDE Loss:  -2.394 | Function Loss:  -2.624\n",
      "Total loss:  -1.5559 | PDE Loss:  -2.3941 | Function Loss:  -2.624\n",
      "Total loss:  -1.5559 | PDE Loss:  -2.3941 | Function Loss:  -2.624\n",
      "Total loss:  -1.5559 | PDE Loss:  -2.3942 | Function Loss:  -2.624\n",
      "Total loss:  -1.5559 | PDE Loss:  -2.3947 | Function Loss:  -2.6239\n",
      "Total loss:  -1.556 | PDE Loss:  -2.3951 | Function Loss:  -2.6239\n",
      "Total loss:  -1.556 | PDE Loss:  -2.3955 | Function Loss:  -2.6238\n",
      "Total loss:  -1.556 | PDE Loss:  -2.3958 | Function Loss:  -2.6238\n",
      "Total loss:  -1.556 | PDE Loss:  -2.3957 | Function Loss:  -2.6238\n",
      "Total loss:  -1.556 | PDE Loss:  -2.3967 | Function Loss:  -2.6237\n",
      "Total loss:  -1.556 | PDE Loss:  -2.3966 | Function Loss:  -2.6237\n",
      "Total loss:  -1.556 | PDE Loss:  -2.3966 | Function Loss:  -2.6237\n",
      "Total loss:  -1.556 | PDE Loss:  -2.3967 | Function Loss:  -2.6237\n",
      "Total loss:  -1.5561 | PDE Loss:  -2.3966 | Function Loss:  -2.6238\n",
      "Total loss:  -1.5561 | PDE Loss:  -2.3966 | Function Loss:  -2.6238\n",
      "Total loss:  -1.5561 | PDE Loss:  -2.3967 | Function Loss:  -2.6238\n",
      "Total loss:  -1.5562 | PDE Loss:  -2.397 | Function Loss:  -2.6238\n",
      "Total loss:  -1.5562 | PDE Loss:  -2.3975 | Function Loss:  -2.6238\n",
      "Total loss:  -1.5563 | PDE Loss:  -2.3978 | Function Loss:  -2.6238\n",
      "Total loss:  -1.5563 | PDE Loss:  -2.3985 | Function Loss:  -2.6237\n",
      "Total loss:  -1.5563 | PDE Loss:  -2.399 | Function Loss:  -2.6237\n",
      "Total loss:  -1.5564 | PDE Loss:  -2.3994 | Function Loss:  -2.6236\n",
      "Total loss:  -1.5564 | PDE Loss:  -2.4 | Function Loss:  -2.6236\n",
      "Total loss:  -1.5564 | PDE Loss:  -2.4004 | Function Loss:  -2.6235\n",
      "Total loss:  -1.5564 | PDE Loss:  -2.4001 | Function Loss:  -2.6236\n",
      "Total loss:  -1.5564 | PDE Loss:  -2.4 | Function Loss:  -2.6236\n",
      "Total loss:  -1.5564 | PDE Loss:  -2.4 | Function Loss:  -2.6236\n",
      "Total loss:  -1.5564 | PDE Loss:  -2.4 | Function Loss:  -2.6236\n",
      "Total loss:  -1.5564 | PDE Loss:  -2.4 | Function Loss:  -2.6236\n",
      "Final Loss:  -1.5563839673995972\n",
      "Discharging\n",
      "##############################  Phase 2  ##############################\n",
      "################################  0  ################################\n",
      "Total loss:  1.5651 | PDE Loss:  0.027 | Function Loss:  0.5523\n",
      "Total loss:  1.5423 | PDE Loss:  0.1405 | Function Loss:  0.5247\n",
      "Total loss:  1.3634 | PDE Loss:  0.7903 | Function Loss:  0.2284\n",
      "Total loss:  1.2853 | PDE Loss:  1.2474 | Function Loss:  -0.7927\n",
      "Total loss:  1.1218 | PDE Loss:  1.0471 | Function Loss:  -0.6793\n",
      "Total loss:  0.9603 | PDE Loss:  -0.8993 | Function Loss:  -0.0457\n",
      "Total loss:  0.6631 | PDE Loss:  -2.3516 | Function Loss:  -0.3373\n",
      "Total loss:  1.7543 | PDE Loss:  1.0316 | Function Loss:  0.6631\n",
      "Total loss:  0.288 | PDE Loss:  -0.4766 | Function Loss:  -0.7939\n",
      "Total loss:  0.4986 | PDE Loss:  0.1168 | Function Loss:  -0.7343\n",
      "Total loss:  0.2251 | PDE Loss:  -1.7004 | Function Loss:  -0.7801\n",
      "Total loss:  0.2469 | PDE Loss:  -1.6918 | Function Loss:  -0.7582\n",
      "Total loss:  0.2002 | PDE Loss:  -2.5786 | Function Loss:  -0.8005\n",
      "Total loss:  0.2 | PDE Loss:  -2.6349 | Function Loss:  -0.8006\n",
      "Total loss:  0.1998 | PDE Loss:  -2.6642 | Function Loss:  -0.8008\n",
      "Total loss:  0.1991 | PDE Loss:  -2.6354 | Function Loss:  -0.8016\n",
      "Total loss:  0.1979 | PDE Loss:  -2.4801 | Function Loss:  -0.803\n",
      "Total loss:  0.1961 | PDE Loss:  -2.2719 | Function Loss:  -0.8054\n",
      "Total loss:  0.1938 | PDE Loss:  -2.1062 | Function Loss:  -0.8084\n",
      "Total loss:  0.191 | PDE Loss:  -2.0231 | Function Loss:  -0.8117\n",
      "Total loss:  0.1873 | PDE Loss:  -2.0515 | Function Loss:  -0.8153\n",
      "Total loss:  0.1828 | PDE Loss:  -2.1812 | Function Loss:  -0.8191\n",
      "Total loss:  0.1802 | PDE Loss:  -2.1444 | Function Loss:  -0.8218\n",
      "Total loss:  0.1795 | PDE Loss:  -2.0491 | Function Loss:  -0.823\n",
      "Total loss:  0.1792 | PDE Loss:  -1.9844 | Function Loss:  -0.8237\n",
      "Total loss:  0.179 | PDE Loss:  -1.931 | Function Loss:  -0.8244\n",
      "Total loss:  0.1784 | PDE Loss:  -1.8668 | Function Loss:  -0.8255\n",
      "Total loss:  0.1771 | PDE Loss:  -1.7829 | Function Loss:  -0.8277\n",
      "Total loss:  0.1733 | PDE Loss:  -1.6826 | Function Loss:  -0.8328\n",
      "Total loss:  0.2354 | PDE Loss:  -0.7015 | Function Loss:  -0.8179\n",
      "Total loss:  0.1666 | PDE Loss:  -1.5692 | Function Loss:  -0.8415\n",
      "Total loss:  0.1618 | PDE Loss:  -1.5073 | Function Loss:  -0.8477\n",
      "Total loss:  0.1564 | PDE Loss:  -1.6985 | Function Loss:  -0.8497\n",
      "Total loss:  0.1521 | PDE Loss:  -1.7336 | Function Loss:  -0.8535\n",
      "Total loss:  0.1484 | PDE Loss:  -1.6395 | Function Loss:  -0.8587\n",
      "Total loss:  0.1456 | PDE Loss:  -1.7798 | Function Loss:  -0.8596\n",
      "Total loss:  0.144 | PDE Loss:  -1.8078 | Function Loss:  -0.8609\n",
      "Total loss:  0.1424 | PDE Loss:  -1.8008 | Function Loss:  -0.8625\n",
      "Total loss:  0.1415 | PDE Loss:  -1.7688 | Function Loss:  -0.8639\n",
      "Total loss:  0.1406 | PDE Loss:  -1.7333 | Function Loss:  -0.8652\n",
      "Total loss:  0.1394 | PDE Loss:  -1.684 | Function Loss:  -0.8671\n",
      "Total loss:  0.1369 | PDE Loss:  -1.6168 | Function Loss:  -0.8708\n",
      "Total loss:  0.1334 | PDE Loss:  -1.546 | Function Loss:  -0.8757\n",
      "Total loss:  0.1322 | PDE Loss:  -1.5554 | Function Loss:  -0.8768\n",
      "Total loss:  0.1318 | PDE Loss:  -1.5438 | Function Loss:  -0.8775\n",
      "Total loss:  0.1311 | PDE Loss:  -1.5413 | Function Loss:  -0.8782\n",
      "Total loss:  0.1299 | PDE Loss:  -1.5717 | Function Loss:  -0.8788\n",
      "Total loss:  0.1289 | PDE Loss:  -1.6295 | Function Loss:  -0.8787\n",
      "Total loss:  0.128 | PDE Loss:  -1.7149 | Function Loss:  -0.8783\n",
      "Total loss:  0.1267 | PDE Loss:  -1.8165 | Function Loss:  -0.8783\n",
      "Total loss:  0.1252 | PDE Loss:  -1.9549 | Function Loss:  -0.8785\n",
      "Total loss:  0.124 | PDE Loss:  -2.0511 | Function Loss:  -0.8789\n",
      "Total loss:  0.123 | PDE Loss:  -2.1338 | Function Loss:  -0.8794\n",
      "Total loss:  0.1223 | PDE Loss:  -2.1929 | Function Loss:  -0.8798\n",
      "Total loss:  0.1218 | PDE Loss:  -2.1953 | Function Loss:  -0.8803\n",
      "Total loss:  0.1214 | PDE Loss:  -2.2187 | Function Loss:  -0.8806\n",
      "Total loss:  0.1211 | PDE Loss:  -2.1762 | Function Loss:  -0.8811\n",
      "Total loss:  0.1209 | PDE Loss:  -2.1639 | Function Loss:  -0.8814\n",
      "Total loss:  0.1207 | PDE Loss:  -2.1586 | Function Loss:  -0.8816\n",
      "Total loss:  0.1205 | PDE Loss:  -2.1617 | Function Loss:  -0.8818\n",
      "Total loss:  0.1202 | PDE Loss:  -2.1725 | Function Loss:  -0.882\n",
      "Total loss:  0.1198 | PDE Loss:  -2.1902 | Function Loss:  -0.8823\n",
      "Total loss:  0.1192 | PDE Loss:  -2.186 | Function Loss:  -0.883\n",
      "Total loss:  0.1185 | PDE Loss:  -2.169 | Function Loss:  -0.8837\n",
      "Total loss:  0.1219 | PDE Loss:  -2.0695 | Function Loss:  -0.8809\n",
      "Total loss:  0.118 | PDE Loss:  -2.186 | Function Loss:  -0.8842\n",
      "Total loss:  0.1175 | PDE Loss:  -2.2001 | Function Loss:  -0.8846\n",
      "Total loss:  0.1165 | PDE Loss:  -2.0607 | Function Loss:  -0.8864\n",
      "Total loss:  0.1158 | PDE Loss:  -2.0937 | Function Loss:  -0.8869\n",
      "Total loss:  0.1167 | PDE Loss:  -2.2567 | Function Loss:  -0.8851\n",
      "Total loss:  0.1152 | PDE Loss:  -2.182 | Function Loss:  -0.887\n",
      "Total loss:  0.1147 | PDE Loss:  -2.1734 | Function Loss:  -0.8875\n",
      "Total loss:  0.1137 | PDE Loss:  -2.1467 | Function Loss:  -0.8887\n",
      "Total loss:  0.1129 | PDE Loss:  -2.204 | Function Loss:  -0.8892\n",
      "Total loss:  0.1122 | PDE Loss:  -2.2119 | Function Loss:  -0.8899\n",
      "Total loss:  0.1118 | PDE Loss:  -2.2871 | Function Loss:  -0.8899\n",
      "Total loss:  0.1117 | PDE Loss:  -2.3119 | Function Loss:  -0.89\n",
      "Total loss:  0.1116 | PDE Loss:  -2.31 | Function Loss:  -0.8901\n",
      "Total loss:  0.1115 | PDE Loss:  -2.3313 | Function Loss:  -0.8901\n",
      "Total loss:  0.1114 | PDE Loss:  -2.3236 | Function Loss:  -0.8902\n",
      "Total loss:  0.1113 | PDE Loss:  -2.3182 | Function Loss:  -0.8903\n",
      "Total loss:  0.1109 | PDE Loss:  -2.2988 | Function Loss:  -0.8908\n",
      "Total loss:  0.1104 | PDE Loss:  -2.2567 | Function Loss:  -0.8915\n",
      "Total loss:  0.11 | PDE Loss:  -2.2094 | Function Loss:  -0.8921\n",
      "Total loss:  0.1094 | PDE Loss:  -2.1401 | Function Loss:  -0.8931\n",
      "Total loss:  0.1082 | PDE Loss:  -1.9972 | Function Loss:  -0.8952\n",
      "Total loss:  0.1073 | PDE Loss:  -1.8761 | Function Loss:  -0.8972\n",
      "Total loss:  0.1061 | PDE Loss:  -1.744 | Function Loss:  -0.9001\n",
      "Total loss:  0.1046 | PDE Loss:  -1.5835 | Function Loss:  -0.9044\n",
      "Total loss:  0.1051 | PDE Loss:  -1.4764 | Function Loss:  -0.9065\n",
      "Total loss:  0.1039 | PDE Loss:  -1.5347 | Function Loss:  -0.9062\n",
      "Total loss:  0.103 | PDE Loss:  -1.5281 | Function Loss:  -0.9073\n",
      "Total loss:  0.1019 | PDE Loss:  -1.4948 | Function Loss:  -0.9092\n",
      "Total loss:  0.1012 | PDE Loss:  -1.4903 | Function Loss:  -0.9101\n",
      "Total loss:  0.1002 | PDE Loss:  -1.4693 | Function Loss:  -0.9117\n",
      "Total loss:  0.0988 | PDE Loss:  -1.4591 | Function Loss:  -0.9134\n",
      "Total loss:  0.0978 | PDE Loss:  -1.4271 | Function Loss:  -0.9153\n",
      "Total loss:  0.0969 | PDE Loss:  -1.369 | Function Loss:  -0.9182\n",
      "Total loss:  0.096 | PDE Loss:  -1.3104 | Function Loss:  -0.9213\n",
      "Total loss:  0.0948 | PDE Loss:  -1.2377 | Function Loss:  -0.9258\n",
      "Total loss:  0.0928 | PDE Loss:  -1.1139 | Function Loss:  -0.935\n",
      "Total loss:  0.0909 | PDE Loss:  -1.0196 | Function Loss:  -0.9441\n",
      "Total loss:  0.0929 | PDE Loss:  -0.935 | Function Loss:  -0.9499\n",
      "Total loss:  0.0888 | PDE Loss:  -0.9768 | Function Loss:  -0.9502\n",
      "Total loss:  0.083 | PDE Loss:  -1.0099 | Function Loss:  -0.9536\n",
      "Total loss:  0.0857 | PDE Loss:  -1.1031 | Function Loss:  -0.9433\n",
      "Total loss:  0.0811 | PDE Loss:  -1.0627 | Function Loss:  -0.9513\n",
      "Total loss:  0.0804 | PDE Loss:  -1.0691 | Function Loss:  -0.9516\n",
      "Total loss:  0.08 | PDE Loss:  -1.0675 | Function Loss:  -0.9521\n",
      "Total loss:  0.079 | PDE Loss:  -1.0787 | Function Loss:  -0.9523\n",
      "Total loss:  0.0782 | PDE Loss:  -1.0635 | Function Loss:  -0.9543\n",
      "Total loss:  0.0774 | PDE Loss:  -1.036 | Function Loss:  -0.9574\n",
      "Total loss:  0.0767 | PDE Loss:  -1.0169 | Function Loss:  -0.9598\n",
      "Total loss:  0.0759 | PDE Loss:  -0.986 | Function Loss:  -0.9635\n",
      "Total loss:  0.0743 | PDE Loss:  -0.9652 | Function Loss:  -0.9673\n",
      "Total loss:  0.0713 | PDE Loss:  -0.9257 | Function Loss:  -0.9748\n",
      "Total loss:  0.0695 | PDE Loss:  -0.9956 | Function Loss:  -0.9696\n",
      "Total loss:  0.0685 | PDE Loss:  -0.9721 | Function Loss:  -0.9729\n",
      "Total loss:  0.0651 | PDE Loss:  -1.0377 | Function Loss:  -0.9706\n",
      "Total loss:  0.0616 | PDE Loss:  -1.1301 | Function Loss:  -0.9673\n",
      "Total loss:  0.0591 | PDE Loss:  -1.0823 | Function Loss:  -0.9734\n",
      "Total loss:  0.0586 | PDE Loss:  -1.0816 | Function Loss:  -0.9741\n",
      "Total loss:  0.0576 | PDE Loss:  -1.0708 | Function Loss:  -0.976\n",
      "Total loss:  0.0567 | PDE Loss:  -1.0454 | Function Loss:  -0.979\n",
      "Total loss:  0.0555 | PDE Loss:  -1.0194 | Function Loss:  -0.9826\n",
      "Total loss:  0.0539 | PDE Loss:  -0.9851 | Function Loss:  -0.9877\n",
      "Total loss:  0.0522 | PDE Loss:  -0.9703 | Function Loss:  -0.9911\n",
      "Total loss:  0.0503 | PDE Loss:  -0.9666 | Function Loss:  -0.9936\n",
      "Total loss:  0.0461 | PDE Loss:  -0.9621 | Function Loss:  -0.9988\n",
      "Total loss:  0.0372 | PDE Loss:  -1.0126 | Function Loss:  -1.0033\n",
      "Total loss:  0.0316 | PDE Loss:  -1.0299 | Function Loss:  -1.0078\n",
      "Total loss:  0.0316 | PDE Loss:  -1.0307 | Function Loss:  -1.0078\n",
      "Total loss:  0.0298 | PDE Loss:  -1.0432 | Function Loss:  -1.0085\n",
      "Total loss:  0.0267 | PDE Loss:  -1.0527 | Function Loss:  -1.0111\n",
      "Total loss:  0.0249 | PDE Loss:  -1.0492 | Function Loss:  -1.0134\n",
      "Total loss:  0.0235 | PDE Loss:  -1.032 | Function Loss:  -1.0165\n",
      "Total loss:  0.0229 | PDE Loss:  -1.0252 | Function Loss:  -1.0178\n",
      "Total loss:  0.0226 | PDE Loss:  -1.0242 | Function Loss:  -1.0183\n",
      "Total loss:  0.0221 | PDE Loss:  -1.0149 | Function Loss:  -1.0197\n",
      "Total loss:  0.0214 | PDE Loss:  -1.0011 | Function Loss:  -1.022\n",
      "Total loss:  0.0208 | PDE Loss:  -0.9862 | Function Loss:  -1.0242\n",
      "Total loss:  0.0201 | PDE Loss:  -0.9685 | Function Loss:  -1.027\n",
      "Total loss:  0.019 | PDE Loss:  -0.9392 | Function Loss:  -1.0316\n",
      "Total loss:  0.0179 | PDE Loss:  -0.8934 | Function Loss:  -1.039\n",
      "Total loss:  0.0171 | PDE Loss:  -0.8439 | Function Loss:  -1.0472\n",
      "Total loss:  0.0168 | PDE Loss:  -0.8504 | Function Loss:  -1.0466\n",
      "Total loss:  0.0167 | PDE Loss:  -0.8489 | Function Loss:  -1.0469\n",
      "Total loss:  0.0167 | PDE Loss:  -0.8496 | Function Loss:  -1.0469\n",
      "Total loss:  0.0165 | PDE Loss:  -0.8528 | Function Loss:  -1.0465\n",
      "Total loss:  0.0164 | PDE Loss:  -0.8572 | Function Loss:  -1.046\n",
      "Total loss:  0.0163 | PDE Loss:  -0.8602 | Function Loss:  -1.0456\n",
      "Total loss:  0.0161 | PDE Loss:  -0.8632 | Function Loss:  -1.0454\n",
      "Total loss:  0.0159 | PDE Loss:  -0.8645 | Function Loss:  -1.0454\n",
      "Total loss:  0.0157 | PDE Loss:  -0.8659 | Function Loss:  -1.0455\n",
      "Total loss:  0.0152 | PDE Loss:  -0.8663 | Function Loss:  -1.0459\n",
      "Total loss:  0.0146 | PDE Loss:  -0.8682 | Function Loss:  -1.0464\n",
      "Total loss:  0.0135 | PDE Loss:  -0.8732 | Function Loss:  -1.0469\n",
      "Total loss:  0.0119 | PDE Loss:  -0.886 | Function Loss:  -1.0468\n",
      "Total loss:  0.0106 | PDE Loss:  -0.9157 | Function Loss:  -1.0441\n",
      "Total loss:  0.009 | PDE Loss:  -0.9291 | Function Loss:  -1.0442\n",
      "Total loss:  0.0074 | PDE Loss:  -0.9264 | Function Loss:  -1.0464\n",
      "Total loss:  0.0049 | PDE Loss:  -0.9155 | Function Loss:  -1.0507\n",
      "Total loss:  0.0136 | PDE Loss:  -0.9287 | Function Loss:  -1.0391\n",
      "Total loss:  0.0026 | PDE Loss:  -0.9434 | Function Loss:  -1.0496\n",
      "Total loss:  0.0018 | PDE Loss:  -0.9598 | Function Loss:  -1.0485\n",
      "Total loss:  0.0005 | PDE Loss:  -0.9269 | Function Loss:  -1.0541\n",
      "Total loss:  -0.0002 | PDE Loss:  -0.9305 | Function Loss:  -1.0545\n",
      "Total loss:  -0.0008 | PDE Loss:  -0.9196 | Function Loss:  -1.0566\n",
      "Total loss:  -0.0019 | PDE Loss:  -0.9092 | Function Loss:  -1.0593\n",
      "Total loss:  -0.003 | PDE Loss:  -0.895 | Function Loss:  -1.0626\n",
      "Total loss:  -0.0046 | PDE Loss:  -0.8753 | Function Loss:  -1.0674\n",
      "Total loss:  -0.0048 | PDE Loss:  -0.8645 | Function Loss:  -1.0694\n",
      "Total loss:  -0.0058 | PDE Loss:  -0.8677 | Function Loss:  -1.07\n",
      "Total loss:  -0.0074 | PDE Loss:  -0.8407 | Function Loss:  -1.0764\n",
      "Total loss:  -0.0094 | PDE Loss:  -0.8276 | Function Loss:  -1.081\n",
      "Total loss:  -0.0107 | PDE Loss:  -0.7841 | Function Loss:  -1.0908\n",
      "Total loss:  -0.0123 | PDE Loss:  -0.7355 | Function Loss:  -1.1033\n",
      "Total loss:  -0.0129 | PDE Loss:  -0.7517 | Function Loss:  -1.1004\n",
      "Total loss:  -0.0134 | PDE Loss:  -0.7541 | Function Loss:  -1.1004\n",
      "Total loss:  -0.0142 | PDE Loss:  -0.7644 | Function Loss:  -1.0992\n",
      "Total loss:  -0.0152 | PDE Loss:  -0.7502 | Function Loss:  -1.1035\n",
      "Total loss:  -0.0158 | PDE Loss:  -0.7487 | Function Loss:  -1.1046\n",
      "Total loss:  -0.0168 | PDE Loss:  -0.7625 | Function Loss:  -1.1028\n",
      "Total loss:  -0.0176 | PDE Loss:  -0.7747 | Function Loss:  -1.1011\n",
      "Total loss:  -0.0184 | PDE Loss:  -0.7817 | Function Loss:  -1.1006\n",
      "Total loss:  -0.0195 | PDE Loss:  -0.8075 | Function Loss:  -1.0967\n",
      "Total loss:  -0.0204 | PDE Loss:  -0.8125 | Function Loss:  -1.0969\n",
      "Total loss:  -0.0212 | PDE Loss:  -0.8272 | Function Loss:  -1.0951\n",
      "Total loss:  -0.0227 | PDE Loss:  -0.8566 | Function Loss:  -1.0916\n",
      "Total loss:  -0.0233 | PDE Loss:  -0.8612 | Function Loss:  -1.0915\n",
      "Total loss:  -0.0241 | PDE Loss:  -0.8648 | Function Loss:  -1.0917\n",
      "Total loss:  -0.0253 | PDE Loss:  -0.87 | Function Loss:  -1.0923\n",
      "Total loss:  -0.0264 | PDE Loss:  -0.8622 | Function Loss:  -1.095\n",
      "Total loss:  -0.028 | PDE Loss:  -0.8618 | Function Loss:  -1.0968\n",
      "Total loss:  -0.029 | PDE Loss:  -0.8618 | Function Loss:  -1.098\n",
      "Total loss:  -0.0302 | PDE Loss:  -0.8604 | Function Loss:  -1.0997\n",
      "Total loss:  -0.0312 | PDE Loss:  -0.8626 | Function Loss:  -1.1004\n",
      "Total loss:  -0.0322 | PDE Loss:  -0.8608 | Function Loss:  -1.1019\n",
      "Total loss:  -0.0328 | PDE Loss:  -0.861 | Function Loss:  -1.1027\n",
      "Total loss:  -0.0349 | PDE Loss:  -0.8597 | Function Loss:  -1.1053\n",
      "Total loss:  -0.0384 | PDE Loss:  -0.8443 | Function Loss:  -1.1123\n",
      "Total loss:  -0.0431 | PDE Loss:  -0.8446 | Function Loss:  -1.1177\n",
      "Total loss:  -0.0476 | PDE Loss:  -0.8181 | Function Loss:  -1.1283\n",
      "Total loss:  -0.0525 | PDE Loss:  -0.8196 | Function Loss:  -1.1339\n",
      "Total loss:  -0.0587 | PDE Loss:  -0.817 | Function Loss:  -1.142\n",
      "Total loss:  -0.0665 | PDE Loss:  -0.7799 | Function Loss:  -1.1599\n",
      "Total loss:  -0.0267 | PDE Loss:  -0.7418 | Function Loss:  -1.1197\n",
      "Total loss:  -0.0679 | PDE Loss:  -0.7921 | Function Loss:  -1.1587\n",
      "Total loss:  -0.0717 | PDE Loss:  -0.7802 | Function Loss:  -1.1663\n",
      "Total loss:  -0.0765 | PDE Loss:  -0.789 | Function Loss:  -1.1701\n",
      "Total loss:  -0.0825 | PDE Loss:  -0.8093 | Function Loss:  -1.1728\n",
      "Total loss:  -0.0902 | PDE Loss:  -0.7921 | Function Loss:  -1.1863\n",
      "Total loss:  -0.0979 | PDE Loss:  -0.834 | Function Loss:  -1.186\n",
      "Total loss:  -0.0919 | PDE Loss:  -0.7853 | Function Loss:  -1.1902\n",
      "Total loss:  -0.1023 | PDE Loss:  -0.8257 | Function Loss:  -1.1934\n",
      "Total loss:  -0.1079 | PDE Loss:  -0.839 | Function Loss:  -1.1971\n",
      "Total loss:  -0.1115 | PDE Loss:  -0.8344 | Function Loss:  -1.2026\n",
      "Total loss:  -0.1128 | PDE Loss:  -0.8209 | Function Loss:  -1.2075\n",
      "Total loss:  -0.1138 | PDE Loss:  -0.821 | Function Loss:  -1.2086\n",
      "Total loss:  -0.1141 | PDE Loss:  -0.824 | Function Loss:  -1.2083\n",
      "Total loss:  -0.1147 | PDE Loss:  -0.819 | Function Loss:  -1.2103\n",
      "Total loss:  -0.1151 | PDE Loss:  -0.8157 | Function Loss:  -1.2115\n",
      "Total loss:  -0.1154 | PDE Loss:  -0.8153 | Function Loss:  -1.212\n",
      "Total loss:  -0.1158 | PDE Loss:  -0.8142 | Function Loss:  -1.2128\n",
      "Total loss:  -0.1163 | PDE Loss:  -0.8102 | Function Loss:  -1.2145\n",
      "Total loss:  -0.1169 | PDE Loss:  -0.8089 | Function Loss:  -1.2156\n",
      "Total loss:  -0.1177 | PDE Loss:  -0.8058 | Function Loss:  -1.2174\n",
      "Total loss:  -0.1189 | PDE Loss:  -0.8047 | Function Loss:  -1.2191\n",
      "Total loss:  -0.1208 | PDE Loss:  -0.8065 | Function Loss:  -1.221\n",
      "Total loss:  -0.1241 | PDE Loss:  -0.8138 | Function Loss:  -1.2233\n",
      "Total loss:  -0.1282 | PDE Loss:  -0.8287 | Function Loss:  -1.2247\n",
      "Total loss:  -0.1123 | PDE Loss:  -0.8512 | Function Loss:  -1.1998\n",
      "Total loss:  -0.1307 | PDE Loss:  -0.8431 | Function Loss:  -1.2243\n",
      "Total loss:  -0.1355 | PDE Loss:  -0.8581 | Function Loss:  -1.2267\n",
      "Total loss:  -0.1416 | PDE Loss:  -0.8738 | Function Loss:  -1.2306\n",
      "Total loss:  -0.1499 | PDE Loss:  -0.911 | Function Loss:  -1.2325\n",
      "Total loss:  -0.1578 | PDE Loss:  -0.9549 | Function Loss:  -1.2333\n",
      "Total loss:  -0.1622 | PDE Loss:  -0.9973 | Function Loss:  -1.2309\n",
      "Total loss:  -0.1677 | PDE Loss:  -1.0505 | Function Loss:  -1.2287\n",
      "Total loss:  -0.1707 | PDE Loss:  -1.0513 | Function Loss:  -1.232\n",
      "Total loss:  -0.1733 | PDE Loss:  -1.0713 | Function Loss:  -1.2321\n",
      "Total loss:  -0.1739 | PDE Loss:  -1.078 | Function Loss:  -1.2317\n",
      "Total loss:  -0.1747 | PDE Loss:  -1.0765 | Function Loss:  -1.2328\n",
      "Total loss:  -0.1764 | PDE Loss:  -1.0687 | Function Loss:  -1.2359\n",
      "Total loss:  -0.1787 | PDE Loss:  -1.0665 | Function Loss:  -1.2389\n",
      "Total loss:  -0.1812 | PDE Loss:  -1.0612 | Function Loss:  -1.2425\n",
      "Total loss:  -0.1835 | PDE Loss:  -1.0615 | Function Loss:  -1.2451\n",
      "Total loss:  -0.186 | PDE Loss:  -1.0598 | Function Loss:  -1.2483\n",
      "Total loss:  -0.1857 | PDE Loss:  -1.0594 | Function Loss:  -1.2481\n",
      "Total loss:  -0.1875 | PDE Loss:  -1.0617 | Function Loss:  -1.2498\n",
      "Total loss:  -0.1919 | PDE Loss:  -1.0596 | Function Loss:  -1.2552\n",
      "Total loss:  -0.1944 | PDE Loss:  -1.0564 | Function Loss:  -1.2586\n",
      "Total loss:  -0.1971 | PDE Loss:  -1.0357 | Function Loss:  -1.2651\n",
      "Total loss:  -0.1975 | PDE Loss:  -1.0318 | Function Loss:  -1.2663\n",
      "Total loss:  -0.1964 | PDE Loss:  -1.0165 | Function Loss:  -1.2676\n",
      "Total loss:  -0.1987 | PDE Loss:  -1.0315 | Function Loss:  -1.2677\n",
      "Total loss:  -0.1994 | PDE Loss:  -1.0246 | Function Loss:  -1.2697\n",
      "Total loss:  -0.1999 | PDE Loss:  -1.0224 | Function Loss:  -1.2708\n",
      "Total loss:  -0.201 | PDE Loss:  -1.0139 | Function Loss:  -1.2735\n",
      "Total loss:  -0.2025 | PDE Loss:  -1.0091 | Function Loss:  -1.2762\n",
      "Total loss:  -0.2046 | PDE Loss:  -1.0004 | Function Loss:  -1.2803\n",
      "Total loss:  -0.2071 | PDE Loss:  -0.99 | Function Loss:  -1.2853\n",
      "Total loss:  -0.2105 | PDE Loss:  -0.9552 | Function Loss:  -1.2967\n",
      "Total loss:  -0.2131 | PDE Loss:  -0.9455 | Function Loss:  -1.302\n",
      "Total loss:  -0.2158 | PDE Loss:  -0.9464 | Function Loss:  -1.3051\n",
      "Total loss:  -0.2178 | PDE Loss:  -0.9409 | Function Loss:  -1.3088\n",
      "Total loss:  -0.219 | PDE Loss:  -0.9349 | Function Loss:  -1.3117\n",
      "Total loss:  -0.2203 | PDE Loss:  -0.9179 | Function Loss:  -1.3175\n",
      "Total loss:  -0.2214 | PDE Loss:  -0.9034 | Function Loss:  -1.3227\n",
      "Total loss:  -0.2236 | PDE Loss:  -0.8779 | Function Loss:  -1.3324\n",
      "Total loss:  -0.2249 | PDE Loss:  -0.8571 | Function Loss:  -1.3402\n",
      "Total loss:  -0.2258 | PDE Loss:  -0.8409 | Function Loss:  -1.3465\n",
      "Total loss:  -0.2265 | PDE Loss:  -0.8182 | Function Loss:  -1.3549\n",
      "Total loss:  -0.2271 | PDE Loss:  -0.8108 | Function Loss:  -1.3583\n",
      "Total loss:  -0.2281 | PDE Loss:  -0.7972 | Function Loss:  -1.3646\n",
      "Total loss:  -0.2293 | PDE Loss:  -0.7809 | Function Loss:  -1.3724\n",
      "Total loss:  -0.2309 | PDE Loss:  -0.7646 | Function Loss:  -1.3812\n",
      "Total loss:  -0.2322 | PDE Loss:  -0.745 | Function Loss:  -1.3915\n",
      "Total loss:  -0.2337 | PDE Loss:  -0.7364 | Function Loss:  -1.3976\n",
      "Total loss:  -0.2356 | PDE Loss:  -0.7299 | Function Loss:  -1.4033\n",
      "Total loss:  -0.2385 | PDE Loss:  -0.728 | Function Loss:  -1.4086\n",
      "Total loss:  -0.243 | PDE Loss:  -0.7353 | Function Loss:  -1.4117\n",
      "Total loss:  -0.2475 | PDE Loss:  -0.751 | Function Loss:  -1.411\n",
      "Total loss:  -0.2497 | PDE Loss:  -0.771 | Function Loss:  -1.4053\n",
      "Total loss:  -0.2537 | PDE Loss:  -0.7935 | Function Loss:  -1.4016\n",
      "Total loss:  -0.2558 | PDE Loss:  -0.8041 | Function Loss:  -1.4003\n",
      "Total loss:  -0.2598 | PDE Loss:  -0.8231 | Function Loss:  -1.3985\n",
      "Total loss:  -0.2642 | PDE Loss:  -0.8434 | Function Loss:  -1.397\n",
      "Total loss:  -0.2671 | PDE Loss:  -0.8568 | Function Loss:  -1.3962\n",
      "Total loss:  -0.2707 | PDE Loss:  -0.8693 | Function Loss:  -1.3968\n",
      "Total loss:  -0.2762 | PDE Loss:  -0.8817 | Function Loss:  -1.4\n",
      "Total loss:  -0.2814 | PDE Loss:  -0.8868 | Function Loss:  -1.4052\n",
      "Total loss:  -0.2844 | PDE Loss:  -0.8831 | Function Loss:  -1.4104\n",
      "Total loss:  -0.2864 | PDE Loss:  -0.873 | Function Loss:  -1.4167\n",
      "Total loss:  -0.2881 | PDE Loss:  -0.8658 | Function Loss:  -1.4215\n",
      "Total loss:  -0.2897 | PDE Loss:  -0.857 | Function Loss:  -1.4268\n",
      "Total loss:  -0.2915 | PDE Loss:  -0.848 | Function Loss:  -1.4327\n",
      "Total loss:  -0.2925 | PDE Loss:  -0.8391 | Function Loss:  -1.4376\n",
      "Total loss:  -0.2932 | PDE Loss:  -0.8329 | Function Loss:  -1.441\n",
      "Total loss:  -0.2936 | PDE Loss:  -0.8302 | Function Loss:  -1.4427\n",
      "Total loss:  -0.2942 | PDE Loss:  -0.8269 | Function Loss:  -1.445\n",
      "Total loss:  -0.2948 | PDE Loss:  -0.8237 | Function Loss:  -1.4472\n",
      "Total loss:  -0.2954 | PDE Loss:  -0.8204 | Function Loss:  -1.4494\n",
      "Total loss:  -0.2959 | PDE Loss:  -0.8167 | Function Loss:  -1.4517\n",
      "Total loss:  -0.2964 | PDE Loss:  -0.8129 | Function Loss:  -1.4541\n",
      "Total loss:  -0.2973 | PDE Loss:  -0.8073 | Function Loss:  -1.4578\n",
      "Total loss:  -0.2984 | PDE Loss:  -0.8 | Function Loss:  -1.4627\n",
      "Total loss:  -0.2995 | PDE Loss:  -0.7927 | Function Loss:  -1.4677\n",
      "Total loss:  -0.3006 | PDE Loss:  -0.7864 | Function Loss:  -1.4725\n",
      "Total loss:  -0.3019 | PDE Loss:  -0.78 | Function Loss:  -1.4774\n",
      "Total loss:  -0.3038 | PDE Loss:  -0.7726 | Function Loss:  -1.4841\n",
      "Total loss:  -0.307 | PDE Loss:  -0.7616 | Function Loss:  -1.4948\n",
      "Total loss:  -0.3118 | PDE Loss:  -0.7501 | Function Loss:  -1.5086\n",
      "Total loss:  -0.3185 | PDE Loss:  -0.7401 | Function Loss:  -1.5252\n",
      "Total loss:  -0.3206 | PDE Loss:  -0.7309 | Function Loss:  -1.5344\n",
      "Total loss:  -0.3233 | PDE Loss:  -0.7362 | Function Loss:  -1.5355\n",
      "Total loss:  -0.3287 | PDE Loss:  -0.7504 | Function Loss:  -1.5354\n",
      "Total loss:  -0.3327 | PDE Loss:  -0.7482 | Function Loss:  -1.5433\n",
      "Total loss:  -0.3393 | PDE Loss:  -0.7528 | Function Loss:  -1.5511\n",
      "Total loss:  -0.3429 | PDE Loss:  -0.7659 | Function Loss:  -1.5489\n",
      "Total loss:  -0.3451 | PDE Loss:  -0.7731 | Function Loss:  -1.548\n",
      "Total loss:  -0.3472 | PDE Loss:  -0.7789 | Function Loss:  -1.548\n",
      "Total loss:  -0.3498 | PDE Loss:  -0.7859 | Function Loss:  -1.5479\n",
      "Total loss:  -0.3542 | PDE Loss:  -0.7937 | Function Loss:  -1.5504\n",
      "Total loss:  -0.358 | PDE Loss:  -0.8103 | Function Loss:  -1.5471\n",
      "Total loss:  -0.3623 | PDE Loss:  -0.8126 | Function Loss:  -1.5525\n",
      "Total loss:  -0.3666 | PDE Loss:  -0.8333 | Function Loss:  -1.5479\n",
      "Total loss:  -0.3631 | PDE Loss:  -0.8517 | Function Loss:  -1.5335\n",
      "Total loss:  -0.3696 | PDE Loss:  -0.8465 | Function Loss:  -1.5458\n",
      "Total loss:  -0.3705 | PDE Loss:  -0.8384 | Function Loss:  -1.5513\n",
      "Total loss:  -0.3739 | PDE Loss:  -0.8443 | Function Loss:  -1.5534\n",
      "Total loss:  -0.3762 | PDE Loss:  -0.8552 | Function Loss:  -1.5514\n",
      "Total loss:  -0.3785 | PDE Loss:  -0.8635 | Function Loss:  -1.5507\n",
      "Total loss:  -0.3801 | PDE Loss:  -0.8698 | Function Loss:  -1.55\n",
      "Total loss:  -0.3813 | PDE Loss:  -0.8691 | Function Loss:  -1.5521\n",
      "Total loss:  -0.382 | PDE Loss:  -0.8711 | Function Loss:  -1.5521\n",
      "Total loss:  -0.3825 | PDE Loss:  -0.8667 | Function Loss:  -1.5552\n",
      "Total loss:  -0.3829 | PDE Loss:  -0.8625 | Function Loss:  -1.5578\n",
      "Total loss:  -0.3836 | PDE Loss:  -0.8578 | Function Loss:  -1.5611\n",
      "Total loss:  -0.3842 | PDE Loss:  -0.8537 | Function Loss:  -1.5641\n",
      "Total loss:  -0.385 | PDE Loss:  -0.8506 | Function Loss:  -1.567\n",
      "Total loss:  -0.386 | PDE Loss:  -0.8505 | Function Loss:  -1.5685\n",
      "Total loss:  -0.3871 | PDE Loss:  -0.8509 | Function Loss:  -1.5701\n",
      "Total loss:  -0.3884 | PDE Loss:  -0.8595 | Function Loss:  -1.5675\n",
      "Total loss:  -0.3898 | PDE Loss:  -0.8687 | Function Loss:  -1.565\n",
      "Total loss:  -0.3908 | PDE Loss:  -0.8781 | Function Loss:  -1.5619\n",
      "Total loss:  -0.3916 | PDE Loss:  -0.8868 | Function Loss:  -1.5589\n",
      "Total loss:  -0.3923 | PDE Loss:  -0.8929 | Function Loss:  -1.557\n",
      "Total loss:  -0.393 | PDE Loss:  -0.8976 | Function Loss:  -1.556\n",
      "Total loss:  -0.3939 | PDE Loss:  -0.9021 | Function Loss:  -1.5553\n",
      "Total loss:  -0.3952 | PDE Loss:  -0.903 | Function Loss:  -1.5567\n",
      "Total loss:  -0.3968 | PDE Loss:  -0.9088 | Function Loss:  -1.5565\n",
      "Total loss:  -0.3985 | PDE Loss:  -0.9063 | Function Loss:  -1.56\n",
      "Total loss:  -0.4004 | PDE Loss:  -0.9052 | Function Loss:  -1.5633\n",
      "Total loss:  -0.4025 | PDE Loss:  -0.8997 | Function Loss:  -1.5689\n",
      "Total loss:  -0.404 | PDE Loss:  -0.8955 | Function Loss:  -1.5731\n",
      "Total loss:  -0.4055 | PDE Loss:  -0.8917 | Function Loss:  -1.5772\n",
      "Total loss:  -0.407 | PDE Loss:  -0.8874 | Function Loss:  -1.5815\n",
      "Total loss:  -0.4094 | PDE Loss:  -0.8897 | Function Loss:  -1.5839\n",
      "Total loss:  -0.4111 | PDE Loss:  -0.8942 | Function Loss:  -1.5842\n",
      "Total loss:  -0.4121 | PDE Loss:  -0.8993 | Function Loss:  -1.5832\n",
      "Total loss:  -0.4127 | PDE Loss:  -0.9057 | Function Loss:  -1.5811\n",
      "Total loss:  -0.4132 | PDE Loss:  -0.9109 | Function Loss:  -1.5793\n",
      "Total loss:  -0.4139 | PDE Loss:  -0.9156 | Function Loss:  -1.5783\n",
      "Total loss:  -0.4152 | PDE Loss:  -0.9216 | Function Loss:  -1.5773\n",
      "Total loss:  -0.4164 | PDE Loss:  -0.9232 | Function Loss:  -1.5784\n",
      "Total loss:  -0.4177 | PDE Loss:  -0.9241 | Function Loss:  -1.5799\n",
      "Total loss:  -0.4191 | PDE Loss:  -0.9191 | Function Loss:  -1.5842\n",
      "Total loss:  -0.4208 | PDE Loss:  -0.9136 | Function Loss:  -1.5893\n",
      "Total loss:  -0.423 | PDE Loss:  -0.9027 | Function Loss:  -1.5978\n",
      "Total loss:  -0.4252 | PDE Loss:  -0.8967 | Function Loss:  -1.6042\n",
      "Total loss:  -0.4275 | PDE Loss:  -0.8882 | Function Loss:  -1.612\n",
      "Total loss:  -0.429 | PDE Loss:  -0.8893 | Function Loss:  -1.6137\n",
      "Total loss:  -0.4304 | PDE Loss:  -0.894 | Function Loss:  -1.6134\n",
      "Total loss:  -0.4317 | PDE Loss:  -0.9042 | Function Loss:  -1.6101\n",
      "Total loss:  -0.4333 | PDE Loss:  -0.9212 | Function Loss:  -1.6042\n",
      "Total loss:  -0.4346 | PDE Loss:  -0.9384 | Function Loss:  -1.598\n",
      "Total loss:  -0.4359 | PDE Loss:  -0.954 | Function Loss:  -1.5928\n",
      "Total loss:  -0.4369 | PDE Loss:  -0.9725 | Function Loss:  -1.5865\n",
      "Total loss:  -0.4381 | PDE Loss:  -0.9896 | Function Loss:  -1.5812\n",
      "Total loss:  -0.4387 | PDE Loss:  -0.9981 | Function Loss:  -1.5789\n",
      "Total loss:  -0.4397 | PDE Loss:  -1.0047 | Function Loss:  -1.5778\n",
      "Total loss:  -0.4409 | PDE Loss:  -1.006 | Function Loss:  -1.579\n",
      "Total loss:  -0.4424 | PDE Loss:  -1.0029 | Function Loss:  -1.5821\n",
      "Total loss:  -0.4441 | PDE Loss:  -0.9925 | Function Loss:  -1.5886\n",
      "Total loss:  -0.4462 | PDE Loss:  -0.9799 | Function Loss:  -1.5966\n",
      "Total loss:  -0.4479 | PDE Loss:  -0.965 | Function Loss:  -1.6053\n",
      "Total loss:  -0.4499 | PDE Loss:  -0.9487 | Function Loss:  -1.6156\n",
      "Total loss:  -0.4524 | PDE Loss:  -0.9308 | Function Loss:  -1.6278\n",
      "Total loss:  -0.4546 | PDE Loss:  -0.9196 | Function Loss:  -1.637\n",
      "Total loss:  -0.4578 | PDE Loss:  -0.9095 | Function Loss:  -1.6472\n",
      "Total loss:  -0.4625 | PDE Loss:  -0.8985 | Function Loss:  -1.6607\n",
      "Total loss:  -0.4669 | PDE Loss:  -0.891 | Function Loss:  -1.6722\n",
      "Total loss:  -0.4706 | PDE Loss:  -0.884 | Function Loss:  -1.6825\n",
      "Total loss:  -0.4733 | PDE Loss:  -0.8709 | Function Loss:  -1.6954\n",
      "Total loss:  -0.4754 | PDE Loss:  -0.8738 | Function Loss:  -1.6969\n",
      "Total loss:  -0.4765 | PDE Loss:  -0.8707 | Function Loss:  -1.7008\n",
      "Total loss:  -0.4784 | PDE Loss:  -0.8747 | Function Loss:  -1.7013\n",
      "Total loss:  -0.4801 | PDE Loss:  -0.8804 | Function Loss:  -1.7004\n",
      "Total loss:  -0.4812 | PDE Loss:  -0.8887 | Function Loss:  -1.6968\n",
      "Total loss:  -0.4818 | PDE Loss:  -0.8948 | Function Loss:  -1.694\n",
      "Total loss:  -0.4825 | PDE Loss:  -0.9014 | Function Loss:  -1.6909\n",
      "Total loss:  -0.4831 | PDE Loss:  -0.9074 | Function Loss:  -1.6883\n",
      "Total loss:  -0.4837 | PDE Loss:  -0.9105 | Function Loss:  -1.6873\n",
      "Total loss:  -0.4841 | PDE Loss:  -0.9125 | Function Loss:  -1.6867\n",
      "Total loss:  -0.4844 | PDE Loss:  -0.9111 | Function Loss:  -1.688\n",
      "Total loss:  -0.4846 | PDE Loss:  -0.9083 | Function Loss:  -1.6901\n",
      "Total loss:  -0.485 | PDE Loss:  -0.9044 | Function Loss:  -1.6931\n",
      "Total loss:  -0.4855 | PDE Loss:  -0.8983 | Function Loss:  -1.6977\n",
      "Total loss:  -0.4861 | PDE Loss:  -0.8917 | Function Loss:  -1.7029\n",
      "Total loss:  -0.4867 | PDE Loss:  -0.8875 | Function Loss:  -1.7067\n",
      "Total loss:  -0.4877 | PDE Loss:  -0.8814 | Function Loss:  -1.7124\n",
      "Total loss:  -0.4886 | PDE Loss:  -0.8796 | Function Loss:  -1.7151\n",
      "Total loss:  -0.4895 | PDE Loss:  -0.8826 | Function Loss:  -1.7146\n",
      "Total loss:  -0.4907 | PDE Loss:  -0.8873 | Function Loss:  -1.7135\n",
      "Total loss:  -0.4924 | PDE Loss:  -0.8986 | Function Loss:  -1.7088\n",
      "Total loss:  -0.4945 | PDE Loss:  -0.9196 | Function Loss:  -1.6991\n",
      "Total loss:  -0.4954 | PDE Loss:  -0.9263 | Function Loss:  -1.6965\n",
      "Total loss:  -0.4963 | PDE Loss:  -0.9314 | Function Loss:  -1.695\n",
      "Total loss:  -0.497 | PDE Loss:  -0.9351 | Function Loss:  -1.6941\n",
      "Total loss:  -0.4977 | PDE Loss:  -0.9368 | Function Loss:  -1.6941\n",
      "Total loss:  -0.4984 | PDE Loss:  -0.9337 | Function Loss:  -1.6971\n",
      "Total loss:  -0.4991 | PDE Loss:  -0.9343 | Function Loss:  -1.6977\n",
      "Total loss:  -0.4999 | PDE Loss:  -0.9329 | Function Loss:  -1.6998\n",
      "Total loss:  -0.5009 | PDE Loss:  -0.9294 | Function Loss:  -1.7035\n",
      "Total loss:  -0.5016 | PDE Loss:  -0.9287 | Function Loss:  -1.705\n",
      "Total loss:  -0.5024 | PDE Loss:  -0.9276 | Function Loss:  -1.707\n",
      "Total loss:  -0.5034 | PDE Loss:  -0.929 | Function Loss:  -1.7077\n",
      "Total loss:  -0.5045 | PDE Loss:  -0.9283 | Function Loss:  -1.71\n",
      "Total loss:  -0.5057 | PDE Loss:  -0.9323 | Function Loss:  -1.7094\n",
      "Total loss:  -0.5072 | PDE Loss:  -0.9349 | Function Loss:  -1.7103\n",
      "Total loss:  -0.5086 | PDE Loss:  -0.9397 | Function Loss:  -1.7097\n",
      "Total loss:  -0.5106 | PDE Loss:  -0.9453 | Function Loss:  -1.7096\n",
      "Total loss:  -0.5121 | PDE Loss:  -0.9488 | Function Loss:  -1.7099\n",
      "Total loss:  -0.5116 | PDE Loss:  -0.9511 | Function Loss:  -1.7079\n",
      "Total loss:  -0.5128 | PDE Loss:  -0.9508 | Function Loss:  -1.7098\n",
      "Total loss:  -0.5135 | PDE Loss:  -0.955 | Function Loss:  -1.7085\n",
      "Total loss:  -0.5139 | PDE Loss:  -0.954 | Function Loss:  -1.7098\n",
      "Total loss:  -0.5143 | PDE Loss:  -0.9565 | Function Loss:  -1.709\n",
      "Total loss:  -0.5147 | PDE Loss:  -0.9585 | Function Loss:  -1.7084\n",
      "Total loss:  -0.515 | PDE Loss:  -0.96 | Function Loss:  -1.7081\n",
      "Total loss:  -0.5152 | PDE Loss:  -0.9612 | Function Loss:  -1.7078\n",
      "Total loss:  -0.5156 | PDE Loss:  -0.9623 | Function Loss:  -1.7076\n",
      "Total loss:  -0.516 | PDE Loss:  -0.964 | Function Loss:  -1.7074\n",
      "Total loss:  -0.5165 | PDE Loss:  -0.9651 | Function Loss:  -1.7076\n",
      "Total loss:  -0.5173 | PDE Loss:  -0.9673 | Function Loss:  -1.7076\n",
      "Total loss:  -0.5184 | PDE Loss:  -0.9697 | Function Loss:  -1.708\n",
      "Total loss:  -0.5195 | PDE Loss:  -0.9721 | Function Loss:  -1.7084\n",
      "Total loss:  -0.5212 | PDE Loss:  -0.9751 | Function Loss:  -1.7093\n",
      "Total loss:  -0.5231 | PDE Loss:  -0.9783 | Function Loss:  -1.7106\n",
      "Total loss:  -0.5254 | PDE Loss:  -0.9817 | Function Loss:  -1.7123\n",
      "Total loss:  -0.5272 | PDE Loss:  -0.9807 | Function Loss:  -1.7155\n",
      "Total loss:  -0.5295 | PDE Loss:  -0.9801 | Function Loss:  -1.7195\n",
      "Total loss:  -0.532 | PDE Loss:  -0.9705 | Function Loss:  -1.7288\n",
      "Total loss:  -0.5346 | PDE Loss:  -0.9713 | Function Loss:  -1.7323\n",
      "Total loss:  -0.5367 | PDE Loss:  -0.9716 | Function Loss:  -1.7355\n",
      "Total loss:  -0.5385 | PDE Loss:  -0.9737 | Function Loss:  -1.7372\n",
      "Total loss:  -0.54 | PDE Loss:  -0.9677 | Function Loss:  -1.7431\n",
      "Total loss:  -0.5414 | PDE Loss:  -0.9662 | Function Loss:  -1.7462\n",
      "Total loss:  -0.5426 | PDE Loss:  -0.9587 | Function Loss:  -1.7528\n",
      "Total loss:  -0.544 | PDE Loss:  -0.9467 | Function Loss:  -1.7627\n",
      "Total loss:  -0.5452 | PDE Loss:  -0.9487 | Function Loss:  -1.7634\n",
      "Total loss:  -0.5461 | PDE Loss:  -0.9547 | Function Loss:  -1.761\n",
      "Total loss:  -0.5469 | PDE Loss:  -0.9585 | Function Loss:  -1.7599\n",
      "Total loss:  -0.5475 | PDE Loss:  -0.9634 | Function Loss:  -1.7578\n",
      "Total loss:  -0.5482 | PDE Loss:  -0.9673 | Function Loss:  -1.7565\n",
      "Total loss:  -0.5489 | PDE Loss:  -0.9724 | Function Loss:  -1.7545\n",
      "Total loss:  -0.5495 | PDE Loss:  -0.9761 | Function Loss:  -1.7533\n",
      "Total loss:  -0.5505 | PDE Loss:  -0.9821 | Function Loss:  -1.7512\n",
      "Total loss:  -0.5518 | PDE Loss:  -0.9885 | Function Loss:  -1.7496\n",
      "Total loss:  -0.5532 | PDE Loss:  -0.9976 | Function Loss:  -1.7467\n",
      "Total loss:  -0.5548 | PDE Loss:  -1.0048 | Function Loss:  -1.7452\n",
      "Total loss:  -0.5565 | PDE Loss:  -1.0113 | Function Loss:  -1.7442\n",
      "Total loss:  -0.5583 | PDE Loss:  -1.0188 | Function Loss:  -1.743\n",
      "Total loss:  -0.56 | PDE Loss:  -1.019 | Function Loss:  -1.7455\n",
      "Total loss:  -0.562 | PDE Loss:  -1.0156 | Function Loss:  -1.7504\n",
      "Total loss:  -0.5634 | PDE Loss:  -1.0108 | Function Loss:  -1.7552\n",
      "Total loss:  -0.565 | PDE Loss:  -1.0048 | Function Loss:  -1.761\n",
      "Total loss:  -0.566 | PDE Loss:  -1.002 | Function Loss:  -1.7643\n",
      "Total loss:  -0.5674 | PDE Loss:  -1.0 | Function Loss:  -1.7676\n",
      "Total loss:  -0.5689 | PDE Loss:  -0.9995 | Function Loss:  -1.7703\n",
      "Total loss:  -0.5708 | PDE Loss:  -0.9964 | Function Loss:  -1.7751\n",
      "Total loss:  -0.5719 | PDE Loss:  -0.9987 | Function Loss:  -1.7756\n",
      "Total loss:  -0.5728 | PDE Loss:  -0.999 | Function Loss:  -1.7768\n",
      "Total loss:  -0.5732 | PDE Loss:  -0.9993 | Function Loss:  -1.7772\n",
      "Total loss:  -0.5734 | PDE Loss:  -1.0019 | Function Loss:  -1.7761\n",
      "Total loss:  -0.5736 | PDE Loss:  -1.0022 | Function Loss:  -1.7761\n",
      "Total loss:  -0.5736 | PDE Loss:  -1.0026 | Function Loss:  -1.776\n",
      "Total loss:  -0.5737 | PDE Loss:  -1.003 | Function Loss:  -1.7759\n",
      "Total loss:  -0.5738 | PDE Loss:  -1.0032 | Function Loss:  -1.7759\n",
      "Total loss:  -0.574 | PDE Loss:  -1.0032 | Function Loss:  -1.7762\n",
      "Total loss:  -0.5744 | PDE Loss:  -1.0025 | Function Loss:  -1.7772\n",
      "Total loss:  -0.5753 | PDE Loss:  -1.0005 | Function Loss:  -1.7799\n",
      "Total loss:  -0.5762 | PDE Loss:  -0.9993 | Function Loss:  -1.7821\n",
      "Total loss:  -0.5773 | PDE Loss:  -0.9969 | Function Loss:  -1.7853\n",
      "Total loss:  -0.579 | PDE Loss:  -0.9947 | Function Loss:  -1.7893\n",
      "Total loss:  -0.5816 | PDE Loss:  -0.9906 | Function Loss:  -1.7961\n",
      "Total loss:  -0.5839 | PDE Loss:  -0.9835 | Function Loss:  -1.8047\n",
      "Total loss:  -0.5818 | PDE Loss:  -0.9661 | Function Loss:  -1.813\n",
      "Total loss:  -0.5867 | PDE Loss:  -0.9808 | Function Loss:  -1.8111\n",
      "Total loss:  -0.591 | PDE Loss:  -0.9842 | Function Loss:  -1.8161\n",
      "Total loss:  -0.5959 | PDE Loss:  -0.9907 | Function Loss:  -1.8198\n",
      "Total loss:  -0.5984 | PDE Loss:  -0.99 | Function Loss:  -1.8245\n",
      "Total loss:  -0.6019 | PDE Loss:  -0.9934 | Function Loss:  -1.8282\n",
      "Total loss:  -0.6042 | PDE Loss:  -0.9855 | Function Loss:  -1.8375\n",
      "Total loss:  -0.6056 | PDE Loss:  -0.9817 | Function Loss:  -1.8427\n",
      "Total loss:  -0.6073 | PDE Loss:  -0.9784 | Function Loss:  -1.8479\n",
      "Total loss:  -0.6095 | PDE Loss:  -0.9842 | Function Loss:  -1.8475\n",
      "Total loss:  -0.6111 | PDE Loss:  -0.9889 | Function Loss:  -1.8469\n",
      "Total loss:  -0.6144 | PDE Loss:  -0.9961 | Function Loss:  -1.8474\n",
      "Total loss:  -0.6171 | PDE Loss:  -1.0078 | Function Loss:  -1.8438\n",
      "Total loss:  -0.6188 | PDE Loss:  -1.0112 | Function Loss:  -1.8445\n",
      "Total loss:  -0.621 | PDE Loss:  -1.0139 | Function Loss:  -1.8463\n",
      "Total loss:  -0.6227 | PDE Loss:  -1.0126 | Function Loss:  -1.85\n",
      "Total loss:  -0.6242 | PDE Loss:  -1.011 | Function Loss:  -1.8536\n",
      "Total loss:  -0.625 | PDE Loss:  -1.0087 | Function Loss:  -1.8566\n",
      "Total loss:  -0.6259 | PDE Loss:  -1.0071 | Function Loss:  -1.8594\n",
      "Total loss:  -0.6276 | PDE Loss:  -1.0063 | Function Loss:  -1.8628\n",
      "Total loss:  -0.6298 | PDE Loss:  -1.0052 | Function Loss:  -1.8673\n",
      "Total loss:  -0.6328 | PDE Loss:  -1.005 | Function Loss:  -1.8727\n",
      "Total loss:  -0.6355 | PDE Loss:  -1.0029 | Function Loss:  -1.879\n",
      "Total loss:  -0.6367 | PDE Loss:  -0.9988 | Function Loss:  -1.8842\n",
      "Total loss:  -0.6391 | PDE Loss:  -0.9947 | Function Loss:  -1.8916\n",
      "Total loss:  -0.6403 | PDE Loss:  -0.9956 | Function Loss:  -1.8931\n",
      "Total loss:  -0.642 | PDE Loss:  -0.9901 | Function Loss:  -1.9005\n",
      "Total loss:  -0.6434 | PDE Loss:  -0.9905 | Function Loss:  -1.9027\n",
      "Total loss:  -0.6445 | PDE Loss:  -0.9891 | Function Loss:  -1.906\n",
      "Total loss:  -0.6461 | PDE Loss:  -0.9885 | Function Loss:  -1.9093\n",
      "Total loss:  -0.6478 | PDE Loss:  -0.9872 | Function Loss:  -1.9137\n",
      "Total loss:  -0.6497 | PDE Loss:  -0.9861 | Function Loss:  -1.918\n",
      "Total loss:  -0.6519 | PDE Loss:  -0.9878 | Function Loss:  -1.9206\n",
      "Total loss:  -0.6529 | PDE Loss:  -0.9826 | Function Loss:  -1.927\n",
      "Total loss:  -0.6536 | PDE Loss:  -0.9836 | Function Loss:  -1.9274\n",
      "Total loss:  -0.6542 | PDE Loss:  -0.9827 | Function Loss:  -1.9294\n",
      "Total loss:  -0.6547 | PDE Loss:  -0.9822 | Function Loss:  -1.9308\n",
      "Total loss:  -0.6553 | PDE Loss:  -0.9817 | Function Loss:  -1.9323\n",
      "Total loss:  -0.656 | PDE Loss:  -0.98 | Function Loss:  -1.9351\n",
      "Total loss:  -0.6569 | PDE Loss:  -0.9794 | Function Loss:  -1.9374\n",
      "Total loss:  -0.6578 | PDE Loss:  -0.9775 | Function Loss:  -1.941\n",
      "Total loss:  -0.659 | PDE Loss:  -0.9766 | Function Loss:  -1.9441\n",
      "Total loss:  -0.661 | PDE Loss:  -0.9761 | Function Loss:  -1.9484\n",
      "Total loss:  -0.6633 | PDE Loss:  -0.9705 | Function Loss:  -1.9583\n",
      "Total loss:  -0.6662 | PDE Loss:  -0.9682 | Function Loss:  -1.9662\n",
      "Total loss:  -0.6678 | PDE Loss:  -0.9654 | Function Loss:  -1.9722\n",
      "Total loss:  -0.6698 | PDE Loss:  -0.963 | Function Loss:  -1.9788\n",
      "Total loss:  -0.6711 | PDE Loss:  -0.9609 | Function Loss:  -1.9837\n",
      "Total loss:  -0.6719 | PDE Loss:  -0.9584 | Function Loss:  -1.9879\n",
      "Total loss:  -0.6725 | PDE Loss:  -0.9599 | Function Loss:  -1.9875\n",
      "Total loss:  -0.6736 | PDE Loss:  -0.9628 | Function Loss:  -1.9868\n",
      "Total loss:  -0.6747 | PDE Loss:  -0.9666 | Function Loss:  -1.9849\n",
      "Total loss:  -0.6754 | PDE Loss:  -0.9699 | Function Loss:  -1.9832\n",
      "Total loss:  -0.6762 | PDE Loss:  -0.974 | Function Loss:  -1.9804\n",
      "Total loss:  -0.6766 | PDE Loss:  -0.9752 | Function Loss:  -1.98\n",
      "Total loss:  -0.6771 | PDE Loss:  -0.9766 | Function Loss:  -1.9798\n",
      "Total loss:  -0.6778 | PDE Loss:  -0.9765 | Function Loss:  -1.9812\n",
      "Total loss:  -0.6786 | PDE Loss:  -0.9753 | Function Loss:  -1.984\n",
      "Total loss:  -0.6794 | PDE Loss:  -0.9732 | Function Loss:  -1.9878\n",
      "Total loss:  -0.6803 | PDE Loss:  -0.9716 | Function Loss:  -1.9913\n",
      "Total loss:  -0.6806 | PDE Loss:  -0.9675 | Function Loss:  -1.9962\n",
      "Total loss:  -0.6809 | PDE Loss:  -0.9695 | Function Loss:  -1.9947\n",
      "Total loss:  -0.682 | PDE Loss:  -0.9694 | Function Loss:  -1.997\n",
      "Total loss:  -0.6828 | PDE Loss:  -0.9707 | Function Loss:  -1.9974\n",
      "Total loss:  -0.6837 | PDE Loss:  -0.974 | Function Loss:  -1.9957\n",
      "Total loss:  -0.6844 | PDE Loss:  -0.9766 | Function Loss:  -1.9945\n",
      "Total loss:  -0.6849 | PDE Loss:  -0.9802 | Function Loss:  -1.9917\n",
      "Total loss:  -0.6852 | PDE Loss:  -0.9813 | Function Loss:  -1.9912\n",
      "Total loss:  -0.6855 | PDE Loss:  -0.9812 | Function Loss:  -1.9919\n",
      "Total loss:  -0.6859 | PDE Loss:  -0.9802 | Function Loss:  -1.9938\n",
      "Total loss:  -0.6864 | PDE Loss:  -0.9792 | Function Loss:  -1.9958\n",
      "Total loss:  -0.687 | PDE Loss:  -0.9765 | Function Loss:  -1.9999\n",
      "Total loss:  -0.6878 | PDE Loss:  -0.9751 | Function Loss:  -2.0031\n",
      "Total loss:  -0.6896 | PDE Loss:  -0.9748 | Function Loss:  -2.0071\n",
      "Total loss:  -0.6933 | PDE Loss:  -0.9741 | Function Loss:  -2.0156\n",
      "Total loss:  -0.6967 | PDE Loss:  -0.9763 | Function Loss:  -2.0202\n",
      "Total loss:  -0.6992 | PDE Loss:  -0.9777 | Function Loss:  -2.0239\n",
      "Total loss:  -0.701 | PDE Loss:  -0.9871 | Function Loss:  -2.0174\n",
      "Total loss:  -0.7035 | PDE Loss:  -0.9894 | Function Loss:  -2.0201\n",
      "Total loss:  -0.7047 | PDE Loss:  -0.9929 | Function Loss:  -2.019\n",
      "Total loss:  -0.7057 | PDE Loss:  -0.9981 | Function Loss:  -2.0154\n",
      "Total loss:  -0.7064 | PDE Loss:  -1.0037 | Function Loss:  -2.0112\n",
      "Total loss:  -0.7073 | PDE Loss:  -1.0102 | Function Loss:  -2.0065\n",
      "Total loss:  -0.7082 | PDE Loss:  -1.0131 | Function Loss:  -2.0053\n",
      "Total loss:  -0.7093 | PDE Loss:  -1.017 | Function Loss:  -2.0038\n",
      "Total loss:  -0.7109 | PDE Loss:  -1.0218 | Function Loss:  -2.0023\n",
      "Total loss:  -0.712 | PDE Loss:  -1.0276 | Function Loss:  -1.9989\n",
      "Total loss:  -0.7134 | PDE Loss:  -1.0331 | Function Loss:  -1.9964\n",
      "Total loss:  -0.7141 | PDE Loss:  -1.0388 | Function Loss:  -1.9927\n",
      "Total loss:  -0.7152 | PDE Loss:  -1.044 | Function Loss:  -1.99\n",
      "Total loss:  -0.7165 | PDE Loss:  -1.0515 | Function Loss:  -1.986\n",
      "Total loss:  -0.7177 | PDE Loss:  -1.0579 | Function Loss:  -1.9828\n",
      "Total loss:  -0.719 | PDE Loss:  -1.0636 | Function Loss:  -1.9804\n",
      "Total loss:  -0.7199 | PDE Loss:  -1.0731 | Function Loss:  -1.9743\n",
      "Total loss:  -0.7205 | PDE Loss:  -1.0746 | Function Loss:  -1.9742\n",
      "Total loss:  -0.7217 | PDE Loss:  -1.0782 | Function Loss:  -1.9737\n",
      "Total loss:  -0.723 | PDE Loss:  -1.0806 | Function Loss:  -1.974\n",
      "Total loss:  -0.7245 | PDE Loss:  -1.0867 | Function Loss:  -1.9719\n",
      "Total loss:  -0.7257 | PDE Loss:  -1.0892 | Function Loss:  -1.9722\n",
      "Total loss:  -0.7262 | PDE Loss:  -1.0854 | Function Loss:  -1.9759\n",
      "Total loss:  -0.7275 | PDE Loss:  -1.092 | Function Loss:  -1.9731\n",
      "Total loss:  -0.7287 | PDE Loss:  -1.0946 | Function Loss:  -1.9733\n",
      "Total loss:  -0.7302 | PDE Loss:  -1.0937 | Function Loss:  -1.9766\n",
      "Total loss:  -0.7326 | PDE Loss:  -1.0921 | Function Loss:  -1.9821\n",
      "Total loss:  -0.7349 | PDE Loss:  -1.0877 | Function Loss:  -1.9897\n",
      "Total loss:  -0.7368 | PDE Loss:  -1.082 | Function Loss:  -1.9977\n",
      "Total loss:  -0.739 | PDE Loss:  -1.0801 | Function Loss:  -2.0033\n",
      "Total loss:  -0.7405 | PDE Loss:  -1.0752 | Function Loss:  -2.0104\n",
      "Total loss:  -0.7417 | PDE Loss:  -1.0753 | Function Loss:  -2.0124\n",
      "Total loss:  -0.7422 | PDE Loss:  -1.0734 | Function Loss:  -2.0151\n",
      "Total loss:  -0.7433 | PDE Loss:  -1.0713 | Function Loss:  -2.0189\n",
      "Total loss:  -0.7441 | PDE Loss:  -1.0705 | Function Loss:  -2.0212\n",
      "Total loss:  -0.7447 | PDE Loss:  -1.0698 | Function Loss:  -2.0228\n",
      "Total loss:  -0.7451 | PDE Loss:  -1.0704 | Function Loss:  -2.0231\n",
      "Total loss:  -0.7457 | PDE Loss:  -1.0717 | Function Loss:  -2.0232\n",
      "Total loss:  -0.7467 | PDE Loss:  -1.0754 | Function Loss:  -2.0216\n",
      "Total loss:  -0.7481 | PDE Loss:  -1.0813 | Function Loss:  -2.0192\n",
      "Total loss:  -0.7497 | PDE Loss:  -1.0901 | Function Loss:  -2.0147\n",
      "Total loss:  -0.7518 | PDE Loss:  -1.1028 | Function Loss:  -2.0081\n",
      "Total loss:  -0.7531 | PDE Loss:  -1.1118 | Function Loss:  -2.0032\n",
      "Total loss:  -0.7542 | PDE Loss:  -1.1188 | Function Loss:  -1.9998\n",
      "Total loss:  -0.7552 | PDE Loss:  -1.123 | Function Loss:  -1.9984\n",
      "Total loss:  -0.7573 | PDE Loss:  -1.1322 | Function Loss:  -1.9952\n",
      "Total loss:  -0.759 | PDE Loss:  -1.1381 | Function Loss:  -1.9939\n",
      "Total loss:  -0.7609 | PDE Loss:  -1.1447 | Function Loss:  -1.9924\n",
      "Total loss:  -0.7631 | PDE Loss:  -1.1485 | Function Loss:  -1.9935\n",
      "Total loss:  -0.7661 | PDE Loss:  -1.1508 | Function Loss:  -1.9969\n",
      "Total loss:  -0.7682 | PDE Loss:  -1.1584 | Function Loss:  -1.9953\n",
      "Total loss:  -0.7711 | PDE Loss:  -1.1491 | Function Loss:  -2.0068\n",
      "Total loss:  -0.7728 | PDE Loss:  -1.1509 | Function Loss:  -2.0084\n",
      "Total loss:  -0.7741 | PDE Loss:  -1.1519 | Function Loss:  -2.0099\n",
      "Total loss:  -0.7748 | PDE Loss:  -1.1514 | Function Loss:  -2.0114\n",
      "Total loss:  -0.7751 | PDE Loss:  -1.1513 | Function Loss:  -2.0121\n",
      "Total loss:  -0.7754 | PDE Loss:  -1.1521 | Function Loss:  -2.012\n",
      "Total loss:  -0.7757 | PDE Loss:  -1.1528 | Function Loss:  -2.0119\n",
      "Total loss:  -0.7759 | PDE Loss:  -1.154 | Function Loss:  -2.0114\n",
      "Total loss:  -0.7761 | PDE Loss:  -1.1559 | Function Loss:  -2.0105\n",
      "Total loss:  -0.7765 | PDE Loss:  -1.1572 | Function Loss:  -2.0102\n",
      "Total loss:  -0.7769 | PDE Loss:  -1.1592 | Function Loss:  -2.0094\n",
      "Total loss:  -0.7772 | PDE Loss:  -1.1601 | Function Loss:  -2.0095\n",
      "Total loss:  -0.7779 | PDE Loss:  -1.1601 | Function Loss:  -2.0106\n",
      "Total loss:  -0.7788 | PDE Loss:  -1.1598 | Function Loss:  -2.0122\n",
      "Total loss:  -0.7796 | PDE Loss:  -1.1568 | Function Loss:  -2.0159\n",
      "Total loss:  -0.7803 | PDE Loss:  -1.1555 | Function Loss:  -2.018\n",
      "Total loss:  -0.7807 | PDE Loss:  -1.1527 | Function Loss:  -2.0208\n",
      "Total loss:  -0.7812 | PDE Loss:  -1.1517 | Function Loss:  -2.0223\n",
      "Total loss:  -0.7816 | PDE Loss:  -1.1481 | Function Loss:  -2.0257\n",
      "Total loss:  -0.7818 | PDE Loss:  -1.1477 | Function Loss:  -2.0265\n",
      "Total loss:  -0.7823 | PDE Loss:  -1.1468 | Function Loss:  -2.0279\n",
      "Total loss:  -0.783 | PDE Loss:  -1.1452 | Function Loss:  -2.0305\n",
      "Total loss:  -0.7841 | PDE Loss:  -1.1422 | Function Loss:  -2.0348\n",
      "Total loss:  -0.786 | PDE Loss:  -1.1369 | Function Loss:  -2.0422\n",
      "Total loss:  -0.7877 | PDE Loss:  -1.1309 | Function Loss:  -2.0502\n",
      "Total loss:  -0.7891 | PDE Loss:  -1.1279 | Function Loss:  -2.0553\n",
      "Total loss:  -0.791 | PDE Loss:  -1.1255 | Function Loss:  -2.0611\n",
      "Total loss:  -0.7935 | PDE Loss:  -1.1217 | Function Loss:  -2.069\n",
      "Total loss:  -0.7947 | PDE Loss:  -1.1188 | Function Loss:  -2.0739\n",
      "Total loss:  -0.7957 | PDE Loss:  -1.1207 | Function Loss:  -2.074\n",
      "Total loss:  -0.7972 | PDE Loss:  -1.1216 | Function Loss:  -2.076\n",
      "Total loss:  -0.7986 | PDE Loss:  -1.123 | Function Loss:  -2.0775\n",
      "Total loss:  -0.8003 | PDE Loss:  -1.1244 | Function Loss:  -2.0794\n",
      "Total loss:  -0.8019 | PDE Loss:  -1.1297 | Function Loss:  -2.0776\n",
      "Total loss:  -0.8027 | PDE Loss:  -1.1305 | Function Loss:  -2.0785\n",
      "Total loss:  -0.8033 | PDE Loss:  -1.1353 | Function Loss:  -2.0755\n",
      "Total loss:  -0.8038 | PDE Loss:  -1.1374 | Function Loss:  -2.0746\n",
      "Total loss:  -0.8043 | PDE Loss:  -1.1382 | Function Loss:  -2.0748\n",
      "Total loss:  -0.8049 | PDE Loss:  -1.1393 | Function Loss:  -2.075\n",
      "Total loss:  -0.8056 | PDE Loss:  -1.1396 | Function Loss:  -2.0759\n",
      "Total loss:  -0.8065 | PDE Loss:  -1.1406 | Function Loss:  -2.0767\n",
      "Total loss:  -0.8076 | PDE Loss:  -1.1416 | Function Loss:  -2.078\n",
      "Total loss:  -0.8086 | PDE Loss:  -1.1423 | Function Loss:  -2.0793\n",
      "Total loss:  -0.8101 | PDE Loss:  -1.1444 | Function Loss:  -2.0801\n",
      "Total loss:  -0.8115 | PDE Loss:  -1.1448 | Function Loss:  -2.0825\n",
      "Total loss:  -0.8124 | PDE Loss:  -1.1436 | Function Loss:  -2.0851\n",
      "Total loss:  -0.813 | PDE Loss:  -1.1427 | Function Loss:  -2.0871\n",
      "Total loss:  -0.8135 | PDE Loss:  -1.1413 | Function Loss:  -2.0893\n",
      "Total loss:  -0.814 | PDE Loss:  -1.1395 | Function Loss:  -2.0919\n",
      "Total loss:  -0.8146 | PDE Loss:  -1.1365 | Function Loss:  -2.0957\n",
      "Total loss:  -0.8151 | PDE Loss:  -1.1306 | Function Loss:  -2.1021\n",
      "Total loss:  -0.8156 | PDE Loss:  -1.1287 | Function Loss:  -2.1049\n",
      "Total loss:  -0.8166 | PDE Loss:  -1.1253 | Function Loss:  -2.1101\n",
      "Total loss:  -0.8179 | PDE Loss:  -1.1211 | Function Loss:  -2.1167\n",
      "Total loss:  -0.819 | PDE Loss:  -1.1224 | Function Loss:  -2.1178\n",
      "Total loss:  -0.8199 | PDE Loss:  -1.1243 | Function Loss:  -2.1176\n",
      "Total loss:  -0.8216 | PDE Loss:  -1.1339 | Function Loss:  -2.1117\n",
      "Total loss:  -0.8214 | PDE Loss:  -1.1421 | Function Loss:  -2.1037\n",
      "Total loss:  -0.8224 | PDE Loss:  -1.1385 | Function Loss:  -2.1089\n",
      "Total loss:  -0.8237 | PDE Loss:  -1.1467 | Function Loss:  -2.1038\n",
      "Total loss:  -0.8247 | PDE Loss:  -1.1536 | Function Loss:  -2.0996\n",
      "Total loss:  -0.8256 | PDE Loss:  -1.1569 | Function Loss:  -2.0984\n",
      "Total loss:  -0.826 | PDE Loss:  -1.1563 | Function Loss:  -2.0997\n",
      "Total loss:  -0.8265 | PDE Loss:  -1.1554 | Function Loss:  -2.1012\n",
      "Total loss:  -0.8269 | PDE Loss:  -1.1535 | Function Loss:  -2.1037\n",
      "Total loss:  -0.8273 | PDE Loss:  -1.1535 | Function Loss:  -2.1046\n",
      "Total loss:  -0.8282 | PDE Loss:  -1.1528 | Function Loss:  -2.1068\n",
      "Total loss:  -0.8291 | PDE Loss:  -1.1525 | Function Loss:  -2.1088\n",
      "Total loss:  -0.8299 | PDE Loss:  -1.1516 | Function Loss:  -2.1112\n",
      "Total loss:  -0.8306 | PDE Loss:  -1.15 | Function Loss:  -2.114\n",
      "Total loss:  -0.831 | PDE Loss:  -1.1516 | Function Loss:  -2.1133\n",
      "Total loss:  -0.8318 | PDE Loss:  -1.1478 | Function Loss:  -2.1183\n",
      "Total loss:  -0.8323 | PDE Loss:  -1.148 | Function Loss:  -2.1191\n",
      "Total loss:  -0.8328 | PDE Loss:  -1.1476 | Function Loss:  -2.1204\n",
      "Total loss:  -0.8337 | PDE Loss:  -1.1462 | Function Loss:  -2.1235\n",
      "Total loss:  -0.8347 | PDE Loss:  -1.148 | Function Loss:  -2.1237\n",
      "Total loss:  -0.8358 | PDE Loss:  -1.1502 | Function Loss:  -2.1239\n",
      "Total loss:  -0.8375 | PDE Loss:  -1.1559 | Function Loss:  -2.1219\n",
      "Total loss:  -0.8399 | PDE Loss:  -1.1681 | Function Loss:  -2.1154\n",
      "Total loss:  -0.8418 | PDE Loss:  -1.1785 | Function Loss:  -2.1098\n",
      "Total loss:  -0.8443 | PDE Loss:  -1.1928 | Function Loss:  -2.1025\n",
      "Total loss:  -0.8471 | PDE Loss:  -1.2055 | Function Loss:  -2.0974\n",
      "Total loss:  -0.8486 | PDE Loss:  -1.2172 | Function Loss:  -2.0911\n",
      "Total loss:  -0.8501 | PDE Loss:  -1.217 | Function Loss:  -2.0939\n",
      "Total loss:  -0.8511 | PDE Loss:  -1.2107 | Function Loss:  -2.1005\n",
      "Total loss:  -0.8519 | PDE Loss:  -1.2077 | Function Loss:  -2.1043\n",
      "Total loss:  -0.8527 | PDE Loss:  -1.2034 | Function Loss:  -2.1092\n",
      "Total loss:  -0.8536 | PDE Loss:  -1.1957 | Function Loss:  -2.1171\n",
      "Total loss:  -0.8545 | PDE Loss:  -1.1908 | Function Loss:  -2.1228\n",
      "Total loss:  -0.8555 | PDE Loss:  -1.186 | Function Loss:  -2.1288\n",
      "Total loss:  -0.8564 | PDE Loss:  -1.1838 | Function Loss:  -2.1326\n",
      "Total loss:  -0.8571 | PDE Loss:  -1.1831 | Function Loss:  -2.1346\n",
      "Total loss:  -0.8577 | PDE Loss:  -1.1845 | Function Loss:  -2.1345\n",
      "Total loss:  -0.8584 | PDE Loss:  -1.1862 | Function Loss:  -2.1343\n",
      "Total loss:  -0.859 | PDE Loss:  -1.1873 | Function Loss:  -2.1344\n",
      "Total loss:  -0.8594 | PDE Loss:  -1.1874 | Function Loss:  -2.1351\n",
      "Total loss:  -0.8598 | PDE Loss:  -1.1865 | Function Loss:  -2.1366\n",
      "Total loss:  -0.8602 | PDE Loss:  -1.1856 | Function Loss:  -2.1382\n",
      "Total loss:  -0.8607 | PDE Loss:  -1.1833 | Function Loss:  -2.1412\n",
      "Total loss:  -0.8614 | PDE Loss:  -1.181 | Function Loss:  -2.1447\n",
      "Total loss:  -0.8624 | PDE Loss:  -1.1777 | Function Loss:  -2.1496\n",
      "Total loss:  -0.8633 | PDE Loss:  -1.1765 | Function Loss:  -2.1525\n",
      "Total loss:  -0.864 | PDE Loss:  -1.1748 | Function Loss:  -2.1554\n",
      "Total loss:  -0.8642 | PDE Loss:  -1.1752 | Function Loss:  -2.1554\n",
      "Total loss:  -0.8643 | PDE Loss:  -1.176 | Function Loss:  -2.155\n",
      "Total loss:  -0.8645 | PDE Loss:  -1.1768 | Function Loss:  -2.1545\n",
      "Total loss:  -0.8647 | PDE Loss:  -1.1786 | Function Loss:  -2.1532\n",
      "Total loss:  -0.8651 | PDE Loss:  -1.1818 | Function Loss:  -2.1509\n",
      "Total loss:  -0.8657 | PDE Loss:  -1.1862 | Function Loss:  -2.1481\n",
      "Total loss:  -0.8668 | PDE Loss:  -1.1923 | Function Loss:  -2.1446\n",
      "Total loss:  -0.8684 | PDE Loss:  -1.1992 | Function Loss:  -2.1415\n",
      "Total loss:  -0.8703 | PDE Loss:  -1.2046 | Function Loss:  -2.1404\n",
      "Total loss:  -0.8719 | PDE Loss:  -1.2067 | Function Loss:  -2.1415\n",
      "Total loss:  -0.8736 | PDE Loss:  -1.2079 | Function Loss:  -2.1436\n",
      "Total loss:  -0.8751 | PDE Loss:  -1.2096 | Function Loss:  -2.1451\n",
      "Total loss:  -0.8766 | PDE Loss:  -1.2101 | Function Loss:  -2.1474\n",
      "Total loss:  -0.8779 | PDE Loss:  -1.2119 | Function Loss:  -2.1482\n",
      "Total loss:  -0.8798 | PDE Loss:  -1.2148 | Function Loss:  -2.1493\n",
      "Total loss:  -0.8829 | PDE Loss:  -1.2189 | Function Loss:  -2.1516\n",
      "Total loss:  -0.8869 | PDE Loss:  -1.2252 | Function Loss:  -2.1536\n",
      "Total loss:  -0.893 | PDE Loss:  -1.2348 | Function Loss:  -2.1568\n",
      "Total loss:  -0.8977 | PDE Loss:  -1.2465 | Function Loss:  -2.1558\n",
      "Total loss:  -0.899 | PDE Loss:  -1.2663 | Function Loss:  -2.1427\n",
      "Total loss:  -0.9021 | PDE Loss:  -1.2585 | Function Loss:  -2.1541\n",
      "Total loss:  -0.9023 | PDE Loss:  -1.2602 | Function Loss:  -2.153\n",
      "Total loss:  -0.9066 | PDE Loss:  -1.2622 | Function Loss:  -2.1592\n",
      "Total loss:  -0.9102 | PDE Loss:  -1.2643 | Function Loss:  -2.1639\n",
      "Total loss:  -0.912 | PDE Loss:  -1.2692 | Function Loss:  -2.1633\n",
      "Total loss:  -0.913 | PDE Loss:  -1.2724 | Function Loss:  -2.1626\n",
      "Total loss:  -0.9137 | PDE Loss:  -1.2716 | Function Loss:  -2.1644\n",
      "Total loss:  -0.9143 | PDE Loss:  -1.2751 | Function Loss:  -2.1627\n",
      "Total loss:  -0.915 | PDE Loss:  -1.2778 | Function Loss:  -2.1619\n",
      "Total loss:  -0.9156 | PDE Loss:  -1.2795 | Function Loss:  -2.1616\n",
      "Total loss:  -0.9165 | PDE Loss:  -1.2834 | Function Loss:  -2.1603\n",
      "Total loss:  -0.9179 | PDE Loss:  -1.2901 | Function Loss:  -2.1578\n",
      "Total loss:  -0.9199 | PDE Loss:  -1.2996 | Function Loss:  -2.1543\n",
      "Total loss:  -0.9221 | PDE Loss:  -1.3132 | Function Loss:  -2.1485\n",
      "Total loss:  -0.9243 | PDE Loss:  -1.3261 | Function Loss:  -2.1436\n",
      "Total loss:  -0.9263 | PDE Loss:  -1.341 | Function Loss:  -2.1373\n",
      "Total loss:  -0.9277 | PDE Loss:  -1.347 | Function Loss:  -2.1359\n",
      "Total loss:  -0.9295 | PDE Loss:  -1.3493 | Function Loss:  -2.1374\n",
      "Total loss:  -0.9313 | PDE Loss:  -1.3551 | Function Loss:  -2.1367\n",
      "Total loss:  -0.9327 | PDE Loss:  -1.3542 | Function Loss:  -2.1395\n",
      "Total loss:  -0.9347 | PDE Loss:  -1.3511 | Function Loss:  -2.1446\n",
      "Total loss:  -0.9353 | PDE Loss:  -1.3521 | Function Loss:  -2.145\n",
      "Total loss:  -0.9369 | PDE Loss:  -1.3476 | Function Loss:  -2.1504\n",
      "Total loss:  -0.9373 | PDE Loss:  -1.3492 | Function Loss:  -2.1501\n",
      "Total loss:  -0.9379 | PDE Loss:  -1.3523 | Function Loss:  -2.1491\n",
      "Total loss:  -0.9386 | PDE Loss:  -1.3565 | Function Loss:  -2.1476\n",
      "Total loss:  -0.9396 | PDE Loss:  -1.3632 | Function Loss:  -2.1451\n",
      "Total loss:  -0.941 | PDE Loss:  -1.3726 | Function Loss:  -2.1418\n",
      "Total loss:  -0.9424 | PDE Loss:  -1.3835 | Function Loss:  -2.1377\n",
      "Total loss:  -0.943 | PDE Loss:  -1.3905 | Function Loss:  -2.1347\n",
      "Total loss:  -0.9443 | PDE Loss:  -1.3933 | Function Loss:  -2.1352\n",
      "Total loss:  -0.9457 | PDE Loss:  -1.3927 | Function Loss:  -2.1377\n",
      "Total loss:  -0.9472 | PDE Loss:  -1.3939 | Function Loss:  -2.1394\n",
      "Total loss:  -0.9482 | PDE Loss:  -1.3952 | Function Loss:  -2.1402\n",
      "Total loss:  -0.9491 | PDE Loss:  -1.3946 | Function Loss:  -2.1419\n",
      "Total loss:  -0.9497 | PDE Loss:  -1.3984 | Function Loss:  -2.1408\n",
      "Total loss:  -0.9505 | PDE Loss:  -1.4034 | Function Loss:  -2.1393\n",
      "Total loss:  -0.9515 | PDE Loss:  -1.4105 | Function Loss:  -2.1369\n",
      "Total loss:  -0.9523 | PDE Loss:  -1.4181 | Function Loss:  -2.1341\n",
      "Total loss:  -0.9528 | PDE Loss:  -1.4236 | Function Loss:  -2.132\n",
      "Total loss:  -0.953 | PDE Loss:  -1.4261 | Function Loss:  -2.1312\n",
      "Total loss:  -0.9533 | PDE Loss:  -1.4276 | Function Loss:  -2.1307\n",
      "Total loss:  -0.9536 | PDE Loss:  -1.4287 | Function Loss:  -2.1307\n",
      "Total loss:  -0.9539 | PDE Loss:  -1.4295 | Function Loss:  -2.1308\n",
      "Total loss:  -0.9542 | PDE Loss:  -1.4295 | Function Loss:  -2.1312\n",
      "Total loss:  -0.9547 | PDE Loss:  -1.4296 | Function Loss:  -2.1319\n",
      "Total loss:  -0.9554 | PDE Loss:  -1.4297 | Function Loss:  -2.133\n",
      "Total loss:  -0.9567 | PDE Loss:  -1.43 | Function Loss:  -2.1347\n",
      "Total loss:  -0.9586 | PDE Loss:  -1.4312 | Function Loss:  -2.137\n",
      "Total loss:  -0.961 | PDE Loss:  -1.4332 | Function Loss:  -2.1395\n",
      "Total loss:  -0.9638 | PDE Loss:  -1.4383 | Function Loss:  -2.1411\n",
      "Total loss:  -0.9663 | PDE Loss:  -1.4401 | Function Loss:  -2.144\n",
      "Total loss:  -0.9694 | PDE Loss:  -1.4463 | Function Loss:  -2.1456\n",
      "Total loss:  -0.9716 | PDE Loss:  -1.4433 | Function Loss:  -2.1504\n",
      "Total loss:  -0.9744 | PDE Loss:  -1.4427 | Function Loss:  -2.155\n",
      "Total loss:  -0.9762 | PDE Loss:  -1.4432 | Function Loss:  -2.1574\n",
      "Total loss:  -0.978 | PDE Loss:  -1.4354 | Function Loss:  -2.1643\n",
      "Total loss:  -0.9795 | PDE Loss:  -1.4361 | Function Loss:  -2.1663\n",
      "Total loss:  -0.9809 | PDE Loss:  -1.4357 | Function Loss:  -2.1685\n",
      "Total loss:  -0.9819 | PDE Loss:  -1.4325 | Function Loss:  -2.1719\n",
      "Total loss:  -0.9834 | PDE Loss:  -1.4309 | Function Loss:  -2.1751\n",
      "Total loss:  -0.9846 | PDE Loss:  -1.4295 | Function Loss:  -2.1777\n",
      "Total loss:  -0.9854 | PDE Loss:  -1.4246 | Function Loss:  -2.1818\n",
      "Total loss:  -0.986 | PDE Loss:  -1.4195 | Function Loss:  -2.1856\n",
      "Total loss:  -0.9865 | PDE Loss:  -1.4191 | Function Loss:  -2.1868\n",
      "Total loss:  -0.9871 | PDE Loss:  -1.4166 | Function Loss:  -2.1891\n",
      "Total loss:  -0.9878 | PDE Loss:  -1.4129 | Function Loss:  -2.1925\n",
      "Total loss:  -0.9888 | PDE Loss:  -1.4067 | Function Loss:  -2.1978\n",
      "Total loss:  -0.99 | PDE Loss:  -1.4001 | Function Loss:  -2.2039\n",
      "Total loss:  -0.9917 | PDE Loss:  -1.3897 | Function Loss:  -2.2135\n",
      "Total loss:  -0.9934 | PDE Loss:  -1.3856 | Function Loss:  -2.2191\n",
      "Total loss:  -0.995 | PDE Loss:  -1.3854 | Function Loss:  -2.2219\n",
      "Total loss:  -0.9964 | PDE Loss:  -1.3889 | Function Loss:  -2.2219\n",
      "Total loss:  -0.9973 | PDE Loss:  -1.3953 | Function Loss:  -2.2191\n",
      "Total loss:  -0.9976 | PDE Loss:  -1.3987 | Function Loss:  -2.2174\n",
      "Total loss:  -0.9984 | PDE Loss:  -1.4001 | Function Loss:  -2.2177\n",
      "Total loss:  -0.9991 | PDE Loss:  -1.4041 | Function Loss:  -2.2162\n",
      "Total loss:  -0.9998 | PDE Loss:  -1.4062 | Function Loss:  -2.2161\n",
      "Total loss:  -1.001 | PDE Loss:  -1.4107 | Function Loss:  -2.2151\n",
      "Total loss:  -1.0029 | PDE Loss:  -1.4142 | Function Loss:  -2.216\n",
      "Total loss:  -1.0053 | PDE Loss:  -1.421 | Function Loss:  -2.2157\n",
      "Total loss:  -1.0072 | PDE Loss:  -1.4253 | Function Loss:  -2.2161\n",
      "Total loss:  -1.0098 | PDE Loss:  -1.4323 | Function Loss:  -2.2159\n",
      "Total loss:  -1.0118 | PDE Loss:  -1.4282 | Function Loss:  -2.2217\n",
      "Total loss:  -1.0146 | PDE Loss:  -1.4336 | Function Loss:  -2.223\n",
      "Total loss:  -1.0165 | PDE Loss:  -1.4376 | Function Loss:  -2.2236\n",
      "Total loss:  -1.0179 | PDE Loss:  -1.43 | Function Loss:  -2.2306\n",
      "Total loss:  -1.0212 | PDE Loss:  -1.4295 | Function Loss:  -2.2363\n",
      "Total loss:  -1.0236 | PDE Loss:  -1.4301 | Function Loss:  -2.2397\n",
      "Total loss:  -1.0261 | PDE Loss:  -1.4254 | Function Loss:  -2.247\n",
      "Total loss:  -1.0315 | PDE Loss:  -1.4185 | Function Loss:  -2.2608\n",
      "Total loss:  -1.0354 | PDE Loss:  -1.4212 | Function Loss:  -2.2655\n",
      "Total loss:  -1.04 | PDE Loss:  -1.4094 | Function Loss:  -2.282\n",
      "Total loss:  -1.0426 | PDE Loss:  -1.4194 | Function Loss:  -2.2791\n",
      "Total loss:  -1.0402 | PDE Loss:  -1.4148 | Function Loss:  -2.2783\n",
      "Total loss:  -1.0445 | PDE Loss:  -1.4209 | Function Loss:  -2.2813\n",
      "Total loss:  -1.0463 | PDE Loss:  -1.4244 | Function Loss:  -2.2819\n",
      "Total loss:  -1.0489 | PDE Loss:  -1.4294 | Function Loss:  -2.2828\n",
      "Total loss:  -1.0524 | PDE Loss:  -1.4378 | Function Loss:  -2.2828\n",
      "Total loss:  -1.0561 | PDE Loss:  -1.4399 | Function Loss:  -2.2877\n",
      "Total loss:  -1.0598 | PDE Loss:  -1.4496 | Function Loss:  -2.2871\n",
      "Total loss:  -1.0624 | PDE Loss:  -1.4525 | Function Loss:  -2.2895\n",
      "Total loss:  -1.0653 | PDE Loss:  -1.4612 | Function Loss:  -2.2886\n",
      "Total loss:  -1.0673 | PDE Loss:  -1.4653 | Function Loss:  -2.2891\n",
      "Total loss:  -1.0683 | PDE Loss:  -1.466 | Function Loss:  -2.2903\n",
      "Total loss:  -1.0694 | PDE Loss:  -1.4717 | Function Loss:  -2.2883\n",
      "Total loss:  -1.0704 | PDE Loss:  -1.4739 | Function Loss:  -2.2886\n",
      "Total loss:  -1.0716 | PDE Loss:  -1.479 | Function Loss:  -2.2873\n",
      "Total loss:  -1.0736 | PDE Loss:  -1.4863 | Function Loss:  -2.2858\n",
      "Total loss:  -1.0776 | PDE Loss:  -1.5013 | Function Loss:  -2.2831\n",
      "Total loss:  -1.083 | PDE Loss:  -1.5296 | Function Loss:  -2.2752\n",
      "Total loss:  -1.0878 | PDE Loss:  -1.5525 | Function Loss:  -2.2703\n",
      "Total loss:  -1.0958 | PDE Loss:  -1.5811 | Function Loss:  -2.2678\n",
      "Total loss:  -1.1034 | PDE Loss:  -1.6214 | Function Loss:  -2.2605\n",
      "Total loss:  -1.1082 | PDE Loss:  -1.6372 | Function Loss:  -2.2606\n",
      "Total loss:  -1.1115 | PDE Loss:  -1.6693 | Function Loss:  -2.2523\n",
      "Total loss:  -1.1143 | PDE Loss:  -1.6813 | Function Loss:  -2.2516\n",
      "Total loss:  -1.1168 | PDE Loss:  -1.6947 | Function Loss:  -2.2501\n",
      "Total loss:  -1.1187 | PDE Loss:  -1.7053 | Function Loss:  -2.2489\n",
      "Total loss:  -1.1212 | PDE Loss:  -1.7192 | Function Loss:  -2.2475\n",
      "Total loss:  -1.124 | PDE Loss:  -1.7269 | Function Loss:  -2.2487\n",
      "Total loss:  -1.1263 | PDE Loss:  -1.7395 | Function Loss:  -2.2476\n",
      "Total loss:  -1.1289 | PDE Loss:  -1.7435 | Function Loss:  -2.2497\n",
      "Total loss:  -1.132 | PDE Loss:  -1.7503 | Function Loss:  -2.2517\n",
      "Total loss:  -1.1373 | PDE Loss:  -1.7455 | Function Loss:  -2.2602\n",
      "Total loss:  -1.1416 | PDE Loss:  -1.7366 | Function Loss:  -2.2689\n",
      "Total loss:  -1.1411 | PDE Loss:  -1.7175 | Function Loss:  -2.275\n",
      "Total loss:  -1.144 | PDE Loss:  -1.7318 | Function Loss:  -2.2738\n",
      "Total loss:  -1.147 | PDE Loss:  -1.7213 | Function Loss:  -2.2816\n",
      "Total loss:  -1.1488 | PDE Loss:  -1.7004 | Function Loss:  -2.292\n",
      "Total loss:  -1.1507 | PDE Loss:  -1.6965 | Function Loss:  -2.2962\n",
      "Total loss:  -1.1532 | PDE Loss:  -1.696 | Function Loss:  -2.2998\n",
      "Total loss:  -1.1558 | PDE Loss:  -1.6908 | Function Loss:  -2.3056\n",
      "Total loss:  -1.1614 | PDE Loss:  -1.6835 | Function Loss:  -2.3167\n",
      "Total loss:  -1.1662 | PDE Loss:  -1.6849 | Function Loss:  -2.3229\n",
      "Total loss:  -1.1693 | PDE Loss:  -1.6867 | Function Loss:  -2.3266\n",
      "Total loss:  -1.1719 | PDE Loss:  -1.7046 | Function Loss:  -2.3227\n",
      "Total loss:  -1.1734 | PDE Loss:  -1.7062 | Function Loss:  -2.3241\n",
      "Total loss:  -1.1746 | PDE Loss:  -1.7007 | Function Loss:  -2.3281\n",
      "Total loss:  -1.1754 | PDE Loss:  -1.6981 | Function Loss:  -2.3304\n",
      "Total loss:  -1.1762 | PDE Loss:  -1.6962 | Function Loss:  -2.3323\n",
      "Total loss:  -1.1774 | PDE Loss:  -1.6887 | Function Loss:  -2.3374\n",
      "Total loss:  -1.1788 | PDE Loss:  -1.6816 | Function Loss:  -2.3425\n",
      "Total loss:  -1.1803 | PDE Loss:  -1.6733 | Function Loss:  -2.3486\n",
      "Total loss:  -1.1817 | PDE Loss:  -1.6661 | Function Loss:  -2.3542\n",
      "Total loss:  -1.1831 | PDE Loss:  -1.6604 | Function Loss:  -2.3591\n",
      "Total loss:  -1.1842 | PDE Loss:  -1.6603 | Function Loss:  -2.3607\n",
      "Total loss:  -1.1853 | PDE Loss:  -1.6595 | Function Loss:  -2.3629\n",
      "Total loss:  -1.1864 | PDE Loss:  -1.66 | Function Loss:  -2.3642\n",
      "Total loss:  -1.1876 | PDE Loss:  -1.6621 | Function Loss:  -2.365\n",
      "Total loss:  -1.1894 | PDE Loss:  -1.6639 | Function Loss:  -2.3668\n",
      "Total loss:  -1.1911 | PDE Loss:  -1.6678 | Function Loss:  -2.3674\n",
      "Total loss:  -1.1925 | PDE Loss:  -1.6718 | Function Loss:  -2.3675\n",
      "Total loss:  -1.1934 | PDE Loss:  -1.6724 | Function Loss:  -2.3685\n",
      "Total loss:  -1.1939 | PDE Loss:  -1.6786 | Function Loss:  -2.3663\n",
      "Total loss:  -1.1943 | PDE Loss:  -1.6815 | Function Loss:  -2.3655\n",
      "Total loss:  -1.1947 | PDE Loss:  -1.6854 | Function Loss:  -2.3642\n",
      "Total loss:  -1.1952 | PDE Loss:  -1.6903 | Function Loss:  -2.3626\n",
      "Total loss:  -1.1957 | PDE Loss:  -1.6949 | Function Loss:  -2.3612\n",
      "Total loss:  -1.1962 | PDE Loss:  -1.699 | Function Loss:  -2.3601\n",
      "Total loss:  -1.1968 | PDE Loss:  -1.7017 | Function Loss:  -2.3597\n",
      "Total loss:  -1.1977 | PDE Loss:  -1.7035 | Function Loss:  -2.3601\n",
      "Total loss:  -1.1986 | PDE Loss:  -1.7035 | Function Loss:  -2.3614\n",
      "Total loss:  -1.1997 | PDE Loss:  -1.7042 | Function Loss:  -2.3627\n",
      "Total loss:  -1.2008 | PDE Loss:  -1.7023 | Function Loss:  -2.3652\n",
      "Total loss:  -1.2019 | PDE Loss:  -1.7005 | Function Loss:  -2.3676\n",
      "Total loss:  -1.2039 | PDE Loss:  -1.6991 | Function Loss:  -2.3713\n",
      "Total loss:  -1.2069 | PDE Loss:  -1.6924 | Function Loss:  -2.3789\n",
      "Total loss:  -1.1991 | PDE Loss:  -1.6673 | Function Loss:  -2.3797\n",
      "Total loss:  -1.2094 | PDE Loss:  -1.6866 | Function Loss:  -2.3854\n",
      "Total loss:  -1.2114 | PDE Loss:  -1.6867 | Function Loss:  -2.3883\n",
      "Total loss:  -1.2139 | PDE Loss:  -1.6831 | Function Loss:  -2.394\n",
      "Total loss:  -1.2153 | PDE Loss:  -1.6814 | Function Loss:  -2.3971\n",
      "Total loss:  -1.2166 | PDE Loss:  -1.6812 | Function Loss:  -2.3991\n",
      "Total loss:  -1.2176 | PDE Loss:  -1.6801 | Function Loss:  -2.4013\n",
      "Total loss:  -1.2183 | PDE Loss:  -1.6824 | Function Loss:  -2.4011\n",
      "Total loss:  -1.2189 | PDE Loss:  -1.6834 | Function Loss:  -2.4015\n",
      "Total loss:  -1.2195 | PDE Loss:  -1.6852 | Function Loss:  -2.4014\n",
      "Total loss:  -1.2202 | PDE Loss:  -1.6897 | Function Loss:  -2.4002\n",
      "Total loss:  -1.2208 | PDE Loss:  -1.6934 | Function Loss:  -2.3992\n",
      "Total loss:  -1.2219 | PDE Loss:  -1.6976 | Function Loss:  -2.3988\n",
      "Total loss:  -1.2233 | PDE Loss:  -1.7044 | Function Loss:  -2.3974\n",
      "Total loss:  -1.2246 | PDE Loss:  -1.7097 | Function Loss:  -2.3967\n",
      "Total loss:  -1.2261 | PDE Loss:  -1.7127 | Function Loss:  -2.3975\n",
      "Total loss:  -1.228 | PDE Loss:  -1.718 | Function Loss:  -2.3978\n",
      "Total loss:  -1.2301 | PDE Loss:  -1.7208 | Function Loss:  -2.3996\n",
      "Total loss:  -1.2331 | PDE Loss:  -1.7167 | Function Loss:  -2.4059\n",
      "Total loss:  -1.2377 | PDE Loss:  -1.7175 | Function Loss:  -2.4125\n",
      "Total loss:  -1.2427 | PDE Loss:  -1.7167 | Function Loss:  -2.4204\n",
      "Total loss:  -1.2498 | PDE Loss:  -1.7143 | Function Loss:  -2.4323\n",
      "Total loss:  -1.2528 | PDE Loss:  -1.7082 | Function Loss:  -2.4401\n",
      "Total loss:  -1.2568 | PDE Loss:  -1.7177 | Function Loss:  -2.4413\n",
      "Total loss:  -1.2591 | PDE Loss:  -1.7157 | Function Loss:  -2.4459\n",
      "Total loss:  -1.2614 | PDE Loss:  -1.7131 | Function Loss:  -2.4507\n",
      "Total loss:  -1.2649 | PDE Loss:  -1.7146 | Function Loss:  -2.4554\n",
      "Total loss:  -1.2672 | PDE Loss:  -1.7162 | Function Loss:  -2.4581\n",
      "Total loss:  -1.2686 | PDE Loss:  -1.7207 | Function Loss:  -2.4578\n",
      "Total loss:  -1.2697 | PDE Loss:  -1.7212 | Function Loss:  -2.4591\n",
      "Total loss:  -1.2709 | PDE Loss:  -1.7227 | Function Loss:  -2.4602\n",
      "Total loss:  -1.2722 | PDE Loss:  -1.7217 | Function Loss:  -2.4627\n",
      "Total loss:  -1.2733 | PDE Loss:  -1.7234 | Function Loss:  -2.4636\n",
      "Total loss:  -1.2741 | PDE Loss:  -1.7229 | Function Loss:  -2.465\n",
      "Total loss:  -1.2751 | PDE Loss:  -1.7215 | Function Loss:  -2.4674\n",
      "Total loss:  -1.2767 | PDE Loss:  -1.7202 | Function Loss:  -2.4706\n",
      "Total loss:  -1.2795 | PDE Loss:  -1.717 | Function Loss:  -2.4769\n",
      "Total loss:  -1.2848 | PDE Loss:  -1.7116 | Function Loss:  -2.4885\n",
      "Total loss:  -1.2915 | PDE Loss:  -1.7044 | Function Loss:  -2.5037\n",
      "Total loss:  -1.2994 | PDE Loss:  -1.7004 | Function Loss:  -2.5192\n",
      "Total loss:  -1.3027 | PDE Loss:  -1.6868 | Function Loss:  -2.534\n",
      "Total loss:  -1.308 | PDE Loss:  -1.6969 | Function Loss:  -2.5359\n",
      "Total loss:  -1.3127 | PDE Loss:  -1.7095 | Function Loss:  -2.5354\n",
      "Total loss:  -1.3169 | PDE Loss:  -1.7202 | Function Loss:  -2.5352\n",
      "Total loss:  -1.3196 | PDE Loss:  -1.7281 | Function Loss:  -2.5345\n",
      "Total loss:  -1.322 | PDE Loss:  -1.7315 | Function Loss:  -2.5363\n",
      "Total loss:  -1.3237 | PDE Loss:  -1.731 | Function Loss:  -2.5394\n",
      "Total loss:  -1.3251 | PDE Loss:  -1.7324 | Function Loss:  -2.5408\n",
      "Total loss:  -1.3262 | PDE Loss:  -1.7335 | Function Loss:  -2.5419\n",
      "Total loss:  -1.3276 | PDE Loss:  -1.732 | Function Loss:  -2.5452\n",
      "Total loss:  -1.3292 | PDE Loss:  -1.732 | Function Loss:  -2.5478\n",
      "Total loss:  -1.3311 | PDE Loss:  -1.7368 | Function Loss:  -2.5479\n",
      "Total loss:  -1.3336 | PDE Loss:  -1.744 | Function Loss:  -2.5473\n",
      "Total loss:  -1.3372 | PDE Loss:  -1.7577 | Function Loss:  -2.5447\n",
      "Total loss:  -1.3406 | PDE Loss:  -1.7757 | Function Loss:  -2.5394\n",
      "Total loss:  -1.3439 | PDE Loss:  -1.7929 | Function Loss:  -2.5349\n",
      "Total loss:  -1.3473 | PDE Loss:  -1.8121 | Function Loss:  -2.5297\n",
      "Total loss:  -1.3508 | PDE Loss:  -1.8257 | Function Loss:  -2.5279\n",
      "Total loss:  -1.3541 | PDE Loss:  -1.8404 | Function Loss:  -2.5257\n",
      "Total loss:  -1.3577 | PDE Loss:  -1.8453 | Function Loss:  -2.5286\n",
      "Total loss:  -1.3603 | PDE Loss:  -1.8512 | Function Loss:  -2.5297\n",
      "Total loss:  -1.3628 | PDE Loss:  -1.8531 | Function Loss:  -2.5325\n",
      "Total loss:  -1.3655 | PDE Loss:  -1.8518 | Function Loss:  -2.5371\n",
      "Total loss:  -1.3674 | PDE Loss:  -1.8531 | Function Loss:  -2.5393\n",
      "Total loss:  -1.3687 | PDE Loss:  -1.8493 | Function Loss:  -2.543\n",
      "Total loss:  -1.3695 | PDE Loss:  -1.8509 | Function Loss:  -2.5435\n",
      "Total loss:  -1.3702 | PDE Loss:  -1.8536 | Function Loss:  -2.5432\n",
      "Total loss:  -1.3714 | PDE Loss:  -1.8578 | Function Loss:  -2.5429\n",
      "Total loss:  -1.3728 | PDE Loss:  -1.8681 | Function Loss:  -2.5401\n",
      "Total loss:  -1.374 | PDE Loss:  -1.8732 | Function Loss:  -2.5394\n",
      "Total loss:  -1.3749 | PDE Loss:  -1.8778 | Function Loss:  -2.5386\n",
      "Total loss:  -1.376 | PDE Loss:  -1.8835 | Function Loss:  -2.5376\n",
      "Total loss:  -1.3769 | PDE Loss:  -1.8882 | Function Loss:  -2.5368\n",
      "Total loss:  -1.3778 | PDE Loss:  -1.8919 | Function Loss:  -2.5366\n",
      "Total loss:  -1.379 | PDE Loss:  -1.8965 | Function Loss:  -2.5362\n",
      "Total loss:  -1.3807 | PDE Loss:  -1.9005 | Function Loss:  -2.5369\n",
      "Total loss:  -1.3834 | PDE Loss:  -1.907 | Function Loss:  -2.5379\n",
      "Total loss:  -1.3866 | PDE Loss:  -1.911 | Function Loss:  -2.5408\n",
      "Total loss:  -1.3875 | PDE Loss:  -1.9173 | Function Loss:  -2.5395\n",
      "Total loss:  -1.3885 | PDE Loss:  -1.9167 | Function Loss:  -2.5411\n",
      "Total loss:  -1.3904 | PDE Loss:  -1.9189 | Function Loss:  -2.5429\n",
      "Total loss:  -1.3926 | PDE Loss:  -1.9222 | Function Loss:  -2.5446\n",
      "Total loss:  -1.3942 | PDE Loss:  -1.9255 | Function Loss:  -2.5455\n",
      "Total loss:  -1.3954 | PDE Loss:  -1.9299 | Function Loss:  -2.5455\n",
      "Total loss:  -1.3966 | PDE Loss:  -1.9327 | Function Loss:  -2.5459\n",
      "Total loss:  -1.3975 | PDE Loss:  -1.9365 | Function Loss:  -2.5456\n",
      "Total loss:  -1.3988 | PDE Loss:  -1.9427 | Function Loss:  -2.545\n",
      "Total loss:  -1.4001 | PDE Loss:  -1.9477 | Function Loss:  -2.5448\n",
      "Total loss:  -1.401 | PDE Loss:  -1.9534 | Function Loss:  -2.5438\n",
      "Total loss:  -1.4017 | PDE Loss:  -1.9558 | Function Loss:  -2.5439\n",
      "Total loss:  -1.4021 | PDE Loss:  -1.9587 | Function Loss:  -2.5433\n",
      "Total loss:  -1.4024 | PDE Loss:  -1.9605 | Function Loss:  -2.5431\n",
      "Total loss:  -1.4028 | PDE Loss:  -1.9614 | Function Loss:  -2.5432\n",
      "Total loss:  -1.4031 | PDE Loss:  -1.9625 | Function Loss:  -2.5433\n",
      "Total loss:  -1.4034 | PDE Loss:  -1.963 | Function Loss:  -2.5435\n",
      "Total loss:  -1.4037 | PDE Loss:  -1.9634 | Function Loss:  -2.5438\n",
      "Total loss:  -1.4041 | PDE Loss:  -1.9635 | Function Loss:  -2.5442\n",
      "Total loss:  -1.4045 | PDE Loss:  -1.9636 | Function Loss:  -2.5448\n",
      "Total loss:  -1.405 | PDE Loss:  -1.9632 | Function Loss:  -2.5456\n",
      "Total loss:  -1.4056 | PDE Loss:  -1.9627 | Function Loss:  -2.5466\n",
      "Total loss:  -1.406 | PDE Loss:  -1.9625 | Function Loss:  -2.5473\n",
      "Total loss:  -1.4065 | PDE Loss:  -1.9617 | Function Loss:  -2.5483\n",
      "Total loss:  -1.4069 | PDE Loss:  -1.9625 | Function Loss:  -2.5485\n",
      "Total loss:  -1.4071 | PDE Loss:  -1.9621 | Function Loss:  -2.549\n",
      "Total loss:  -1.4073 | PDE Loss:  -1.9625 | Function Loss:  -2.5491\n",
      "Total loss:  -1.4076 | PDE Loss:  -1.9631 | Function Loss:  -2.5492\n",
      "Total loss:  -1.408 | PDE Loss:  -1.9646 | Function Loss:  -2.5492\n",
      "Total loss:  -1.4086 | PDE Loss:  -1.9667 | Function Loss:  -2.5492\n",
      "Total loss:  -1.4093 | PDE Loss:  -1.9704 | Function Loss:  -2.5488\n",
      "Total loss:  -1.41 | PDE Loss:  -1.971 | Function Loss:  -2.5495\n",
      "Total loss:  -1.4108 | PDE Loss:  -1.9726 | Function Loss:  -2.55\n",
      "Total loss:  -1.4118 | PDE Loss:  -1.9726 | Function Loss:  -2.5515\n",
      "Total loss:  -1.412 | PDE Loss:  -1.9732 | Function Loss:  -2.5515\n",
      "Total loss:  -1.4123 | PDE Loss:  -1.9736 | Function Loss:  -2.5518\n",
      "Total loss:  -1.4133 | PDE Loss:  -1.9729 | Function Loss:  -2.5534\n",
      "Total loss:  -1.4138 | PDE Loss:  -1.9724 | Function Loss:  -2.5542\n",
      "Total loss:  -1.4143 | PDE Loss:  -1.9734 | Function Loss:  -2.5546\n",
      "Total loss:  -1.415 | PDE Loss:  -1.9741 | Function Loss:  -2.5553\n",
      "Total loss:  -1.4158 | PDE Loss:  -1.9749 | Function Loss:  -2.556\n",
      "Total loss:  -1.4166 | PDE Loss:  -1.9764 | Function Loss:  -2.5566\n",
      "Total loss:  -1.4179 | PDE Loss:  -1.9776 | Function Loss:  -2.558\n",
      "Total loss:  -1.4194 | PDE Loss:  -1.98 | Function Loss:  -2.5591\n",
      "Total loss:  -1.4194 | PDE Loss:  -1.9766 | Function Loss:  -2.5603\n",
      "Total loss:  -1.4202 | PDE Loss:  -1.9797 | Function Loss:  -2.5603\n",
      "Total loss:  -1.4214 | PDE Loss:  -1.9819 | Function Loss:  -2.5611\n",
      "Total loss:  -1.4225 | PDE Loss:  -1.9844 | Function Loss:  -2.5617\n",
      "Total loss:  -1.4237 | PDE Loss:  -1.9842 | Function Loss:  -2.5634\n",
      "Total loss:  -1.4241 | PDE Loss:  -1.9835 | Function Loss:  -2.5642\n",
      "Total loss:  -1.4254 | PDE Loss:  -1.9819 | Function Loss:  -2.5667\n",
      "Total loss:  -1.4273 | PDE Loss:  -1.9818 | Function Loss:  -2.5693\n",
      "Total loss:  -1.4276 | PDE Loss:  -1.9767 | Function Loss:  -2.5717\n",
      "Total loss:  -1.4285 | PDE Loss:  -1.9801 | Function Loss:  -2.5717\n",
      "Total loss:  -1.4302 | PDE Loss:  -1.9812 | Function Loss:  -2.5736\n",
      "Total loss:  -1.4313 | PDE Loss:  -1.9794 | Function Loss:  -2.5759\n",
      "Total loss:  -1.4322 | PDE Loss:  -1.9806 | Function Loss:  -2.5767\n",
      "Total loss:  -1.433 | PDE Loss:  -1.9822 | Function Loss:  -2.5771\n",
      "Total loss:  -1.4334 | PDE Loss:  -1.9835 | Function Loss:  -2.5772\n",
      "Total loss:  -1.4338 | PDE Loss:  -1.9848 | Function Loss:  -2.5772\n",
      "Total loss:  -1.434 | PDE Loss:  -1.9866 | Function Loss:  -2.5767\n",
      "Total loss:  -1.4342 | PDE Loss:  -1.9886 | Function Loss:  -2.5763\n",
      "Total loss:  -1.4347 | PDE Loss:  -1.9922 | Function Loss:  -2.5756\n",
      "Total loss:  -1.4352 | PDE Loss:  -1.9965 | Function Loss:  -2.5747\n",
      "Total loss:  -1.4357 | PDE Loss:  -2.0011 | Function Loss:  -2.5736\n",
      "Total loss:  -1.4363 | PDE Loss:  -2.0052 | Function Loss:  -2.5728\n",
      "Total loss:  -1.4368 | PDE Loss:  -2.0095 | Function Loss:  -2.572\n",
      "Total loss:  -1.4376 | PDE Loss:  -2.013 | Function Loss:  -2.5718\n",
      "Total loss:  -1.4389 | PDE Loss:  -2.0193 | Function Loss:  -2.5713\n",
      "Total loss:  -1.4404 | PDE Loss:  -2.0247 | Function Loss:  -2.5714\n",
      "Total loss:  -1.442 | PDE Loss:  -2.0281 | Function Loss:  -2.5724\n",
      "Total loss:  -1.4437 | PDE Loss:  -2.0333 | Function Loss:  -2.5729\n",
      "Total loss:  -1.445 | PDE Loss:  -2.0314 | Function Loss:  -2.5752\n",
      "Total loss:  -1.446 | PDE Loss:  -2.0301 | Function Loss:  -2.5771\n",
      "Total loss:  -1.447 | PDE Loss:  -2.0281 | Function Loss:  -2.5792\n",
      "Total loss:  -1.4477 | PDE Loss:  -2.0266 | Function Loss:  -2.5807\n",
      "Total loss:  -1.4482 | PDE Loss:  -2.0261 | Function Loss:  -2.5814\n",
      "Total loss:  -1.4485 | PDE Loss:  -2.0256 | Function Loss:  -2.5821\n",
      "Total loss:  -1.4488 | PDE Loss:  -2.0261 | Function Loss:  -2.5823\n",
      "Total loss:  -1.4491 | PDE Loss:  -2.0265 | Function Loss:  -2.5826\n",
      "Total loss:  -1.4496 | PDE Loss:  -2.0272 | Function Loss:  -2.583\n",
      "Total loss:  -1.4501 | PDE Loss:  -2.027 | Function Loss:  -2.5838\n",
      "Total loss:  -1.4507 | PDE Loss:  -2.027 | Function Loss:  -2.5846\n",
      "Total loss:  -1.4514 | PDE Loss:  -2.0245 | Function Loss:  -2.5864\n",
      "Total loss:  -1.4521 | PDE Loss:  -2.023 | Function Loss:  -2.588\n",
      "Total loss:  -1.453 | PDE Loss:  -2.0196 | Function Loss:  -2.5905\n",
      "Total loss:  -1.4543 | PDE Loss:  -2.0176 | Function Loss:  -2.5929\n",
      "Total loss:  -1.4555 | PDE Loss:  -2.0111 | Function Loss:  -2.5971\n",
      "Total loss:  -1.4569 | PDE Loss:  -2.0128 | Function Loss:  -2.5983\n",
      "Total loss:  -1.4581 | PDE Loss:  -2.0123 | Function Loss:  -2.6002\n",
      "Total loss:  -1.4595 | PDE Loss:  -2.0154 | Function Loss:  -2.601\n",
      "Total loss:  -1.4608 | PDE Loss:  -2.0203 | Function Loss:  -2.601\n",
      "Total loss:  -1.4623 | PDE Loss:  -2.0242 | Function Loss:  -2.6015\n",
      "Total loss:  -1.4638 | PDE Loss:  -2.0324 | Function Loss:  -2.6005\n",
      "Total loss:  -1.4653 | PDE Loss:  -2.0378 | Function Loss:  -2.6005\n",
      "Total loss:  -1.4675 | PDE Loss:  -2.0462 | Function Loss:  -2.6005\n",
      "Total loss:  -1.4706 | PDE Loss:  -2.059 | Function Loss:  -2.6001\n",
      "Total loss:  -1.4729 | PDE Loss:  -2.0714 | Function Loss:  -2.599\n",
      "Total loss:  -1.4746 | PDE Loss:  -2.0793 | Function Loss:  -2.5986\n",
      "Total loss:  -1.4761 | PDE Loss:  -2.0872 | Function Loss:  -2.598\n",
      "Total loss:  -1.4774 | PDE Loss:  -2.0941 | Function Loss:  -2.5975\n",
      "Total loss:  -1.4787 | PDE Loss:  -2.1021 | Function Loss:  -2.5968\n",
      "Total loss:  -1.4797 | PDE Loss:  -2.1082 | Function Loss:  -2.5962\n",
      "Total loss:  -1.4806 | PDE Loss:  -2.1136 | Function Loss:  -2.5957\n",
      "Total loss:  -1.4812 | PDE Loss:  -2.1205 | Function Loss:  -2.5944\n",
      "Total loss:  -1.4819 | PDE Loss:  -2.1225 | Function Loss:  -2.5947\n",
      "Total loss:  -1.4825 | PDE Loss:  -2.1264 | Function Loss:  -2.5943\n",
      "Total loss:  -1.4831 | PDE Loss:  -2.1281 | Function Loss:  -2.5946\n",
      "Total loss:  -1.4837 | PDE Loss:  -2.1305 | Function Loss:  -2.5947\n",
      "Total loss:  -1.4842 | PDE Loss:  -2.1319 | Function Loss:  -2.5949\n",
      "Total loss:  -1.4846 | PDE Loss:  -2.1338 | Function Loss:  -2.5949\n",
      "Total loss:  -1.4851 | PDE Loss:  -2.1351 | Function Loss:  -2.5952\n",
      "Total loss:  -1.4858 | PDE Loss:  -2.1383 | Function Loss:  -2.5951\n",
      "Total loss:  -1.4867 | PDE Loss:  -2.1412 | Function Loss:  -2.5955\n",
      "Total loss:  -1.4881 | PDE Loss:  -2.1474 | Function Loss:  -2.5955\n",
      "Total loss:  -1.4895 | PDE Loss:  -2.1534 | Function Loss:  -2.5956\n",
      "Total loss:  -1.491 | PDE Loss:  -2.1624 | Function Loss:  -2.595\n",
      "Total loss:  -1.4923 | PDE Loss:  -2.1651 | Function Loss:  -2.596\n",
      "Total loss:  -1.4937 | PDE Loss:  -2.1658 | Function Loss:  -2.5976\n",
      "Total loss:  -1.4954 | PDE Loss:  -2.1667 | Function Loss:  -2.5995\n",
      "Total loss:  -1.4968 | PDE Loss:  -2.1676 | Function Loss:  -2.6011\n",
      "Total loss:  -1.4977 | PDE Loss:  -2.1696 | Function Loss:  -2.6016\n",
      "Total loss:  -1.4988 | PDE Loss:  -2.1739 | Function Loss:  -2.6019\n",
      "Total loss:  -1.5001 | PDE Loss:  -2.1806 | Function Loss:  -2.6017\n",
      "Total loss:  -1.5012 | PDE Loss:  -2.1864 | Function Loss:  -2.6016\n",
      "Total loss:  -1.5023 | PDE Loss:  -2.1944 | Function Loss:  -2.601\n",
      "Total loss:  -1.5035 | PDE Loss:  -2.2018 | Function Loss:  -2.6006\n",
      "Total loss:  -1.5038 | PDE Loss:  -2.2168 | Function Loss:  -2.5973\n",
      "Total loss:  -1.5045 | PDE Loss:  -2.2119 | Function Loss:  -2.5993\n",
      "Total loss:  -1.506 | PDE Loss:  -2.2205 | Function Loss:  -2.5991\n",
      "Total loss:  -1.5056 | PDE Loss:  -2.2279 | Function Loss:  -2.5969\n",
      "Total loss:  -1.5069 | PDE Loss:  -2.2273 | Function Loss:  -2.5987\n",
      "Total loss:  -1.5083 | PDE Loss:  -2.2437 | Function Loss:  -2.5966\n",
      "Total loss:  -1.5092 | PDE Loss:  -2.2507 | Function Loss:  -2.5961\n",
      "Total loss:  -1.5098 | PDE Loss:  -2.251 | Function Loss:  -2.5967\n",
      "Total loss:  -1.5107 | PDE Loss:  -2.2537 | Function Loss:  -2.5972\n",
      "Total loss:  -1.5112 | PDE Loss:  -2.2531 | Function Loss:  -2.598\n",
      "Total loss:  -1.5117 | PDE Loss:  -2.2519 | Function Loss:  -2.5989\n",
      "Total loss:  -1.5121 | PDE Loss:  -2.2521 | Function Loss:  -2.5994\n",
      "Total loss:  -1.5127 | PDE Loss:  -2.2541 | Function Loss:  -2.5996\n",
      "Total loss:  -1.5132 | PDE Loss:  -2.2554 | Function Loss:  -2.6\n",
      "Total loss:  -1.5139 | PDE Loss:  -2.2597 | Function Loss:  -2.5999\n",
      "Total loss:  -1.5146 | PDE Loss:  -2.2627 | Function Loss:  -2.6001\n",
      "Total loss:  -1.5154 | PDE Loss:  -2.2662 | Function Loss:  -2.6003\n",
      "Total loss:  -1.5171 | PDE Loss:  -2.2728 | Function Loss:  -2.6009\n",
      "Total loss:  -1.5192 | PDE Loss:  -2.2783 | Function Loss:  -2.6022\n",
      "Total loss:  -1.5205 | PDE Loss:  -2.278 | Function Loss:  -2.6039\n",
      "Total loss:  -1.5213 | PDE Loss:  -2.2752 | Function Loss:  -2.6055\n",
      "Total loss:  -1.5223 | PDE Loss:  -2.2746 | Function Loss:  -2.6069\n",
      "Total loss:  -1.5231 | PDE Loss:  -2.2678 | Function Loss:  -2.6093\n",
      "Total loss:  -1.5241 | PDE Loss:  -2.2628 | Function Loss:  -2.6116\n",
      "Total loss:  -1.5249 | PDE Loss:  -2.2606 | Function Loss:  -2.613\n",
      "Total loss:  -1.526 | PDE Loss:  -2.2578 | Function Loss:  -2.6151\n",
      "Total loss:  -1.5267 | PDE Loss:  -2.2548 | Function Loss:  -2.6167\n",
      "Total loss:  -1.5274 | PDE Loss:  -2.2523 | Function Loss:  -2.618\n",
      "Total loss:  -1.5281 | PDE Loss:  -2.249 | Function Loss:  -2.6197\n",
      "Total loss:  -1.5289 | PDE Loss:  -2.2428 | Function Loss:  -2.6221\n",
      "Total loss:  -1.5301 | PDE Loss:  -2.2405 | Function Loss:  -2.6242\n",
      "Total loss:  -1.5314 | PDE Loss:  -2.2408 | Function Loss:  -2.6258\n",
      "Total loss:  -1.5323 | PDE Loss:  -2.2392 | Function Loss:  -2.6273\n",
      "Total loss:  -1.5332 | PDE Loss:  -2.2418 | Function Loss:  -2.6278\n",
      "Total loss:  -1.534 | PDE Loss:  -2.2439 | Function Loss:  -2.6282\n",
      "Total loss:  -1.5346 | PDE Loss:  -2.245 | Function Loss:  -2.6287\n",
      "Total loss:  -1.5352 | PDE Loss:  -2.2456 | Function Loss:  -2.6294\n",
      "Total loss:  -1.5363 | PDE Loss:  -2.2494 | Function Loss:  -2.6297\n",
      "Total loss:  -1.5373 | PDE Loss:  -2.2521 | Function Loss:  -2.6303\n",
      "Total loss:  -1.5383 | PDE Loss:  -2.2588 | Function Loss:  -2.63\n",
      "Total loss:  -1.5395 | PDE Loss:  -2.267 | Function Loss:  -2.6295\n",
      "Total loss:  -1.5411 | PDE Loss:  -2.2798 | Function Loss:  -2.6286\n",
      "Total loss:  -1.5421 | PDE Loss:  -2.2921 | Function Loss:  -2.6271\n",
      "Total loss:  -1.5427 | PDE Loss:  -2.2984 | Function Loss:  -2.6265\n",
      "Total loss:  -1.5434 | PDE Loss:  -2.302 | Function Loss:  -2.6266\n",
      "Total loss:  -1.5441 | PDE Loss:  -2.3027 | Function Loss:  -2.6273\n",
      "Total loss:  -1.5444 | PDE Loss:  -2.3042 | Function Loss:  -2.6274\n",
      "Total loss:  -1.545 | PDE Loss:  -2.3027 | Function Loss:  -2.6284\n",
      "Total loss:  -1.5455 | PDE Loss:  -2.3059 | Function Loss:  -2.6284\n",
      "Total loss:  -1.546 | PDE Loss:  -2.3093 | Function Loss:  -2.6283\n",
      "Total loss:  -1.5466 | PDE Loss:  -2.3124 | Function Loss:  -2.6283\n",
      "Total loss:  -1.547 | PDE Loss:  -2.3142 | Function Loss:  -2.6284\n",
      "Total loss:  -1.5474 | PDE Loss:  -2.3155 | Function Loss:  -2.6286\n",
      "Total loss:  -1.5477 | PDE Loss:  -2.3152 | Function Loss:  -2.6291\n",
      "Total loss:  -1.5481 | PDE Loss:  -2.3151 | Function Loss:  -2.6296\n",
      "Total loss:  -1.5488 | PDE Loss:  -2.3136 | Function Loss:  -2.6307\n",
      "Total loss:  -1.5496 | PDE Loss:  -2.3103 | Function Loss:  -2.6324\n",
      "Total loss:  -1.5507 | PDE Loss:  -2.3084 | Function Loss:  -2.634\n",
      "Total loss:  -1.5519 | PDE Loss:  -2.3061 | Function Loss:  -2.636\n",
      "Total loss:  -1.554 | PDE Loss:  -2.3059 | Function Loss:  -2.6386\n",
      "Total loss:  -1.5557 | PDE Loss:  -2.3051 | Function Loss:  -2.6409\n",
      "Total loss:  -1.557 | PDE Loss:  -2.3031 | Function Loss:  -2.6429\n",
      "Total loss:  -1.5583 | PDE Loss:  -2.3101 | Function Loss:  -2.6429\n",
      "Total loss:  -1.5599 | PDE Loss:  -2.3138 | Function Loss:  -2.6441\n",
      "Total loss:  -1.5618 | PDE Loss:  -2.3193 | Function Loss:  -2.6452\n",
      "Total loss:  -1.5637 | PDE Loss:  -2.3222 | Function Loss:  -2.6469\n",
      "Total loss:  -1.5656 | PDE Loss:  -2.3226 | Function Loss:  -2.6492\n",
      "Total loss:  -1.5674 | PDE Loss:  -2.3237 | Function Loss:  -2.651\n",
      "Total loss:  -1.5687 | PDE Loss:  -2.3251 | Function Loss:  -2.6524\n",
      "Total loss:  -1.5706 | PDE Loss:  -2.3277 | Function Loss:  -2.6541\n",
      "Total loss:  -1.5727 | PDE Loss:  -2.3306 | Function Loss:  -2.656\n",
      "Total loss:  -1.5749 | PDE Loss:  -2.3368 | Function Loss:  -2.6574\n",
      "Total loss:  -1.577 | PDE Loss:  -2.3369 | Function Loss:  -2.6599\n",
      "Total loss:  -1.5786 | PDE Loss:  -2.3432 | Function Loss:  -2.6606\n",
      "Total loss:  -1.5795 | PDE Loss:  -2.3473 | Function Loss:  -2.6608\n",
      "Total loss:  -1.5814 | PDE Loss:  -2.3511 | Function Loss:  -2.6622\n",
      "Total loss:  -1.5821 | PDE Loss:  -2.352 | Function Loss:  -2.6629\n",
      "Total loss:  -1.5827 | PDE Loss:  -2.3555 | Function Loss:  -2.663\n",
      "Total loss:  -1.5835 | PDE Loss:  -2.3598 | Function Loss:  -2.6631\n",
      "Total loss:  -1.5841 | PDE Loss:  -2.3629 | Function Loss:  -2.6632\n",
      "Total loss:  -1.5846 | PDE Loss:  -2.3651 | Function Loss:  -2.6634\n",
      "Total loss:  -1.5853 | PDE Loss:  -2.3675 | Function Loss:  -2.6637\n",
      "Total loss:  -1.5864 | PDE Loss:  -2.3718 | Function Loss:  -2.6642\n",
      "Total loss:  -1.5877 | PDE Loss:  -2.3769 | Function Loss:  -2.6647\n",
      "Total loss:  -1.5892 | PDE Loss:  -2.3824 | Function Loss:  -2.6655\n",
      "Total loss:  -1.5901 | PDE Loss:  -2.3881 | Function Loss:  -2.6655\n",
      "Total loss:  -1.5912 | PDE Loss:  -2.3907 | Function Loss:  -2.6663\n",
      "Total loss:  -1.5919 | PDE Loss:  -2.3913 | Function Loss:  -2.6669\n",
      "Total loss:  -1.5931 | PDE Loss:  -2.3914 | Function Loss:  -2.6683\n",
      "Total loss:  -1.5947 | PDE Loss:  -2.3889 | Function Loss:  -2.6707\n",
      "Total loss:  -1.5961 | PDE Loss:  -2.3846 | Function Loss:  -2.6732\n",
      "Total loss:  -1.5971 | PDE Loss:  -2.3817 | Function Loss:  -2.6749\n",
      "Total loss:  -1.5978 | PDE Loss:  -2.3774 | Function Loss:  -2.6767\n",
      "Total loss:  -1.5982 | PDE Loss:  -2.3692 | Function Loss:  -2.6789\n",
      "Total loss:  -1.5989 | PDE Loss:  -2.3698 | Function Loss:  -2.6795\n",
      "Total loss:  -1.5994 | PDE Loss:  -2.3694 | Function Loss:  -2.6802\n",
      "Total loss:  -1.6 | PDE Loss:  -2.3683 | Function Loss:  -2.6812\n",
      "Total loss:  -1.6008 | PDE Loss:  -2.3659 | Function Loss:  -2.6826\n",
      "Total loss:  -1.6016 | PDE Loss:  -2.3621 | Function Loss:  -2.6844\n",
      "Total loss:  -1.6024 | PDE Loss:  -2.3582 | Function Loss:  -2.6862\n",
      "Total loss:  -1.6032 | PDE Loss:  -2.3538 | Function Loss:  -2.6881\n",
      "Total loss:  -1.604 | PDE Loss:  -2.3509 | Function Loss:  -2.6897\n",
      "Total loss:  -1.6046 | PDE Loss:  -2.3498 | Function Loss:  -2.6907\n",
      "Total loss:  -1.6052 | PDE Loss:  -2.3499 | Function Loss:  -2.6914\n",
      "Total loss:  -1.6058 | PDE Loss:  -2.3502 | Function Loss:  -2.692\n",
      "Total loss:  -1.6062 | PDE Loss:  -2.3514 | Function Loss:  -2.6923\n",
      "Total loss:  -1.6066 | PDE Loss:  -2.3523 | Function Loss:  -2.6926\n",
      "Total loss:  -1.6072 | PDE Loss:  -2.3546 | Function Loss:  -2.6928\n",
      "Total loss:  -1.6085 | PDE Loss:  -2.3576 | Function Loss:  -2.6937\n",
      "Total loss:  -1.6106 | PDE Loss:  -2.3651 | Function Loss:  -2.6947\n",
      "Total loss:  -1.6128 | PDE Loss:  -2.3721 | Function Loss:  -2.6958\n",
      "Total loss:  -1.6147 | PDE Loss:  -2.3775 | Function Loss:  -2.697\n",
      "Total loss:  -1.616 | PDE Loss:  -2.3781 | Function Loss:  -2.6985\n",
      "Total loss:  -1.6169 | PDE Loss:  -2.3769 | Function Loss:  -2.6998\n",
      "Total loss:  -1.6176 | PDE Loss:  -2.3744 | Function Loss:  -2.7012\n",
      "Total loss:  -1.6182 | PDE Loss:  -2.3706 | Function Loss:  -2.7027\n",
      "Total loss:  -1.6187 | PDE Loss:  -2.3695 | Function Loss:  -2.7036\n",
      "Total loss:  -1.6196 | PDE Loss:  -2.3671 | Function Loss:  -2.7051\n",
      "Total loss:  -1.6207 | PDE Loss:  -2.3679 | Function Loss:  -2.7064\n",
      "Total loss:  -1.622 | PDE Loss:  -2.3667 | Function Loss:  -2.7082\n",
      "Total loss:  -1.6217 | PDE Loss:  -2.3777 | Function Loss:  -2.7054\n",
      "Total loss:  -1.6227 | PDE Loss:  -2.3748 | Function Loss:  -2.7073\n",
      "Total loss:  -1.6238 | PDE Loss:  -2.3753 | Function Loss:  -2.7085\n",
      "Total loss:  -1.6246 | PDE Loss:  -2.3744 | Function Loss:  -2.7096\n",
      "Total loss:  -1.6252 | PDE Loss:  -2.3764 | Function Loss:  -2.71\n",
      "Total loss:  -1.6256 | PDE Loss:  -2.3745 | Function Loss:  -2.7109\n",
      "Total loss:  -1.6259 | PDE Loss:  -2.3737 | Function Loss:  -2.7115\n",
      "Total loss:  -1.6263 | PDE Loss:  -2.3736 | Function Loss:  -2.7119\n",
      "Total loss:  -1.6266 | PDE Loss:  -2.3724 | Function Loss:  -2.7126\n",
      "Total loss:  -1.6269 | PDE Loss:  -2.3724 | Function Loss:  -2.713\n",
      "Total loss:  -1.6271 | PDE Loss:  -2.3721 | Function Loss:  -2.7132\n",
      "Total loss:  -1.6273 | PDE Loss:  -2.3713 | Function Loss:  -2.7137\n",
      "Total loss:  -1.6275 | PDE Loss:  -2.371 | Function Loss:  -2.714\n",
      "Total loss:  -1.6278 | PDE Loss:  -2.3706 | Function Loss:  -2.7143\n",
      "Total loss:  -1.628 | PDE Loss:  -2.3706 | Function Loss:  -2.7147\n",
      "Total loss:  -1.6286 | PDE Loss:  -2.3713 | Function Loss:  -2.7152\n",
      "Total loss:  -1.6295 | PDE Loss:  -2.3714 | Function Loss:  -2.7163\n",
      "Total loss:  -1.6307 | PDE Loss:  -2.3717 | Function Loss:  -2.7177\n",
      "Total loss:  -1.6322 | PDE Loss:  -2.3714 | Function Loss:  -2.7196\n",
      "Total loss:  -1.634 | PDE Loss:  -2.3696 | Function Loss:  -2.7222\n",
      "Total loss:  -1.6356 | PDE Loss:  -2.368 | Function Loss:  -2.7246\n",
      "Total loss:  -1.6362 | PDE Loss:  -2.3631 | Function Loss:  -2.7264\n",
      "Total loss:  -1.6372 | PDE Loss:  -2.3651 | Function Loss:  -2.7271\n",
      "Total loss:  -1.6378 | PDE Loss:  -2.3688 | Function Loss:  -2.7271\n",
      "Total loss:  -1.6383 | PDE Loss:  -2.3698 | Function Loss:  -2.7274\n",
      "Total loss:  -1.6386 | PDE Loss:  -2.3708 | Function Loss:  -2.7276\n",
      "Total loss:  -1.639 | PDE Loss:  -2.3714 | Function Loss:  -2.7279\n",
      "Total loss:  -1.6394 | PDE Loss:  -2.3722 | Function Loss:  -2.7282\n",
      "Total loss:  -1.6398 | PDE Loss:  -2.374 | Function Loss:  -2.7283\n",
      "Total loss:  -1.6404 | PDE Loss:  -2.3757 | Function Loss:  -2.7286\n",
      "Total loss:  -1.6412 | PDE Loss:  -2.3806 | Function Loss:  -2.7286\n",
      "Total loss:  -1.6423 | PDE Loss:  -2.3853 | Function Loss:  -2.7289\n",
      "Total loss:  -1.6439 | PDE Loss:  -2.3945 | Function Loss:  -2.7288\n",
      "Total loss:  -1.6452 | PDE Loss:  -2.401 | Function Loss:  -2.729\n",
      "Total loss:  -1.6468 | PDE Loss:  -2.4098 | Function Loss:  -2.7291\n",
      "Total loss:  -1.648 | PDE Loss:  -2.4136 | Function Loss:  -2.7297\n",
      "Total loss:  -1.6491 | PDE Loss:  -2.4152 | Function Loss:  -2.7307\n",
      "Total loss:  -1.6501 | PDE Loss:  -2.416 | Function Loss:  -2.7318\n",
      "Total loss:  -1.6512 | PDE Loss:  -2.4159 | Function Loss:  -2.7331\n",
      "Total loss:  -1.652 | PDE Loss:  -2.4142 | Function Loss:  -2.7345\n",
      "Total loss:  -1.6532 | PDE Loss:  -2.4152 | Function Loss:  -2.7357\n",
      "Total loss:  -1.6545 | PDE Loss:  -2.4172 | Function Loss:  -2.7368\n",
      "Total loss:  -1.6557 | PDE Loss:  -2.422 | Function Loss:  -2.7373\n",
      "Total loss:  -1.6568 | PDE Loss:  -2.427 | Function Loss:  -2.7376\n",
      "Total loss:  -1.658 | PDE Loss:  -2.4337 | Function Loss:  -2.7377\n",
      "Total loss:  -1.6589 | PDE Loss:  -2.4421 | Function Loss:  -2.7371\n",
      "Total loss:  -1.6601 | PDE Loss:  -2.4482 | Function Loss:  -2.7373\n",
      "Total loss:  -1.6612 | PDE Loss:  -2.4509 | Function Loss:  -2.7381\n",
      "Total loss:  -1.6622 | PDE Loss:  -2.4541 | Function Loss:  -2.7387\n",
      "Total loss:  -1.6637 | PDE Loss:  -2.4591 | Function Loss:  -2.7395\n",
      "Total loss:  -1.665 | PDE Loss:  -2.465 | Function Loss:  -2.7399\n",
      "Total loss:  -1.666 | PDE Loss:  -2.4717 | Function Loss:  -2.7399\n",
      "Total loss:  -1.6672 | PDE Loss:  -2.4805 | Function Loss:  -2.7397\n",
      "Total loss:  -1.6688 | PDE Loss:  -2.4926 | Function Loss:  -2.7394\n",
      "Total loss:  -1.6705 | PDE Loss:  -2.5081 | Function Loss:  -2.7387\n",
      "Total loss:  -1.6719 | PDE Loss:  -2.5197 | Function Loss:  -2.7384\n",
      "Total loss:  -1.673 | PDE Loss:  -2.5278 | Function Loss:  -2.7384\n",
      "Total loss:  -1.6725 | PDE Loss:  -2.531 | Function Loss:  -2.7372\n",
      "Total loss:  -1.674 | PDE Loss:  -2.5349 | Function Loss:  -2.7384\n",
      "Total loss:  -1.675 | PDE Loss:  -2.5382 | Function Loss:  -2.739\n",
      "Total loss:  -1.6761 | PDE Loss:  -2.5387 | Function Loss:  -2.7402\n",
      "Total loss:  -1.6768 | PDE Loss:  -2.5372 | Function Loss:  -2.7413\n",
      "Total loss:  -1.6774 | PDE Loss:  -2.5366 | Function Loss:  -2.742\n",
      "Total loss:  -1.6776 | PDE Loss:  -2.5377 | Function Loss:  -2.7421\n",
      "Total loss:  -1.6778 | PDE Loss:  -2.5394 | Function Loss:  -2.7421\n",
      "Total loss:  -1.678 | PDE Loss:  -2.541 | Function Loss:  -2.7421\n",
      "Total loss:  -1.6782 | PDE Loss:  -2.5409 | Function Loss:  -2.7423\n",
      "Total loss:  -1.6785 | PDE Loss:  -2.5405 | Function Loss:  -2.7427\n",
      "Total loss:  -1.6787 | PDE Loss:  -2.5381 | Function Loss:  -2.7433\n",
      "Total loss:  -1.6791 | PDE Loss:  -2.5364 | Function Loss:  -2.744\n",
      "Total loss:  -1.6793 | PDE Loss:  -2.5337 | Function Loss:  -2.7448\n",
      "Total loss:  -1.6796 | PDE Loss:  -2.5301 | Function Loss:  -2.7457\n",
      "Total loss:  -1.6799 | PDE Loss:  -2.5256 | Function Loss:  -2.7467\n",
      "Total loss:  -1.6801 | PDE Loss:  -2.522 | Function Loss:  -2.7475\n",
      "Total loss:  -1.6802 | PDE Loss:  -2.5212 | Function Loss:  -2.7478\n",
      "Total loss:  -1.6803 | PDE Loss:  -2.5204 | Function Loss:  -2.7481\n",
      "Total loss:  -1.6805 | PDE Loss:  -2.5202 | Function Loss:  -2.7483\n",
      "Total loss:  -1.6806 | PDE Loss:  -2.5198 | Function Loss:  -2.7485\n",
      "Total loss:  -1.6808 | PDE Loss:  -2.52 | Function Loss:  -2.7487\n",
      "Total loss:  -1.6809 | PDE Loss:  -2.5195 | Function Loss:  -2.7489\n",
      "Total loss:  -1.6811 | PDE Loss:  -2.5191 | Function Loss:  -2.7492\n",
      "Total loss:  -1.6813 | PDE Loss:  -2.5177 | Function Loss:  -2.7497\n",
      "Total loss:  -1.6816 | PDE Loss:  -2.5159 | Function Loss:  -2.7504\n",
      "Total loss:  -1.682 | PDE Loss:  -2.5128 | Function Loss:  -2.7514\n",
      "Total loss:  -1.6823 | PDE Loss:  -2.5119 | Function Loss:  -2.7519\n",
      "Total loss:  -1.6826 | PDE Loss:  -2.5085 | Function Loss:  -2.7529\n",
      "Total loss:  -1.683 | PDE Loss:  -2.5092 | Function Loss:  -2.7532\n",
      "Total loss:  -1.6831 | PDE Loss:  -2.5079 | Function Loss:  -2.7536\n",
      "Total loss:  -1.6833 | PDE Loss:  -2.507 | Function Loss:  -2.7539\n",
      "Total loss:  -1.6834 | PDE Loss:  -2.5063 | Function Loss:  -2.7542\n",
      "Total loss:  -1.6835 | PDE Loss:  -2.5053 | Function Loss:  -2.7545\n",
      "Total loss:  -1.6836 | PDE Loss:  -2.5041 | Function Loss:  -2.7547\n",
      "Total loss:  -1.6836 | PDE Loss:  -2.5027 | Function Loss:  -2.7551\n",
      "Total loss:  -1.6838 | PDE Loss:  -2.5005 | Function Loss:  -2.7556\n",
      "Total loss:  -1.6839 | PDE Loss:  -2.4984 | Function Loss:  -2.7562\n",
      "Total loss:  -1.6841 | PDE Loss:  -2.4958 | Function Loss:  -2.7568\n",
      "Total loss:  -1.6843 | PDE Loss:  -2.4938 | Function Loss:  -2.7575\n",
      "Total loss:  -1.6846 | PDE Loss:  -2.4907 | Function Loss:  -2.7584\n",
      "Total loss:  -1.685 | PDE Loss:  -2.4898 | Function Loss:  -2.7591\n",
      "Total loss:  -1.6851 | PDE Loss:  -2.4864 | Function Loss:  -2.7598\n",
      "Total loss:  -1.6853 | PDE Loss:  -2.4884 | Function Loss:  -2.7597\n",
      "Total loss:  -1.6857 | PDE Loss:  -2.4897 | Function Loss:  -2.7599\n",
      "Total loss:  -1.6866 | PDE Loss:  -2.4951 | Function Loss:  -2.76\n",
      "Total loss:  -1.6873 | PDE Loss:  -2.4961 | Function Loss:  -2.7605\n",
      "Total loss:  -1.6878 | PDE Loss:  -2.5009 | Function Loss:  -2.7603\n",
      "Total loss:  -1.688 | PDE Loss:  -2.5026 | Function Loss:  -2.7603\n",
      "Total loss:  -1.6882 | PDE Loss:  -2.503 | Function Loss:  -2.7604\n",
      "Total loss:  -1.6883 | PDE Loss:  -2.5028 | Function Loss:  -2.7606\n",
      "Total loss:  -1.6885 | PDE Loss:  -2.5021 | Function Loss:  -2.7609\n",
      "Total loss:  -1.6887 | PDE Loss:  -2.501 | Function Loss:  -2.7613\n",
      "Total loss:  -1.6889 | PDE Loss:  -2.4995 | Function Loss:  -2.7619\n",
      "Total loss:  -1.6892 | PDE Loss:  -2.4982 | Function Loss:  -2.7625\n",
      "Total loss:  -1.6895 | PDE Loss:  -2.4966 | Function Loss:  -2.7631\n",
      "Total loss:  -1.6898 | PDE Loss:  -2.4955 | Function Loss:  -2.7636\n",
      "Total loss:  -1.69 | PDE Loss:  -2.4942 | Function Loss:  -2.7642\n",
      "Total loss:  -1.6903 | PDE Loss:  -2.4947 | Function Loss:  -2.7644\n",
      "Total loss:  -1.6905 | PDE Loss:  -2.4953 | Function Loss:  -2.7645\n",
      "Total loss:  -1.6907 | PDE Loss:  -2.4967 | Function Loss:  -2.7645\n",
      "Total loss:  -1.691 | PDE Loss:  -2.4991 | Function Loss:  -2.7644\n",
      "Total loss:  -1.6913 | PDE Loss:  -2.5015 | Function Loss:  -2.7644\n",
      "Total loss:  -1.6918 | PDE Loss:  -2.5049 | Function Loss:  -2.7643\n",
      "Total loss:  -1.6924 | PDE Loss:  -2.507 | Function Loss:  -2.7646\n",
      "Total loss:  -1.6926 | PDE Loss:  -2.5088 | Function Loss:  -2.7646\n",
      "Total loss:  -1.693 | PDE Loss:  -2.5087 | Function Loss:  -2.7651\n",
      "Total loss:  -1.6935 | PDE Loss:  -2.508 | Function Loss:  -2.7657\n",
      "Total loss:  -1.694 | PDE Loss:  -2.5077 | Function Loss:  -2.7665\n",
      "Total loss:  -1.6948 | PDE Loss:  -2.5071 | Function Loss:  -2.7674\n",
      "Total loss:  -1.6954 | PDE Loss:  -2.507 | Function Loss:  -2.7682\n",
      "Total loss:  -1.696 | PDE Loss:  -2.5056 | Function Loss:  -2.7691\n",
      "Total loss:  -1.696 | PDE Loss:  -2.5046 | Function Loss:  -2.7694\n",
      "Total loss:  -1.6962 | PDE Loss:  -2.5053 | Function Loss:  -2.7695\n",
      "Total loss:  -1.6965 | PDE Loss:  -2.5049 | Function Loss:  -2.7698\n",
      "Total loss:  -1.6967 | PDE Loss:  -2.5054 | Function Loss:  -2.7701\n",
      "Total loss:  -1.697 | PDE Loss:  -2.5054 | Function Loss:  -2.7704\n",
      "Total loss:  -1.6973 | PDE Loss:  -2.5051 | Function Loss:  -2.7708\n",
      "Total loss:  -1.6977 | PDE Loss:  -2.5047 | Function Loss:  -2.7713\n",
      "Total loss:  -1.698 | PDE Loss:  -2.5042 | Function Loss:  -2.7718\n",
      "Total loss:  -1.6982 | PDE Loss:  -2.5043 | Function Loss:  -2.772\n",
      "Total loss:  -1.6984 | PDE Loss:  -2.5048 | Function Loss:  -2.7722\n",
      "Total loss:  -1.6987 | PDE Loss:  -2.5052 | Function Loss:  -2.7724\n",
      "Total loss:  -1.699 | PDE Loss:  -2.5065 | Function Loss:  -2.7725\n",
      "Total loss:  -1.6991 | PDE Loss:  -2.5069 | Function Loss:  -2.7726\n",
      "Total loss:  -1.6994 | PDE Loss:  -2.5077 | Function Loss:  -2.7728\n",
      "Total loss:  -1.6997 | PDE Loss:  -2.5079 | Function Loss:  -2.7731\n",
      "Total loss:  -1.6999 | PDE Loss:  -2.5079 | Function Loss:  -2.7733\n",
      "Total loss:  -1.7002 | PDE Loss:  -2.5071 | Function Loss:  -2.7739\n",
      "Total loss:  -1.7007 | PDE Loss:  -2.5049 | Function Loss:  -2.7748\n",
      "Total loss:  -1.7005 | PDE Loss:  -2.4981 | Function Loss:  -2.7759\n",
      "Total loss:  -1.701 | PDE Loss:  -2.5028 | Function Loss:  -2.7756\n",
      "Total loss:  -1.7016 | PDE Loss:  -2.4989 | Function Loss:  -2.7771\n",
      "Total loss:  -1.7026 | PDE Loss:  -2.4947 | Function Loss:  -2.779\n",
      "Total loss:  -1.7032 | PDE Loss:  -2.4863 | Function Loss:  -2.7814\n",
      "Total loss:  -1.7039 | PDE Loss:  -2.4812 | Function Loss:  -2.7833\n",
      "Total loss:  -1.7042 | PDE Loss:  -2.4775 | Function Loss:  -2.7844\n",
      "Total loss:  -1.7045 | PDE Loss:  -2.4736 | Function Loss:  -2.7856\n",
      "Total loss:  -1.7047 | PDE Loss:  -2.472 | Function Loss:  -2.786\n",
      "Total loss:  -1.7048 | PDE Loss:  -2.4699 | Function Loss:  -2.7866\n",
      "Total loss:  -1.7049 | PDE Loss:  -2.4686 | Function Loss:  -2.787\n",
      "Total loss:  -1.7051 | PDE Loss:  -2.4676 | Function Loss:  -2.7874\n",
      "Total loss:  -1.7053 | PDE Loss:  -2.4659 | Function Loss:  -2.7881\n",
      "Total loss:  -1.7055 | PDE Loss:  -2.4657 | Function Loss:  -2.7883\n",
      "Total loss:  -1.7057 | PDE Loss:  -2.4644 | Function Loss:  -2.7888\n",
      "Total loss:  -1.7058 | PDE Loss:  -2.4644 | Function Loss:  -2.789\n",
      "Total loss:  -1.706 | PDE Loss:  -2.4647 | Function Loss:  -2.7892\n",
      "Total loss:  -1.7063 | PDE Loss:  -2.4655 | Function Loss:  -2.7894\n",
      "Total loss:  -1.7066 | PDE Loss:  -2.4656 | Function Loss:  -2.7897\n",
      "Total loss:  -1.707 | PDE Loss:  -2.4678 | Function Loss:  -2.7897\n",
      "Total loss:  -1.7073 | PDE Loss:  -2.4668 | Function Loss:  -2.7903\n",
      "Total loss:  -1.7077 | PDE Loss:  -2.4666 | Function Loss:  -2.7908\n",
      "Total loss:  -1.7083 | PDE Loss:  -2.4678 | Function Loss:  -2.7913\n",
      "Total loss:  -1.7087 | PDE Loss:  -2.4659 | Function Loss:  -2.7923\n",
      "Total loss:  -1.7091 | PDE Loss:  -2.4666 | Function Loss:  -2.7925\n",
      "Total loss:  -1.7096 | PDE Loss:  -2.468 | Function Loss:  -2.7929\n",
      "Total loss:  -1.71 | PDE Loss:  -2.4688 | Function Loss:  -2.7932\n",
      "Total loss:  -1.7104 | PDE Loss:  -2.4689 | Function Loss:  -2.7936\n",
      "Total loss:  -1.7107 | PDE Loss:  -2.4705 | Function Loss:  -2.7937\n",
      "Total loss:  -1.7112 | PDE Loss:  -2.4706 | Function Loss:  -2.7942\n",
      "Total loss:  -1.7119 | PDE Loss:  -2.4706 | Function Loss:  -2.795\n",
      "Total loss:  -1.7132 | PDE Loss:  -2.4714 | Function Loss:  -2.7964\n",
      "Total loss:  -1.7144 | PDE Loss:  -2.4768 | Function Loss:  -2.7968\n",
      "Total loss:  -1.7158 | PDE Loss:  -2.4738 | Function Loss:  -2.7991\n",
      "Total loss:  -1.7171 | PDE Loss:  -2.474 | Function Loss:  -2.8006\n",
      "Total loss:  -1.7184 | PDE Loss:  -2.4727 | Function Loss:  -2.8025\n",
      "Total loss:  -1.7195 | PDE Loss:  -2.4758 | Function Loss:  -2.8032\n",
      "Total loss:  -1.7208 | PDE Loss:  -2.4801 | Function Loss:  -2.8038\n",
      "Total loss:  -1.7216 | PDE Loss:  -2.483 | Function Loss:  -2.8043\n",
      "Total loss:  -1.7227 | PDE Loss:  -2.4886 | Function Loss:  -2.8043\n",
      "Total loss:  -1.7238 | PDE Loss:  -2.4941 | Function Loss:  -2.8045\n",
      "Total loss:  -1.7245 | PDE Loss:  -2.4968 | Function Loss:  -2.8049\n",
      "Total loss:  -1.7251 | PDE Loss:  -2.4998 | Function Loss:  -2.8049\n",
      "Total loss:  -1.7255 | PDE Loss:  -2.5015 | Function Loss:  -2.8051\n",
      "Total loss:  -1.7259 | PDE Loss:  -2.5058 | Function Loss:  -2.8047\n",
      "Total loss:  -1.726 | PDE Loss:  -2.5076 | Function Loss:  -2.8045\n",
      "Total loss:  -1.7261 | PDE Loss:  -2.5095 | Function Loss:  -2.8043\n",
      "Total loss:  -1.7263 | PDE Loss:  -2.5114 | Function Loss:  -2.8041\n",
      "Total loss:  -1.7264 | PDE Loss:  -2.5138 | Function Loss:  -2.8038\n",
      "Total loss:  -1.7266 | PDE Loss:  -2.5171 | Function Loss:  -2.8034\n",
      "Total loss:  -1.7268 | PDE Loss:  -2.5186 | Function Loss:  -2.8033\n",
      "Total loss:  -1.7272 | PDE Loss:  -2.5207 | Function Loss:  -2.8033\n",
      "Total loss:  -1.7276 | PDE Loss:  -2.5222 | Function Loss:  -2.8036\n",
      "Total loss:  -1.7279 | PDE Loss:  -2.5225 | Function Loss:  -2.8039\n",
      "Total loss:  -1.7281 | PDE Loss:  -2.5222 | Function Loss:  -2.8042\n",
      "Total loss:  -1.7283 | PDE Loss:  -2.5214 | Function Loss:  -2.8045\n",
      "Total loss:  -1.7283 | PDE Loss:  -2.5201 | Function Loss:  -2.8048\n",
      "Total loss:  -1.7284 | PDE Loss:  -2.5197 | Function Loss:  -2.805\n",
      "Total loss:  -1.7284 | PDE Loss:  -2.5189 | Function Loss:  -2.8052\n",
      "Total loss:  -1.7285 | PDE Loss:  -2.5182 | Function Loss:  -2.8054\n",
      "Total loss:  -1.7286 | PDE Loss:  -2.518 | Function Loss:  -2.8055\n",
      "Total loss:  -1.7286 | PDE Loss:  -2.5177 | Function Loss:  -2.8057\n",
      "Total loss:  -1.7287 | PDE Loss:  -2.518 | Function Loss:  -2.8057\n",
      "Total loss:  -1.7288 | PDE Loss:  -2.5187 | Function Loss:  -2.8057\n",
      "Total loss:  -1.729 | PDE Loss:  -2.5198 | Function Loss:  -2.8057\n",
      "Total loss:  -1.7291 | PDE Loss:  -2.5217 | Function Loss:  -2.8055\n",
      "Total loss:  -1.7293 | PDE Loss:  -2.523 | Function Loss:  -2.8054\n",
      "Total loss:  -1.7294 | PDE Loss:  -2.5236 | Function Loss:  -2.8054\n",
      "Total loss:  -1.7297 | PDE Loss:  -2.5254 | Function Loss:  -2.8054\n",
      "Total loss:  -1.73 | PDE Loss:  -2.5274 | Function Loss:  -2.8055\n",
      "Total loss:  -1.7304 | PDE Loss:  -2.5293 | Function Loss:  -2.8056\n",
      "Total loss:  -1.731 | PDE Loss:  -2.5325 | Function Loss:  -2.8056\n",
      "Total loss:  -1.7316 | PDE Loss:  -2.5351 | Function Loss:  -2.8058\n",
      "Total loss:  -1.7319 | PDE Loss:  -2.5368 | Function Loss:  -2.8059\n",
      "Total loss:  -1.7326 | PDE Loss:  -2.5376 | Function Loss:  -2.8066\n",
      "Total loss:  -1.7332 | PDE Loss:  -2.5379 | Function Loss:  -2.8073\n",
      "Total loss:  -1.7341 | PDE Loss:  -2.5365 | Function Loss:  -2.8086\n",
      "Total loss:  -1.7349 | PDE Loss:  -2.5369 | Function Loss:  -2.8095\n",
      "Total loss:  -1.7359 | PDE Loss:  -2.5363 | Function Loss:  -2.8107\n",
      "Total loss:  -1.7365 | PDE Loss:  -2.5347 | Function Loss:  -2.8118\n",
      "Total loss:  -1.737 | PDE Loss:  -2.5331 | Function Loss:  -2.8127\n",
      "Total loss:  -1.7378 | PDE Loss:  -2.5373 | Function Loss:  -2.8128\n",
      "Total loss:  -1.7387 | PDE Loss:  -2.5441 | Function Loss:  -2.8126\n",
      "Total loss:  -1.7392 | PDE Loss:  -2.5472 | Function Loss:  -2.8126\n",
      "Total loss:  -1.7402 | PDE Loss:  -2.5542 | Function Loss:  -2.8126\n",
      "Total loss:  -1.7414 | PDE Loss:  -2.5675 | Function Loss:  -2.8116\n",
      "Total loss:  -1.7428 | PDE Loss:  -2.5773 | Function Loss:  -2.8115\n",
      "Total loss:  -1.744 | PDE Loss:  -2.5882 | Function Loss:  -2.8111\n",
      "Total loss:  -1.7459 | PDE Loss:  -2.6059 | Function Loss:  -2.8104\n",
      "Total loss:  -1.7475 | PDE Loss:  -2.617 | Function Loss:  -2.8105\n",
      "Total loss:  -1.7483 | PDE Loss:  -2.6194 | Function Loss:  -2.8111\n",
      "Total loss:  -1.7493 | PDE Loss:  -2.6331 | Function Loss:  -2.8101\n",
      "Total loss:  -1.7499 | PDE Loss:  -2.6368 | Function Loss:  -2.8102\n",
      "Total loss:  -1.7504 | PDE Loss:  -2.641 | Function Loss:  -2.8102\n",
      "Total loss:  -1.751 | PDE Loss:  -2.648 | Function Loss:  -2.8099\n",
      "Total loss:  -1.7517 | PDE Loss:  -2.6517 | Function Loss:  -2.8101\n",
      "Total loss:  -1.7521 | PDE Loss:  -2.655 | Function Loss:  -2.8102\n",
      "Total loss:  -1.7526 | PDE Loss:  -2.6539 | Function Loss:  -2.8108\n",
      "Total loss:  -1.7528 | PDE Loss:  -2.6533 | Function Loss:  -2.8112\n",
      "Total loss:  -1.753 | PDE Loss:  -2.6519 | Function Loss:  -2.8116\n",
      "Total loss:  -1.7533 | PDE Loss:  -2.6508 | Function Loss:  -2.8121\n",
      "Total loss:  -1.7536 | PDE Loss:  -2.6493 | Function Loss:  -2.8126\n",
      "Total loss:  -1.7538 | PDE Loss:  -2.6515 | Function Loss:  -2.8125\n",
      "Total loss:  -1.754 | PDE Loss:  -2.6529 | Function Loss:  -2.8126\n",
      "Total loss:  -1.7543 | PDE Loss:  -2.6568 | Function Loss:  -2.8124\n",
      "Total loss:  -1.7548 | PDE Loss:  -2.6633 | Function Loss:  -2.812\n",
      "Total loss:  -1.7554 | PDE Loss:  -2.6721 | Function Loss:  -2.8114\n",
      "Total loss:  -1.756 | PDE Loss:  -2.6832 | Function Loss:  -2.8107\n",
      "Total loss:  -1.7566 | PDE Loss:  -2.6905 | Function Loss:  -2.8104\n",
      "Total loss:  -1.7575 | PDE Loss:  -2.6997 | Function Loss:  -2.8102\n",
      "Total loss:  -1.7585 | PDE Loss:  -2.7099 | Function Loss:  -2.81\n",
      "Total loss:  -1.7592 | PDE Loss:  -2.713 | Function Loss:  -2.8104\n",
      "Total loss:  -1.7597 | PDE Loss:  -2.7139 | Function Loss:  -2.8109\n",
      "Total loss:  -1.7608 | PDE Loss:  -2.7119 | Function Loss:  -2.8123\n",
      "Total loss:  -1.7619 | PDE Loss:  -2.7146 | Function Loss:  -2.8133\n",
      "Total loss:  -1.7626 | PDE Loss:  -2.7138 | Function Loss:  -2.8141\n",
      "Total loss:  -1.763 | PDE Loss:  -2.7198 | Function Loss:  -2.8138\n",
      "Total loss:  -1.7633 | PDE Loss:  -2.7195 | Function Loss:  -2.8142\n",
      "Total loss:  -1.7636 | PDE Loss:  -2.7222 | Function Loss:  -2.8142\n",
      "Total loss:  -1.7645 | PDE Loss:  -2.7291 | Function Loss:  -2.8143\n",
      "Total loss:  -1.7653 | PDE Loss:  -2.7344 | Function Loss:  -2.8147\n",
      "Total loss:  -1.766 | PDE Loss:  -2.7379 | Function Loss:  -2.815\n",
      "Total loss:  -1.7669 | PDE Loss:  -2.7367 | Function Loss:  -2.8162\n",
      "Total loss:  -1.7678 | PDE Loss:  -2.7332 | Function Loss:  -2.8176\n",
      "Total loss:  -1.7692 | PDE Loss:  -2.7272 | Function Loss:  -2.8199\n",
      "Total loss:  -1.7705 | PDE Loss:  -2.7198 | Function Loss:  -2.8222\n",
      "Total loss:  -1.7716 | PDE Loss:  -2.7074 | Function Loss:  -2.8251\n",
      "Total loss:  -1.7726 | PDE Loss:  -2.6983 | Function Loss:  -2.8275\n",
      "Total loss:  -1.7729 | PDE Loss:  -2.6901 | Function Loss:  -2.8289\n",
      "Total loss:  -1.7737 | PDE Loss:  -2.6853 | Function Loss:  -2.8305\n",
      "Total loss:  -1.774 | PDE Loss:  -2.6788 | Function Loss:  -2.8318\n",
      "Total loss:  -1.7747 | PDE Loss:  -2.6774 | Function Loss:  -2.8327\n",
      "Total loss:  -1.7752 | PDE Loss:  -2.6757 | Function Loss:  -2.8336\n",
      "Total loss:  -1.776 | PDE Loss:  -2.6677 | Function Loss:  -2.8356\n",
      "Total loss:  -1.7766 | PDE Loss:  -2.661 | Function Loss:  -2.8373\n",
      "Total loss:  -1.7771 | PDE Loss:  -2.6561 | Function Loss:  -2.8387\n",
      "Total loss:  -1.7777 | PDE Loss:  -2.6539 | Function Loss:  -2.8397\n",
      "Total loss:  -1.7782 | PDE Loss:  -2.6476 | Function Loss:  -2.8413\n",
      "Total loss:  -1.7786 | PDE Loss:  -2.649 | Function Loss:  -2.8415\n",
      "Total loss:  -1.7789 | PDE Loss:  -2.6462 | Function Loss:  -2.8423\n",
      "Total loss:  -1.7793 | PDE Loss:  -2.648 | Function Loss:  -2.8425\n",
      "Total loss:  -1.78 | PDE Loss:  -2.6521 | Function Loss:  -2.8426\n",
      "Total loss:  -1.7807 | PDE Loss:  -2.6538 | Function Loss:  -2.8432\n",
      "Total loss:  -1.7812 | PDE Loss:  -2.6555 | Function Loss:  -2.8435\n",
      "Total loss:  -1.7816 | PDE Loss:  -2.6587 | Function Loss:  -2.8434\n",
      "Total loss:  -1.7818 | PDE Loss:  -2.6592 | Function Loss:  -2.8436\n",
      "Total loss:  -1.7822 | PDE Loss:  -2.6611 | Function Loss:  -2.8438\n",
      "Total loss:  -1.7828 | PDE Loss:  -2.6657 | Function Loss:  -2.8437\n",
      "Total loss:  -1.7835 | PDE Loss:  -2.6698 | Function Loss:  -2.8439\n",
      "Total loss:  -1.7842 | PDE Loss:  -2.6763 | Function Loss:  -2.8438\n",
      "Total loss:  -1.7848 | PDE Loss:  -2.6786 | Function Loss:  -2.8441\n",
      "Total loss:  -1.7854 | PDE Loss:  -2.6814 | Function Loss:  -2.8444\n",
      "Total loss:  -1.7858 | PDE Loss:  -2.6825 | Function Loss:  -2.8447\n",
      "Total loss:  -1.7861 | PDE Loss:  -2.6843 | Function Loss:  -2.8448\n",
      "Total loss:  -1.7865 | PDE Loss:  -2.687 | Function Loss:  -2.8449\n",
      "Total loss:  -1.787 | PDE Loss:  -2.6927 | Function Loss:  -2.8447\n",
      "Total loss:  -1.7876 | PDE Loss:  -2.6968 | Function Loss:  -2.8447\n",
      "Total loss:  -1.7881 | PDE Loss:  -2.7043 | Function Loss:  -2.8443\n",
      "Total loss:  -1.7886 | PDE Loss:  -2.7086 | Function Loss:  -2.8442\n",
      "Total loss:  -1.789 | PDE Loss:  -2.7086 | Function Loss:  -2.8446\n",
      "Total loss:  -1.7892 | PDE Loss:  -2.711 | Function Loss:  -2.8446\n",
      "Total loss:  -1.7895 | PDE Loss:  -2.7109 | Function Loss:  -2.8449\n",
      "Total loss:  -1.7898 | PDE Loss:  -2.7102 | Function Loss:  -2.8454\n",
      "Total loss:  -1.7902 | PDE Loss:  -2.7088 | Function Loss:  -2.846\n",
      "Total loss:  -1.7906 | PDE Loss:  -2.7075 | Function Loss:  -2.8466\n",
      "Total loss:  -1.791 | PDE Loss:  -2.7076 | Function Loss:  -2.8471\n",
      "Total loss:  -1.7914 | PDE Loss:  -2.7089 | Function Loss:  -2.8474\n",
      "Total loss:  -1.7918 | PDE Loss:  -2.7098 | Function Loss:  -2.8478\n",
      "Total loss:  -1.7922 | PDE Loss:  -2.7116 | Function Loss:  -2.8479\n",
      "Total loss:  -1.7924 | PDE Loss:  -2.7118 | Function Loss:  -2.8482\n",
      "Total loss:  -1.7926 | PDE Loss:  -2.7118 | Function Loss:  -2.8483\n",
      "Total loss:  -1.7928 | PDE Loss:  -2.711 | Function Loss:  -2.8486\n",
      "Total loss:  -1.7929 | PDE Loss:  -2.707 | Function Loss:  -2.8493\n",
      "Total loss:  -1.793 | PDE Loss:  -2.7068 | Function Loss:  -2.8495\n",
      "Total loss:  -1.7931 | PDE Loss:  -2.7059 | Function Loss:  -2.8497\n",
      "Total loss:  -1.7932 | PDE Loss:  -2.7047 | Function Loss:  -2.85\n",
      "Total loss:  -1.7933 | PDE Loss:  -2.7036 | Function Loss:  -2.8502\n",
      "Total loss:  -1.7934 | PDE Loss:  -2.7028 | Function Loss:  -2.8504\n",
      "Total loss:  -1.7936 | PDE Loss:  -2.7037 | Function Loss:  -2.8506\n",
      "Total loss:  -1.794 | PDE Loss:  -2.7022 | Function Loss:  -2.8513\n",
      "Total loss:  -1.7945 | PDE Loss:  -2.705 | Function Loss:  -2.8515\n",
      "Total loss:  -1.7952 | PDE Loss:  -2.7094 | Function Loss:  -2.8516\n",
      "Total loss:  -1.7961 | PDE Loss:  -2.7163 | Function Loss:  -2.8517\n",
      "Total loss:  -1.7968 | PDE Loss:  -2.7219 | Function Loss:  -2.8517\n",
      "Total loss:  -1.7973 | PDE Loss:  -2.7277 | Function Loss:  -2.8515\n",
      "Total loss:  -1.7976 | PDE Loss:  -2.73 | Function Loss:  -2.8516\n",
      "Total loss:  -1.7977 | PDE Loss:  -2.7308 | Function Loss:  -2.8516\n",
      "Total loss:  -1.7979 | PDE Loss:  -2.7319 | Function Loss:  -2.8517\n",
      "Total loss:  -1.7981 | PDE Loss:  -2.7327 | Function Loss:  -2.8517\n",
      "Total loss:  -1.7984 | PDE Loss:  -2.7351 | Function Loss:  -2.8518\n",
      "Total loss:  -1.7988 | PDE Loss:  -2.7368 | Function Loss:  -2.8521\n",
      "Total loss:  -1.7995 | PDE Loss:  -2.7414 | Function Loss:  -2.8522\n",
      "Total loss:  -1.8003 | PDE Loss:  -2.7449 | Function Loss:  -2.8527\n",
      "Total loss:  -1.8011 | PDE Loss:  -2.7474 | Function Loss:  -2.8533\n",
      "Total loss:  -1.8023 | PDE Loss:  -2.7491 | Function Loss:  -2.8544\n",
      "Total loss:  -1.8031 | PDE Loss:  -2.7533 | Function Loss:  -2.8547\n",
      "Total loss:  -1.8038 | PDE Loss:  -2.75 | Function Loss:  -2.8559\n",
      "Total loss:  -1.8041 | PDE Loss:  -2.7505 | Function Loss:  -2.8562\n",
      "Total loss:  -1.8044 | PDE Loss:  -2.7511 | Function Loss:  -2.8565\n",
      "Total loss:  -1.8046 | PDE Loss:  -2.7501 | Function Loss:  -2.8569\n",
      "Total loss:  -1.8048 | PDE Loss:  -2.7499 | Function Loss:  -2.8572\n",
      "Total loss:  -1.8053 | PDE Loss:  -2.7474 | Function Loss:  -2.858\n",
      "Total loss:  -1.8059 | PDE Loss:  -2.7446 | Function Loss:  -2.859\n",
      "Total loss:  -1.8063 | PDE Loss:  -2.7392 | Function Loss:  -2.8602\n",
      "Total loss:  -1.8068 | PDE Loss:  -2.7341 | Function Loss:  -2.8615\n",
      "Total loss:  -1.8074 | PDE Loss:  -2.727 | Function Loss:  -2.8631\n",
      "Total loss:  -1.808 | PDE Loss:  -2.7172 | Function Loss:  -2.8651\n",
      "Total loss:  -1.8084 | PDE Loss:  -2.7088 | Function Loss:  -2.8668\n",
      "Total loss:  -1.8088 | PDE Loss:  -2.7023 | Function Loss:  -2.8682\n",
      "Total loss:  -1.8093 | PDE Loss:  -2.6939 | Function Loss:  -2.87\n",
      "Total loss:  -1.8098 | PDE Loss:  -2.6821 | Function Loss:  -2.8724\n",
      "Total loss:  -1.8103 | PDE Loss:  -2.6742 | Function Loss:  -2.8742\n",
      "Total loss:  -1.8107 | PDE Loss:  -2.666 | Function Loss:  -2.8759\n",
      "Total loss:  -1.8111 | PDE Loss:  -2.6602 | Function Loss:  -2.8774\n",
      "Total loss:  -1.8115 | PDE Loss:  -2.6532 | Function Loss:  -2.879\n",
      "Total loss:  -1.8118 | PDE Loss:  -2.652 | Function Loss:  -2.8796\n",
      "Total loss:  -1.8122 | PDE Loss:  -2.6515 | Function Loss:  -2.8801\n",
      "Total loss:  -1.8126 | PDE Loss:  -2.6564 | Function Loss:  -2.8798\n",
      "Total loss:  -1.813 | PDE Loss:  -2.6615 | Function Loss:  -2.8794\n",
      "Total loss:  -1.8134 | PDE Loss:  -2.6681 | Function Loss:  -2.8787\n",
      "Total loss:  -1.8137 | PDE Loss:  -2.6734 | Function Loss:  -2.8783\n",
      "Total loss:  -1.814 | PDE Loss:  -2.6788 | Function Loss:  -2.8777\n",
      "Total loss:  -1.8142 | PDE Loss:  -2.6813 | Function Loss:  -2.8776\n",
      "Total loss:  -1.8144 | PDE Loss:  -2.6845 | Function Loss:  -2.8773\n",
      "Total loss:  -1.8147 | PDE Loss:  -2.6878 | Function Loss:  -2.8772\n",
      "Total loss:  -1.8152 | PDE Loss:  -2.6925 | Function Loss:  -2.877\n",
      "Total loss:  -1.8157 | PDE Loss:  -2.7007 | Function Loss:  -2.8763\n",
      "Total loss:  -1.8161 | PDE Loss:  -2.7061 | Function Loss:  -2.8761\n",
      "Total loss:  -1.8166 | PDE Loss:  -2.7134 | Function Loss:  -2.8755\n",
      "Total loss:  -1.817 | PDE Loss:  -2.7177 | Function Loss:  -2.8754\n",
      "Total loss:  -1.8174 | PDE Loss:  -2.7186 | Function Loss:  -2.8756\n",
      "Total loss:  -1.8176 | PDE Loss:  -2.719 | Function Loss:  -2.8758\n",
      "Total loss:  -1.8178 | PDE Loss:  -2.719 | Function Loss:  -2.8761\n",
      "Total loss:  -1.8179 | PDE Loss:  -2.7187 | Function Loss:  -2.8762\n",
      "Total loss:  -1.818 | PDE Loss:  -2.7184 | Function Loss:  -2.8764\n",
      "Total loss:  -1.8182 | PDE Loss:  -2.7171 | Function Loss:  -2.8768\n",
      "Total loss:  -1.8183 | PDE Loss:  -2.7164 | Function Loss:  -2.877\n",
      "Total loss:  -1.8183 | PDE Loss:  -2.7147 | Function Loss:  -2.8773\n",
      "Total loss:  -1.8184 | PDE Loss:  -2.7136 | Function Loss:  -2.8775\n",
      "Total loss:  -1.8185 | PDE Loss:  -2.7117 | Function Loss:  -2.878\n",
      "Total loss:  -1.8187 | PDE Loss:  -2.7104 | Function Loss:  -2.8784\n",
      "Total loss:  -1.8189 | PDE Loss:  -2.7084 | Function Loss:  -2.8789\n",
      "Total loss:  -1.8191 | PDE Loss:  -2.7059 | Function Loss:  -2.8795\n",
      "Total loss:  -1.8193 | PDE Loss:  -2.705 | Function Loss:  -2.8798\n",
      "Total loss:  -1.8195 | PDE Loss:  -2.7034 | Function Loss:  -2.8803\n",
      "Total loss:  -1.8198 | PDE Loss:  -2.7036 | Function Loss:  -2.8806\n",
      "Total loss:  -1.8202 | PDE Loss:  -2.7047 | Function Loss:  -2.8809\n",
      "Total loss:  -1.8206 | PDE Loss:  -2.7073 | Function Loss:  -2.881\n",
      "Total loss:  -1.8211 | PDE Loss:  -2.7118 | Function Loss:  -2.8809\n",
      "Total loss:  -1.8217 | PDE Loss:  -2.7205 | Function Loss:  -2.8803\n",
      "Total loss:  -1.8221 | PDE Loss:  -2.7255 | Function Loss:  -2.88\n",
      "Total loss:  -1.8224 | PDE Loss:  -2.7254 | Function Loss:  -2.8804\n",
      "Total loss:  -1.823 | PDE Loss:  -2.7285 | Function Loss:  -2.8807\n",
      "Total loss:  -1.8238 | PDE Loss:  -2.7335 | Function Loss:  -2.8808\n",
      "Total loss:  -1.8247 | PDE Loss:  -2.7338 | Function Loss:  -2.8818\n",
      "Total loss:  -1.8251 | PDE Loss:  -2.7365 | Function Loss:  -2.8819\n",
      "Total loss:  -1.8257 | PDE Loss:  -2.7343 | Function Loss:  -2.8829\n",
      "Total loss:  -1.8262 | PDE Loss:  -2.7253 | Function Loss:  -2.8848\n",
      "Total loss:  -1.8266 | PDE Loss:  -2.7219 | Function Loss:  -2.8858\n",
      "Total loss:  -1.8271 | PDE Loss:  -2.7174 | Function Loss:  -2.887\n",
      "Total loss:  -1.8274 | PDE Loss:  -2.7123 | Function Loss:  -2.8881\n",
      "Total loss:  -1.8277 | PDE Loss:  -2.7089 | Function Loss:  -2.8889\n",
      "Total loss:  -1.8278 | PDE Loss:  -2.7082 | Function Loss:  -2.8891\n",
      "Total loss:  -1.8281 | PDE Loss:  -2.7082 | Function Loss:  -2.8894\n",
      "Total loss:  -1.8282 | PDE Loss:  -2.707 | Function Loss:  -2.8898\n",
      "Total loss:  -1.8285 | PDE Loss:  -2.7095 | Function Loss:  -2.8898\n",
      "Total loss:  -1.8289 | PDE Loss:  -2.7126 | Function Loss:  -2.8897\n",
      "Total loss:  -1.8295 | PDE Loss:  -2.7167 | Function Loss:  -2.8898\n",
      "Total loss:  -1.8304 | PDE Loss:  -2.7262 | Function Loss:  -2.8895\n",
      "Total loss:  -1.8318 | PDE Loss:  -2.731 | Function Loss:  -2.8903\n",
      "Total loss:  -1.8324 | PDE Loss:  -2.7334 | Function Loss:  -2.8907\n",
      "Total loss:  -1.833 | PDE Loss:  -2.7379 | Function Loss:  -2.8907\n",
      "Total loss:  -1.8333 | PDE Loss:  -2.739 | Function Loss:  -2.891\n",
      "Total loss:  -1.8335 | PDE Loss:  -2.7379 | Function Loss:  -2.8913\n",
      "Total loss:  -1.8337 | PDE Loss:  -2.7392 | Function Loss:  -2.8913\n",
      "Total loss:  -1.834 | PDE Loss:  -2.7427 | Function Loss:  -2.8912\n",
      "Total loss:  -1.8343 | PDE Loss:  -2.7445 | Function Loss:  -2.8913\n",
      "Total loss:  -1.8347 | PDE Loss:  -2.7453 | Function Loss:  -2.8916\n",
      "Total loss:  -1.8349 | PDE Loss:  -2.7477 | Function Loss:  -2.8916\n",
      "Total loss:  -1.8351 | PDE Loss:  -2.7479 | Function Loss:  -2.8918\n",
      "Total loss:  -1.8354 | PDE Loss:  -2.7489 | Function Loss:  -2.8919\n",
      "Total loss:  -1.8358 | PDE Loss:  -2.7497 | Function Loss:  -2.8922\n",
      "Total loss:  -1.8362 | PDE Loss:  -2.752 | Function Loss:  -2.8924\n",
      "Total loss:  -1.8367 | PDE Loss:  -2.7535 | Function Loss:  -2.8928\n",
      "Total loss:  -1.8373 | PDE Loss:  -2.7561 | Function Loss:  -2.8931\n",
      "Total loss:  -1.8378 | PDE Loss:  -2.7578 | Function Loss:  -2.8934\n",
      "Total loss:  -1.8383 | PDE Loss:  -2.7589 | Function Loss:  -2.8938\n",
      "Total loss:  -1.8387 | PDE Loss:  -2.7615 | Function Loss:  -2.894\n",
      "Total loss:  -1.8393 | PDE Loss:  -2.7608 | Function Loss:  -2.8947\n",
      "Total loss:  -1.8397 | PDE Loss:  -2.7593 | Function Loss:  -2.8954\n",
      "Total loss:  -1.8403 | PDE Loss:  -2.7559 | Function Loss:  -2.8965\n",
      "Total loss:  -1.8409 | PDE Loss:  -2.7492 | Function Loss:  -2.8982\n",
      "Total loss:  -1.8413 | PDE Loss:  -2.7446 | Function Loss:  -2.8992\n",
      "Total loss:  -1.8415 | PDE Loss:  -2.7374 | Function Loss:  -2.9006\n",
      "Total loss:  -1.8417 | PDE Loss:  -2.735 | Function Loss:  -2.9011\n",
      "Total loss:  -1.8418 | PDE Loss:  -2.7332 | Function Loss:  -2.9015\n",
      "Total loss:  -1.8419 | PDE Loss:  -2.7324 | Function Loss:  -2.9017\n",
      "Total loss:  -1.842 | PDE Loss:  -2.7326 | Function Loss:  -2.9018\n",
      "Total loss:  -1.8421 | PDE Loss:  -2.7342 | Function Loss:  -2.9017\n",
      "Total loss:  -1.8423 | PDE Loss:  -2.736 | Function Loss:  -2.9017\n",
      "Total loss:  -1.8425 | PDE Loss:  -2.7394 | Function Loss:  -2.9014\n",
      "Total loss:  -1.8427 | PDE Loss:  -2.7421 | Function Loss:  -2.9013\n",
      "Total loss:  -1.843 | PDE Loss:  -2.7447 | Function Loss:  -2.9011\n",
      "Total loss:  -1.8431 | PDE Loss:  -2.7458 | Function Loss:  -2.9011\n",
      "Total loss:  -1.8432 | PDE Loss:  -2.747 | Function Loss:  -2.9011\n",
      "Total loss:  -1.8432 | PDE Loss:  -2.7475 | Function Loss:  -2.9011\n",
      "Total loss:  -1.8433 | PDE Loss:  -2.7481 | Function Loss:  -2.9011\n",
      "Total loss:  -1.8434 | PDE Loss:  -2.749 | Function Loss:  -2.9011\n",
      "Total loss:  -1.8436 | PDE Loss:  -2.7504 | Function Loss:  -2.901\n",
      "Total loss:  -1.8438 | PDE Loss:  -2.752 | Function Loss:  -2.901\n",
      "Total loss:  -1.844 | PDE Loss:  -2.7545 | Function Loss:  -2.9009\n",
      "Total loss:  -1.8442 | PDE Loss:  -2.7563 | Function Loss:  -2.9009\n",
      "Total loss:  -1.8444 | PDE Loss:  -2.7576 | Function Loss:  -2.901\n",
      "Total loss:  -1.8446 | PDE Loss:  -2.7578 | Function Loss:  -2.9012\n",
      "Total loss:  -1.8448 | PDE Loss:  -2.7573 | Function Loss:  -2.9014\n",
      "Total loss:  -1.8449 | PDE Loss:  -2.7553 | Function Loss:  -2.9018\n",
      "Total loss:  -1.845 | PDE Loss:  -2.7538 | Function Loss:  -2.9021\n",
      "Total loss:  -1.845 | PDE Loss:  -2.7522 | Function Loss:  -2.9024\n",
      "Total loss:  -1.8451 | PDE Loss:  -2.7488 | Function Loss:  -2.903\n",
      "Total loss:  -1.8451 | PDE Loss:  -2.7477 | Function Loss:  -2.9032\n",
      "Total loss:  -1.8452 | PDE Loss:  -2.7465 | Function Loss:  -2.9034\n",
      "Total loss:  -1.8452 | PDE Loss:  -2.7449 | Function Loss:  -2.9037\n",
      "Total loss:  -1.8453 | PDE Loss:  -2.743 | Function Loss:  -2.9041\n",
      "Total loss:  -1.8455 | PDE Loss:  -2.7415 | Function Loss:  -2.9045\n",
      "Total loss:  -1.8457 | PDE Loss:  -2.7401 | Function Loss:  -2.9049\n",
      "Total loss:  -1.8459 | PDE Loss:  -2.7387 | Function Loss:  -2.9054\n",
      "Total loss:  -1.8461 | PDE Loss:  -2.7399 | Function Loss:  -2.9055\n",
      "Total loss:  -1.8464 | PDE Loss:  -2.7415 | Function Loss:  -2.9056\n",
      "Total loss:  -1.8467 | PDE Loss:  -2.7447 | Function Loss:  -2.9054\n",
      "Total loss:  -1.8469 | PDE Loss:  -2.7475 | Function Loss:  -2.9052\n",
      "Total loss:  -1.8471 | PDE Loss:  -2.7492 | Function Loss:  -2.9052\n",
      "Total loss:  -1.8473 | PDE Loss:  -2.7532 | Function Loss:  -2.9049\n",
      "Total loss:  -1.8476 | PDE Loss:  -2.7549 | Function Loss:  -2.905\n",
      "Total loss:  -1.8481 | PDE Loss:  -2.7584 | Function Loss:  -2.905\n",
      "Total loss:  -1.8487 | PDE Loss:  -2.7612 | Function Loss:  -2.9054\n",
      "Total loss:  -1.8493 | PDE Loss:  -2.7631 | Function Loss:  -2.9058\n",
      "Total loss:  -1.85 | PDE Loss:  -2.763 | Function Loss:  -2.9066\n",
      "Total loss:  -1.8506 | PDE Loss:  -2.7626 | Function Loss:  -2.9073\n",
      "Total loss:  -1.8511 | PDE Loss:  -2.7605 | Function Loss:  -2.9082\n",
      "Total loss:  -1.8508 | PDE Loss:  -2.7551 | Function Loss:  -2.9087\n",
      "Total loss:  -1.8514 | PDE Loss:  -2.759 | Function Loss:  -2.9087\n",
      "Total loss:  -1.8517 | PDE Loss:  -2.757 | Function Loss:  -2.9094\n",
      "Total loss:  -1.852 | PDE Loss:  -2.7542 | Function Loss:  -2.9101\n",
      "Total loss:  -1.8522 | PDE Loss:  -2.7527 | Function Loss:  -2.9106\n",
      "Total loss:  -1.8527 | PDE Loss:  -2.7502 | Function Loss:  -2.9115\n",
      "Total loss:  -1.853 | PDE Loss:  -2.7466 | Function Loss:  -2.9124\n",
      "Total loss:  -1.8533 | PDE Loss:  -2.7423 | Function Loss:  -2.9134\n",
      "Total loss:  -1.8536 | PDE Loss:  -2.7386 | Function Loss:  -2.9143\n",
      "Total loss:  -1.8539 | PDE Loss:  -2.7342 | Function Loss:  -2.9153\n",
      "Total loss:  -1.8542 | PDE Loss:  -2.7279 | Function Loss:  -2.9165\n",
      "Total loss:  -1.8543 | PDE Loss:  -2.7261 | Function Loss:  -2.917\n",
      "Total loss:  -1.8545 | PDE Loss:  -2.7247 | Function Loss:  -2.9174\n",
      "Total loss:  -1.8546 | PDE Loss:  -2.7244 | Function Loss:  -2.9176\n",
      "Total loss:  -1.8548 | PDE Loss:  -2.7232 | Function Loss:  -2.9179\n",
      "Total loss:  -1.8549 | PDE Loss:  -2.7227 | Function Loss:  -2.9182\n",
      "Total loss:  -1.8551 | PDE Loss:  -2.7219 | Function Loss:  -2.9185\n",
      "Total loss:  -1.8552 | PDE Loss:  -2.7212 | Function Loss:  -2.9188\n",
      "Total loss:  -1.8554 | PDE Loss:  -2.7211 | Function Loss:  -2.919\n",
      "Total loss:  -1.8557 | PDE Loss:  -2.7213 | Function Loss:  -2.9193\n",
      "Total loss:  -1.8561 | PDE Loss:  -2.7216 | Function Loss:  -2.9197\n",
      "Total loss:  -1.8566 | PDE Loss:  -2.7229 | Function Loss:  -2.9201\n",
      "Total loss:  -1.8571 | PDE Loss:  -2.7237 | Function Loss:  -2.9206\n",
      "Total loss:  -1.8578 | PDE Loss:  -2.7253 | Function Loss:  -2.9211\n",
      "Total loss:  -1.8586 | PDE Loss:  -2.7271 | Function Loss:  -2.9217\n",
      "Total loss:  -1.8594 | PDE Loss:  -2.7257 | Function Loss:  -2.9229\n",
      "Total loss:  -1.8603 | PDE Loss:  -2.7294 | Function Loss:  -2.9233\n",
      "Total loss:  -1.8616 | PDE Loss:  -2.726 | Function Loss:  -2.9254\n",
      "Total loss:  -1.8628 | PDE Loss:  -2.724 | Function Loss:  -2.9271\n",
      "Total loss:  -1.864 | PDE Loss:  -2.7221 | Function Loss:  -2.9288\n",
      "Total loss:  -1.8651 | PDE Loss:  -2.7221 | Function Loss:  -2.93\n",
      "Total loss:  -1.866 | PDE Loss:  -2.7206 | Function Loss:  -2.9314\n",
      "Total loss:  -1.867 | PDE Loss:  -2.7229 | Function Loss:  -2.9322\n",
      "Total loss:  -1.8681 | PDE Loss:  -2.72 | Function Loss:  -2.9339\n",
      "Total loss:  -1.8691 | PDE Loss:  -2.7206 | Function Loss:  -2.935\n",
      "Total loss:  -1.87 | PDE Loss:  -2.7246 | Function Loss:  -2.9353\n",
      "Total loss:  -1.8713 | PDE Loss:  -2.7256 | Function Loss:  -2.9368\n",
      "Total loss:  -1.8721 | PDE Loss:  -2.7263 | Function Loss:  -2.9376\n",
      "Total loss:  -1.8729 | PDE Loss:  -2.729 | Function Loss:  -2.9381\n",
      "Total loss:  -1.8735 | PDE Loss:  -2.7319 | Function Loss:  -2.9383\n",
      "Total loss:  -1.8741 | PDE Loss:  -2.7338 | Function Loss:  -2.9386\n",
      "Total loss:  -1.8748 | PDE Loss:  -2.7341 | Function Loss:  -2.9395\n",
      "Total loss:  -1.876 | PDE Loss:  -2.7373 | Function Loss:  -2.9403\n",
      "Total loss:  -1.8772 | PDE Loss:  -2.7359 | Function Loss:  -2.9419\n",
      "Total loss:  -1.8783 | PDE Loss:  -2.7361 | Function Loss:  -2.9431\n",
      "Total loss:  -1.879 | PDE Loss:  -2.737 | Function Loss:  -2.9439\n",
      "Total loss:  -1.8797 | PDE Loss:  -2.7328 | Function Loss:  -2.9453\n",
      "Total loss:  -1.8805 | PDE Loss:  -2.7329 | Function Loss:  -2.9462\n",
      "Total loss:  -1.8811 | PDE Loss:  -2.7357 | Function Loss:  -2.9464\n",
      "Total loss:  -1.882 | PDE Loss:  -2.7347 | Function Loss:  -2.9477\n",
      "Total loss:  -1.8827 | PDE Loss:  -2.7334 | Function Loss:  -2.9487\n",
      "Total loss:  -1.8831 | PDE Loss:  -2.7312 | Function Loss:  -2.9495\n",
      "Total loss:  -1.8833 | PDE Loss:  -2.7296 | Function Loss:  -2.95\n",
      "Total loss:  -1.8836 | PDE Loss:  -2.7252 | Function Loss:  -2.9511\n",
      "Total loss:  -1.8838 | PDE Loss:  -2.7243 | Function Loss:  -2.9515\n",
      "Total loss:  -1.8839 | PDE Loss:  -2.7235 | Function Loss:  -2.9518\n",
      "Total loss:  -1.8841 | PDE Loss:  -2.7224 | Function Loss:  -2.9522\n",
      "Total loss:  -1.8842 | PDE Loss:  -2.721 | Function Loss:  -2.9526\n",
      "Total loss:  -1.8843 | PDE Loss:  -2.7206 | Function Loss:  -2.9528\n",
      "Total loss:  -1.8844 | PDE Loss:  -2.7206 | Function Loss:  -2.9529\n",
      "Total loss:  -1.8844 | PDE Loss:  -2.7203 | Function Loss:  -2.953\n",
      "Total loss:  -1.8845 | PDE Loss:  -2.7203 | Function Loss:  -2.953\n",
      "Total loss:  -1.8846 | PDE Loss:  -2.7205 | Function Loss:  -2.953\n",
      "Total loss:  -1.8846 | PDE Loss:  -2.7212 | Function Loss:  -2.953\n",
      "Total loss:  -1.8847 | PDE Loss:  -2.7221 | Function Loss:  -2.953\n",
      "Total loss:  -1.8849 | PDE Loss:  -2.7248 | Function Loss:  -2.9527\n",
      "Total loss:  -1.8851 | PDE Loss:  -2.7265 | Function Loss:  -2.9527\n",
      "Total loss:  -1.8854 | PDE Loss:  -2.7296 | Function Loss:  -2.9525\n",
      "Total loss:  -1.8858 | PDE Loss:  -2.7334 | Function Loss:  -2.9523\n",
      "Total loss:  -1.8863 | PDE Loss:  -2.7373 | Function Loss:  -2.9523\n",
      "Total loss:  -1.8868 | PDE Loss:  -2.7415 | Function Loss:  -2.9521\n",
      "Total loss:  -1.8871 | PDE Loss:  -2.7461 | Function Loss:  -2.9518\n",
      "Total loss:  -1.8875 | PDE Loss:  -2.7478 | Function Loss:  -2.9519\n",
      "Total loss:  -1.8878 | PDE Loss:  -2.7509 | Function Loss:  -2.9519\n",
      "Total loss:  -1.8884 | PDE Loss:  -2.7567 | Function Loss:  -2.9516\n",
      "Total loss:  -1.8896 | PDE Loss:  -2.76 | Function Loss:  -2.9525\n",
      "Total loss:  -1.8906 | PDE Loss:  -2.7615 | Function Loss:  -2.9534\n",
      "Total loss:  -1.892 | PDE Loss:  -2.7598 | Function Loss:  -2.9553\n",
      "Total loss:  -1.893 | PDE Loss:  -2.7556 | Function Loss:  -2.9571\n",
      "Total loss:  -1.8931 | PDE Loss:  -2.75 | Function Loss:  -2.9581\n",
      "Total loss:  -1.8936 | PDE Loss:  -2.7543 | Function Loss:  -2.9581\n",
      "Total loss:  -1.8939 | PDE Loss:  -2.7514 | Function Loss:  -2.9589\n",
      "Total loss:  -1.8945 | PDE Loss:  -2.7468 | Function Loss:  -2.9602\n",
      "Total loss:  -1.8949 | PDE Loss:  -2.74 | Function Loss:  -2.9618\n",
      "Total loss:  -1.8952 | PDE Loss:  -2.7394 | Function Loss:  -2.9623\n",
      "Total loss:  -1.8955 | PDE Loss:  -2.7383 | Function Loss:  -2.9629\n",
      "Total loss:  -1.8957 | PDE Loss:  -2.7361 | Function Loss:  -2.9635\n",
      "Total loss:  -1.8959 | PDE Loss:  -2.7355 | Function Loss:  -2.9637\n",
      "Total loss:  -1.8961 | PDE Loss:  -2.7336 | Function Loss:  -2.9643\n",
      "Total loss:  -1.8964 | PDE Loss:  -2.7306 | Function Loss:  -2.9651\n",
      "Total loss:  -1.8967 | PDE Loss:  -2.7261 | Function Loss:  -2.9663\n",
      "Total loss:  -1.8972 | PDE Loss:  -2.7211 | Function Loss:  -2.9677\n",
      "Total loss:  -1.8977 | PDE Loss:  -2.7137 | Function Loss:  -2.9697\n",
      "Total loss:  -1.8984 | PDE Loss:  -2.7075 | Function Loss:  -2.9716\n",
      "Total loss:  -1.8987 | PDE Loss:  -2.701 | Function Loss:  -2.9732\n",
      "Total loss:  -1.899 | PDE Loss:  -2.6993 | Function Loss:  -2.9738\n",
      "Total loss:  -1.8995 | PDE Loss:  -2.6967 | Function Loss:  -2.9749\n",
      "Total loss:  -1.9 | PDE Loss:  -2.6946 | Function Loss:  -2.9759\n",
      "Total loss:  -1.9003 | PDE Loss:  -2.697 | Function Loss:  -2.9759\n",
      "Total loss:  -1.9008 | PDE Loss:  -2.6967 | Function Loss:  -2.9765\n",
      "Total loss:  -1.9011 | PDE Loss:  -2.6987 | Function Loss:  -2.9766\n",
      "Total loss:  -1.9016 | PDE Loss:  -2.7039 | Function Loss:  -2.9762\n",
      "Total loss:  -1.9021 | PDE Loss:  -2.7057 | Function Loss:  -2.9763\n",
      "Total loss:  -1.9025 | PDE Loss:  -2.7103 | Function Loss:  -2.976\n",
      "Total loss:  -1.9029 | PDE Loss:  -2.7097 | Function Loss:  -2.9765\n",
      "Total loss:  -1.9033 | PDE Loss:  -2.7075 | Function Loss:  -2.9774\n",
      "Total loss:  -1.9037 | PDE Loss:  -2.7014 | Function Loss:  -2.979\n",
      "Total loss:  -1.9041 | PDE Loss:  -2.7013 | Function Loss:  -2.9796\n",
      "Total loss:  -1.9046 | PDE Loss:  -2.6969 | Function Loss:  -2.9811\n",
      "Total loss:  -1.9051 | PDE Loss:  -2.6942 | Function Loss:  -2.9822\n",
      "Total loss:  -1.9055 | PDE Loss:  -2.6914 | Function Loss:  -2.9832\n",
      "Total loss:  -1.9062 | PDE Loss:  -2.6887 | Function Loss:  -2.9845\n",
      "Total loss:  -1.907 | PDE Loss:  -2.6854 | Function Loss:  -2.9861\n",
      "Total loss:  -1.9076 | PDE Loss:  -2.6881 | Function Loss:  -2.9864\n",
      "Total loss:  -1.9078 | PDE Loss:  -2.6857 | Function Loss:  -2.987\n",
      "Total loss:  -1.908 | PDE Loss:  -2.6872 | Function Loss:  -2.987\n",
      "Total loss:  -1.9086 | PDE Loss:  -2.6881 | Function Loss:  -2.9875\n",
      "Total loss:  -1.9092 | PDE Loss:  -2.6925 | Function Loss:  -2.9874\n",
      "Total loss:  -1.9097 | PDE Loss:  -2.6926 | Function Loss:  -2.9879\n",
      "Total loss:  -1.9101 | PDE Loss:  -2.694 | Function Loss:  -2.9881\n",
      "Total loss:  -1.9104 | PDE Loss:  -2.6943 | Function Loss:  -2.9885\n",
      "Total loss:  -1.911 | PDE Loss:  -2.6919 | Function Loss:  -2.9896\n",
      "Total loss:  -1.9117 | PDE Loss:  -2.6892 | Function Loss:  -2.991\n",
      "Total loss:  -1.9123 | PDE Loss:  -2.6856 | Function Loss:  -2.9925\n",
      "Total loss:  -1.9131 | PDE Loss:  -2.6796 | Function Loss:  -2.9946\n",
      "Total loss:  -1.9136 | PDE Loss:  -2.6758 | Function Loss:  -2.9961\n",
      "Total loss:  -1.9142 | PDE Loss:  -2.6754 | Function Loss:  -2.9968\n",
      "Total loss:  -1.9152 | PDE Loss:  -2.6741 | Function Loss:  -2.9983\n",
      "Total loss:  -1.9162 | PDE Loss:  -2.6733 | Function Loss:  -2.9997\n",
      "Total loss:  -1.9168 | PDE Loss:  -2.6721 | Function Loss:  -3.0007\n",
      "Total loss:  -1.9174 | PDE Loss:  -2.67 | Function Loss:  -3.0019\n",
      "Total loss:  -1.9182 | PDE Loss:  -2.6636 | Function Loss:  -3.0042\n",
      "Total loss:  -1.9186 | PDE Loss:  -2.6625 | Function Loss:  -3.005\n",
      "Total loss:  -1.919 | PDE Loss:  -2.6569 | Function Loss:  -3.0067\n",
      "Total loss:  -1.9191 | PDE Loss:  -2.6546 | Function Loss:  -3.0074\n",
      "Total loss:  -1.9194 | PDE Loss:  -2.6533 | Function Loss:  -3.008\n",
      "Total loss:  -1.9197 | PDE Loss:  -2.6537 | Function Loss:  -3.0083\n",
      "Total loss:  -1.92 | PDE Loss:  -2.6551 | Function Loss:  -3.0083\n",
      "Total loss:  -1.9204 | PDE Loss:  -2.6587 | Function Loss:  -3.008\n",
      "Total loss:  -1.9212 | PDE Loss:  -2.6675 | Function Loss:  -3.007\n",
      "Total loss:  -1.922 | PDE Loss:  -2.6777 | Function Loss:  -3.0058\n",
      "Total loss:  -1.9225 | PDE Loss:  -2.6833 | Function Loss:  -3.0053\n",
      "Total loss:  -1.9232 | PDE Loss:  -2.6911 | Function Loss:  -3.0045\n",
      "Total loss:  -1.9239 | PDE Loss:  -2.6953 | Function Loss:  -3.0045\n",
      "Total loss:  -1.9246 | PDE Loss:  -2.7 | Function Loss:  -3.0043\n",
      "Total loss:  -1.9252 | PDE Loss:  -2.7033 | Function Loss:  -3.0044\n",
      "Total loss:  -1.9258 | PDE Loss:  -2.7074 | Function Loss:  -3.0043\n",
      "Total loss:  -1.9262 | PDE Loss:  -2.7112 | Function Loss:  -3.0041\n",
      "Total loss:  -1.9266 | PDE Loss:  -2.7149 | Function Loss:  -3.0037\n",
      "Total loss:  -1.9267 | PDE Loss:  -2.7186 | Function Loss:  -3.0032\n",
      "Total loss:  -1.9269 | PDE Loss:  -2.7196 | Function Loss:  -3.0032\n",
      "Total loss:  -1.9272 | PDE Loss:  -2.7216 | Function Loss:  -3.0032\n",
      "Total loss:  -1.9274 | PDE Loss:  -2.7232 | Function Loss:  -3.0031\n",
      "Total loss:  -1.9276 | PDE Loss:  -2.7268 | Function Loss:  -3.0027\n",
      "Total loss:  -1.9278 | PDE Loss:  -2.7291 | Function Loss:  -3.0025\n",
      "Total loss:  -1.9281 | PDE Loss:  -2.7327 | Function Loss:  -3.0021\n",
      "Total loss:  -1.9284 | PDE Loss:  -2.7375 | Function Loss:  -3.0017\n",
      "Total loss:  -1.9288 | PDE Loss:  -2.7423 | Function Loss:  -3.0013\n",
      "Total loss:  -1.9291 | PDE Loss:  -2.7496 | Function Loss:  -3.0003\n",
      "Total loss:  -1.9294 | PDE Loss:  -2.7512 | Function Loss:  -3.0004\n",
      "Total loss:  -1.9297 | PDE Loss:  -2.7553 | Function Loss:  -3.0\n",
      "Total loss:  -1.93 | PDE Loss:  -2.7599 | Function Loss:  -2.9995\n",
      "Total loss:  -1.9302 | PDE Loss:  -2.765 | Function Loss:  -2.9989\n",
      "Total loss:  -1.9304 | PDE Loss:  -2.7691 | Function Loss:  -2.9985\n",
      "Total loss:  -1.9306 | PDE Loss:  -2.7732 | Function Loss:  -2.998\n",
      "Total loss:  -1.9308 | PDE Loss:  -2.7762 | Function Loss:  -2.9977\n",
      "Total loss:  -1.931 | PDE Loss:  -2.7804 | Function Loss:  -2.9973\n",
      "Total loss:  -1.9312 | PDE Loss:  -2.7825 | Function Loss:  -2.9972\n",
      "Total loss:  -1.9315 | PDE Loss:  -2.7841 | Function Loss:  -2.9973\n",
      "Total loss:  -1.9319 | PDE Loss:  -2.7865 | Function Loss:  -2.9973\n",
      "Total loss:  -1.9322 | PDE Loss:  -2.7862 | Function Loss:  -2.9977\n",
      "Total loss:  -1.9326 | PDE Loss:  -2.7883 | Function Loss:  -2.9978\n",
      "Total loss:  -1.9329 | PDE Loss:  -2.7879 | Function Loss:  -2.9982\n",
      "Total loss:  -1.9331 | PDE Loss:  -2.7884 | Function Loss:  -2.9984\n",
      "Total loss:  -1.9333 | PDE Loss:  -2.7886 | Function Loss:  -2.9986\n",
      "Total loss:  -1.9334 | PDE Loss:  -2.7892 | Function Loss:  -2.9986\n",
      "Total loss:  -1.9336 | PDE Loss:  -2.79 | Function Loss:  -2.9987\n",
      "Total loss:  -1.9337 | PDE Loss:  -2.7916 | Function Loss:  -2.9986\n",
      "Total loss:  -1.9339 | PDE Loss:  -2.7933 | Function Loss:  -2.9985\n",
      "Total loss:  -1.9341 | PDE Loss:  -2.7956 | Function Loss:  -2.9983\n",
      "Total loss:  -1.9342 | PDE Loss:  -2.8 | Function Loss:  -2.9978\n",
      "Total loss:  -1.9346 | PDE Loss:  -2.8011 | Function Loss:  -2.9981\n",
      "Total loss:  -1.9349 | PDE Loss:  -2.8011 | Function Loss:  -2.9984\n",
      "Total loss:  -1.9354 | PDE Loss:  -2.8049 | Function Loss:  -2.9985\n",
      "Total loss:  -1.9361 | PDE Loss:  -2.8033 | Function Loss:  -2.9995\n",
      "Total loss:  -1.9369 | PDE Loss:  -2.805 | Function Loss:  -3.0001\n",
      "Total loss:  -1.9378 | PDE Loss:  -2.8038 | Function Loss:  -3.0013\n",
      "Total loss:  -1.9385 | PDE Loss:  -2.799 | Function Loss:  -3.0029\n",
      "Total loss:  -1.9389 | PDE Loss:  -2.7969 | Function Loss:  -3.0037\n",
      "Total loss:  -1.9393 | PDE Loss:  -2.7915 | Function Loss:  -3.005\n",
      "Total loss:  -1.9398 | PDE Loss:  -2.7866 | Function Loss:  -3.0064\n",
      "Total loss:  -1.9402 | PDE Loss:  -2.7858 | Function Loss:  -3.007\n",
      "Total loss:  -1.9406 | PDE Loss:  -2.786 | Function Loss:  -3.0075\n",
      "Total loss:  -1.941 | PDE Loss:  -2.7864 | Function Loss:  -3.0079\n",
      "Total loss:  -1.9414 | PDE Loss:  -2.7867 | Function Loss:  -3.0083\n",
      "Total loss:  -1.9417 | PDE Loss:  -2.7872 | Function Loss:  -3.0086\n",
      "Total loss:  -1.9419 | PDE Loss:  -2.7901 | Function Loss:  -3.0084\n",
      "Total loss:  -1.9422 | PDE Loss:  -2.795 | Function Loss:  -3.0079\n",
      "Total loss:  -1.9427 | PDE Loss:  -2.8036 | Function Loss:  -3.007\n",
      "Total loss:  -1.9432 | PDE Loss:  -2.8168 | Function Loss:  -3.0056\n",
      "Total loss:  -1.9438 | PDE Loss:  -2.8306 | Function Loss:  -3.0041\n",
      "Total loss:  -1.9442 | PDE Loss:  -2.8421 | Function Loss:  -3.003\n",
      "Total loss:  -1.9447 | PDE Loss:  -2.8505 | Function Loss:  -3.0023\n",
      "Total loss:  -1.9452 | PDE Loss:  -2.8565 | Function Loss:  -3.002\n",
      "Total loss:  -1.9456 | PDE Loss:  -2.8592 | Function Loss:  -3.0021\n",
      "Total loss:  -1.9459 | PDE Loss:  -2.8586 | Function Loss:  -3.0026\n",
      "Total loss:  -1.9462 | PDE Loss:  -2.8565 | Function Loss:  -3.0032\n",
      "Total loss:  -1.9466 | PDE Loss:  -2.8525 | Function Loss:  -3.0042\n",
      "Total loss:  -1.947 | PDE Loss:  -2.8475 | Function Loss:  -3.0054\n",
      "Total loss:  -1.9475 | PDE Loss:  -2.8421 | Function Loss:  -3.0067\n",
      "Total loss:  -1.948 | PDE Loss:  -2.8308 | Function Loss:  -3.009\n",
      "Total loss:  -1.9485 | PDE Loss:  -2.821 | Function Loss:  -3.0111\n",
      "Total loss:  -1.949 | PDE Loss:  -2.8189 | Function Loss:  -3.0119\n",
      "Total loss:  -1.9498 | PDE Loss:  -2.8099 | Function Loss:  -3.0143\n",
      "Total loss:  -1.9504 | PDE Loss:  -2.8052 | Function Loss:  -3.0157\n",
      "Total loss:  -1.9508 | PDE Loss:  -2.8037 | Function Loss:  -3.0165\n",
      "Total loss:  -1.9512 | PDE Loss:  -2.7999 | Function Loss:  -3.0176\n",
      "Total loss:  -1.9516 | PDE Loss:  -2.8015 | Function Loss:  -3.0178\n",
      "Total loss:  -1.9519 | PDE Loss:  -2.7988 | Function Loss:  -3.0186\n",
      "Total loss:  -1.9522 | PDE Loss:  -2.7974 | Function Loss:  -3.0192\n",
      "Total loss:  -1.9525 | PDE Loss:  -2.7941 | Function Loss:  -3.02\n",
      "Total loss:  -1.9527 | PDE Loss:  -2.7914 | Function Loss:  -3.0208\n",
      "Total loss:  -1.953 | PDE Loss:  -2.7871 | Function Loss:  -3.0218\n",
      "Total loss:  -1.9534 | PDE Loss:  -2.7833 | Function Loss:  -3.0229\n",
      "Total loss:  -1.9537 | PDE Loss:  -2.7762 | Function Loss:  -3.0246\n",
      "Total loss:  -1.9541 | PDE Loss:  -2.7727 | Function Loss:  -3.0256\n",
      "Total loss:  -1.9545 | PDE Loss:  -2.7687 | Function Loss:  -3.0268\n",
      "Total loss:  -1.9549 | PDE Loss:  -2.7649 | Function Loss:  -3.028\n",
      "Total loss:  -1.9552 | PDE Loss:  -2.7691 | Function Loss:  -3.0276\n",
      "Total loss:  -1.9555 | PDE Loss:  -2.7715 | Function Loss:  -3.0275\n",
      "Total loss:  -1.9559 | PDE Loss:  -2.7768 | Function Loss:  -3.027\n",
      "Total loss:  -1.9563 | PDE Loss:  -2.7831 | Function Loss:  -3.0264\n",
      "Total loss:  -1.9567 | PDE Loss:  -2.7869 | Function Loss:  -3.0262\n",
      "Total loss:  -1.957 | PDE Loss:  -2.7897 | Function Loss:  -3.026\n",
      "Total loss:  -1.9572 | PDE Loss:  -2.7897 | Function Loss:  -3.0263\n",
      "Total loss:  -1.9574 | PDE Loss:  -2.7881 | Function Loss:  -3.0268\n",
      "Total loss:  -1.9577 | PDE Loss:  -2.7847 | Function Loss:  -3.0277\n",
      "Total loss:  -1.9579 | PDE Loss:  -2.7808 | Function Loss:  -3.0287\n",
      "Total loss:  -1.9583 | PDE Loss:  -2.7767 | Function Loss:  -3.0298\n",
      "Total loss:  -1.9588 | PDE Loss:  -2.7691 | Function Loss:  -3.0318\n",
      "Total loss:  -1.9593 | PDE Loss:  -2.767 | Function Loss:  -3.0328\n",
      "Total loss:  -1.9599 | PDE Loss:  -2.7649 | Function Loss:  -3.0339\n",
      "Total loss:  -1.9606 | PDE Loss:  -2.7678 | Function Loss:  -3.0342\n",
      "Total loss:  -1.9611 | PDE Loss:  -2.7673 | Function Loss:  -3.0349\n",
      "Total loss:  -1.9618 | PDE Loss:  -2.7685 | Function Loss:  -3.0354\n",
      "Total loss:  -1.9624 | PDE Loss:  -2.7691 | Function Loss:  -3.0361\n",
      "Total loss:  -1.963 | PDE Loss:  -2.7687 | Function Loss:  -3.0368\n",
      "Total loss:  -1.9634 | PDE Loss:  -2.7694 | Function Loss:  -3.0372\n",
      "Total loss:  -1.9639 | PDE Loss:  -2.7676 | Function Loss:  -3.0381\n",
      "Total loss:  -1.9644 | PDE Loss:  -2.7687 | Function Loss:  -3.0386\n",
      "Total loss:  -1.9649 | PDE Loss:  -2.7673 | Function Loss:  -3.0393\n",
      "Total loss:  -1.9659 | PDE Loss:  -2.7649 | Function Loss:  -3.0411\n",
      "Total loss:  -1.9671 | PDE Loss:  -2.7614 | Function Loss:  -3.0431\n",
      "Total loss:  -1.9683 | PDE Loss:  -2.7646 | Function Loss:  -3.0439\n",
      "Total loss:  -1.9696 | PDE Loss:  -2.7644 | Function Loss:  -3.0456\n",
      "Total loss:  -1.9711 | PDE Loss:  -2.7678 | Function Loss:  -3.0467\n",
      "Total loss:  -1.9696 | PDE Loss:  -2.7634 | Function Loss:  -3.0457\n",
      "Total loss:  -1.9721 | PDE Loss:  -2.7683 | Function Loss:  -3.0477\n",
      "Total loss:  -1.9733 | PDE Loss:  -2.7668 | Function Loss:  -3.0495\n",
      "Total loss:  -1.9751 | PDE Loss:  -2.7682 | Function Loss:  -3.0513\n",
      "Total loss:  -1.9764 | PDE Loss:  -2.7621 | Function Loss:  -3.0541\n",
      "Total loss:  -1.977 | PDE Loss:  -2.7587 | Function Loss:  -3.0554\n",
      "Total loss:  -1.9781 | PDE Loss:  -2.7552 | Function Loss:  -3.0574\n",
      "Total loss:  -1.9784 | PDE Loss:  -2.7509 | Function Loss:  -3.0587\n",
      "Total loss:  -1.9789 | PDE Loss:  -2.7508 | Function Loss:  -3.0594\n",
      "Total loss:  -1.9793 | PDE Loss:  -2.7507 | Function Loss:  -3.0598\n",
      "Total loss:  -1.9795 | PDE Loss:  -2.7512 | Function Loss:  -3.06\n",
      "Total loss:  -1.9797 | PDE Loss:  -2.7497 | Function Loss:  -3.0605\n",
      "Total loss:  -1.9798 | PDE Loss:  -2.7501 | Function Loss:  -3.0605\n",
      "Total loss:  -1.9798 | PDE Loss:  -2.7505 | Function Loss:  -3.0605\n",
      "Total loss:  -1.98 | PDE Loss:  -2.7514 | Function Loss:  -3.0605\n",
      "Total loss:  -1.9801 | PDE Loss:  -2.7528 | Function Loss:  -3.0604\n",
      "Total loss:  -1.9803 | PDE Loss:  -2.7547 | Function Loss:  -3.0602\n",
      "Total loss:  -1.9804 | PDE Loss:  -2.757 | Function Loss:  -3.0599\n",
      "Total loss:  -1.9806 | PDE Loss:  -2.7604 | Function Loss:  -3.0595\n",
      "Total loss:  -1.9808 | PDE Loss:  -2.7626 | Function Loss:  -3.0592\n",
      "Total loss:  -1.981 | PDE Loss:  -2.7655 | Function Loss:  -3.0589\n",
      "Total loss:  -1.9813 | PDE Loss:  -2.7696 | Function Loss:  -3.0585\n",
      "Total loss:  -1.9816 | PDE Loss:  -2.7727 | Function Loss:  -3.0582\n",
      "Total loss:  -1.9818 | PDE Loss:  -2.7758 | Function Loss:  -3.0579\n",
      "Total loss:  -1.982 | PDE Loss:  -2.7763 | Function Loss:  -3.0581\n",
      "Total loss:  -1.9823 | PDE Loss:  -2.7773 | Function Loss:  -3.0582\n",
      "Total loss:  -1.9826 | PDE Loss:  -2.7788 | Function Loss:  -3.0582\n",
      "Total loss:  -1.9826 | PDE Loss:  -2.7779 | Function Loss:  -3.0585\n",
      "Total loss:  -1.9827 | PDE Loss:  -2.778 | Function Loss:  -3.0586\n",
      "Total loss:  -1.9828 | PDE Loss:  -2.7777 | Function Loss:  -3.0588\n",
      "Total loss:  -1.983 | PDE Loss:  -2.7786 | Function Loss:  -3.0587\n",
      "Total loss:  -1.9831 | PDE Loss:  -2.7789 | Function Loss:  -3.0589\n",
      "Total loss:  -1.9833 | PDE Loss:  -2.7819 | Function Loss:  -3.0585\n",
      "Total loss:  -1.9836 | PDE Loss:  -2.7841 | Function Loss:  -3.0585\n",
      "Total loss:  -1.9838 | PDE Loss:  -2.7867 | Function Loss:  -3.0582\n",
      "Total loss:  -1.9842 | PDE Loss:  -2.7913 | Function Loss:  -3.0578\n",
      "Total loss:  -1.9845 | PDE Loss:  -2.7961 | Function Loss:  -3.0573\n",
      "Total loss:  -1.9848 | PDE Loss:  -2.8011 | Function Loss:  -3.0567\n",
      "Total loss:  -1.9849 | PDE Loss:  -2.8053 | Function Loss:  -3.0561\n",
      "Total loss:  -1.9851 | PDE Loss:  -2.8073 | Function Loss:  -3.056\n",
      "Total loss:  -1.9852 | PDE Loss:  -2.8097 | Function Loss:  -3.0557\n",
      "Total loss:  -1.9854 | PDE Loss:  -2.8121 | Function Loss:  -3.0555\n",
      "Total loss:  -1.9856 | PDE Loss:  -2.8143 | Function Loss:  -3.0554\n",
      "Total loss:  -1.9858 | PDE Loss:  -2.816 | Function Loss:  -3.0553\n",
      "Total loss:  -1.986 | PDE Loss:  -2.8173 | Function Loss:  -3.0552\n",
      "Total loss:  -1.9861 | PDE Loss:  -2.8188 | Function Loss:  -3.0551\n",
      "Total loss:  -1.9862 | PDE Loss:  -2.8193 | Function Loss:  -3.0552\n",
      "Total loss:  -1.9864 | PDE Loss:  -2.8206 | Function Loss:  -3.0551\n",
      "Total loss:  -1.9865 | PDE Loss:  -2.8211 | Function Loss:  -3.0552\n",
      "Total loss:  -1.9868 | PDE Loss:  -2.8211 | Function Loss:  -3.0556\n",
      "Total loss:  -1.9871 | PDE Loss:  -2.8205 | Function Loss:  -3.056\n",
      "Total loss:  -1.9874 | PDE Loss:  -2.8192 | Function Loss:  -3.0567\n",
      "Total loss:  -1.9878 | PDE Loss:  -2.8178 | Function Loss:  -3.0573\n",
      "Total loss:  -1.9883 | PDE Loss:  -2.8151 | Function Loss:  -3.0584\n",
      "Total loss:  -1.989 | PDE Loss:  -2.8137 | Function Loss:  -3.0595\n",
      "Total loss:  -1.9901 | PDE Loss:  -2.8121 | Function Loss:  -3.061\n",
      "Total loss:  -1.9912 | PDE Loss:  -2.8099 | Function Loss:  -3.0627\n",
      "Total loss:  -1.9926 | PDE Loss:  -2.8143 | Function Loss:  -3.0635\n",
      "Total loss:  -1.9932 | PDE Loss:  -2.8167 | Function Loss:  -3.0639\n",
      "Total loss:  -1.9938 | PDE Loss:  -2.8211 | Function Loss:  -3.0638\n",
      "Total loss:  -1.9942 | PDE Loss:  -2.8244 | Function Loss:  -3.0637\n",
      "Total loss:  -1.9945 | PDE Loss:  -2.8253 | Function Loss:  -3.0639\n",
      "Total loss:  -1.9949 | PDE Loss:  -2.827 | Function Loss:  -3.0641\n",
      "Total loss:  -1.9954 | PDE Loss:  -2.8296 | Function Loss:  -3.0642\n",
      "Total loss:  -1.9958 | PDE Loss:  -2.8311 | Function Loss:  -3.0644\n",
      "Total loss:  -1.9963 | PDE Loss:  -2.8334 | Function Loss:  -3.0646\n",
      "Total loss:  -1.997 | PDE Loss:  -2.8365 | Function Loss:  -3.0649\n",
      "Total loss:  -1.9977 | PDE Loss:  -2.8396 | Function Loss:  -3.0652\n",
      "Total loss:  -1.9983 | PDE Loss:  -2.8438 | Function Loss:  -3.0652\n",
      "Total loss:  -1.9981 | PDE Loss:  -2.8451 | Function Loss:  -3.0647\n",
      "Total loss:  -1.9988 | PDE Loss:  -2.8454 | Function Loss:  -3.0655\n",
      "Total loss:  -1.9992 | PDE Loss:  -2.847 | Function Loss:  -3.0656\n",
      "Total loss:  -1.9998 | PDE Loss:  -2.8496 | Function Loss:  -3.066\n",
      "Total loss:  -2.0003 | PDE Loss:  -2.8499 | Function Loss:  -3.0664\n",
      "Total loss:  -2.0006 | PDE Loss:  -2.8512 | Function Loss:  -3.0667\n",
      "Total loss:  -2.001 | PDE Loss:  -2.8505 | Function Loss:  -3.0672\n",
      "Total loss:  -2.0012 | PDE Loss:  -2.8486 | Function Loss:  -3.0678\n",
      "Total loss:  -2.0015 | PDE Loss:  -2.8486 | Function Loss:  -3.0681\n",
      "Total loss:  -2.0018 | PDE Loss:  -2.8478 | Function Loss:  -3.0686\n",
      "Total loss:  -2.002 | PDE Loss:  -2.8469 | Function Loss:  -3.069\n",
      "Total loss:  -2.0023 | PDE Loss:  -2.845 | Function Loss:  -3.0696\n",
      "Total loss:  -2.0026 | PDE Loss:  -2.8426 | Function Loss:  -3.0704\n",
      "Total loss:  -2.003 | PDE Loss:  -2.84 | Function Loss:  -3.0713\n",
      "Total loss:  -2.0034 | PDE Loss:  -2.8381 | Function Loss:  -3.0721\n",
      "Total loss:  -2.0039 | PDE Loss:  -2.8379 | Function Loss:  -3.0727\n",
      "Total loss:  -2.0044 | PDE Loss:  -2.8402 | Function Loss:  -3.073\n",
      "Total loss:  -2.0047 | PDE Loss:  -2.8416 | Function Loss:  -3.0731\n",
      "Total loss:  -2.0053 | PDE Loss:  -2.8465 | Function Loss:  -3.0729\n",
      "Total loss:  -2.0056 | PDE Loss:  -2.849 | Function Loss:  -3.0728\n",
      "Total loss:  -2.0058 | PDE Loss:  -2.851 | Function Loss:  -3.0728\n",
      "Total loss:  -2.0064 | PDE Loss:  -2.8541 | Function Loss:  -3.0729\n",
      "Total loss:  -2.0067 | PDE Loss:  -2.856 | Function Loss:  -3.073\n",
      "Total loss:  -2.007 | PDE Loss:  -2.8571 | Function Loss:  -3.0731\n",
      "Total loss:  -2.0073 | PDE Loss:  -2.8577 | Function Loss:  -3.0734\n",
      "Total loss:  -2.0076 | PDE Loss:  -2.8576 | Function Loss:  -3.0737\n",
      "Total loss:  -2.0077 | PDE Loss:  -2.8584 | Function Loss:  -3.0738\n",
      "Total loss:  -2.0079 | PDE Loss:  -2.8576 | Function Loss:  -3.0741\n",
      "Total loss:  -2.0081 | PDE Loss:  -2.8568 | Function Loss:  -3.0745\n",
      "Total loss:  -2.0083 | PDE Loss:  -2.8553 | Function Loss:  -3.075\n",
      "Total loss:  -2.0086 | PDE Loss:  -2.8519 | Function Loss:  -3.0758\n",
      "Total loss:  -2.0088 | PDE Loss:  -2.8518 | Function Loss:  -3.076\n",
      "Total loss:  -2.0092 | PDE Loss:  -2.8507 | Function Loss:  -3.0768\n",
      "Total loss:  -2.0096 | PDE Loss:  -2.8488 | Function Loss:  -3.0776\n",
      "Total loss:  -2.0099 | PDE Loss:  -2.8478 | Function Loss:  -3.078\n",
      "Total loss:  -2.0101 | PDE Loss:  -2.8471 | Function Loss:  -3.0784\n",
      "Total loss:  -2.0103 | PDE Loss:  -2.8455 | Function Loss:  -3.0789\n",
      "Total loss:  -2.0104 | PDE Loss:  -2.8445 | Function Loss:  -3.0793\n",
      "Total loss:  -2.0107 | PDE Loss:  -2.8418 | Function Loss:  -3.08\n",
      "Total loss:  -2.0109 | PDE Loss:  -2.84 | Function Loss:  -3.0805\n",
      "Total loss:  -2.011 | PDE Loss:  -2.838 | Function Loss:  -3.081\n",
      "Total loss:  -2.0111 | PDE Loss:  -2.8356 | Function Loss:  -3.0816\n",
      "Total loss:  -2.0114 | PDE Loss:  -2.8329 | Function Loss:  -3.0823\n",
      "Total loss:  -2.0116 | PDE Loss:  -2.8298 | Function Loss:  -3.0832\n",
      "Total loss:  -2.0118 | PDE Loss:  -2.8276 | Function Loss:  -3.0838\n",
      "Total loss:  -2.012 | PDE Loss:  -2.8259 | Function Loss:  -3.0843\n",
      "Total loss:  -2.0122 | PDE Loss:  -2.825 | Function Loss:  -3.0848\n",
      "Total loss:  -2.0124 | PDE Loss:  -2.8238 | Function Loss:  -3.0852\n",
      "Total loss:  -2.0126 | PDE Loss:  -2.8242 | Function Loss:  -3.0854\n",
      "Total loss:  -2.0127 | PDE Loss:  -2.824 | Function Loss:  -3.0856\n",
      "Total loss:  -2.0129 | PDE Loss:  -2.8244 | Function Loss:  -3.0857\n",
      "Total loss:  -2.0131 | PDE Loss:  -2.8241 | Function Loss:  -3.0859\n",
      "Total loss:  -2.0132 | PDE Loss:  -2.8244 | Function Loss:  -3.0861\n",
      "Total loss:  -2.0133 | PDE Loss:  -2.8246 | Function Loss:  -3.0862\n",
      "Total loss:  -2.0134 | PDE Loss:  -2.825 | Function Loss:  -3.0862\n",
      "Total loss:  -2.0135 | PDE Loss:  -2.8246 | Function Loss:  -3.0864\n",
      "Total loss:  -2.0136 | PDE Loss:  -2.8256 | Function Loss:  -3.0863\n",
      "Total loss:  -2.0137 | PDE Loss:  -2.8258 | Function Loss:  -3.0864\n",
      "Total loss:  -2.0138 | PDE Loss:  -2.827 | Function Loss:  -3.0863\n",
      "Total loss:  -2.0139 | PDE Loss:  -2.8285 | Function Loss:  -3.0862\n",
      "Total loss:  -2.014 | PDE Loss:  -2.8308 | Function Loss:  -3.0859\n",
      "Total loss:  -2.0142 | PDE Loss:  -2.8327 | Function Loss:  -3.0857\n",
      "Total loss:  -2.0143 | PDE Loss:  -2.8349 | Function Loss:  -3.0855\n",
      "Total loss:  -2.0145 | PDE Loss:  -2.8366 | Function Loss:  -3.0854\n",
      "Total loss:  -2.0148 | PDE Loss:  -2.8377 | Function Loss:  -3.0855\n",
      "Total loss:  -2.0151 | PDE Loss:  -2.8384 | Function Loss:  -3.0858\n",
      "Total loss:  -2.0154 | PDE Loss:  -2.8377 | Function Loss:  -3.0862\n",
      "Total loss:  -2.0156 | PDE Loss:  -2.8362 | Function Loss:  -3.0868\n",
      "Total loss:  -2.016 | PDE Loss:  -2.8347 | Function Loss:  -3.0875\n",
      "Total loss:  -2.0162 | PDE Loss:  -2.8322 | Function Loss:  -3.0882\n",
      "Total loss:  -2.0165 | PDE Loss:  -2.8305 | Function Loss:  -3.0888\n",
      "Total loss:  -2.0167 | PDE Loss:  -2.8292 | Function Loss:  -3.0894\n",
      "Total loss:  -2.017 | PDE Loss:  -2.8285 | Function Loss:  -3.0898\n",
      "Total loss:  -2.0174 | PDE Loss:  -2.8284 | Function Loss:  -3.0903\n",
      "Total loss:  -2.0179 | PDE Loss:  -2.8285 | Function Loss:  -3.0909\n",
      "Total loss:  -2.0186 | PDE Loss:  -2.8296 | Function Loss:  -3.0914\n",
      "Total loss:  -2.0193 | PDE Loss:  -2.8307 | Function Loss:  -3.0921\n",
      "Total loss:  -2.0201 | PDE Loss:  -2.8314 | Function Loss:  -3.0929\n",
      "Total loss:  -2.0211 | PDE Loss:  -2.8356 | Function Loss:  -3.0933\n",
      "Total loss:  -2.0213 | PDE Loss:  -2.8337 | Function Loss:  -3.094\n",
      "Total loss:  -2.0217 | PDE Loss:  -2.8355 | Function Loss:  -3.0941\n",
      "Total loss:  -2.0228 | PDE Loss:  -2.8383 | Function Loss:  -3.0949\n",
      "Total loss:  -2.0239 | PDE Loss:  -2.8415 | Function Loss:  -3.0956\n",
      "Total loss:  -2.0246 | PDE Loss:  -2.8415 | Function Loss:  -3.0965\n",
      "Total loss:  -2.0251 | PDE Loss:  -2.8387 | Function Loss:  -3.0976\n",
      "Total loss:  -2.0259 | PDE Loss:  -2.836 | Function Loss:  -3.0989\n",
      "Total loss:  -2.0262 | PDE Loss:  -2.8331 | Function Loss:  -3.0998\n",
      "Total loss:  -2.0265 | PDE Loss:  -2.8302 | Function Loss:  -3.1007\n",
      "Total loss:  -2.027 | PDE Loss:  -2.8256 | Function Loss:  -3.1023\n",
      "Total loss:  -2.0275 | PDE Loss:  -2.8218 | Function Loss:  -3.1035\n",
      "Total loss:  -2.0279 | PDE Loss:  -2.8193 | Function Loss:  -3.1045\n",
      "Total loss:  -2.0284 | PDE Loss:  -2.8166 | Function Loss:  -3.1056\n",
      "Total loss:  -2.0287 | PDE Loss:  -2.8143 | Function Loss:  -3.1064\n",
      "Total loss:  -2.0291 | PDE Loss:  -2.8115 | Function Loss:  -3.1075\n",
      "Total loss:  -2.0295 | PDE Loss:  -2.8091 | Function Loss:  -3.1083\n",
      "Total loss:  -2.0299 | PDE Loss:  -2.8074 | Function Loss:  -3.1092\n",
      "Total loss:  -2.0303 | PDE Loss:  -2.8028 | Function Loss:  -3.1106\n",
      "Total loss:  -2.0307 | PDE Loss:  -2.8046 | Function Loss:  -3.1107\n",
      "Total loss:  -2.031 | PDE Loss:  -2.8045 | Function Loss:  -3.1111\n",
      "Total loss:  -2.0313 | PDE Loss:  -2.8046 | Function Loss:  -3.1115\n",
      "Total loss:  -2.0319 | PDE Loss:  -2.807 | Function Loss:  -3.1117\n",
      "Total loss:  -2.0324 | PDE Loss:  -2.8093 | Function Loss:  -3.1119\n",
      "Total loss:  -2.0329 | PDE Loss:  -2.8146 | Function Loss:  -3.1114\n",
      "Total loss:  -2.0336 | PDE Loss:  -2.8217 | Function Loss:  -3.1108\n",
      "Total loss:  -2.0342 | PDE Loss:  -2.8286 | Function Loss:  -3.1102\n",
      "Total loss:  -2.0347 | PDE Loss:  -2.834 | Function Loss:  -3.1098\n",
      "Total loss:  -2.0353 | PDE Loss:  -2.8375 | Function Loss:  -3.1098\n",
      "Total loss:  -2.0356 | PDE Loss:  -2.8398 | Function Loss:  -3.1098\n",
      "Total loss:  -2.0358 | PDE Loss:  -2.8401 | Function Loss:  -3.11\n",
      "Total loss:  -2.036 | PDE Loss:  -2.8402 | Function Loss:  -3.1102\n",
      "Total loss:  -2.0362 | PDE Loss:  -2.8404 | Function Loss:  -3.1104\n",
      "Total loss:  -2.0364 | PDE Loss:  -2.8404 | Function Loss:  -3.1106\n",
      "Total loss:  -2.0365 | PDE Loss:  -2.8407 | Function Loss:  -3.1106\n",
      "Total loss:  -2.0366 | PDE Loss:  -2.8412 | Function Loss:  -3.1106\n",
      "Total loss:  -2.0366 | PDE Loss:  -2.841 | Function Loss:  -3.1107\n",
      "Total loss:  -2.0366 | PDE Loss:  -2.841 | Function Loss:  -3.1107\n",
      "Total loss:  -2.0366 | PDE Loss:  -2.8408 | Function Loss:  -3.1108\n",
      "Total loss:  -2.0367 | PDE Loss:  -2.8405 | Function Loss:  -3.1109\n",
      "Total loss:  -2.0367 | PDE Loss:  -2.84 | Function Loss:  -3.111\n",
      "Total loss:  -2.0368 | PDE Loss:  -2.8391 | Function Loss:  -3.1113\n",
      "Total loss:  -2.0368 | PDE Loss:  -2.8378 | Function Loss:  -3.1116\n",
      "Total loss:  -2.0369 | PDE Loss:  -2.8362 | Function Loss:  -3.112\n",
      "Total loss:  -2.0371 | PDE Loss:  -2.834 | Function Loss:  -3.1126\n",
      "Total loss:  -2.0372 | PDE Loss:  -2.832 | Function Loss:  -3.1131\n",
      "Total loss:  -2.0373 | PDE Loss:  -2.8307 | Function Loss:  -3.1135\n",
      "Total loss:  -2.0375 | PDE Loss:  -2.8287 | Function Loss:  -3.1142\n",
      "Total loss:  -2.0377 | PDE Loss:  -2.8279 | Function Loss:  -3.1145\n",
      "Total loss:  -2.0379 | PDE Loss:  -2.828 | Function Loss:  -3.1147\n",
      "Total loss:  -2.0381 | PDE Loss:  -2.8286 | Function Loss:  -3.1148\n",
      "Total loss:  -2.0382 | PDE Loss:  -2.8301 | Function Loss:  -3.1147\n",
      "Total loss:  -2.0384 | PDE Loss:  -2.8312 | Function Loss:  -3.1147\n",
      "Total loss:  -2.0386 | PDE Loss:  -2.8336 | Function Loss:  -3.1145\n",
      "Total loss:  -2.0388 | PDE Loss:  -2.8349 | Function Loss:  -3.1145\n",
      "Total loss:  -2.039 | PDE Loss:  -2.8359 | Function Loss:  -3.1146\n",
      "Total loss:  -2.0394 | PDE Loss:  -2.836 | Function Loss:  -3.115\n",
      "Total loss:  -2.0397 | PDE Loss:  -2.835 | Function Loss:  -3.1156\n",
      "Total loss:  -2.0401 | PDE Loss:  -2.8335 | Function Loss:  -3.1163\n",
      "Total loss:  -2.0405 | PDE Loss:  -2.8312 | Function Loss:  -3.1172\n",
      "Total loss:  -2.0407 | PDE Loss:  -2.8294 | Function Loss:  -3.1178\n",
      "Total loss:  -2.0412 | PDE Loss:  -2.8247 | Function Loss:  -3.1193\n",
      "Total loss:  -2.0416 | PDE Loss:  -2.8209 | Function Loss:  -3.1205\n",
      "Total loss:  -2.0418 | PDE Loss:  -2.8191 | Function Loss:  -3.1212\n",
      "Total loss:  -2.0421 | PDE Loss:  -2.8183 | Function Loss:  -3.1217\n",
      "Total loss:  -2.0424 | PDE Loss:  -2.818 | Function Loss:  -3.122\n",
      "Total loss:  -2.0427 | PDE Loss:  -2.8192 | Function Loss:  -3.1222\n",
      "Total loss:  -2.043 | PDE Loss:  -2.8193 | Function Loss:  -3.1226\n",
      "Total loss:  -2.0435 | PDE Loss:  -2.8203 | Function Loss:  -3.1229\n",
      "Total loss:  -2.044 | PDE Loss:  -2.8186 | Function Loss:  -3.1239\n",
      "Total loss:  -2.0446 | PDE Loss:  -2.8208 | Function Loss:  -3.1242\n",
      "Total loss:  -2.045 | PDE Loss:  -2.8199 | Function Loss:  -3.1248\n",
      "Total loss:  -2.0454 | PDE Loss:  -2.8196 | Function Loss:  -3.1254\n",
      "Total loss:  -2.0456 | PDE Loss:  -2.8204 | Function Loss:  -3.1255\n",
      "Total loss:  -2.0461 | PDE Loss:  -2.8201 | Function Loss:  -3.1261\n",
      "Total loss:  -2.0463 | PDE Loss:  -2.8173 | Function Loss:  -3.127\n",
      "Total loss:  -2.0465 | PDE Loss:  -2.8174 | Function Loss:  -3.1271\n",
      "Total loss:  -2.0467 | PDE Loss:  -2.8192 | Function Loss:  -3.1271\n",
      "Total loss:  -2.0471 | PDE Loss:  -2.8193 | Function Loss:  -3.1275\n",
      "Total loss:  -2.0474 | PDE Loss:  -2.8195 | Function Loss:  -3.1278\n",
      "Total loss:  -2.0476 | PDE Loss:  -2.8192 | Function Loss:  -3.1281\n",
      "Total loss:  -2.0478 | PDE Loss:  -2.8189 | Function Loss:  -3.1284\n",
      "Total loss:  -2.048 | PDE Loss:  -2.8183 | Function Loss:  -3.1288\n",
      "Total loss:  -2.0481 | PDE Loss:  -2.8173 | Function Loss:  -3.1291\n",
      "Total loss:  -2.0483 | PDE Loss:  -2.8167 | Function Loss:  -3.1294\n",
      "Total loss:  -2.0484 | PDE Loss:  -2.8163 | Function Loss:  -3.1297\n",
      "Total loss:  -2.0487 | PDE Loss:  -2.8156 | Function Loss:  -3.1302\n",
      "Total loss:  -2.0491 | PDE Loss:  -2.8151 | Function Loss:  -3.1307\n",
      "Total loss:  -2.0495 | PDE Loss:  -2.8145 | Function Loss:  -3.1313\n",
      "Total loss:  -2.0499 | PDE Loss:  -2.8134 | Function Loss:  -3.132\n",
      "Total loss:  -2.0502 | PDE Loss:  -2.8128 | Function Loss:  -3.1325\n",
      "Total loss:  -2.0505 | PDE Loss:  -2.8125 | Function Loss:  -3.1329\n",
      "Total loss:  -2.0507 | PDE Loss:  -2.811 | Function Loss:  -3.1335\n",
      "Total loss:  -2.0508 | PDE Loss:  -2.8118 | Function Loss:  -3.1335\n",
      "Total loss:  -2.0509 | PDE Loss:  -2.8131 | Function Loss:  -3.1333\n",
      "Total loss:  -2.051 | PDE Loss:  -2.8139 | Function Loss:  -3.1333\n",
      "Total loss:  -2.0511 | PDE Loss:  -2.8138 | Function Loss:  -3.1335\n",
      "Total loss:  -2.0512 | PDE Loss:  -2.8132 | Function Loss:  -3.1337\n",
      "Total loss:  -2.0513 | PDE Loss:  -2.8113 | Function Loss:  -3.1342\n",
      "Total loss:  -2.0514 | PDE Loss:  -2.8104 | Function Loss:  -3.1345\n",
      "Total loss:  -2.0515 | PDE Loss:  -2.8098 | Function Loss:  -3.1348\n",
      "Total loss:  -2.0516 | PDE Loss:  -2.8092 | Function Loss:  -3.135\n",
      "Total loss:  -2.0517 | PDE Loss:  -2.809 | Function Loss:  -3.1352\n",
      "Total loss:  -2.0519 | PDE Loss:  -2.8097 | Function Loss:  -3.1352\n",
      "Total loss:  -2.052 | PDE Loss:  -2.8091 | Function Loss:  -3.1355\n",
      "Total loss:  -2.0522 | PDE Loss:  -2.8101 | Function Loss:  -3.1355\n",
      "Total loss:  -2.0528 | PDE Loss:  -2.815 | Function Loss:  -3.1353\n",
      "Total loss:  -2.0535 | PDE Loss:  -2.8219 | Function Loss:  -3.1347\n",
      "Total loss:  -2.0543 | PDE Loss:  -2.8282 | Function Loss:  -3.1343\n",
      "Total loss:  -2.055 | PDE Loss:  -2.8356 | Function Loss:  -3.1337\n",
      "Total loss:  -2.0557 | PDE Loss:  -2.8428 | Function Loss:  -3.1331\n",
      "Total loss:  -2.0563 | PDE Loss:  -2.8441 | Function Loss:  -3.1336\n",
      "Total loss:  -2.0568 | PDE Loss:  -2.8433 | Function Loss:  -3.1343\n",
      "Total loss:  -2.0575 | PDE Loss:  -2.8411 | Function Loss:  -3.1356\n",
      "Total loss:  -2.0581 | PDE Loss:  -2.8382 | Function Loss:  -3.1369\n",
      "Total loss:  -2.0586 | PDE Loss:  -2.8321 | Function Loss:  -3.1387\n",
      "Total loss:  -2.059 | PDE Loss:  -2.8306 | Function Loss:  -3.1395\n",
      "Total loss:  -2.0594 | PDE Loss:  -2.8296 | Function Loss:  -3.1402\n",
      "Total loss:  -2.06 | PDE Loss:  -2.8291 | Function Loss:  -3.141\n",
      "Total loss:  -2.0604 | PDE Loss:  -2.8314 | Function Loss:  -3.141\n",
      "Total loss:  -2.0605 | PDE Loss:  -2.832 | Function Loss:  -3.1411\n",
      "Total loss:  -2.0607 | PDE Loss:  -2.8341 | Function Loss:  -3.1409\n",
      "Total loss:  -2.0609 | PDE Loss:  -2.837 | Function Loss:  -3.1405\n",
      "Total loss:  -2.0611 | PDE Loss:  -2.8385 | Function Loss:  -3.1404\n",
      "Total loss:  -2.0612 | PDE Loss:  -2.8407 | Function Loss:  -3.1401\n",
      "Total loss:  -2.0614 | PDE Loss:  -2.8428 | Function Loss:  -3.1399\n",
      "Total loss:  -2.0615 | PDE Loss:  -2.8448 | Function Loss:  -3.1397\n",
      "Total loss:  -2.0616 | PDE Loss:  -2.8457 | Function Loss:  -3.1396\n",
      "Total loss:  -2.0617 | PDE Loss:  -2.8466 | Function Loss:  -3.1395\n",
      "Total loss:  -2.0618 | PDE Loss:  -2.8469 | Function Loss:  -3.1396\n",
      "Total loss:  -2.0619 | PDE Loss:  -2.8464 | Function Loss:  -3.1399\n",
      "Total loss:  -2.0621 | PDE Loss:  -2.8459 | Function Loss:  -3.1402\n",
      "Total loss:  -2.0623 | PDE Loss:  -2.8451 | Function Loss:  -3.1405\n",
      "Total loss:  -2.0624 | PDE Loss:  -2.8451 | Function Loss:  -3.1407\n",
      "Total loss:  -2.0626 | PDE Loss:  -2.8454 | Function Loss:  -3.1409\n",
      "Total loss:  -2.0628 | PDE Loss:  -2.8454 | Function Loss:  -3.1411\n",
      "Total loss:  -2.063 | PDE Loss:  -2.8459 | Function Loss:  -3.1412\n",
      "Total loss:  -2.0633 | PDE Loss:  -2.8459 | Function Loss:  -3.1415\n",
      "Total loss:  -2.0635 | PDE Loss:  -2.8461 | Function Loss:  -3.1418\n",
      "Total loss:  -2.0638 | PDE Loss:  -2.8465 | Function Loss:  -3.1421\n",
      "Total loss:  -2.0641 | PDE Loss:  -2.8462 | Function Loss:  -3.1425\n",
      "Total loss:  -2.0643 | PDE Loss:  -2.8468 | Function Loss:  -3.1426\n",
      "Total loss:  -2.0645 | PDE Loss:  -2.8455 | Function Loss:  -3.1431\n",
      "Total loss:  -2.0647 | PDE Loss:  -2.8459 | Function Loss:  -3.1433\n",
      "Total loss:  -2.0648 | PDE Loss:  -2.845 | Function Loss:  -3.1436\n",
      "Total loss:  -2.065 | PDE Loss:  -2.8447 | Function Loss:  -3.1439\n",
      "Total loss:  -2.0652 | PDE Loss:  -2.8434 | Function Loss:  -3.1444\n",
      "Total loss:  -2.0654 | PDE Loss:  -2.8428 | Function Loss:  -3.1448\n",
      "Total loss:  -2.0657 | PDE Loss:  -2.8424 | Function Loss:  -3.1451\n",
      "Total loss:  -2.0659 | PDE Loss:  -2.8424 | Function Loss:  -3.1454\n",
      "Total loss:  -2.0662 | PDE Loss:  -2.8436 | Function Loss:  -3.1455\n",
      "Total loss:  -2.0662 | PDE Loss:  -2.8448 | Function Loss:  -3.1453\n",
      "Total loss:  -2.0664 | PDE Loss:  -2.8445 | Function Loss:  -3.1455\n",
      "Total loss:  -2.0666 | PDE Loss:  -2.8473 | Function Loss:  -3.1453\n",
      "Total loss:  -2.0668 | PDE Loss:  -2.8494 | Function Loss:  -3.1451\n",
      "Total loss:  -2.0669 | PDE Loss:  -2.8514 | Function Loss:  -3.1449\n",
      "Total loss:  -2.0671 | PDE Loss:  -2.854 | Function Loss:  -3.1446\n",
      "Total loss:  -2.0673 | PDE Loss:  -2.8564 | Function Loss:  -3.1443\n",
      "Total loss:  -2.0674 | PDE Loss:  -2.8588 | Function Loss:  -3.144\n",
      "Total loss:  -2.0675 | PDE Loss:  -2.8605 | Function Loss:  -3.1438\n",
      "Total loss:  -2.0676 | PDE Loss:  -2.8616 | Function Loss:  -3.1437\n",
      "Total loss:  -2.0678 | PDE Loss:  -2.863 | Function Loss:  -3.1436\n",
      "Total loss:  -2.068 | PDE Loss:  -2.8652 | Function Loss:  -3.1435\n",
      "Total loss:  -2.0682 | PDE Loss:  -2.8651 | Function Loss:  -3.1437\n",
      "Total loss:  -2.0684 | PDE Loss:  -2.8643 | Function Loss:  -3.1441\n",
      "Total loss:  -2.0686 | PDE Loss:  -2.8638 | Function Loss:  -3.1445\n",
      "Total loss:  -2.0688 | PDE Loss:  -2.863 | Function Loss:  -3.1449\n",
      "Total loss:  -2.0691 | PDE Loss:  -2.8622 | Function Loss:  -3.1453\n",
      "Total loss:  -2.0693 | PDE Loss:  -2.8617 | Function Loss:  -3.1457\n",
      "Total loss:  -2.0696 | PDE Loss:  -2.8609 | Function Loss:  -3.1462\n",
      "Total loss:  -2.0698 | PDE Loss:  -2.8609 | Function Loss:  -3.1464\n",
      "Total loss:  -2.0701 | PDE Loss:  -2.8616 | Function Loss:  -3.1466\n",
      "Total loss:  -2.0702 | PDE Loss:  -2.8625 | Function Loss:  -3.1466\n",
      "Total loss:  -2.0704 | PDE Loss:  -2.8644 | Function Loss:  -3.1464\n",
      "Total loss:  -2.0704 | PDE Loss:  -2.8658 | Function Loss:  -3.1463\n",
      "Total loss:  -2.0705 | PDE Loss:  -2.8665 | Function Loss:  -3.1462\n",
      "Total loss:  -2.0706 | PDE Loss:  -2.8672 | Function Loss:  -3.1462\n",
      "Total loss:  -2.0707 | PDE Loss:  -2.8674 | Function Loss:  -3.1463\n",
      "Total loss:  -2.0708 | PDE Loss:  -2.8696 | Function Loss:  -3.146\n",
      "Total loss:  -2.071 | PDE Loss:  -2.8689 | Function Loss:  -3.1463\n",
      "Total loss:  -2.0712 | PDE Loss:  -2.8678 | Function Loss:  -3.1468\n",
      "Total loss:  -2.0714 | PDE Loss:  -2.8669 | Function Loss:  -3.1472\n",
      "Total loss:  -2.0717 | PDE Loss:  -2.8667 | Function Loss:  -3.1476\n",
      "Total loss:  -2.0719 | PDE Loss:  -2.8679 | Function Loss:  -3.1476\n",
      "Total loss:  -2.0721 | PDE Loss:  -2.8694 | Function Loss:  -3.1476\n",
      "Total loss:  -2.0723 | PDE Loss:  -2.8713 | Function Loss:  -3.1474\n",
      "Total loss:  -2.0724 | PDE Loss:  -2.8738 | Function Loss:  -3.1471\n",
      "Total loss:  -2.0725 | PDE Loss:  -2.8755 | Function Loss:  -3.1469\n",
      "Total loss:  -2.0726 | PDE Loss:  -2.8765 | Function Loss:  -3.1468\n",
      "Total loss:  -2.0727 | PDE Loss:  -2.8776 | Function Loss:  -3.1467\n",
      "Total loss:  -2.0728 | PDE Loss:  -2.8775 | Function Loss:  -3.1468\n",
      "Total loss:  -2.0729 | PDE Loss:  -2.8772 | Function Loss:  -3.147\n",
      "Total loss:  -2.0729 | PDE Loss:  -2.8762 | Function Loss:  -3.1473\n",
      "Total loss:  -2.073 | PDE Loss:  -2.8747 | Function Loss:  -3.1477\n",
      "Total loss:  -2.0731 | PDE Loss:  -2.8726 | Function Loss:  -3.1481\n",
      "Total loss:  -2.0732 | PDE Loss:  -2.8711 | Function Loss:  -3.1485\n",
      "Total loss:  -2.0732 | PDE Loss:  -2.8692 | Function Loss:  -3.1489\n",
      "Total loss:  -2.0733 | PDE Loss:  -2.8674 | Function Loss:  -3.1494\n",
      "Total loss:  -2.0734 | PDE Loss:  -2.8651 | Function Loss:  -3.15\n",
      "Total loss:  -2.0735 | PDE Loss:  -2.8631 | Function Loss:  -3.1505\n",
      "Total loss:  -2.0737 | PDE Loss:  -2.8609 | Function Loss:  -3.1511\n",
      "Total loss:  -2.0738 | PDE Loss:  -2.8585 | Function Loss:  -3.1517\n",
      "Total loss:  -2.074 | PDE Loss:  -2.8561 | Function Loss:  -3.1524\n",
      "Total loss:  -2.0742 | PDE Loss:  -2.8535 | Function Loss:  -3.1532\n",
      "Total loss:  -2.0745 | PDE Loss:  -2.85 | Function Loss:  -3.1542\n",
      "Total loss:  -2.0748 | PDE Loss:  -2.8475 | Function Loss:  -3.1551\n",
      "Total loss:  -2.075 | PDE Loss:  -2.8429 | Function Loss:  -3.1562\n",
      "Total loss:  -2.0753 | PDE Loss:  -2.8403 | Function Loss:  -3.1571\n",
      "Total loss:  -2.0757 | PDE Loss:  -2.8443 | Function Loss:  -3.1568\n",
      "Total loss:  -2.0759 | PDE Loss:  -2.8425 | Function Loss:  -3.1574\n",
      "Total loss:  -2.0764 | PDE Loss:  -2.8379 | Function Loss:  -3.159\n",
      "Total loss:  -2.0766 | PDE Loss:  -2.8368 | Function Loss:  -3.1595\n",
      "Total loss:  -2.0769 | PDE Loss:  -2.8353 | Function Loss:  -3.1601\n",
      "Total loss:  -2.0771 | PDE Loss:  -2.8353 | Function Loss:  -3.1604\n",
      "Total loss:  -2.0774 | PDE Loss:  -2.834 | Function Loss:  -3.161\n",
      "Total loss:  -2.0776 | PDE Loss:  -2.834 | Function Loss:  -3.1612\n",
      "Total loss:  -2.0777 | PDE Loss:  -2.8352 | Function Loss:  -3.1612\n",
      "Total loss:  -2.0778 | PDE Loss:  -2.836 | Function Loss:  -3.1611\n",
      "Total loss:  -2.0779 | PDE Loss:  -2.8371 | Function Loss:  -3.161\n",
      "Total loss:  -2.0781 | PDE Loss:  -2.8403 | Function Loss:  -3.1605\n",
      "Total loss:  -2.0782 | PDE Loss:  -2.8415 | Function Loss:  -3.1605\n",
      "Total loss:  -2.0785 | PDE Loss:  -2.8433 | Function Loss:  -3.1604\n",
      "Total loss:  -2.0788 | PDE Loss:  -2.8438 | Function Loss:  -3.1607\n",
      "Total loss:  -2.0791 | PDE Loss:  -2.8456 | Function Loss:  -3.1607\n",
      "Total loss:  -2.0795 | PDE Loss:  -2.8446 | Function Loss:  -3.1613\n",
      "Total loss:  -2.0798 | PDE Loss:  -2.8437 | Function Loss:  -3.1619\n",
      "Total loss:  -2.0802 | PDE Loss:  -2.8425 | Function Loss:  -3.1626\n",
      "Total loss:  -2.0806 | PDE Loss:  -2.8412 | Function Loss:  -3.1634\n",
      "Total loss:  -2.081 | PDE Loss:  -2.8395 | Function Loss:  -3.1642\n",
      "Total loss:  -2.0813 | PDE Loss:  -2.8395 | Function Loss:  -3.1646\n",
      "Total loss:  -2.0816 | PDE Loss:  -2.8387 | Function Loss:  -3.1652\n",
      "Total loss:  -2.0818 | PDE Loss:  -2.8396 | Function Loss:  -3.1652\n",
      "Total loss:  -2.082 | PDE Loss:  -2.8404 | Function Loss:  -3.1652\n",
      "Total loss:  -2.0822 | PDE Loss:  -2.8414 | Function Loss:  -3.1652\n",
      "Total loss:  -2.0823 | PDE Loss:  -2.8427 | Function Loss:  -3.1652\n",
      "Total loss:  -2.0825 | PDE Loss:  -2.8439 | Function Loss:  -3.1652\n",
      "Total loss:  -2.0828 | PDE Loss:  -2.8455 | Function Loss:  -3.1651\n",
      "Total loss:  -2.083 | PDE Loss:  -2.8464 | Function Loss:  -3.1652\n",
      "Total loss:  -2.0833 | PDE Loss:  -2.8473 | Function Loss:  -3.1654\n",
      "Total loss:  -2.0836 | PDE Loss:  -2.8475 | Function Loss:  -3.1657\n",
      "Total loss:  -2.0839 | PDE Loss:  -2.8472 | Function Loss:  -3.1661\n",
      "Total loss:  -2.0843 | PDE Loss:  -2.8473 | Function Loss:  -3.1665\n",
      "Total loss:  -2.0847 | PDE Loss:  -2.8468 | Function Loss:  -3.1672\n",
      "Total loss:  -2.0852 | PDE Loss:  -2.8472 | Function Loss:  -3.1677\n",
      "Total loss:  -2.0854 | PDE Loss:  -2.843 | Function Loss:  -3.1688\n",
      "Total loss:  -2.0858 | PDE Loss:  -2.8444 | Function Loss:  -3.169\n",
      "Total loss:  -2.0858 | PDE Loss:  -2.8471 | Function Loss:  -3.1685\n",
      "Total loss:  -2.0859 | PDE Loss:  -2.8459 | Function Loss:  -3.1689\n",
      "Total loss:  -2.0861 | PDE Loss:  -2.8452 | Function Loss:  -3.1692\n",
      "Total loss:  -2.0863 | PDE Loss:  -2.8445 | Function Loss:  -3.1696\n",
      "Total loss:  -2.0865 | PDE Loss:  -2.8425 | Function Loss:  -3.1702\n",
      "Total loss:  -2.0866 | PDE Loss:  -2.841 | Function Loss:  -3.1707\n",
      "Total loss:  -2.0867 | PDE Loss:  -2.8378 | Function Loss:  -3.1715\n",
      "Total loss:  -2.0868 | PDE Loss:  -2.8372 | Function Loss:  -3.1718\n",
      "Total loss:  -2.087 | PDE Loss:  -2.8369 | Function Loss:  -3.172\n",
      "Total loss:  -2.0871 | PDE Loss:  -2.8364 | Function Loss:  -3.1723\n",
      "Total loss:  -2.0873 | PDE Loss:  -2.8353 | Function Loss:  -3.1727\n",
      "Total loss:  -2.0875 | PDE Loss:  -2.8338 | Function Loss:  -3.1733\n",
      "Total loss:  -2.0877 | PDE Loss:  -2.8324 | Function Loss:  -3.1739\n",
      "Total loss:  -2.088 | PDE Loss:  -2.8301 | Function Loss:  -3.1748\n",
      "Total loss:  -2.0883 | PDE Loss:  -2.8286 | Function Loss:  -3.1754\n",
      "Total loss:  -2.0885 | PDE Loss:  -2.8256 | Function Loss:  -3.1764\n",
      "Total loss:  -2.0887 | PDE Loss:  -2.8244 | Function Loss:  -3.1769\n",
      "Total loss:  -2.0889 | PDE Loss:  -2.8221 | Function Loss:  -3.1776\n",
      "Total loss:  -2.0891 | PDE Loss:  -2.8209 | Function Loss:  -3.1782\n",
      "Total loss:  -2.0892 | PDE Loss:  -2.8213 | Function Loss:  -3.1783\n",
      "Total loss:  -2.0894 | PDE Loss:  -2.8207 | Function Loss:  -3.1786\n",
      "Total loss:  -2.0896 | PDE Loss:  -2.8206 | Function Loss:  -3.1788\n",
      "Total loss:  -2.0898 | PDE Loss:  -2.8211 | Function Loss:  -3.1789\n",
      "Total loss:  -2.0899 | PDE Loss:  -2.8222 | Function Loss:  -3.1789\n",
      "Total loss:  -2.0901 | PDE Loss:  -2.8226 | Function Loss:  -3.179\n",
      "Total loss:  -2.0903 | PDE Loss:  -2.8235 | Function Loss:  -3.1791\n",
      "Total loss:  -2.0905 | PDE Loss:  -2.8239 | Function Loss:  -3.1792\n",
      "Total loss:  -2.0907 | PDE Loss:  -2.8254 | Function Loss:  -3.1791\n",
      "Total loss:  -2.0909 | PDE Loss:  -2.8261 | Function Loss:  -3.1792\n",
      "Total loss:  -2.0912 | PDE Loss:  -2.8276 | Function Loss:  -3.1792\n",
      "Total loss:  -2.0915 | PDE Loss:  -2.8282 | Function Loss:  -3.1794\n",
      "Total loss:  -2.0917 | PDE Loss:  -2.8291 | Function Loss:  -3.1796\n",
      "Total loss:  -2.092 | PDE Loss:  -2.8298 | Function Loss:  -3.1797\n",
      "Total loss:  -2.0923 | PDE Loss:  -2.8309 | Function Loss:  -3.1798\n",
      "Total loss:  -2.0925 | PDE Loss:  -2.8325 | Function Loss:  -3.1798\n",
      "Total loss:  -2.0927 | PDE Loss:  -2.8339 | Function Loss:  -3.1797\n",
      "Total loss:  -2.0928 | PDE Loss:  -2.8346 | Function Loss:  -3.1797\n",
      "Total loss:  -2.0929 | PDE Loss:  -2.8352 | Function Loss:  -3.1797\n",
      "Total loss:  -2.0931 | PDE Loss:  -2.8362 | Function Loss:  -3.1796\n",
      "Total loss:  -2.0932 | PDE Loss:  -2.837 | Function Loss:  -3.1796\n",
      "Total loss:  -2.0934 | PDE Loss:  -2.8374 | Function Loss:  -3.1797\n",
      "Total loss:  -2.0936 | PDE Loss:  -2.8369 | Function Loss:  -3.18\n",
      "Total loss:  -2.0938 | PDE Loss:  -2.8355 | Function Loss:  -3.1806\n",
      "Total loss:  -2.0939 | PDE Loss:  -2.8334 | Function Loss:  -3.1813\n",
      "Total loss:  -2.094 | PDE Loss:  -2.832 | Function Loss:  -3.1817\n",
      "Total loss:  -2.0941 | PDE Loss:  -2.8307 | Function Loss:  -3.182\n",
      "Total loss:  -2.0941 | PDE Loss:  -2.8303 | Function Loss:  -3.1822\n",
      "Total loss:  -2.0942 | PDE Loss:  -2.8295 | Function Loss:  -3.1825\n",
      "Total loss:  -2.0943 | PDE Loss:  -2.8299 | Function Loss:  -3.1825\n",
      "Total loss:  -2.0943 | PDE Loss:  -2.8298 | Function Loss:  -3.1826\n",
      "Total loss:  -2.0944 | PDE Loss:  -2.8303 | Function Loss:  -3.1825\n",
      "Total loss:  -2.0944 | PDE Loss:  -2.8309 | Function Loss:  -3.1824\n",
      "Total loss:  -2.0945 | PDE Loss:  -2.831 | Function Loss:  -3.1824\n",
      "Total loss:  -2.0945 | PDE Loss:  -2.8313 | Function Loss:  -3.1824\n",
      "Total loss:  -2.0946 | PDE Loss:  -2.8318 | Function Loss:  -3.1825\n",
      "Total loss:  -2.0947 | PDE Loss:  -2.832 | Function Loss:  -3.1825\n",
      "Total loss:  -2.0948 | PDE Loss:  -2.8318 | Function Loss:  -3.1827\n",
      "Total loss:  -2.095 | PDE Loss:  -2.8316 | Function Loss:  -3.183\n",
      "Total loss:  -2.0952 | PDE Loss:  -2.8304 | Function Loss:  -3.1835\n",
      "Total loss:  -2.0953 | PDE Loss:  -2.8294 | Function Loss:  -3.1839\n",
      "Total loss:  -2.0955 | PDE Loss:  -2.8284 | Function Loss:  -3.1843\n",
      "Total loss:  -2.0956 | PDE Loss:  -2.8272 | Function Loss:  -3.1847\n",
      "Total loss:  -2.0958 | PDE Loss:  -2.8268 | Function Loss:  -3.1851\n",
      "Total loss:  -2.096 | PDE Loss:  -2.8261 | Function Loss:  -3.1855\n",
      "Total loss:  -2.0963 | PDE Loss:  -2.8255 | Function Loss:  -3.1859\n",
      "Total loss:  -2.0964 | PDE Loss:  -2.8263 | Function Loss:  -3.1859\n",
      "Total loss:  -2.0968 | PDE Loss:  -2.8278 | Function Loss:  -3.1861\n",
      "Total loss:  -2.097 | PDE Loss:  -2.8282 | Function Loss:  -3.1863\n",
      "Total loss:  -2.0973 | PDE Loss:  -2.8302 | Function Loss:  -3.1861\n",
      "Total loss:  -2.0975 | PDE Loss:  -2.8304 | Function Loss:  -3.1863\n",
      "Total loss:  -2.0977 | PDE Loss:  -2.8306 | Function Loss:  -3.1865\n",
      "Total loss:  -2.0979 | PDE Loss:  -2.8323 | Function Loss:  -3.1864\n",
      "Total loss:  -2.0982 | PDE Loss:  -2.8339 | Function Loss:  -3.1864\n",
      "Total loss:  -2.0984 | PDE Loss:  -2.8345 | Function Loss:  -3.1865\n",
      "Total loss:  -2.0985 | PDE Loss:  -2.835 | Function Loss:  -3.1866\n",
      "Total loss:  -2.0986 | PDE Loss:  -2.8362 | Function Loss:  -3.1864\n",
      "Total loss:  -2.0987 | PDE Loss:  -2.837 | Function Loss:  -3.1862\n",
      "Total loss:  -2.0987 | PDE Loss:  -2.8373 | Function Loss:  -3.1862\n",
      "Total loss:  -2.0988 | PDE Loss:  -2.838 | Function Loss:  -3.1861\n",
      "Total loss:  -2.0988 | PDE Loss:  -2.838 | Function Loss:  -3.1862\n",
      "Total loss:  -2.0989 | PDE Loss:  -2.8382 | Function Loss:  -3.1863\n",
      "Total loss:  -2.099 | PDE Loss:  -2.8387 | Function Loss:  -3.1863\n",
      "Total loss:  -2.0991 | PDE Loss:  -2.8386 | Function Loss:  -3.1865\n",
      "Total loss:  -2.0992 | PDE Loss:  -2.8394 | Function Loss:  -3.1864\n",
      "Total loss:  -2.0993 | PDE Loss:  -2.8403 | Function Loss:  -3.1863\n",
      "Total loss:  -2.0994 | PDE Loss:  -2.8417 | Function Loss:  -3.1862\n",
      "Total loss:  -2.0996 | PDE Loss:  -2.8437 | Function Loss:  -3.1859\n",
      "Total loss:  -2.0997 | PDE Loss:  -2.8458 | Function Loss:  -3.1855\n",
      "Total loss:  -2.0998 | PDE Loss:  -2.8481 | Function Loss:  -3.1852\n",
      "Total loss:  -2.0999 | PDE Loss:  -2.8512 | Function Loss:  -3.1846\n",
      "Total loss:  -2.1 | PDE Loss:  -2.8544 | Function Loss:  -3.1841\n",
      "Total loss:  -2.1001 | PDE Loss:  -2.8574 | Function Loss:  -3.1836\n",
      "Total loss:  -2.1002 | PDE Loss:  -2.8601 | Function Loss:  -3.1831\n",
      "Total loss:  -2.1002 | PDE Loss:  -2.8619 | Function Loss:  -3.1828\n",
      "Total loss:  -2.1003 | PDE Loss:  -2.864 | Function Loss:  -3.1824\n",
      "Total loss:  -2.1004 | PDE Loss:  -2.8655 | Function Loss:  -3.1823\n",
      "Total loss:  -2.1006 | PDE Loss:  -2.8673 | Function Loss:  -3.1821\n",
      "Total loss:  -2.1007 | PDE Loss:  -2.8676 | Function Loss:  -3.1822\n",
      "Total loss:  -2.1009 | PDE Loss:  -2.8676 | Function Loss:  -3.1824\n",
      "Total loss:  -2.101 | PDE Loss:  -2.8671 | Function Loss:  -3.1827\n",
      "Total loss:  -2.1013 | PDE Loss:  -2.8662 | Function Loss:  -3.1831\n",
      "Total loss:  -2.1015 | PDE Loss:  -2.8658 | Function Loss:  -3.1836\n",
      "Total loss:  -2.1018 | PDE Loss:  -2.8642 | Function Loss:  -3.1842\n",
      "Total loss:  -2.102 | PDE Loss:  -2.8653 | Function Loss:  -3.1842\n",
      "Total loss:  -2.1022 | PDE Loss:  -2.8668 | Function Loss:  -3.1841\n",
      "Total loss:  -2.1024 | PDE Loss:  -2.8677 | Function Loss:  -3.1842\n",
      "Total loss:  -2.1025 | PDE Loss:  -2.8691 | Function Loss:  -3.184\n",
      "Total loss:  -2.1026 | PDE Loss:  -2.8701 | Function Loss:  -3.184\n",
      "Total loss:  -2.1028 | PDE Loss:  -2.8715 | Function Loss:  -3.1839\n",
      "Total loss:  -2.1029 | PDE Loss:  -2.8724 | Function Loss:  -3.1839\n",
      "Total loss:  -2.1031 | PDE Loss:  -2.8736 | Function Loss:  -3.1838\n",
      "Total loss:  -2.1032 | PDE Loss:  -2.875 | Function Loss:  -3.1837\n",
      "Total loss:  -2.1034 | PDE Loss:  -2.8763 | Function Loss:  -3.1837\n",
      "Total loss:  -2.1037 | PDE Loss:  -2.8779 | Function Loss:  -3.1837\n",
      "Total loss:  -2.104 | PDE Loss:  -2.8796 | Function Loss:  -3.1837\n",
      "Total loss:  -2.1044 | PDE Loss:  -2.8806 | Function Loss:  -3.184\n",
      "Total loss:  -2.1047 | PDE Loss:  -2.8815 | Function Loss:  -3.1841\n",
      "Total loss:  -2.1049 | PDE Loss:  -2.8816 | Function Loss:  -3.1844\n",
      "Total loss:  -2.1053 | PDE Loss:  -2.8822 | Function Loss:  -3.1848\n",
      "Total loss:  -2.1057 | PDE Loss:  -2.8824 | Function Loss:  -3.1852\n",
      "Total loss:  -2.106 | PDE Loss:  -2.884 | Function Loss:  -3.1852\n",
      "Total loss:  -2.1064 | PDE Loss:  -2.8864 | Function Loss:  -3.1853\n",
      "Total loss:  -2.107 | PDE Loss:  -2.8915 | Function Loss:  -3.1849\n",
      "Total loss:  -2.1074 | PDE Loss:  -2.8953 | Function Loss:  -3.1847\n",
      "Total loss:  -2.108 | PDE Loss:  -2.9015 | Function Loss:  -3.1841\n",
      "Total loss:  -2.1084 | PDE Loss:  -2.9075 | Function Loss:  -3.1835\n",
      "Total loss:  -2.1089 | PDE Loss:  -2.9132 | Function Loss:  -3.1831\n",
      "Total loss:  -2.1092 | PDE Loss:  -2.9166 | Function Loss:  -3.1828\n",
      "Total loss:  -2.1094 | PDE Loss:  -2.9191 | Function Loss:  -3.1826\n",
      "Total loss:  -2.1096 | PDE Loss:  -2.9205 | Function Loss:  -3.1825\n",
      "Total loss:  -2.1097 | PDE Loss:  -2.9215 | Function Loss:  -3.1825\n",
      "Total loss:  -2.1099 | PDE Loss:  -2.9216 | Function Loss:  -3.1826\n",
      "Total loss:  -2.1101 | PDE Loss:  -2.9214 | Function Loss:  -3.1829\n",
      "Total loss:  -2.1103 | PDE Loss:  -2.9209 | Function Loss:  -3.1833\n",
      "Total loss:  -2.1105 | PDE Loss:  -2.9195 | Function Loss:  -3.1837\n",
      "Total loss:  -2.1106 | PDE Loss:  -2.9194 | Function Loss:  -3.184\n",
      "Total loss:  -2.1108 | PDE Loss:  -2.9193 | Function Loss:  -3.1842\n",
      "Total loss:  -2.111 | PDE Loss:  -2.9202 | Function Loss:  -3.1843\n",
      "Total loss:  -2.1113 | PDE Loss:  -2.9211 | Function Loss:  -3.1844\n",
      "Total loss:  -2.1115 | PDE Loss:  -2.9228 | Function Loss:  -3.1843\n",
      "Total loss:  -2.1116 | PDE Loss:  -2.9235 | Function Loss:  -3.1844\n",
      "Total loss:  -2.1118 | PDE Loss:  -2.9248 | Function Loss:  -3.1843\n",
      "Total loss:  -2.1119 | PDE Loss:  -2.925 | Function Loss:  -3.1844\n",
      "Total loss:  -2.1119 | PDE Loss:  -2.9262 | Function Loss:  -3.1842\n",
      "Total loss:  -2.112 | PDE Loss:  -2.926 | Function Loss:  -3.1843\n",
      "Total loss:  -2.1121 | PDE Loss:  -2.9258 | Function Loss:  -3.1845\n",
      "Total loss:  -2.1122 | PDE Loss:  -2.9245 | Function Loss:  -3.1848\n",
      "Total loss:  -2.1122 | PDE Loss:  -2.9238 | Function Loss:  -3.185\n",
      "Total loss:  -2.1123 | PDE Loss:  -2.9228 | Function Loss:  -3.1853\n",
      "Total loss:  -2.1124 | PDE Loss:  -2.9216 | Function Loss:  -3.1856\n",
      "Total loss:  -2.1125 | PDE Loss:  -2.9204 | Function Loss:  -3.1859\n",
      "Total loss:  -2.1125 | PDE Loss:  -2.9197 | Function Loss:  -3.1861\n",
      "Total loss:  -2.1126 | PDE Loss:  -2.9191 | Function Loss:  -3.1863\n",
      "Total loss:  -2.1127 | PDE Loss:  -2.9186 | Function Loss:  -3.1865\n",
      "Total loss:  -2.1127 | PDE Loss:  -2.9179 | Function Loss:  -3.1867\n",
      "Total loss:  -2.1128 | PDE Loss:  -2.9178 | Function Loss:  -3.1867\n",
      "Total loss:  -2.1128 | PDE Loss:  -2.9182 | Function Loss:  -3.1867\n",
      "Total loss:  -2.1129 | PDE Loss:  -2.9187 | Function Loss:  -3.1867\n",
      "Total loss:  -2.113 | PDE Loss:  -2.92 | Function Loss:  -3.1866\n",
      "Total loss:  -2.113 | PDE Loss:  -2.921 | Function Loss:  -3.1865\n",
      "Total loss:  -2.1131 | PDE Loss:  -2.9224 | Function Loss:  -3.1864\n",
      "Total loss:  -2.1132 | PDE Loss:  -2.9237 | Function Loss:  -3.1863\n",
      "Total loss:  -2.1129 | PDE Loss:  -2.9258 | Function Loss:  -3.1855\n",
      "Total loss:  -2.1133 | PDE Loss:  -2.9245 | Function Loss:  -3.1862\n",
      "Total loss:  -2.1134 | PDE Loss:  -2.9256 | Function Loss:  -3.1861\n",
      "Total loss:  -2.1136 | PDE Loss:  -2.9264 | Function Loss:  -3.1861\n",
      "Total loss:  -2.1137 | PDE Loss:  -2.9273 | Function Loss:  -3.1861\n",
      "Total loss:  -2.1139 | PDE Loss:  -2.9275 | Function Loss:  -3.1863\n",
      "Total loss:  -2.114 | PDE Loss:  -2.9281 | Function Loss:  -3.1864\n",
      "Total loss:  -2.1141 | PDE Loss:  -2.9275 | Function Loss:  -3.1866\n",
      "Total loss:  -2.1143 | PDE Loss:  -2.9279 | Function Loss:  -3.1867\n",
      "Total loss:  -2.1144 | PDE Loss:  -2.9277 | Function Loss:  -3.1869\n",
      "Total loss:  -2.1146 | PDE Loss:  -2.9274 | Function Loss:  -3.1872\n",
      "Total loss:  -2.1147 | PDE Loss:  -2.9274 | Function Loss:  -3.1873\n",
      "Total loss:  -2.1149 | PDE Loss:  -2.9271 | Function Loss:  -3.1875\n",
      "Total loss:  -2.115 | PDE Loss:  -2.9266 | Function Loss:  -3.1878\n",
      "Total loss:  -2.1152 | PDE Loss:  -2.926 | Function Loss:  -3.1882\n",
      "Total loss:  -2.1154 | PDE Loss:  -2.9251 | Function Loss:  -3.1886\n",
      "Total loss:  -2.1154 | PDE Loss:  -2.9245 | Function Loss:  -3.1887\n",
      "Total loss:  -2.1155 | PDE Loss:  -2.925 | Function Loss:  -3.1887\n",
      "Total loss:  -2.1157 | PDE Loss:  -2.9246 | Function Loss:  -3.1889\n",
      "Total loss:  -2.1158 | PDE Loss:  -2.9239 | Function Loss:  -3.1892\n",
      "Total loss:  -2.1159 | PDE Loss:  -2.924 | Function Loss:  -3.1893\n",
      "Total loss:  -2.1159 | PDE Loss:  -2.9236 | Function Loss:  -3.1894\n",
      "Total loss:  -2.116 | PDE Loss:  -2.9233 | Function Loss:  -3.1896\n",
      "Total loss:  -2.1161 | PDE Loss:  -2.9229 | Function Loss:  -3.1898\n",
      "Total loss:  -2.1161 | PDE Loss:  -2.9222 | Function Loss:  -3.19\n",
      "Total loss:  -2.1162 | PDE Loss:  -2.921 | Function Loss:  -3.1903\n",
      "Total loss:  -2.1163 | PDE Loss:  -2.9208 | Function Loss:  -3.1904\n",
      "Total loss:  -2.1165 | PDE Loss:  -2.9201 | Function Loss:  -3.1907\n",
      "Total loss:  -2.1166 | PDE Loss:  -2.92 | Function Loss:  -3.1908\n",
      "Total loss:  -2.1166 | PDE Loss:  -2.9199 | Function Loss:  -3.1909\n",
      "Total loss:  -2.1167 | PDE Loss:  -2.9197 | Function Loss:  -3.191\n",
      "Total loss:  -2.1168 | PDE Loss:  -2.9198 | Function Loss:  -3.1911\n",
      "Total loss:  -2.1168 | PDE Loss:  -2.9198 | Function Loss:  -3.1912\n",
      "Total loss:  -2.1169 | PDE Loss:  -2.92 | Function Loss:  -3.1913\n",
      "Total loss:  -2.117 | PDE Loss:  -2.9202 | Function Loss:  -3.1913\n",
      "Total loss:  -2.1171 | PDE Loss:  -2.9207 | Function Loss:  -3.1914\n",
      "Total loss:  -2.1172 | PDE Loss:  -2.9208 | Function Loss:  -3.1915\n",
      "Total loss:  -2.1173 | PDE Loss:  -2.9212 | Function Loss:  -3.1915\n",
      "Total loss:  -2.1174 | PDE Loss:  -2.9214 | Function Loss:  -3.1916\n",
      "Total loss:  -2.1175 | PDE Loss:  -2.9219 | Function Loss:  -3.1916\n",
      "Total loss:  -2.1176 | PDE Loss:  -2.922 | Function Loss:  -3.1917\n",
      "Total loss:  -2.1176 | PDE Loss:  -2.9222 | Function Loss:  -3.1917\n",
      "Total loss:  -2.1177 | PDE Loss:  -2.9222 | Function Loss:  -3.1918\n",
      "Total loss:  -2.1178 | PDE Loss:  -2.9221 | Function Loss:  -3.1919\n",
      "Total loss:  -2.1179 | PDE Loss:  -2.9219 | Function Loss:  -3.1921\n",
      "Total loss:  -2.118 | PDE Loss:  -2.9215 | Function Loss:  -3.1922\n",
      "Total loss:  -2.1181 | PDE Loss:  -2.9212 | Function Loss:  -3.1924\n",
      "Total loss:  -2.1182 | PDE Loss:  -2.9203 | Function Loss:  -3.1928\n",
      "Total loss:  -2.1184 | PDE Loss:  -2.9198 | Function Loss:  -3.193\n",
      "Total loss:  -2.1185 | PDE Loss:  -2.9185 | Function Loss:  -3.1934\n",
      "Total loss:  -2.1187 | PDE Loss:  -2.9188 | Function Loss:  -3.1936\n",
      "Total loss:  -2.1189 | PDE Loss:  -2.9192 | Function Loss:  -3.1938\n",
      "Total loss:  -2.1191 | PDE Loss:  -2.9192 | Function Loss:  -3.194\n",
      "Total loss:  -2.1193 | PDE Loss:  -2.9182 | Function Loss:  -3.1944\n",
      "Total loss:  -2.1194 | PDE Loss:  -2.9179 | Function Loss:  -3.1946\n",
      "Total loss:  -2.1195 | PDE Loss:  -2.9179 | Function Loss:  -3.1947\n",
      "Total loss:  -2.1195 | PDE Loss:  -2.9169 | Function Loss:  -3.195\n",
      "Total loss:  -2.1197 | PDE Loss:  -2.9164 | Function Loss:  -3.1952\n",
      "Total loss:  -2.1198 | PDE Loss:  -2.916 | Function Loss:  -3.1955\n",
      "Total loss:  -2.12 | PDE Loss:  -2.915 | Function Loss:  -3.1958\n",
      "Total loss:  -2.1202 | PDE Loss:  -2.9136 | Function Loss:  -3.1964\n",
      "Total loss:  -2.1204 | PDE Loss:  -2.9115 | Function Loss:  -3.1971\n",
      "Total loss:  -2.1206 | PDE Loss:  -2.9113 | Function Loss:  -3.1974\n",
      "Total loss:  -2.1207 | PDE Loss:  -2.9099 | Function Loss:  -3.1978\n",
      "Total loss:  -2.1209 | PDE Loss:  -2.9106 | Function Loss:  -3.1978\n",
      "Total loss:  -2.1211 | PDE Loss:  -2.9113 | Function Loss:  -3.1979\n",
      "Total loss:  -2.1212 | PDE Loss:  -2.9116 | Function Loss:  -3.198\n",
      "Total loss:  -2.1213 | PDE Loss:  -2.9117 | Function Loss:  -3.1981\n",
      "Total loss:  -2.1214 | PDE Loss:  -2.912 | Function Loss:  -3.1982\n",
      "Total loss:  -2.1215 | PDE Loss:  -2.9112 | Function Loss:  -3.1984\n",
      "Total loss:  -2.1216 | PDE Loss:  -2.9114 | Function Loss:  -3.1985\n",
      "Total loss:  -2.1217 | PDE Loss:  -2.9114 | Function Loss:  -3.1986\n",
      "Total loss:  -2.1219 | PDE Loss:  -2.9108 | Function Loss:  -3.1989\n",
      "Total loss:  -2.122 | PDE Loss:  -2.911 | Function Loss:  -3.1991\n",
      "Total loss:  -2.1221 | PDE Loss:  -2.9111 | Function Loss:  -3.1992\n",
      "Total loss:  -2.1222 | PDE Loss:  -2.9108 | Function Loss:  -3.1993\n",
      "Total loss:  -2.1223 | PDE Loss:  -2.9115 | Function Loss:  -3.1993\n",
      "Total loss:  -2.1223 | PDE Loss:  -2.912 | Function Loss:  -3.1992\n",
      "Total loss:  -2.1224 | PDE Loss:  -2.913 | Function Loss:  -3.1991\n",
      "Total loss:  -2.1224 | PDE Loss:  -2.9134 | Function Loss:  -3.1991\n",
      "Total loss:  -2.1225 | PDE Loss:  -2.914 | Function Loss:  -3.199\n",
      "Total loss:  -2.1225 | PDE Loss:  -2.9144 | Function Loss:  -3.199\n",
      "Total loss:  -2.1226 | PDE Loss:  -2.9151 | Function Loss:  -3.1989\n",
      "Total loss:  -2.1226 | PDE Loss:  -2.9155 | Function Loss:  -3.1989\n",
      "Total loss:  -2.1227 | PDE Loss:  -2.9158 | Function Loss:  -3.1989\n",
      "Total loss:  -2.1227 | PDE Loss:  -2.9159 | Function Loss:  -3.1989\n",
      "Total loss:  -2.1227 | PDE Loss:  -2.9157 | Function Loss:  -3.199\n",
      "Total loss:  -2.1228 | PDE Loss:  -2.9158 | Function Loss:  -3.1991\n",
      "Total loss:  -2.1228 | PDE Loss:  -2.9158 | Function Loss:  -3.1991\n",
      "Total loss:  -2.1229 | PDE Loss:  -2.9158 | Function Loss:  -3.1992\n",
      "Total loss:  -2.123 | PDE Loss:  -2.9162 | Function Loss:  -3.1992\n",
      "Total loss:  -2.1231 | PDE Loss:  -2.9164 | Function Loss:  -3.1993\n",
      "Total loss:  -2.1232 | PDE Loss:  -2.9169 | Function Loss:  -3.1994\n",
      "Total loss:  -2.1234 | PDE Loss:  -2.918 | Function Loss:  -3.1993\n",
      "Total loss:  -2.1235 | PDE Loss:  -2.9189 | Function Loss:  -3.1993\n",
      "Total loss:  -2.1237 | PDE Loss:  -2.9193 | Function Loss:  -3.1995\n",
      "Total loss:  -2.124 | PDE Loss:  -2.9205 | Function Loss:  -3.1996\n",
      "Total loss:  -2.1242 | PDE Loss:  -2.9206 | Function Loss:  -3.1998\n",
      "Total loss:  -2.1243 | PDE Loss:  -2.9196 | Function Loss:  -3.2002\n",
      "Total loss:  -2.1246 | PDE Loss:  -2.9198 | Function Loss:  -3.2004\n",
      "Total loss:  -2.1247 | PDE Loss:  -2.9201 | Function Loss:  -3.2005\n",
      "Total loss:  -2.1249 | PDE Loss:  -2.9201 | Function Loss:  -3.2008\n",
      "Total loss:  -2.1251 | PDE Loss:  -2.9198 | Function Loss:  -3.201\n",
      "Total loss:  -2.1252 | PDE Loss:  -2.9196 | Function Loss:  -3.2012\n",
      "Total loss:  -2.1253 | PDE Loss:  -2.9192 | Function Loss:  -3.2014\n",
      "Total loss:  -2.1255 | PDE Loss:  -2.9193 | Function Loss:  -3.2016\n",
      "Total loss:  -2.1257 | PDE Loss:  -2.9201 | Function Loss:  -3.2017\n",
      "Total loss:  -2.1258 | PDE Loss:  -2.9202 | Function Loss:  -3.2018\n",
      "Total loss:  -2.1259 | PDE Loss:  -2.9207 | Function Loss:  -3.2018\n",
      "Total loss:  -2.1261 | PDE Loss:  -2.9209 | Function Loss:  -3.202\n",
      "Total loss:  -2.1263 | PDE Loss:  -2.9209 | Function Loss:  -3.2022\n",
      "Total loss:  -2.1265 | PDE Loss:  -2.9203 | Function Loss:  -3.2026\n",
      "Total loss:  -2.1266 | PDE Loss:  -2.9191 | Function Loss:  -3.203\n",
      "Total loss:  -2.1268 | PDE Loss:  -2.9187 | Function Loss:  -3.2032\n",
      "Total loss:  -2.1268 | PDE Loss:  -2.9171 | Function Loss:  -3.2036\n",
      "Total loss:  -2.127 | PDE Loss:  -2.9165 | Function Loss:  -3.2039\n",
      "Total loss:  -2.1271 | PDE Loss:  -2.9165 | Function Loss:  -3.2041\n",
      "Total loss:  -2.1272 | PDE Loss:  -2.9159 | Function Loss:  -3.2043\n",
      "Total loss:  -2.1273 | PDE Loss:  -2.9153 | Function Loss:  -3.2046\n",
      "Total loss:  -2.1274 | PDE Loss:  -2.9148 | Function Loss:  -3.2048\n",
      "Total loss:  -2.1276 | PDE Loss:  -2.9135 | Function Loss:  -3.2052\n",
      "Total loss:  -2.1278 | PDE Loss:  -2.913 | Function Loss:  -3.2055\n",
      "Total loss:  -2.1279 | PDE Loss:  -2.9125 | Function Loss:  -3.2058\n",
      "Total loss:  -2.1281 | PDE Loss:  -2.9126 | Function Loss:  -3.2061\n",
      "Total loss:  -2.1284 | PDE Loss:  -2.9131 | Function Loss:  -3.2062\n",
      "Total loss:  -2.1286 | PDE Loss:  -2.9143 | Function Loss:  -3.2063\n",
      "Total loss:  -2.1289 | PDE Loss:  -2.9149 | Function Loss:  -3.2065\n",
      "Total loss:  -2.1291 | PDE Loss:  -2.9158 | Function Loss:  -3.2066\n",
      "Total loss:  -2.1293 | PDE Loss:  -2.9163 | Function Loss:  -3.2067\n",
      "Total loss:  -2.1295 | PDE Loss:  -2.916 | Function Loss:  -3.207\n",
      "Total loss:  -2.1297 | PDE Loss:  -2.9151 | Function Loss:  -3.2075\n",
      "Total loss:  -2.1301 | PDE Loss:  -2.9136 | Function Loss:  -3.2082\n",
      "Total loss:  -2.1303 | PDE Loss:  -2.9112 | Function Loss:  -3.2089\n",
      "Total loss:  -2.1305 | PDE Loss:  -2.9086 | Function Loss:  -3.2097\n",
      "Total loss:  -2.1306 | PDE Loss:  -2.9061 | Function Loss:  -3.2103\n",
      "Total loss:  -2.1307 | PDE Loss:  -2.9041 | Function Loss:  -3.2109\n",
      "Total loss:  -2.1308 | PDE Loss:  -2.9029 | Function Loss:  -3.2112\n",
      "Total loss:  -2.131 | PDE Loss:  -2.9018 | Function Loss:  -3.2116\n",
      "Total loss:  -2.1311 | PDE Loss:  -2.9016 | Function Loss:  -3.2119\n",
      "Total loss:  -2.1313 | PDE Loss:  -2.9013 | Function Loss:  -3.2121\n",
      "Total loss:  -2.1315 | PDE Loss:  -2.9021 | Function Loss:  -3.2122\n",
      "Total loss:  -2.1319 | PDE Loss:  -2.9041 | Function Loss:  -3.2122\n",
      "Total loss:  -2.1322 | PDE Loss:  -2.9071 | Function Loss:  -3.212\n",
      "Total loss:  -2.1325 | PDE Loss:  -2.91 | Function Loss:  -3.2118\n",
      "Total loss:  -2.1329 | PDE Loss:  -2.913 | Function Loss:  -3.2117\n",
      "Total loss:  -2.1333 | PDE Loss:  -2.9181 | Function Loss:  -3.2112\n",
      "Total loss:  -2.1338 | PDE Loss:  -2.9203 | Function Loss:  -3.2113\n",
      "Total loss:  -2.1341 | PDE Loss:  -2.9218 | Function Loss:  -3.2114\n",
      "Total loss:  -2.1343 | PDE Loss:  -2.922 | Function Loss:  -3.2117\n",
      "Total loss:  -2.1346 | PDE Loss:  -2.9227 | Function Loss:  -3.2118\n",
      "Total loss:  -2.1348 | PDE Loss:  -2.922 | Function Loss:  -3.2122\n",
      "Total loss:  -2.1352 | PDE Loss:  -2.9205 | Function Loss:  -3.213\n",
      "Total loss:  -2.1357 | PDE Loss:  -2.9202 | Function Loss:  -3.2136\n",
      "Total loss:  -2.1361 | PDE Loss:  -2.9208 | Function Loss:  -3.214\n",
      "Total loss:  -2.1367 | PDE Loss:  -2.9232 | Function Loss:  -3.2142\n",
      "Total loss:  -2.1371 | PDE Loss:  -2.9256 | Function Loss:  -3.2143\n",
      "Total loss:  -2.1376 | PDE Loss:  -2.9292 | Function Loss:  -3.2141\n",
      "Total loss:  -2.1378 | PDE Loss:  -2.9313 | Function Loss:  -3.2139\n",
      "Total loss:  -2.138 | PDE Loss:  -2.9331 | Function Loss:  -3.2138\n",
      "Total loss:  -2.1382 | PDE Loss:  -2.9358 | Function Loss:  -3.2136\n",
      "Total loss:  -2.1385 | PDE Loss:  -2.939 | Function Loss:  -3.2133\n",
      "Total loss:  -2.1389 | PDE Loss:  -2.9427 | Function Loss:  -3.2131\n",
      "Total loss:  -2.1391 | PDE Loss:  -2.9457 | Function Loss:  -3.2128\n",
      "Total loss:  -2.1394 | PDE Loss:  -2.9461 | Function Loss:  -3.2131\n",
      "Total loss:  -2.1397 | PDE Loss:  -2.9467 | Function Loss:  -3.2133\n",
      "Total loss:  -2.14 | PDE Loss:  -2.9472 | Function Loss:  -3.2136\n",
      "Total loss:  -2.1403 | PDE Loss:  -2.9485 | Function Loss:  -3.2138\n",
      "Total loss:  -2.1407 | PDE Loss:  -2.9504 | Function Loss:  -3.2138\n",
      "Total loss:  -2.1413 | PDE Loss:  -2.9535 | Function Loss:  -3.214\n",
      "Total loss:  -2.1417 | PDE Loss:  -2.9593 | Function Loss:  -3.2134\n",
      "Total loss:  -2.1422 | PDE Loss:  -2.9634 | Function Loss:  -3.2133\n",
      "Total loss:  -2.1427 | PDE Loss:  -2.9677 | Function Loss:  -3.2131\n",
      "Total loss:  -2.1432 | PDE Loss:  -2.9753 | Function Loss:  -3.2123\n",
      "Total loss:  -2.1435 | PDE Loss:  -2.9822 | Function Loss:  -3.2116\n",
      "Total loss:  -2.1438 | PDE Loss:  -2.9893 | Function Loss:  -3.2107\n",
      "Total loss:  -2.1441 | PDE Loss:  -2.9953 | Function Loss:  -3.21\n",
      "Total loss:  -2.1441 | PDE Loss:  -2.9975 | Function Loss:  -3.2097\n",
      "Total loss:  -2.1443 | PDE Loss:  -3.0001 | Function Loss:  -3.2095\n",
      "Total loss:  -2.1444 | PDE Loss:  -3.0037 | Function Loss:  -3.209\n",
      "Total loss:  -2.1445 | PDE Loss:  -3.0039 | Function Loss:  -3.2091\n",
      "Total loss:  -2.1446 | PDE Loss:  -3.0037 | Function Loss:  -3.2093\n",
      "Total loss:  -2.1447 | PDE Loss:  -3.0032 | Function Loss:  -3.2095\n",
      "Total loss:  -2.1449 | PDE Loss:  -3.0026 | Function Loss:  -3.2097\n",
      "Total loss:  -2.145 | PDE Loss:  -3.0026 | Function Loss:  -3.2099\n",
      "Total loss:  -2.1451 | PDE Loss:  -3.0026 | Function Loss:  -3.21\n",
      "Total loss:  -2.1452 | PDE Loss:  -3.0035 | Function Loss:  -3.21\n",
      "Total loss:  -2.1453 | PDE Loss:  -3.004 | Function Loss:  -3.21\n",
      "Total loss:  -2.1454 | PDE Loss:  -3.0049 | Function Loss:  -3.21\n",
      "Total loss:  -2.1455 | PDE Loss:  -3.0055 | Function Loss:  -3.21\n",
      "Total loss:  -2.1455 | PDE Loss:  -3.0061 | Function Loss:  -3.2099\n",
      "Total loss:  -2.1456 | PDE Loss:  -3.0064 | Function Loss:  -3.21\n",
      "Total loss:  -2.1456 | PDE Loss:  -3.0058 | Function Loss:  -3.2101\n",
      "Total loss:  -2.1457 | PDE Loss:  -3.0058 | Function Loss:  -3.2102\n",
      "Total loss:  -2.1458 | PDE Loss:  -3.0052 | Function Loss:  -3.2104\n",
      "Total loss:  -2.1459 | PDE Loss:  -3.0047 | Function Loss:  -3.2106\n",
      "Total loss:  -2.1461 | PDE Loss:  -3.004 | Function Loss:  -3.2109\n",
      "Total loss:  -2.1462 | PDE Loss:  -3.0037 | Function Loss:  -3.2111\n",
      "Total loss:  -2.1464 | PDE Loss:  -3.0035 | Function Loss:  -3.2113\n",
      "Total loss:  -2.1465 | PDE Loss:  -3.0044 | Function Loss:  -3.2114\n",
      "Total loss:  -2.1467 | PDE Loss:  -3.0049 | Function Loss:  -3.2115\n",
      "Total loss:  -2.1468 | PDE Loss:  -3.0067 | Function Loss:  -3.2113\n",
      "Total loss:  -2.1469 | PDE Loss:  -3.0075 | Function Loss:  -3.2113\n",
      "Total loss:  -2.147 | PDE Loss:  -3.0091 | Function Loss:  -3.2111\n",
      "Total loss:  -2.147 | PDE Loss:  -3.011 | Function Loss:  -3.2109\n",
      "Total loss:  -2.1471 | PDE Loss:  -3.0128 | Function Loss:  -3.2107\n",
      "Total loss:  -2.1472 | PDE Loss:  -3.0147 | Function Loss:  -3.2105\n",
      "Total loss:  -2.1474 | PDE Loss:  -3.0169 | Function Loss:  -3.2104\n",
      "Total loss:  -2.1476 | PDE Loss:  -3.0199 | Function Loss:  -3.2101\n",
      "Total loss:  -2.1477 | PDE Loss:  -3.0207 | Function Loss:  -3.2101\n",
      "Total loss:  -2.1479 | PDE Loss:  -3.0217 | Function Loss:  -3.2102\n",
      "Total loss:  -2.1481 | PDE Loss:  -3.0234 | Function Loss:  -3.2102\n",
      "Total loss:  -2.1483 | PDE Loss:  -3.0232 | Function Loss:  -3.2104\n",
      "Total loss:  -2.1484 | PDE Loss:  -3.0236 | Function Loss:  -3.2105\n",
      "Total loss:  -2.1485 | PDE Loss:  -3.0241 | Function Loss:  -3.2105\n",
      "Total loss:  -2.1485 | PDE Loss:  -3.0234 | Function Loss:  -3.2107\n",
      "Total loss:  -2.1486 | PDE Loss:  -3.0229 | Function Loss:  -3.2109\n",
      "Total loss:  -2.1487 | PDE Loss:  -3.0225 | Function Loss:  -3.211\n",
      "Total loss:  -2.1487 | PDE Loss:  -3.022 | Function Loss:  -3.2111\n",
      "Total loss:  -2.1488 | PDE Loss:  -3.0223 | Function Loss:  -3.2111\n",
      "Total loss:  -2.1488 | PDE Loss:  -3.0231 | Function Loss:  -3.2111\n",
      "Total loss:  -2.1489 | PDE Loss:  -3.0246 | Function Loss:  -3.211\n",
      "Total loss:  -2.149 | PDE Loss:  -3.0266 | Function Loss:  -3.2107\n",
      "Total loss:  -2.149 | PDE Loss:  -3.0283 | Function Loss:  -3.2105\n",
      "Total loss:  -2.1491 | PDE Loss:  -3.0303 | Function Loss:  -3.2103\n",
      "Total loss:  -2.1492 | PDE Loss:  -3.0322 | Function Loss:  -3.2101\n",
      "Total loss:  -2.1492 | PDE Loss:  -3.0336 | Function Loss:  -3.21\n",
      "Total loss:  -2.1493 | PDE Loss:  -3.0349 | Function Loss:  -3.2098\n",
      "Total loss:  -2.1493 | PDE Loss:  -3.0358 | Function Loss:  -3.2097\n",
      "Total loss:  -2.1494 | PDE Loss:  -3.0367 | Function Loss:  -3.2097\n",
      "Total loss:  -2.1494 | PDE Loss:  -3.0374 | Function Loss:  -3.2096\n",
      "Total loss:  -2.1495 | PDE Loss:  -3.0377 | Function Loss:  -3.2097\n",
      "Total loss:  -2.1496 | PDE Loss:  -3.038 | Function Loss:  -3.2097\n",
      "Total loss:  -2.1496 | PDE Loss:  -3.0376 | Function Loss:  -3.2098\n",
      "Total loss:  -2.1497 | PDE Loss:  -3.0374 | Function Loss:  -3.2099\n",
      "Total loss:  -2.1497 | PDE Loss:  -3.0369 | Function Loss:  -3.21\n",
      "Total loss:  -2.1497 | PDE Loss:  -3.0365 | Function Loss:  -3.2101\n",
      "Total loss:  -2.1497 | PDE Loss:  -3.0364 | Function Loss:  -3.2101\n",
      "Total loss:  -2.1498 | PDE Loss:  -3.0365 | Function Loss:  -3.2102\n",
      "Total loss:  -2.1498 | PDE Loss:  -3.0369 | Function Loss:  -3.2102\n",
      "Total loss:  -2.1499 | PDE Loss:  -3.0376 | Function Loss:  -3.2101\n",
      "Total loss:  -2.15 | PDE Loss:  -3.0384 | Function Loss:  -3.2101\n",
      "Total loss:  -2.1501 | PDE Loss:  -3.0399 | Function Loss:  -3.21\n",
      "Total loss:  -2.1502 | PDE Loss:  -3.0402 | Function Loss:  -3.21\n",
      "Total loss:  -2.1502 | PDE Loss:  -3.0408 | Function Loss:  -3.21\n",
      "Total loss:  -2.1503 | PDE Loss:  -3.0408 | Function Loss:  -3.2101\n",
      "Total loss:  -2.1503 | PDE Loss:  -3.041 | Function Loss:  -3.2101\n",
      "Total loss:  -2.1504 | PDE Loss:  -3.0411 | Function Loss:  -3.2101\n",
      "Total loss:  -2.1504 | PDE Loss:  -3.041 | Function Loss:  -3.2102\n",
      "Total loss:  -2.1504 | PDE Loss:  -3.0412 | Function Loss:  -3.2102\n",
      "Total loss:  -2.1504 | PDE Loss:  -3.0412 | Function Loss:  -3.2102\n",
      "Total loss:  -2.1504 | PDE Loss:  -3.0414 | Function Loss:  -3.2102\n",
      "Total loss:  -2.1505 | PDE Loss:  -3.0416 | Function Loss:  -3.2102\n",
      "Total loss:  -2.1505 | PDE Loss:  -3.0419 | Function Loss:  -3.2102\n",
      "Total loss:  -2.1505 | PDE Loss:  -3.0423 | Function Loss:  -3.2102\n",
      "Total loss:  -2.1505 | PDE Loss:  -3.0423 | Function Loss:  -3.2102\n",
      "Total loss:  -2.1506 | PDE Loss:  -3.0429 | Function Loss:  -3.2101\n",
      "Total loss:  -2.1506 | PDE Loss:  -3.0434 | Function Loss:  -3.2101\n",
      "Total loss:  -2.1506 | PDE Loss:  -3.0443 | Function Loss:  -3.21\n",
      "Total loss:  -2.1507 | PDE Loss:  -3.045 | Function Loss:  -3.2099\n",
      "Total loss:  -2.1507 | PDE Loss:  -3.0464 | Function Loss:  -3.2098\n",
      "Total loss:  -2.1508 | PDE Loss:  -3.0475 | Function Loss:  -3.2097\n",
      "Total loss:  -2.1508 | PDE Loss:  -3.049 | Function Loss:  -3.2095\n",
      "Total loss:  -2.1509 | PDE Loss:  -3.0505 | Function Loss:  -3.2094\n",
      "Total loss:  -2.151 | PDE Loss:  -3.0523 | Function Loss:  -3.2092\n",
      "Total loss:  -2.1511 | PDE Loss:  -3.0549 | Function Loss:  -3.209\n",
      "Total loss:  -2.1512 | PDE Loss:  -3.056 | Function Loss:  -3.2089\n",
      "Total loss:  -2.1513 | PDE Loss:  -3.0579 | Function Loss:  -3.2087\n",
      "Total loss:  -2.1514 | PDE Loss:  -3.0589 | Function Loss:  -3.2087\n",
      "Total loss:  -2.1515 | PDE Loss:  -3.0602 | Function Loss:  -3.2087\n",
      "Total loss:  -2.1516 | PDE Loss:  -3.0612 | Function Loss:  -3.2087\n",
      "Total loss:  -2.1517 | PDE Loss:  -3.0619 | Function Loss:  -3.2087\n",
      "Total loss:  -2.1518 | PDE Loss:  -3.0632 | Function Loss:  -3.2086\n",
      "Total loss:  -2.1519 | PDE Loss:  -3.0634 | Function Loss:  -3.2087\n",
      "Total loss:  -2.152 | PDE Loss:  -3.0649 | Function Loss:  -3.2086\n",
      "Total loss:  -2.152 | PDE Loss:  -3.0653 | Function Loss:  -3.2086\n",
      "Total loss:  -2.1522 | PDE Loss:  -3.0652 | Function Loss:  -3.2088\n",
      "Total loss:  -2.1523 | PDE Loss:  -3.0646 | Function Loss:  -3.209\n",
      "Total loss:  -2.1524 | PDE Loss:  -3.0627 | Function Loss:  -3.2093\n",
      "Total loss:  -2.1524 | PDE Loss:  -3.0617 | Function Loss:  -3.2095\n",
      "Total loss:  -2.1525 | PDE Loss:  -3.0603 | Function Loss:  -3.2098\n",
      "Total loss:  -2.1526 | PDE Loss:  -3.058 | Function Loss:  -3.2102\n",
      "Total loss:  -2.1526 | PDE Loss:  -3.0566 | Function Loss:  -3.2105\n",
      "Total loss:  -2.1527 | PDE Loss:  -3.0555 | Function Loss:  -3.2107\n",
      "Total loss:  -2.1528 | PDE Loss:  -3.054 | Function Loss:  -3.2111\n",
      "Total loss:  -2.1529 | PDE Loss:  -3.0533 | Function Loss:  -3.2112\n",
      "Total loss:  -2.1529 | PDE Loss:  -3.0524 | Function Loss:  -3.2114\n",
      "Total loss:  -2.153 | PDE Loss:  -3.0513 | Function Loss:  -3.2117\n",
      "Total loss:  -2.1531 | PDE Loss:  -3.05 | Function Loss:  -3.212\n",
      "Total loss:  -2.1532 | PDE Loss:  -3.048 | Function Loss:  -3.2124\n",
      "Total loss:  -2.1534 | PDE Loss:  -3.046 | Function Loss:  -3.2129\n",
      "Total loss:  -2.1535 | PDE Loss:  -3.0439 | Function Loss:  -3.2133\n",
      "Total loss:  -2.1536 | PDE Loss:  -3.0412 | Function Loss:  -3.2139\n",
      "Total loss:  -2.1537 | PDE Loss:  -3.0389 | Function Loss:  -3.2143\n",
      "Total loss:  -2.1538 | PDE Loss:  -3.0369 | Function Loss:  -3.2148\n",
      "Total loss:  -2.1539 | PDE Loss:  -3.0345 | Function Loss:  -3.2152\n",
      "Total loss:  -2.154 | PDE Loss:  -3.034 | Function Loss:  -3.2153\n",
      "Total loss:  -2.154 | PDE Loss:  -3.034 | Function Loss:  -3.2154\n",
      "Total loss:  -2.1541 | PDE Loss:  -3.0348 | Function Loss:  -3.2153\n",
      "Total loss:  -2.1541 | PDE Loss:  -3.0359 | Function Loss:  -3.2152\n",
      "Total loss:  -2.1541 | PDE Loss:  -3.0364 | Function Loss:  -3.2152\n",
      "Total loss:  -2.1542 | PDE Loss:  -3.0371 | Function Loss:  -3.2151\n",
      "Total loss:  -2.1542 | PDE Loss:  -3.0373 | Function Loss:  -3.2151\n",
      "Total loss:  -2.1543 | PDE Loss:  -3.0377 | Function Loss:  -3.2151\n",
      "Total loss:  -2.1543 | PDE Loss:  -3.0372 | Function Loss:  -3.2153\n",
      "Total loss:  -2.1544 | PDE Loss:  -3.0365 | Function Loss:  -3.2155\n",
      "Total loss:  -2.1545 | PDE Loss:  -3.0361 | Function Loss:  -3.2157\n",
      "Total loss:  -2.1546 | PDE Loss:  -3.0358 | Function Loss:  -3.2158\n",
      "Total loss:  -2.1547 | PDE Loss:  -3.0363 | Function Loss:  -3.2159\n",
      "Total loss:  -2.1548 | PDE Loss:  -3.0373 | Function Loss:  -3.2158\n",
      "Total loss:  -2.1549 | PDE Loss:  -3.0376 | Function Loss:  -3.2159\n",
      "Total loss:  -2.1551 | PDE Loss:  -3.0392 | Function Loss:  -3.2158\n",
      "Total loss:  -2.1552 | PDE Loss:  -3.0405 | Function Loss:  -3.2158\n",
      "Total loss:  -2.1555 | PDE Loss:  -3.044 | Function Loss:  -3.2156\n",
      "Total loss:  -2.1557 | PDE Loss:  -3.0455 | Function Loss:  -3.2156\n",
      "Total loss:  -2.1558 | PDE Loss:  -3.0472 | Function Loss:  -3.2155\n",
      "Total loss:  -2.1561 | PDE Loss:  -3.0497 | Function Loss:  -3.2154\n",
      "Total loss:  -2.1564 | PDE Loss:  -3.0555 | Function Loss:  -3.215\n",
      "Total loss:  -2.1569 | PDE Loss:  -3.0617 | Function Loss:  -3.2146\n",
      "Total loss:  -2.1575 | PDE Loss:  -3.0682 | Function Loss:  -3.2144\n",
      "Total loss:  -2.158 | PDE Loss:  -3.0743 | Function Loss:  -3.2141\n",
      "Total loss:  -2.1582 | PDE Loss:  -3.08 | Function Loss:  -3.2136\n",
      "Total loss:  -2.1587 | PDE Loss:  -3.0796 | Function Loss:  -3.2142\n",
      "Total loss:  -2.1591 | PDE Loss:  -3.081 | Function Loss:  -3.2145\n",
      "Total loss:  -2.1595 | PDE Loss:  -3.0841 | Function Loss:  -3.2145\n",
      "Total loss:  -2.1597 | PDE Loss:  -3.0847 | Function Loss:  -3.2147\n",
      "Total loss:  -2.1599 | PDE Loss:  -3.0852 | Function Loss:  -3.2149\n",
      "Total loss:  -2.1601 | PDE Loss:  -3.0899 | Function Loss:  -3.2145\n",
      "Total loss:  -2.1604 | PDE Loss:  -3.0935 | Function Loss:  -3.2143\n",
      "Total loss:  -2.1606 | PDE Loss:  -3.0946 | Function Loss:  -3.2144\n",
      "Total loss:  -2.1609 | PDE Loss:  -3.0971 | Function Loss:  -3.2144\n",
      "Total loss:  -2.1612 | PDE Loss:  -3.1003 | Function Loss:  -3.2143\n",
      "Total loss:  -2.1615 | PDE Loss:  -3.1034 | Function Loss:  -3.2142\n",
      "Total loss:  -2.1618 | PDE Loss:  -3.107 | Function Loss:  -3.2141\n",
      "Total loss:  -2.162 | PDE Loss:  -3.1089 | Function Loss:  -3.2141\n",
      "Total loss:  -2.1622 | PDE Loss:  -3.1115 | Function Loss:  -3.214\n",
      "Total loss:  -2.1623 | PDE Loss:  -3.1122 | Function Loss:  -3.214\n",
      "Total loss:  -2.1625 | PDE Loss:  -3.1138 | Function Loss:  -3.214\n",
      "Total loss:  -2.1627 | PDE Loss:  -3.115 | Function Loss:  -3.2141\n",
      "Total loss:  -2.1628 | PDE Loss:  -3.1158 | Function Loss:  -3.2141\n",
      "Total loss:  -2.1629 | PDE Loss:  -3.1179 | Function Loss:  -3.214\n",
      "Total loss:  -2.163 | PDE Loss:  -3.1192 | Function Loss:  -3.2139\n",
      "Total loss:  -2.1631 | PDE Loss:  -3.1204 | Function Loss:  -3.2139\n",
      "Total loss:  -2.1632 | PDE Loss:  -3.1212 | Function Loss:  -3.2139\n",
      "Total loss:  -2.1633 | PDE Loss:  -3.1223 | Function Loss:  -3.2139\n",
      "Total loss:  -2.1634 | PDE Loss:  -3.1222 | Function Loss:  -3.214\n",
      "Total loss:  -2.1635 | PDE Loss:  -3.122 | Function Loss:  -3.2141\n",
      "Total loss:  -2.1636 | PDE Loss:  -3.1206 | Function Loss:  -3.2144\n",
      "Total loss:  -2.1637 | PDE Loss:  -3.1193 | Function Loss:  -3.2147\n",
      "Total loss:  -2.1638 | PDE Loss:  -3.1178 | Function Loss:  -3.2149\n",
      "Total loss:  -2.1638 | PDE Loss:  -3.1161 | Function Loss:  -3.2152\n",
      "Total loss:  -2.164 | PDE Loss:  -3.115 | Function Loss:  -3.2155\n",
      "Total loss:  -2.1642 | PDE Loss:  -3.114 | Function Loss:  -3.2159\n",
      "Total loss:  -2.1645 | PDE Loss:  -3.1145 | Function Loss:  -3.2162\n",
      "Total loss:  -2.1647 | PDE Loss:  -3.1153 | Function Loss:  -3.2163\n",
      "Total loss:  -2.1649 | PDE Loss:  -3.1175 | Function Loss:  -3.2163\n",
      "Total loss:  -2.1651 | PDE Loss:  -3.1194 | Function Loss:  -3.2163\n",
      "Total loss:  -2.1654 | PDE Loss:  -3.1218 | Function Loss:  -3.2162\n",
      "Total loss:  -2.1656 | PDE Loss:  -3.1249 | Function Loss:  -3.2161\n",
      "Total loss:  -2.1657 | PDE Loss:  -3.1274 | Function Loss:  -3.216\n",
      "Total loss:  -2.1659 | PDE Loss:  -3.1293 | Function Loss:  -3.2159\n",
      "Total loss:  -2.166 | PDE Loss:  -3.132 | Function Loss:  -3.2157\n",
      "Total loss:  -2.1661 | PDE Loss:  -3.1335 | Function Loss:  -3.2156\n",
      "Total loss:  -2.1662 | PDE Loss:  -3.135 | Function Loss:  -3.2156\n",
      "Total loss:  -2.1663 | PDE Loss:  -3.1358 | Function Loss:  -3.2155\n",
      "Total loss:  -2.1663 | PDE Loss:  -3.1358 | Function Loss:  -3.2156\n",
      "Total loss:  -2.1663 | PDE Loss:  -3.1361 | Function Loss:  -3.2156\n",
      "Total loss:  -2.1663 | PDE Loss:  -3.136 | Function Loss:  -3.2156\n",
      "Total loss:  -2.1664 | PDE Loss:  -3.1364 | Function Loss:  -3.2156\n",
      "Total loss:  -2.1664 | PDE Loss:  -3.1367 | Function Loss:  -3.2156\n",
      "Total loss:  -2.1665 | PDE Loss:  -3.1376 | Function Loss:  -3.2156\n",
      "Total loss:  -2.1665 | PDE Loss:  -3.1378 | Function Loss:  -3.2156\n",
      "Total loss:  -2.1666 | PDE Loss:  -3.1378 | Function Loss:  -3.2156\n",
      "Total loss:  -2.1666 | PDE Loss:  -3.1375 | Function Loss:  -3.2157\n",
      "Total loss:  -2.1667 | PDE Loss:  -3.1363 | Function Loss:  -3.2159\n",
      "Total loss:  -2.1667 | PDE Loss:  -3.1345 | Function Loss:  -3.2162\n",
      "Total loss:  -2.1668 | PDE Loss:  -3.132 | Function Loss:  -3.2166\n",
      "Total loss:  -2.1668 | PDE Loss:  -3.1287 | Function Loss:  -3.217\n",
      "Total loss:  -2.1669 | PDE Loss:  -3.1257 | Function Loss:  -3.2174\n",
      "Total loss:  -2.1669 | PDE Loss:  -3.1225 | Function Loss:  -3.2179\n",
      "Total loss:  -2.167 | PDE Loss:  -3.1195 | Function Loss:  -3.2184\n",
      "Total loss:  -2.167 | PDE Loss:  -3.1168 | Function Loss:  -3.2187\n",
      "Total loss:  -2.1671 | PDE Loss:  -3.1151 | Function Loss:  -3.219\n",
      "Total loss:  -2.1671 | PDE Loss:  -3.1128 | Function Loss:  -3.2193\n",
      "Total loss:  -2.1671 | PDE Loss:  -3.1121 | Function Loss:  -3.2195\n",
      "Total loss:  -2.1672 | PDE Loss:  -3.1116 | Function Loss:  -3.2195\n",
      "Total loss:  -2.1672 | PDE Loss:  -3.1115 | Function Loss:  -3.2196\n",
      "Total loss:  -2.1672 | PDE Loss:  -3.112 | Function Loss:  -3.2196\n",
      "Total loss:  -2.1672 | PDE Loss:  -3.1127 | Function Loss:  -3.2195\n",
      "Total loss:  -2.1672 | PDE Loss:  -3.1129 | Function Loss:  -3.2195\n",
      "Total loss:  -2.1673 | PDE Loss:  -3.1133 | Function Loss:  -3.2194\n",
      "Total loss:  -2.1673 | PDE Loss:  -3.114 | Function Loss:  -3.2194\n",
      "Total loss:  -2.1673 | PDE Loss:  -3.1142 | Function Loss:  -3.2194\n",
      "Total loss:  -2.1674 | PDE Loss:  -3.1143 | Function Loss:  -3.2194\n",
      "Total loss:  -2.1674 | PDE Loss:  -3.1142 | Function Loss:  -3.2195\n",
      "Total loss:  -2.1676 | PDE Loss:  -3.1135 | Function Loss:  -3.2198\n",
      "Total loss:  -2.1677 | PDE Loss:  -3.1128 | Function Loss:  -3.22\n",
      "Total loss:  -2.1679 | PDE Loss:  -3.1103 | Function Loss:  -3.2206\n",
      "Total loss:  -2.1681 | PDE Loss:  -3.1108 | Function Loss:  -3.2207\n",
      "Total loss:  -2.1682 | PDE Loss:  -3.108 | Function Loss:  -3.2212\n",
      "Total loss:  -2.1684 | PDE Loss:  -3.1086 | Function Loss:  -3.2213\n",
      "Total loss:  -2.1685 | PDE Loss:  -3.111 | Function Loss:  -3.2212\n",
      "Total loss:  -2.1686 | PDE Loss:  -3.1128 | Function Loss:  -3.221\n",
      "Total loss:  -2.1687 | PDE Loss:  -3.1124 | Function Loss:  -3.2211\n",
      "Total loss:  -2.1687 | PDE Loss:  -3.1134 | Function Loss:  -3.2211\n",
      "Total loss:  -2.1688 | PDE Loss:  -3.1137 | Function Loss:  -3.2211\n",
      "Total loss:  -2.1689 | PDE Loss:  -3.1132 | Function Loss:  -3.2213\n",
      "Total loss:  -2.169 | PDE Loss:  -3.1126 | Function Loss:  -3.2215\n",
      "Total loss:  -2.1691 | PDE Loss:  -3.1113 | Function Loss:  -3.2217\n",
      "Total loss:  -2.1692 | PDE Loss:  -3.1107 | Function Loss:  -3.2219\n",
      "Total loss:  -2.1692 | PDE Loss:  -3.1099 | Function Loss:  -3.2221\n",
      "Total loss:  -2.1693 | PDE Loss:  -3.1093 | Function Loss:  -3.2222\n",
      "Total loss:  -2.1693 | PDE Loss:  -3.1084 | Function Loss:  -3.2224\n",
      "Total loss:  -2.1695 | PDE Loss:  -3.1073 | Function Loss:  -3.2227\n",
      "Total loss:  -2.1696 | PDE Loss:  -3.106 | Function Loss:  -3.223\n",
      "Total loss:  -2.1698 | PDE Loss:  -3.1025 | Function Loss:  -3.2237\n",
      "Total loss:  -2.1701 | PDE Loss:  -3.1003 | Function Loss:  -3.2243\n",
      "Total loss:  -2.1704 | PDE Loss:  -3.0964 | Function Loss:  -3.2252\n",
      "Total loss:  -2.1711 | PDE Loss:  -3.092 | Function Loss:  -3.2266\n",
      "Total loss:  -2.1714 | PDE Loss:  -3.088 | Function Loss:  -3.2275\n",
      "Total loss:  -2.1721 | PDE Loss:  -3.0839 | Function Loss:  -3.2289\n",
      "Total loss:  -2.1725 | PDE Loss:  -3.0771 | Function Loss:  -3.2303\n",
      "Total loss:  -2.1723 | PDE Loss:  -3.0773 | Function Loss:  -3.2301\n",
      "Total loss:  -2.1726 | PDE Loss:  -3.0787 | Function Loss:  -3.2302\n",
      "Total loss:  -2.173 | PDE Loss:  -3.0795 | Function Loss:  -3.2305\n",
      "Total loss:  -2.1734 | PDE Loss:  -3.0808 | Function Loss:  -3.2307\n",
      "Total loss:  -2.1738 | PDE Loss:  -3.0792 | Function Loss:  -3.2314\n",
      "Total loss:  -2.1739 | PDE Loss:  -3.0776 | Function Loss:  -3.2318\n",
      "Total loss:  -2.1742 | PDE Loss:  -3.0755 | Function Loss:  -3.2324\n",
      "Total loss:  -2.1743 | PDE Loss:  -3.0765 | Function Loss:  -3.2324\n",
      "Total loss:  -2.1745 | PDE Loss:  -3.0739 | Function Loss:  -3.233\n",
      "Total loss:  -2.1748 | PDE Loss:  -3.0673 | Function Loss:  -3.2343\n",
      "Total loss:  -2.1749 | PDE Loss:  -3.0649 | Function Loss:  -3.2348\n",
      "Total loss:  -2.1751 | PDE Loss:  -3.0646 | Function Loss:  -3.235\n",
      "Total loss:  -2.1752 | PDE Loss:  -3.0623 | Function Loss:  -3.2356\n",
      "Total loss:  -2.1754 | PDE Loss:  -3.0592 | Function Loss:  -3.2363\n",
      "Total loss:  -2.1756 | PDE Loss:  -3.054 | Function Loss:  -3.2372\n",
      "Total loss:  -2.1757 | PDE Loss:  -3.0503 | Function Loss:  -3.238\n",
      "Total loss:  -2.1759 | PDE Loss:  -3.05 | Function Loss:  -3.2382\n",
      "Total loss:  -2.176 | PDE Loss:  -3.0466 | Function Loss:  -3.2389\n",
      "Total loss:  -2.1761 | PDE Loss:  -3.0457 | Function Loss:  -3.2391\n",
      "Total loss:  -2.1762 | PDE Loss:  -3.044 | Function Loss:  -3.2395\n",
      "Total loss:  -2.1764 | PDE Loss:  -3.0446 | Function Loss:  -3.2396\n",
      "Total loss:  -2.1765 | PDE Loss:  -3.0439 | Function Loss:  -3.2398\n",
      "Total loss:  -2.1767 | PDE Loss:  -3.0454 | Function Loss:  -3.2398\n",
      "Total loss:  -2.1769 | PDE Loss:  -3.0458 | Function Loss:  -3.24\n",
      "Total loss:  -2.1771 | PDE Loss:  -3.0467 | Function Loss:  -3.24\n",
      "Total loss:  -2.1773 | PDE Loss:  -3.0498 | Function Loss:  -3.2398\n",
      "Total loss:  -2.1775 | PDE Loss:  -3.0504 | Function Loss:  -3.24\n",
      "Total loss:  -2.1777 | PDE Loss:  -3.0522 | Function Loss:  -3.2399\n",
      "Total loss:  -2.1779 | PDE Loss:  -3.0547 | Function Loss:  -3.2398\n",
      "Total loss:  -2.1782 | PDE Loss:  -3.0583 | Function Loss:  -3.2395\n",
      "Total loss:  -2.1783 | PDE Loss:  -3.0607 | Function Loss:  -3.2394\n",
      "Total loss:  -2.1786 | PDE Loss:  -3.0637 | Function Loss:  -3.2392\n",
      "Total loss:  -2.1788 | PDE Loss:  -3.0669 | Function Loss:  -3.239\n",
      "Total loss:  -2.1789 | PDE Loss:  -3.0682 | Function Loss:  -3.2389\n",
      "Total loss:  -2.179 | PDE Loss:  -3.0685 | Function Loss:  -3.239\n",
      "Total loss:  -2.1791 | PDE Loss:  -3.0694 | Function Loss:  -3.2389\n",
      "Total loss:  -2.1792 | PDE Loss:  -3.0688 | Function Loss:  -3.2391\n",
      "Total loss:  -2.1792 | PDE Loss:  -3.0689 | Function Loss:  -3.2391\n",
      "Total loss:  -2.1793 | PDE Loss:  -3.0687 | Function Loss:  -3.2392\n",
      "Total loss:  -2.1793 | PDE Loss:  -3.0683 | Function Loss:  -3.2393\n",
      "Total loss:  -2.1794 | PDE Loss:  -3.0675 | Function Loss:  -3.2396\n",
      "Total loss:  -2.1795 | PDE Loss:  -3.0656 | Function Loss:  -3.24\n",
      "Total loss:  -2.1796 | PDE Loss:  -3.0632 | Function Loss:  -3.2405\n",
      "Total loss:  -2.1798 | PDE Loss:  -3.0591 | Function Loss:  -3.2413\n",
      "Total loss:  -2.1799 | PDE Loss:  -3.0574 | Function Loss:  -3.2417\n",
      "Total loss:  -2.1802 | PDE Loss:  -3.0513 | Function Loss:  -3.2429\n",
      "Total loss:  -2.1804 | PDE Loss:  -3.0464 | Function Loss:  -3.244\n",
      "Total loss:  -2.1806 | PDE Loss:  -3.0419 | Function Loss:  -3.2449\n",
      "Total loss:  -2.1808 | PDE Loss:  -3.0382 | Function Loss:  -3.2457\n",
      "Total loss:  -2.1809 | PDE Loss:  -3.034 | Function Loss:  -3.2465\n",
      "Total loss:  -2.181 | PDE Loss:  -3.0327 | Function Loss:  -3.2468\n",
      "Total loss:  -2.181 | PDE Loss:  -3.031 | Function Loss:  -3.2472\n",
      "Total loss:  -2.1811 | PDE Loss:  -3.0306 | Function Loss:  -3.2474\n",
      "Total loss:  -2.1812 | PDE Loss:  -3.03 | Function Loss:  -3.2475\n",
      "Total loss:  -2.1813 | PDE Loss:  -3.0297 | Function Loss:  -3.2477\n",
      "Total loss:  -2.1814 | PDE Loss:  -3.0302 | Function Loss:  -3.2477\n",
      "Total loss:  -2.1815 | PDE Loss:  -3.0311 | Function Loss:  -3.2477\n",
      "Total loss:  -2.1816 | PDE Loss:  -3.0335 | Function Loss:  -3.2475\n",
      "Total loss:  -2.1817 | PDE Loss:  -3.0336 | Function Loss:  -3.2475\n",
      "Total loss:  -2.1818 | PDE Loss:  -3.0349 | Function Loss:  -3.2474\n",
      "Total loss:  -2.1818 | PDE Loss:  -3.0354 | Function Loss:  -3.2474\n",
      "Total loss:  -2.1819 | PDE Loss:  -3.0359 | Function Loss:  -3.2474\n",
      "Total loss:  -2.182 | PDE Loss:  -3.0362 | Function Loss:  -3.2474\n",
      "Total loss:  -2.1821 | PDE Loss:  -3.037 | Function Loss:  -3.2474\n",
      "Total loss:  -2.1822 | PDE Loss:  -3.0376 | Function Loss:  -3.2475\n",
      "Total loss:  -2.1823 | PDE Loss:  -3.0388 | Function Loss:  -3.2474\n",
      "Total loss:  -2.1825 | PDE Loss:  -3.0398 | Function Loss:  -3.2474\n",
      "Total loss:  -2.1827 | PDE Loss:  -3.0408 | Function Loss:  -3.2475\n",
      "Total loss:  -2.1828 | PDE Loss:  -3.0427 | Function Loss:  -3.2473\n",
      "Total loss:  -2.1829 | PDE Loss:  -3.0433 | Function Loss:  -3.2474\n",
      "Total loss:  -2.183 | PDE Loss:  -3.0444 | Function Loss:  -3.2473\n",
      "Total loss:  -2.1831 | PDE Loss:  -3.0453 | Function Loss:  -3.2473\n",
      "Total loss:  -2.1832 | PDE Loss:  -3.0463 | Function Loss:  -3.2472\n",
      "Total loss:  -2.1832 | PDE Loss:  -3.0471 | Function Loss:  -3.2471\n",
      "Total loss:  -2.1833 | PDE Loss:  -3.049 | Function Loss:  -3.2469\n",
      "Total loss:  -2.1833 | PDE Loss:  -3.0504 | Function Loss:  -3.2467\n",
      "Total loss:  -2.1834 | PDE Loss:  -3.0522 | Function Loss:  -3.2465\n",
      "Total loss:  -2.1835 | PDE Loss:  -3.0546 | Function Loss:  -3.2462\n",
      "Total loss:  -2.1835 | PDE Loss:  -3.0586 | Function Loss:  -3.2457\n",
      "Total loss:  -2.1836 | PDE Loss:  -3.0598 | Function Loss:  -3.2456\n",
      "Total loss:  -2.1837 | PDE Loss:  -3.0613 | Function Loss:  -3.2454\n",
      "Total loss:  -2.1838 | PDE Loss:  -3.0625 | Function Loss:  -3.2453\n",
      "Total loss:  -2.1838 | PDE Loss:  -3.0633 | Function Loss:  -3.2453\n",
      "Total loss:  -2.1839 | PDE Loss:  -3.0644 | Function Loss:  -3.2452\n",
      "Total loss:  -2.184 | PDE Loss:  -3.0644 | Function Loss:  -3.2453\n",
      "Total loss:  -2.184 | PDE Loss:  -3.0648 | Function Loss:  -3.2453\n",
      "Total loss:  -2.1841 | PDE Loss:  -3.0645 | Function Loss:  -3.2454\n",
      "Total loss:  -2.1841 | PDE Loss:  -3.0644 | Function Loss:  -3.2455\n",
      "Total loss:  -2.1842 | PDE Loss:  -3.064 | Function Loss:  -3.2456\n",
      "Total loss:  -2.1842 | PDE Loss:  -3.0639 | Function Loss:  -3.2456\n",
      "Total loss:  -2.1842 | PDE Loss:  -3.0643 | Function Loss:  -3.2456\n",
      "Total loss:  -2.1843 | PDE Loss:  -3.0646 | Function Loss:  -3.2456\n",
      "Total loss:  -2.1843 | PDE Loss:  -3.0659 | Function Loss:  -3.2455\n",
      "Total loss:  -2.1844 | PDE Loss:  -3.0667 | Function Loss:  -3.2454\n",
      "Total loss:  -2.1844 | PDE Loss:  -3.0682 | Function Loss:  -3.2452\n",
      "Total loss:  -2.1844 | PDE Loss:  -3.0696 | Function Loss:  -3.2451\n",
      "Total loss:  -2.1845 | PDE Loss:  -3.0718 | Function Loss:  -3.2448\n",
      "Total loss:  -2.1845 | PDE Loss:  -3.0728 | Function Loss:  -3.2447\n",
      "Total loss:  -2.1846 | PDE Loss:  -3.0728 | Function Loss:  -3.2447\n",
      "Total loss:  -2.1846 | PDE Loss:  -3.0725 | Function Loss:  -3.2448\n",
      "Total loss:  -2.1847 | PDE Loss:  -3.0716 | Function Loss:  -3.245\n",
      "Total loss:  -2.1847 | PDE Loss:  -3.0702 | Function Loss:  -3.2453\n",
      "Total loss:  -2.1848 | PDE Loss:  -3.0685 | Function Loss:  -3.2456\n",
      "Total loss:  -2.1849 | PDE Loss:  -3.0664 | Function Loss:  -3.246\n",
      "Total loss:  -2.1849 | PDE Loss:  -3.0642 | Function Loss:  -3.2464\n",
      "Total loss:  -2.185 | PDE Loss:  -3.0624 | Function Loss:  -3.2468\n",
      "Total loss:  -2.1851 | PDE Loss:  -3.0607 | Function Loss:  -3.2471\n",
      "Total loss:  -2.1851 | PDE Loss:  -3.0595 | Function Loss:  -3.2474\n",
      "Total loss:  -2.1852 | PDE Loss:  -3.0587 | Function Loss:  -3.2476\n",
      "Total loss:  -2.1853 | PDE Loss:  -3.0579 | Function Loss:  -3.2478\n",
      "Total loss:  -2.1853 | PDE Loss:  -3.0575 | Function Loss:  -3.2479\n",
      "Total loss:  -2.1855 | PDE Loss:  -3.0564 | Function Loss:  -3.2483\n",
      "Total loss:  -2.1856 | PDE Loss:  -3.0564 | Function Loss:  -3.2484\n",
      "Total loss:  -2.1857 | PDE Loss:  -3.0555 | Function Loss:  -3.2486\n",
      "Total loss:  -2.1857 | PDE Loss:  -3.0559 | Function Loss:  -3.2486\n",
      "Total loss:  -2.1858 | PDE Loss:  -3.0556 | Function Loss:  -3.2487\n",
      "Total loss:  -2.1858 | PDE Loss:  -3.0557 | Function Loss:  -3.2488\n",
      "Total loss:  -2.1859 | PDE Loss:  -3.0556 | Function Loss:  -3.2488\n",
      "Total loss:  -2.1859 | PDE Loss:  -3.0555 | Function Loss:  -3.2489\n",
      "Total loss:  -2.186 | PDE Loss:  -3.0554 | Function Loss:  -3.249\n",
      "Total loss:  -2.186 | PDE Loss:  -3.0553 | Function Loss:  -3.2491\n",
      "Total loss:  -2.1861 | PDE Loss:  -3.0551 | Function Loss:  -3.2491\n",
      "Total loss:  -2.1861 | PDE Loss:  -3.0552 | Function Loss:  -3.2492\n",
      "Total loss:  -2.1862 | PDE Loss:  -3.055 | Function Loss:  -3.2493\n",
      "Total loss:  -2.1863 | PDE Loss:  -3.0553 | Function Loss:  -3.2494\n",
      "Total loss:  -2.1864 | PDE Loss:  -3.0546 | Function Loss:  -3.2496\n",
      "Total loss:  -2.1865 | PDE Loss:  -3.0552 | Function Loss:  -3.2497\n",
      "Total loss:  -2.1866 | PDE Loss:  -3.0531 | Function Loss:  -3.2501\n",
      "Total loss:  -2.1867 | PDE Loss:  -3.0524 | Function Loss:  -3.2503\n",
      "Total loss:  -2.1868 | PDE Loss:  -3.0524 | Function Loss:  -3.2504\n",
      "Total loss:  -2.1868 | PDE Loss:  -3.0519 | Function Loss:  -3.2505\n",
      "Total loss:  -2.1869 | PDE Loss:  -3.0515 | Function Loss:  -3.2506\n",
      "Total loss:  -2.1869 | PDE Loss:  -3.0517 | Function Loss:  -3.2507\n",
      "Total loss:  -2.187 | PDE Loss:  -3.0513 | Function Loss:  -3.2508\n",
      "Total loss:  -2.187 | PDE Loss:  -3.0517 | Function Loss:  -3.2508\n",
      "Total loss:  -2.1871 | PDE Loss:  -3.0519 | Function Loss:  -3.2508\n",
      "Total loss:  -2.1871 | PDE Loss:  -3.0521 | Function Loss:  -3.2508\n",
      "Total loss:  -2.1872 | PDE Loss:  -3.0525 | Function Loss:  -3.2508\n",
      "Total loss:  -2.1872 | PDE Loss:  -3.0529 | Function Loss:  -3.2508\n",
      "Total loss:  -2.1873 | PDE Loss:  -3.0533 | Function Loss:  -3.2508\n",
      "Total loss:  -2.1873 | PDE Loss:  -3.054 | Function Loss:  -3.2507\n",
      "Total loss:  -2.1873 | PDE Loss:  -3.0539 | Function Loss:  -3.2508\n",
      "Total loss:  -2.1874 | PDE Loss:  -3.054 | Function Loss:  -3.2508\n",
      "Total loss:  -2.1874 | PDE Loss:  -3.0541 | Function Loss:  -3.2508\n",
      "Total loss:  -2.1874 | PDE Loss:  -3.0544 | Function Loss:  -3.2508\n",
      "Total loss:  -2.1875 | PDE Loss:  -3.0549 | Function Loss:  -3.2508\n",
      "Total loss:  -2.1875 | PDE Loss:  -3.0559 | Function Loss:  -3.2507\n",
      "Total loss:  -2.1876 | PDE Loss:  -3.057 | Function Loss:  -3.2506\n",
      "Total loss:  -2.1876 | PDE Loss:  -3.059 | Function Loss:  -3.2504\n",
      "Total loss:  -2.1877 | PDE Loss:  -3.0606 | Function Loss:  -3.2502\n",
      "Total loss:  -2.1877 | PDE Loss:  -3.0629 | Function Loss:  -3.2499\n",
      "Total loss:  -2.1878 | PDE Loss:  -3.0631 | Function Loss:  -3.2499\n",
      "Total loss:  -2.1878 | PDE Loss:  -3.0631 | Function Loss:  -3.2499\n",
      "Total loss:  -2.1879 | PDE Loss:  -3.0635 | Function Loss:  -3.2499\n",
      "Total loss:  -2.1879 | PDE Loss:  -3.0639 | Function Loss:  -3.2499\n",
      "Total loss:  -2.1879 | PDE Loss:  -3.0646 | Function Loss:  -3.2498\n",
      "Total loss:  -2.188 | PDE Loss:  -3.0645 | Function Loss:  -3.2499\n",
      "Total loss:  -2.188 | PDE Loss:  -3.0648 | Function Loss:  -3.2499\n",
      "Total loss:  -2.188 | PDE Loss:  -3.0646 | Function Loss:  -3.25\n",
      "Total loss:  -2.1881 | PDE Loss:  -3.0646 | Function Loss:  -3.25\n",
      "Total loss:  -2.1881 | PDE Loss:  -3.0647 | Function Loss:  -3.25\n",
      "Total loss:  -2.1882 | PDE Loss:  -3.0649 | Function Loss:  -3.2501\n",
      "Total loss:  -2.1883 | PDE Loss:  -3.065 | Function Loss:  -3.2501\n",
      "Total loss:  -2.1883 | PDE Loss:  -3.0653 | Function Loss:  -3.2502\n",
      "Total loss:  -2.1885 | PDE Loss:  -3.0658 | Function Loss:  -3.2503\n",
      "Total loss:  -2.1887 | PDE Loss:  -3.0669 | Function Loss:  -3.2503\n",
      "Total loss:  -2.1889 | PDE Loss:  -3.0669 | Function Loss:  -3.2505\n",
      "Total loss:  -2.1891 | PDE Loss:  -3.0685 | Function Loss:  -3.2505\n",
      "Total loss:  -2.1892 | PDE Loss:  -3.0689 | Function Loss:  -3.2506\n",
      "Total loss:  -2.1895 | PDE Loss:  -3.0692 | Function Loss:  -3.251\n",
      "Total loss:  -2.1897 | PDE Loss:  -3.0678 | Function Loss:  -3.2514\n",
      "Total loss:  -2.1899 | PDE Loss:  -3.0674 | Function Loss:  -3.2517\n",
      "Total loss:  -2.19 | PDE Loss:  -3.0673 | Function Loss:  -3.2518\n",
      "Total loss:  -2.1903 | PDE Loss:  -3.0677 | Function Loss:  -3.2521\n",
      "Total loss:  -2.1905 | PDE Loss:  -3.0677 | Function Loss:  -3.2524\n",
      "Total loss:  -2.1907 | PDE Loss:  -3.0691 | Function Loss:  -3.2524\n",
      "Total loss:  -2.1909 | PDE Loss:  -3.0695 | Function Loss:  -3.2525\n",
      "Total loss:  -2.1911 | PDE Loss:  -3.0707 | Function Loss:  -3.2526\n",
      "Total loss:  -2.1914 | PDE Loss:  -3.0717 | Function Loss:  -3.2528\n",
      "Total loss:  -2.1917 | PDE Loss:  -3.0729 | Function Loss:  -3.2529\n",
      "Total loss:  -2.1919 | PDE Loss:  -3.0736 | Function Loss:  -3.253\n",
      "Total loss:  -2.1921 | PDE Loss:  -3.0739 | Function Loss:  -3.2532\n",
      "Total loss:  -2.1923 | PDE Loss:  -3.0735 | Function Loss:  -3.2535\n",
      "Total loss:  -2.1925 | PDE Loss:  -3.0735 | Function Loss:  -3.2538\n",
      "Total loss:  -2.1927 | PDE Loss:  -3.0719 | Function Loss:  -3.2542\n",
      "Total loss:  -2.1929 | PDE Loss:  -3.0712 | Function Loss:  -3.2545\n",
      "Total loss:  -2.193 | PDE Loss:  -3.0714 | Function Loss:  -3.2547\n",
      "Total loss:  -2.1932 | PDE Loss:  -3.0711 | Function Loss:  -3.2549\n",
      "Total loss:  -2.1934 | PDE Loss:  -3.0707 | Function Loss:  -3.2552\n",
      "Total loss:  -2.1937 | PDE Loss:  -3.0705 | Function Loss:  -3.2556\n",
      "Total loss:  -2.1941 | PDE Loss:  -3.0711 | Function Loss:  -3.2559\n",
      "Total loss:  -2.1944 | PDE Loss:  -3.0698 | Function Loss:  -3.2565\n",
      "Total loss:  -2.1947 | PDE Loss:  -3.0712 | Function Loss:  -3.2566\n",
      "Total loss:  -2.1949 | PDE Loss:  -3.0724 | Function Loss:  -3.2567\n",
      "Total loss:  -2.1953 | PDE Loss:  -3.0741 | Function Loss:  -3.2569\n",
      "Total loss:  -2.1956 | PDE Loss:  -3.0758 | Function Loss:  -3.257\n",
      "Total loss:  -2.1959 | PDE Loss:  -3.0759 | Function Loss:  -3.2573\n",
      "Total loss:  -2.1961 | PDE Loss:  -3.0763 | Function Loss:  -3.2575\n",
      "Total loss:  -2.1964 | PDE Loss:  -3.0765 | Function Loss:  -3.2577\n",
      "Total loss:  -2.1966 | PDE Loss:  -3.0758 | Function Loss:  -3.2581\n",
      "Total loss:  -2.1968 | PDE Loss:  -3.0763 | Function Loss:  -3.2583\n",
      "Total loss:  -2.197 | PDE Loss:  -3.0749 | Function Loss:  -3.2588\n",
      "Total loss:  -2.1973 | PDE Loss:  -3.0759 | Function Loss:  -3.2589\n",
      "Total loss:  -2.1977 | PDE Loss:  -3.0767 | Function Loss:  -3.2592\n",
      "Total loss:  -2.1982 | PDE Loss:  -3.0778 | Function Loss:  -3.2597\n",
      "Total loss:  -2.1986 | PDE Loss:  -3.0772 | Function Loss:  -3.2602\n",
      "Total loss:  -2.199 | PDE Loss:  -3.0759 | Function Loss:  -3.2609\n",
      "Total loss:  -2.1993 | PDE Loss:  -3.0756 | Function Loss:  -3.2612\n",
      "Total loss:  -2.1995 | PDE Loss:  -3.0758 | Function Loss:  -3.2615\n",
      "Total loss:  -2.1997 | PDE Loss:  -3.0752 | Function Loss:  -3.2618\n",
      "Total loss:  -2.1999 | PDE Loss:  -3.0775 | Function Loss:  -3.2616\n",
      "Total loss:  -2.2 | PDE Loss:  -3.0777 | Function Loss:  -3.2618\n",
      "Total loss:  -2.2001 | PDE Loss:  -3.0783 | Function Loss:  -3.2618\n",
      "Total loss:  -2.2002 | PDE Loss:  -3.0788 | Function Loss:  -3.2618\n",
      "Total loss:  -2.2003 | PDE Loss:  -3.0798 | Function Loss:  -3.2618\n",
      "Total loss:  -2.2004 | PDE Loss:  -3.0809 | Function Loss:  -3.2618\n",
      "Total loss:  -2.2006 | PDE Loss:  -3.0821 | Function Loss:  -3.2617\n",
      "Total loss:  -2.2007 | PDE Loss:  -3.0831 | Function Loss:  -3.2618\n",
      "Total loss:  -2.2009 | PDE Loss:  -3.0841 | Function Loss:  -3.2618\n",
      "Total loss:  -2.2011 | PDE Loss:  -3.0845 | Function Loss:  -3.262\n",
      "Total loss:  -2.2013 | PDE Loss:  -3.085 | Function Loss:  -3.2621\n",
      "Total loss:  -2.2015 | PDE Loss:  -3.0847 | Function Loss:  -3.2624\n",
      "Total loss:  -2.2017 | PDE Loss:  -3.0839 | Function Loss:  -3.2627\n",
      "Total loss:  -2.2019 | PDE Loss:  -3.0832 | Function Loss:  -3.2631\n",
      "Total loss:  -2.2022 | PDE Loss:  -3.081 | Function Loss:  -3.2637\n",
      "Total loss:  -2.2024 | PDE Loss:  -3.0803 | Function Loss:  -3.2641\n",
      "Total loss:  -2.2027 | PDE Loss:  -3.0777 | Function Loss:  -3.2648\n",
      "Total loss:  -2.2031 | PDE Loss:  -3.0779 | Function Loss:  -3.2652\n",
      "Total loss:  -2.2033 | PDE Loss:  -3.077 | Function Loss:  -3.2657\n",
      "Total loss:  -2.2037 | PDE Loss:  -3.0763 | Function Loss:  -3.2662\n",
      "Total loss:  -2.204 | PDE Loss:  -3.0759 | Function Loss:  -3.2667\n",
      "Total loss:  -2.2042 | PDE Loss:  -3.0752 | Function Loss:  -3.267\n",
      "Total loss:  -2.2044 | PDE Loss:  -3.0751 | Function Loss:  -3.2672\n",
      "Total loss:  -2.2045 | PDE Loss:  -3.075 | Function Loss:  -3.2673\n",
      "Total loss:  -2.2046 | PDE Loss:  -3.0742 | Function Loss:  -3.2676\n",
      "Total loss:  -2.2048 | PDE Loss:  -3.0735 | Function Loss:  -3.2679\n",
      "Total loss:  -2.2049 | PDE Loss:  -3.073 | Function Loss:  -3.2681\n",
      "Total loss:  -2.205 | PDE Loss:  -3.0718 | Function Loss:  -3.2685\n",
      "Total loss:  -2.2052 | PDE Loss:  -3.0715 | Function Loss:  -3.2686\n",
      "Total loss:  -2.2053 | PDE Loss:  -3.0708 | Function Loss:  -3.2689\n",
      "Total loss:  -2.2054 | PDE Loss:  -3.0708 | Function Loss:  -3.2691\n",
      "Total loss:  -2.2055 | PDE Loss:  -3.0712 | Function Loss:  -3.2691\n",
      "Total loss:  -2.2056 | PDE Loss:  -3.0722 | Function Loss:  -3.2691\n",
      "Total loss:  -2.2057 | PDE Loss:  -3.0727 | Function Loss:  -3.2691\n",
      "Total loss:  -2.2058 | PDE Loss:  -3.0735 | Function Loss:  -3.2691\n",
      "Total loss:  -2.2059 | PDE Loss:  -3.0743 | Function Loss:  -3.2691\n",
      "Total loss:  -2.206 | PDE Loss:  -3.0753 | Function Loss:  -3.269\n",
      "Total loss:  -2.2061 | PDE Loss:  -3.0762 | Function Loss:  -3.269\n",
      "Total loss:  -2.2063 | PDE Loss:  -3.0769 | Function Loss:  -3.2691\n",
      "Total loss:  -2.2065 | PDE Loss:  -3.0779 | Function Loss:  -3.2692\n",
      "Total loss:  -2.2068 | PDE Loss:  -3.079 | Function Loss:  -3.2694\n",
      "Total loss:  -2.207 | PDE Loss:  -3.0799 | Function Loss:  -3.2695\n",
      "Total loss:  -2.2072 | PDE Loss:  -3.0809 | Function Loss:  -3.2695\n",
      "Total loss:  -2.2073 | PDE Loss:  -3.0812 | Function Loss:  -3.2696\n",
      "Total loss:  -2.2075 | PDE Loss:  -3.0818 | Function Loss:  -3.2697\n",
      "Total loss:  -2.2076 | PDE Loss:  -3.0826 | Function Loss:  -3.2697\n",
      "Total loss:  -2.2077 | PDE Loss:  -3.0828 | Function Loss:  -3.2699\n",
      "Total loss:  -2.2079 | PDE Loss:  -3.0834 | Function Loss:  -3.27\n",
      "Total loss:  -2.2082 | PDE Loss:  -3.0843 | Function Loss:  -3.2702\n",
      "Total loss:  -2.2084 | PDE Loss:  -3.0857 | Function Loss:  -3.2702\n",
      "Total loss:  -2.2086 | PDE Loss:  -3.086 | Function Loss:  -3.2704\n",
      "Total loss:  -2.2088 | PDE Loss:  -3.0861 | Function Loss:  -3.2706\n",
      "Total loss:  -2.209 | PDE Loss:  -3.0868 | Function Loss:  -3.2707\n",
      "Total loss:  -2.2093 | PDE Loss:  -3.0889 | Function Loss:  -3.2707\n",
      "Total loss:  -2.2095 | PDE Loss:  -3.0908 | Function Loss:  -3.2707\n",
      "Total loss:  -2.2096 | PDE Loss:  -3.092 | Function Loss:  -3.2706\n",
      "Total loss:  -2.2097 | PDE Loss:  -3.0925 | Function Loss:  -3.2706\n",
      "Total loss:  -2.2097 | PDE Loss:  -3.0927 | Function Loss:  -3.2706\n",
      "Total loss:  -2.2097 | PDE Loss:  -3.0929 | Function Loss:  -3.2707\n",
      "Total loss:  -2.2098 | PDE Loss:  -3.0926 | Function Loss:  -3.2708\n",
      "Total loss:  -2.2098 | PDE Loss:  -3.0927 | Function Loss:  -3.2708\n",
      "Total loss:  -2.2099 | PDE Loss:  -3.0929 | Function Loss:  -3.2709\n",
      "Total loss:  -2.21 | PDE Loss:  -3.0931 | Function Loss:  -3.271\n",
      "Total loss:  -2.2101 | PDE Loss:  -3.0936 | Function Loss:  -3.2709\n",
      "Total loss:  -2.2101 | PDE Loss:  -3.0942 | Function Loss:  -3.2709\n",
      "Total loss:  -2.2102 | PDE Loss:  -3.0952 | Function Loss:  -3.2708\n",
      "Total loss:  -2.2102 | PDE Loss:  -3.0964 | Function Loss:  -3.2707\n",
      "Total loss:  -2.2103 | PDE Loss:  -3.0975 | Function Loss:  -3.2706\n",
      "Total loss:  -2.2103 | PDE Loss:  -3.0988 | Function Loss:  -3.2704\n",
      "Total loss:  -2.2103 | PDE Loss:  -3.0998 | Function Loss:  -3.2703\n",
      "Total loss:  -2.2104 | PDE Loss:  -3.1003 | Function Loss:  -3.2703\n",
      "Total loss:  -2.2104 | PDE Loss:  -3.1003 | Function Loss:  -3.2703\n",
      "Total loss:  -2.2104 | PDE Loss:  -3.1001 | Function Loss:  -3.2704\n",
      "Total loss:  -2.2104 | PDE Loss:  -3.0995 | Function Loss:  -3.2705\n",
      "Total loss:  -2.2105 | PDE Loss:  -3.0989 | Function Loss:  -3.2706\n",
      "Total loss:  -2.2105 | PDE Loss:  -3.0981 | Function Loss:  -3.2707\n",
      "Total loss:  -2.2105 | PDE Loss:  -3.0969 | Function Loss:  -3.271\n",
      "Total loss:  -2.2106 | PDE Loss:  -3.0957 | Function Loss:  -3.2712\n",
      "Total loss:  -2.2106 | PDE Loss:  -3.0945 | Function Loss:  -3.2714\n",
      "Total loss:  -2.2106 | PDE Loss:  -3.0934 | Function Loss:  -3.2716\n",
      "Total loss:  -2.2107 | PDE Loss:  -3.0927 | Function Loss:  -3.2718\n",
      "Total loss:  -2.2107 | PDE Loss:  -3.0925 | Function Loss:  -3.2718\n",
      "Total loss:  -2.2107 | PDE Loss:  -3.0923 | Function Loss:  -3.2719\n",
      "Total loss:  -2.2107 | PDE Loss:  -3.0921 | Function Loss:  -3.2719\n",
      "Total loss:  -2.2108 | PDE Loss:  -3.0916 | Function Loss:  -3.2721\n",
      "Total loss:  -2.2108 | PDE Loss:  -3.0913 | Function Loss:  -3.2721\n",
      "Total loss:  -2.2109 | PDE Loss:  -3.0911 | Function Loss:  -3.2722\n",
      "Total loss:  -2.2109 | PDE Loss:  -3.091 | Function Loss:  -3.2723\n",
      "Total loss:  -2.2109 | PDE Loss:  -3.0909 | Function Loss:  -3.2723\n",
      "Total loss:  -2.211 | PDE Loss:  -3.0909 | Function Loss:  -3.2724\n",
      "Total loss:  -2.211 | PDE Loss:  -3.091 | Function Loss:  -3.2724\n",
      "Total loss:  -2.211 | PDE Loss:  -3.091 | Function Loss:  -3.2724\n",
      "Total loss:  -2.2111 | PDE Loss:  -3.0909 | Function Loss:  -3.2725\n",
      "Total loss:  -2.2111 | PDE Loss:  -3.0909 | Function Loss:  -3.2726\n",
      "Total loss:  -2.2112 | PDE Loss:  -3.0905 | Function Loss:  -3.2727\n",
      "Total loss:  -2.2112 | PDE Loss:  -3.0902 | Function Loss:  -3.2728\n",
      "Total loss:  -2.2113 | PDE Loss:  -3.0898 | Function Loss:  -3.2729\n",
      "Total loss:  -2.2113 | PDE Loss:  -3.0894 | Function Loss:  -3.273\n",
      "Total loss:  -2.2113 | PDE Loss:  -3.0891 | Function Loss:  -3.2731\n",
      "Total loss:  -2.2113 | PDE Loss:  -3.0889 | Function Loss:  -3.2731\n",
      "Total loss:  -2.2113 | PDE Loss:  -3.0891 | Function Loss:  -3.2731\n",
      "Total loss:  -2.2113 | PDE Loss:  -3.0891 | Function Loss:  -3.2731\n",
      "Total loss:  -2.2113 | PDE Loss:  -3.0891 | Function Loss:  -3.2731\n",
      "Total loss:  -2.2113 | PDE Loss:  -3.0891 | Function Loss:  -3.2731\n",
      "Total loss:  -2.2113 | PDE Loss:  -3.0891 | Function Loss:  -3.2731\n",
      "Total loss:  -2.2114 | PDE Loss:  -3.0888 | Function Loss:  -3.2731\n",
      "Total loss:  -2.2114 | PDE Loss:  -3.0887 | Function Loss:  -3.2732\n",
      "Total loss:  -2.2114 | PDE Loss:  -3.0885 | Function Loss:  -3.2733\n",
      "Total loss:  -2.2115 | PDE Loss:  -3.0885 | Function Loss:  -3.2733\n",
      "Total loss:  -2.2115 | PDE Loss:  -3.0886 | Function Loss:  -3.2734\n",
      "Total loss:  -2.2116 | PDE Loss:  -3.0889 | Function Loss:  -3.2734\n",
      "Total loss:  -2.2117 | PDE Loss:  -3.0893 | Function Loss:  -3.2735\n",
      "Total loss:  -2.2118 | PDE Loss:  -3.0902 | Function Loss:  -3.2734\n",
      "Total loss:  -2.2119 | PDE Loss:  -3.091 | Function Loss:  -3.2734\n",
      "Total loss:  -2.212 | PDE Loss:  -3.0919 | Function Loss:  -3.2734\n",
      "Total loss:  -2.2121 | PDE Loss:  -3.0925 | Function Loss:  -3.2734\n",
      "Total loss:  -2.2122 | PDE Loss:  -3.0923 | Function Loss:  -3.2735\n",
      "Total loss:  -2.2122 | PDE Loss:  -3.0921 | Function Loss:  -3.2736\n",
      "Total loss:  -2.2123 | PDE Loss:  -3.0915 | Function Loss:  -3.2738\n",
      "Total loss:  -2.2123 | PDE Loss:  -3.0905 | Function Loss:  -3.274\n",
      "Total loss:  -2.2124 | PDE Loss:  -3.0894 | Function Loss:  -3.2742\n",
      "Total loss:  -2.2125 | PDE Loss:  -3.0883 | Function Loss:  -3.2745\n",
      "Total loss:  -2.2125 | PDE Loss:  -3.0875 | Function Loss:  -3.2747\n",
      "Total loss:  -2.2125 | PDE Loss:  -3.087 | Function Loss:  -3.2748\n",
      "Total loss:  -2.2126 | PDE Loss:  -3.0864 | Function Loss:  -3.2749\n",
      "Total loss:  -2.2127 | PDE Loss:  -3.0865 | Function Loss:  -3.275\n",
      "Total loss:  -2.2127 | PDE Loss:  -3.0866 | Function Loss:  -3.275\n",
      "Total loss:  -2.2128 | PDE Loss:  -3.0875 | Function Loss:  -3.275\n",
      "Total loss:  -2.2129 | PDE Loss:  -3.0891 | Function Loss:  -3.2749\n",
      "Total loss:  -2.213 | PDE Loss:  -3.0918 | Function Loss:  -3.2746\n",
      "Total loss:  -2.2132 | PDE Loss:  -3.0935 | Function Loss:  -3.2745\n",
      "Total loss:  -2.2133 | PDE Loss:  -3.0955 | Function Loss:  -3.2743\n",
      "Total loss:  -2.2134 | PDE Loss:  -3.0974 | Function Loss:  -3.2742\n",
      "Total loss:  -2.2135 | PDE Loss:  -3.0987 | Function Loss:  -3.2741\n",
      "Total loss:  -2.2135 | PDE Loss:  -3.0989 | Function Loss:  -3.2741\n",
      "Total loss:  -2.2135 | PDE Loss:  -3.0994 | Function Loss:  -3.2741\n",
      "Total loss:  -2.2136 | PDE Loss:  -3.0999 | Function Loss:  -3.2741\n",
      "Total loss:  -2.2137 | PDE Loss:  -3.1007 | Function Loss:  -3.274\n",
      "Total loss:  -2.2137 | PDE Loss:  -3.101 | Function Loss:  -3.2741\n",
      "Total loss:  -2.2138 | PDE Loss:  -3.1013 | Function Loss:  -3.274\n",
      "Total loss:  -2.2138 | PDE Loss:  -3.1015 | Function Loss:  -3.2741\n",
      "Total loss:  -2.2139 | PDE Loss:  -3.102 | Function Loss:  -3.2741\n",
      "Total loss:  -2.2139 | PDE Loss:  -3.1023 | Function Loss:  -3.274\n",
      "Total loss:  -2.214 | PDE Loss:  -3.1033 | Function Loss:  -3.274\n",
      "Total loss:  -2.214 | PDE Loss:  -3.1035 | Function Loss:  -3.274\n",
      "Total loss:  -2.2141 | PDE Loss:  -3.1044 | Function Loss:  -3.274\n",
      "Total loss:  -2.2141 | PDE Loss:  -3.1047 | Function Loss:  -3.274\n",
      "Total loss:  -2.2142 | PDE Loss:  -3.1054 | Function Loss:  -3.2739\n",
      "Total loss:  -2.2143 | PDE Loss:  -3.106 | Function Loss:  -3.2739\n",
      "Total loss:  -2.2143 | PDE Loss:  -3.107 | Function Loss:  -3.2738\n",
      "Total loss:  -2.2143 | PDE Loss:  -3.1073 | Function Loss:  -3.2738\n",
      "Total loss:  -2.2143 | PDE Loss:  -3.1076 | Function Loss:  -3.2737\n",
      "Total loss:  -2.2143 | PDE Loss:  -3.108 | Function Loss:  -3.2737\n",
      "Total loss:  -2.2144 | PDE Loss:  -3.1083 | Function Loss:  -3.2737\n",
      "Total loss:  -2.2144 | PDE Loss:  -3.1087 | Function Loss:  -3.2737\n",
      "Total loss:  -2.2144 | PDE Loss:  -3.1095 | Function Loss:  -3.2736\n",
      "Total loss:  -2.2145 | PDE Loss:  -3.1103 | Function Loss:  -3.2735\n",
      "Total loss:  -2.2145 | PDE Loss:  -3.1112 | Function Loss:  -3.2734\n",
      "Total loss:  -2.2145 | PDE Loss:  -3.1118 | Function Loss:  -3.2734\n",
      "Total loss:  -2.2146 | PDE Loss:  -3.1122 | Function Loss:  -3.2733\n",
      "Total loss:  -2.2146 | PDE Loss:  -3.1126 | Function Loss:  -3.2733\n",
      "Total loss:  -2.2146 | PDE Loss:  -3.1129 | Function Loss:  -3.2733\n",
      "Total loss:  -2.2146 | PDE Loss:  -3.1127 | Function Loss:  -3.2733\n",
      "Total loss:  -2.2146 | PDE Loss:  -3.1127 | Function Loss:  -3.2733\n",
      "Total loss:  -2.2146 | PDE Loss:  -3.1127 | Function Loss:  -3.2733\n",
      "Total loss:  -2.2146 | PDE Loss:  -3.1127 | Function Loss:  -3.2733\n",
      "Total loss:  -2.2146 | PDE Loss:  -3.1127 | Function Loss:  -3.2733\n",
      "Total loss:  -2.2146 | PDE Loss:  -3.1131 | Function Loss:  -3.2732\n",
      "Total loss:  -2.2146 | PDE Loss:  -3.1132 | Function Loss:  -3.2732\n",
      "Total loss:  -2.2146 | PDE Loss:  -3.1137 | Function Loss:  -3.2732\n",
      "Total loss:  -2.2146 | PDE Loss:  -3.114 | Function Loss:  -3.2732\n",
      "Total loss:  -2.2147 | PDE Loss:  -3.1145 | Function Loss:  -3.2732\n",
      "Total loss:  -2.2147 | PDE Loss:  -3.114 | Function Loss:  -3.2733\n",
      "Total loss:  -2.2148 | PDE Loss:  -3.1142 | Function Loss:  -3.2733\n",
      "Total loss:  -2.2148 | PDE Loss:  -3.1146 | Function Loss:  -3.2733\n",
      "Total loss:  -2.2149 | PDE Loss:  -3.1143 | Function Loss:  -3.2734\n",
      "Total loss:  -2.2149 | PDE Loss:  -3.1145 | Function Loss:  -3.2734\n",
      "Total loss:  -2.2149 | PDE Loss:  -3.1142 | Function Loss:  -3.2735\n",
      "Total loss:  -2.2149 | PDE Loss:  -3.114 | Function Loss:  -3.2735\n",
      "Total loss:  -2.2149 | PDE Loss:  -3.1138 | Function Loss:  -3.2736\n",
      "Total loss:  -2.215 | PDE Loss:  -3.1135 | Function Loss:  -3.2736\n",
      "Total loss:  -2.215 | PDE Loss:  -3.1132 | Function Loss:  -3.2737\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 3):\n",
    "    t0 = i\n",
    "    tf = i+1\n",
    "\n",
    "    old_pinn = pins_phases[-1]\n",
    "    new_pinn = PinnLaterPhase(n_int, n_sb, n_tb, t0, tf, old_pinn, **kwargs)\n",
    "    hist = new_pinn.fit(num_epochs=1, max_iter=5000, verbose=True)\n",
    "    pins_phases.append(new_pinn)\n",
    "    torch.save(new_pinn.approximate_solution.state_dict(), f'saved_models/pinn_{t0}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3, 8):\n",
    "    t0 = i\n",
    "    tf = i+1\n",
    "\n",
    "    old_pinn = pins_phases[-1]\n",
    "    new_pinn = PinnLaterPhase(n_int, n_sb, n_tb, t0, tf, old_pinn, **kwargs)\n",
    "    print(f'##############################  Phase {t0}  ##############################')\n",
    "    hist = new_pinn.fit(num_epochs=1, max_iter=5000, verbose=False)\n",
    "    pins_phases.append(new_pinn)\n",
    "    torch.save(new_pinn.approximate_solution.state_dict(), f'saved_models/pinn_{t0}.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
