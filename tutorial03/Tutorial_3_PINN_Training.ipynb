{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u_j73SUfQxG",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Physics Informed Neural Networks to Approximate Solution of PDEs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOPdRWmOfQxI",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from pinn import NNAnsatz, PINNTrainer\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "kM0O07h0fQxJ",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Basic theory and problem setup\n",
        "Consider the one-dimensional heat equation:\n",
        "\n",
        "$$\n",
        "u_t(t, x) = u_{xx}(t, x), \\quad t\\in[0,T], ~x\\in [-1,1]\n",
        "$$\n",
        "\n",
        "\n",
        "with zero Dirichlet boundary conditions\n",
        "\n",
        "$$\n",
        "u_b(t, -1)=u_b(t,1)=0,\n",
        "$$\n",
        "\n",
        "and initial condition\n",
        "\n",
        "$$\n",
        "u(x, 0) = u_0(x) = - \\sin(\\pi x)\n",
        "$$\n",
        "\n",
        "We want to obtain an approximate solution of the heat equation $u : [0,T]\\times[-1,1] \\mapsto \\mathbb{R}$ with physics informed neural networks (PINNs).\n",
        "\n",
        "To do so, we approximate the underlying solution with a feedforward dense neural network with tunable parameters $\\theta$:\n",
        "\n",
        "$$\n",
        "u_\\theta(t,x) \\approx u(t,x)\n",
        "$$\n",
        "Define the following residuals:\n",
        "\n",
        "   - Interior residual given by,\n",
        "\n",
        "   $$r_{int,\\theta}(t, x):=  u_{\\theta, t}(x,t) - u_{\\theta, xx}(x,t), \\quad \\forall ~t \\in [0,T],~ x \\in [-1,1].$$\n",
        "   \n",
        "        \n",
        "      \n",
        "        \n",
        "   - Spatial boundary residual given by,\n",
        "   \n",
        "        $$r_{sb,\\theta}(t,-1):= u_{\\theta}(t,-1)- u_b(t,-1), \\quad r_{sb,\\theta}(t,1):= u_{\\theta}(t,1)- u_b(t,1), \\quad \\forall t \\in (0,T].$$\n",
        "        \n",
        "   - Temporal boundary residual given by,\n",
        "   \n",
        "        $$r_{tb,\\theta}(x):= u_{\\theta}(x,0) - u_0(x), \\quad \\forall x \\in [-1,1].$$\n",
        "\n",
        "and compute the corresponding loss functions:\n",
        "\n",
        "$$\n",
        "L_{int}(\\theta) = \\int_{[0,T]\\times[-1,1]}r_{int,\\theta}^2(t, x) dtdx, \\quad\n",
        "L_{sb}(\\theta) = \\int_{[0,T]}r_{sb,\\theta}^2(t,-1) dt + \\int_{[0,T]}r_{sb,\\theta}^2(t,1)dt, \\quad\n",
        "L_{tb}(\\theta) = \\int_{[-1,1]}r_{tb,\\theta}^2(x) dx\n",
        "$$\n",
        "\n",
        "The loss functions include integrals that can be approximated by suitable quadrature rule. We use quasi Monte-Carlo and accordingly define the following training sets\n",
        "\n",
        "$$\n",
        "S_{int} =\\{y_n\\}, \\quad 1 \\leq n \\leq N_{int},\\quad y_n = (x,t)_n \\in D_T,\n",
        "$$\n",
        "\n",
        "$$\n",
        "S_{sb, -1} =\\{t_n, u_b(t_n,-1) \\}, \\quad1 \\leq n \\leq N_{sb}, t_n \\in [0,T],\n",
        "$$\n",
        "\n",
        "$$\n",
        "S_{sb, 1} =\\{t_n, u_b(t_n,1) \\}, \\quad1 \\leq n \\leq N_{sb}, t_n \\in [0,T],\n",
        "$$\n",
        "\n",
        "$$\n",
        "S_{tb}=\\{x_n, u_0(x_n)\\}\\quad  1 \\leq n \\leq N_{tb}, x_n \\in [-1,1].\n",
        "$$\n",
        "\n",
        "with the training inputs points corresponding to low-discrepancy Sobol sequences.\n",
        "\n",
        "$$\n",
        "L_{int}(\\theta) = \\frac{1}{N_{int}}\\sum_{i=1}^{N_{int}}r_{int,\\theta}^2(y_n), \\quad\n",
        "L_{sb}(\\theta) = \\frac{1}{N_{sb}}\\sum_{i=1}^{N_{sb}}r_{sb,\\theta}^2(t_n,-1) + \\frac{1}{N_{sb}}\\sum_{i=1}^{N_{sb}}r_{sb,\\theta}^2(t_n,1), \\quad\n",
        "L_{tb}(\\theta) = \\frac{1}{N_{tb}}\\sum_{i=1}^{N_{tb}}r_{tb,\\theta}^2(x_n)\n",
        "$$\n",
        "\n",
        "and solve the following minimization problem\n",
        "\n",
        "$$\n",
        "\\theta^\\ast = argmin_{\\theta} \\Big(L_{int}(\\theta) + \\lambda_u L_u(\\theta)\\Big)\n",
        "$$\n",
        "\n",
        "with\n",
        "\n",
        "$$\n",
        "L_u(\\theta) = L_{tb}(\\theta) + L_{sb}(\\theta)\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KRlLw7VXn-6"
      },
      "source": [
        "# Your task: Solve the $1D$ heat equation using PINNs\n",
        "\n",
        "You will have to implement the following\n",
        "\n",
        "*  `NNAnsatz` a neural net approximator for the solution of the heat equation.\n",
        "*   Missing functionality in the `PINNTrainer`, namely:\n",
        "    *   `PINNTrainer.compute_pde_residual` to compute the PDE loss on your predictions.\n",
        "    *   `PINNTrainer.compute_loss` to aggregate all the residuals into a single weighted loss.\n",
        "\n",
        "Use `torch.autograd.grad` to compute gradients, second derivatives -- some basic examples can be found [here](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html). Make sure the gradients you compute are attached to the computational graph so that you can backpropagate through them.\n",
        "\n",
        "\n",
        "Follow the `TODOs`.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGxg0CzIZBw7"
      },
      "source": [
        "# Setting up the training data\n",
        "\n",
        "Just familiarize yourself with how wo generate collocation points for the different types of residuals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3ug4ztBfQxM",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Solve the heat equation:\n",
        "# u_t = u_xx, (t,x) in [0, 0.1]x[-1,1]\n",
        "# with zero dirichlet BC and\n",
        "# u(x,0)= -sin(pi * x).\n",
        "\n",
        "n_int = 256\n",
        "n_sb = 64\n",
        "n_tb = 64\n",
        "\n",
        "pinn = PINNTrainer(n_int, n_sb, n_tb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "l4gxwi51fQxM",
        "outputId": "18ccac3a-90ea-46a4-a5b8-f3f6989740d7",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Plot the input training points.\n",
        "input_sb_, output_sb_ = pinn.add_spatial_boundary_points()\n",
        "input_tb_, output_tb_ = pinn.add_temporal_boundary_points()\n",
        "input_int_, output_int_ = pinn.add_interior_points()\n",
        "\n",
        "plt.scatter(\n",
        "    input_sb_[:, 1].detach().numpy(),\n",
        "    input_sb_[:, 0].detach().numpy(),\n",
        "    label=\"Boundary Points\")\n",
        "plt.scatter(\n",
        "    input_int_[:, 1].detach().numpy(),\n",
        "    input_int_[:, 0].detach().numpy(),\n",
        "    label=\"Interior Points\")\n",
        "plt.scatter(\n",
        "    input_tb_[:, 1].detach().numpy(),\n",
        "    input_tb_[:, 0].detach().numpy(),\n",
        "    label=\"Initial Points\")\n",
        "\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"t\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAyqnKQxZTTy"
      },
      "source": [
        "# Training\n",
        "\n",
        "Train your network and ensure your loss is low, and that your predictions are qualitatively similar to the true solution (plots should look similar)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qub-M5jqfQxN",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "hist = pinn.fit(num_epochs=1, verbose=True)\n",
        "\n",
        "plt.figure(dpi=150)\n",
        "plt.grid(True, which=\"both\", ls=\":\")\n",
        "plt.plot(np.arange(1, len(hist) + 1), hist, label=\"Train Loss\")\n",
        "plt.xscale(\"log\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HG9DQM5fQxN",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "pinn.plot()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
