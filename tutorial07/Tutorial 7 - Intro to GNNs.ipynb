{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"1kYQluqhHtCD"},"source":["# Tutorial 7 - Intro to GNNs"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["from torch_geometric.data import Data\n","import torch"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Kv-G5MZ6HtCH"},"outputs":[],"source":["from trainer import Trainer"]},{"cell_type":"markdown","metadata":{"id":"Rm1Eog5QHtCH"},"source":["## Pytorch Geometric Framework\n","\n","#### Generic Message Passing Scheme\n","Generalizing the convolution operator to irregular domains is typically expressed as a *neighborhood aggregation* or *message passing* scheme.\n","With $\\mathbf{x}^{(k-1)}_i \\in \\mathbb{R}^F$ denoting node features of node $i$ in layer $(k-1)$ and $\\mathbf{e}_{i,j} \\in \\mathbb{R}^D$ denoting (optional) edge features from node $i$ to node $j$, message passing graph neural networks can be described as\n","\n","$$\n","  \\mathbf{x}_i^{(k)} = \\gamma^{(k)} \\left( \\mathbf{x}_i^{(k-1)}, \\square_{j \\in \\mathcal{N}(i)} \\, \\phi^{(k)}\\left(\\mathbf{x}_i^{(k-1)}, \\mathbf{x}_j^{(k-1)},\\mathbf{e}_{i,j}\\right) \\right)\n","$$\n","\n","where $\\square$ denotes a differentiable, permutation invariant function, *e.g.*, sum, mean or max, and $\\gamma$ and $\\phi$ denote differentiable functions such as MLPs (Multi Layer Perceptrons).\n","\n","#### Graph data representations in PyG\n","Given a *sparse* **Graph** $\\mathcal{G}=(\\mathbf{X}, (\\mathbf{I}, \\mathbf{E}))$ with **node features** $\\mathbf{X} \\in \\mathbb{R}^{|V| \\times F}$, **edge indices $\\mathbf{I} \\in \\{1, \\cdots, N\\}^{2 \\times |\\mathcal{E}|}$**, (optional) **edge features** $\\mathbf{E} \\in \\mathbb{R}^{|\\mathcal{E} \\times D|}$, it is described by an instance of class `torch_geometric.data.Data`, which holds the corresponding attributes.\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["edge_index = torch.tensor([[1, 2, 3], [0, 0, 0]], dtype=torch.long)\n","x = torch.tensor([[1], [1], [1]], dtype=torch.float)\n","data = Data(edge_index=edge_index, x=x)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["Data(x=[3, 1], edge_index=[2, 3])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"markdown","metadata":{"id":"Xu40n_WdHtCI"},"source":["#### Abstract Message Passing Scheme in PyG\n","\n","PyTorch Geometric provides the `torch_geometric.nn.MessagePassing` base class, which helps in creating such kinds of message passing graph neural networks by automatically taking care of message propagation. The implementation is decoupled into **UPDATE**, **AGGREGATION**, **MESSAGE** functions as:\n","$$\n","    \\mathbf{x}_i^{(k)} = \\mathrm{UPDATE} \\left( \\mathbf{x}_i^{(k-1)},  \\mathrm{AGGR}_{j \\in \\mathcal{N}(i)} \\, \\mathrm{MESSAGE}^{(k)}\\left(\\mathbf{x}_i^{(k-1)}, \\mathbf{x}_j^{(k-1)},\\mathbf{e}_{i,j}\\right) \\right)    \n","$$"]},{"cell_type":"markdown","metadata":{"id":"buvcF_ffHtCJ"},"source":["\n","## Implementing GrapSage\n","You are required to implement this algortihm with **MEAN/SUM/MAX** AGGREGATE.\n","The algorithm of GraphSAGE (*Inductive Representation Learning on Large Graphs (NIPS 2017)* embedding generation is described as:"]},{"cell_type":"markdown","metadata":{"id":"f_lv1XPqHtCJ"},"source":["## Vertex Classification\n","\n","The Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary."]},{"cell_type":"markdown","metadata":{"id":"8QD5P-F5HtCL"},"source":["# Train your network"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"9dWVNEQQkki3"},"outputs":[],"source":["aggrs = ['mean', 'add', 'max']\n","\n","runs = 10\n","epochs = 200\n","lr = 0.01\n","weight_decay =  0.01\n","early_stopping = True"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["GraphSAGE-mean\n"]}],"source":["# for aggr in aggrs:\n","aggr = 'mean'\n","trainer = Trainer(aggr)\n","print('GraphSAGE-{}'.format(aggr))"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Val Loss: 1.363447904586792, Test Accuracy: 0.7733999490737915 Â± 0.012527302838861942, Duration: 20.79770278930664\n"]}],"source":["trainer.run(runs, epochs, lr, weight_decay, early_stopping)"]},{"cell_type":"markdown","metadata":{},"source":["## Solution: https://github.com/sw-gong/GNN-Tutorial/blob/master/GNN-tutorial-solution.ipynb"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}
